{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e9cdc6-a4f2-43ff-9d43-cd767484587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import llm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd2fa969-f9fc-4d83-889f-587dd175412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = llm_utils.get_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c83e8a8e-95d6-4e0c-868a-8cc960c774ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.invoke('ä»‹ç»ä½ è‡ªå·±')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08e92847-c5de-47f9-9694-7a6aabe66617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['graph fraud detection',\n",
       " 'graph neural network fraud',\n",
       " 'GNN anti-fraud',\n",
       " 'graph mining fraud detection',\n",
       " 'network analysis fraud',\n",
       " 'knowledge graph fraud',\n",
       " 'heterogeneous graph fraud',\n",
       " 'graph embedding fraud',\n",
       " 'social network fraud detection',\n",
       " 'financial fraud graph',\n",
       " 'anomaly detection graph',\n",
       " 'fraud prevention graph',\n",
       " 'graph algorithms fraud',\n",
       " 'relational learning fraud',\n",
       " 'graph-based anomaly detection']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_utils.run_generate_queries_chain('å›¾åœ¨åæ¬ºè¯ˆé¢†åŸŸçš„ç ”ç©¶',llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1852d82-2c1b-4136-aa9a-59fcac7a5ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['behavior sequence fraud detection', 'user behavior sequence fraud', 'sequential behavior fraud detection', 'temporal sequence fraud detection', 'fraud detection behavioral patterns', 'sequence mining fraud detection', 'RNN fraud detection behavior', 'LSTM fraud detection sequence', 'Transformer fraud detection behavior', 'graph neural network fraud detection behavior', 'anomaly detection behavior sequence', 'financial fraud behavior sequence', 'e-commerce fraud behavior sequence', 'clickstream fraud detection', 'user action sequence fraud']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Dict, List\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.chat_models.base import BaseChatModel\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from mcp_prompts import query_prompt\n",
    "from langchain_core.output_parsers.openai_tools import JsonOutputKeyToolsParser\n",
    "\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆè¯»å– .env æ–‡ä»¶ä¸­çš„ DEEPSEEK_API_KEYï¼‰\n",
    "load_dotenv(override=True)\n",
    "\n",
    "def get_llm(model_name: str = \"deepseek-chat\", model_provider: str = \"deepseek\") -> BaseChatModel:\n",
    "    \"\"\"\n",
    "    åˆå§‹åŒ–ä¸€ä¸ª LLMï¼ˆè¿™é‡Œé»˜è®¤æ˜¯ DeepSeekï¼‰ã€‚\n",
    "    \n",
    "    Args:\n",
    "        model_name: æ¨¡å‹åç§°ï¼Œä¾‹å¦‚ \"deepseek-chat\"\n",
    "        model_provider: æ¨¡å‹æä¾›å•†ï¼Œä¾‹å¦‚ \"deepseek\"\n",
    "    Returns:\n",
    "        å·²åˆå§‹åŒ–çš„ LangChain ChatModel\n",
    "    \"\"\"\n",
    "    return init_chat_model(model=model_name, model_provider=model_provider)\n",
    "\n",
    "\n",
    "import json\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class QueriesListParser(BaseOutputParser):\n",
    "    def parse(self, text: str) -> list[str]:\n",
    "        try:\n",
    "            # ç§»é™¤å¯èƒ½çš„ Markdown åŒ…è£¹\n",
    "            if text.startswith(\"```\") and text.endswith(\"```\"):\n",
    "                text = \"\\n\".join(text.split(\"\\n\")[1:-1])\n",
    "            data = json.loads(text)\n",
    "            queries = data.get(\"queries\", [])\n",
    "            if not isinstance(queries, list):\n",
    "                raise ValueError(f\"'queries' ä¸æ˜¯åˆ—è¡¨: {queries}\")\n",
    "            return queries\n",
    "        except Exception as e:\n",
    "            print(\"è§£æ queries å¤±è´¥:\", e)\n",
    "            print(\"åŸå§‹æ–‡æœ¬:\", text)\n",
    "            return []\n",
    "\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(query_prompt.generate_search_query.content)\n",
    "    \n",
    "# æ„å»ºé“¾å¼è°ƒç”¨\n",
    "parser = QueriesListParser()\n",
    "querry_chain = chat_prompt | llm | parser\n",
    "\n",
    "queries = querry_chain.invoke({\"topic\": \"è¡Œä¸ºåºåˆ—åœ¨åæ¬ºè¯ˆé¢†åŸŸçš„ç ”ç©¶\"})\n",
    "print(queries)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d94c7a0-5a96-4e9e-b22b-26fed7d636d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c21165b-6af7-4255-9175-038f61f13dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "209c910b-db47-40b8-8b06-3e9ba80f2ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fraud detection anomaly', 'anomaly detection fraud', 'financial fraud anomaly', 'credit card fraud anomaly', 'insurance fraud anomaly', 'banking fraud anomaly', 'transaction fraud anomaly', 'network intrusion anomaly', 'cybersecurity fraud anomaly', 'money laundering anomaly', 'outlier detection fraud', 'unsupervised fraud detection', 'semi-supervised fraud detection', 'deep learning fraud detection', 'machine learning fraud detection', 'GAN fraud detection', 'autoencoder fraud detection', 'isolation forest fraud', 'one-class SVM fraud', 'graph neural network fraud', 'time series anomaly fraud', 'real-time fraud detection', 'imbalanced learning fraud', 'fraud pattern recognition', 'behavioral analytics fraud']\n"
     ]
    }
   ],
   "source": [
    "queries = querry_chain.invoke({\"topic\": \"å¼‚å¸¸æ£€æµ‹åœ¨åæ¬ºè¯ˆé¢†åŸŸçš„ç ”ç©¶\"})\n",
    "print(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c374de-ea7d-4cae-bfff-b1d8a14f346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "\n",
    "query = 'fraud detection behavior sequence'\n",
    "\n",
    "print(query)\n",
    "batch_size = 20\n",
    "max_results = 10000  # æ€»å…±æœ€å¤šæŠ“å¤šå°‘ç¯‡\n",
    "save_path = \"arxiv_results.json\"\n",
    "\n",
    "fetched = 0\n",
    "\n",
    "\n",
    "def _process_paper(paper: arxiv.Result) -> Dict[str, Any]:\n",
    "    \"\"\"Process paper information with resource URI.\"\"\"\n",
    "    return {\n",
    "        \"id\": paper.get_short_id(),\n",
    "        \"title\": paper.title,\n",
    "        \"authors\": [author.name for author in paper.authors],\n",
    "        \"abstract\": paper.summary,\n",
    "        \"categories\": paper.categories,\n",
    "        \"published\": paper.published.isoformat(),\n",
    "        \"url\": paper.pdf_url,\n",
    "        \"doi\": paper.doi\n",
    "    }\n",
    "result_meta_data = []\n",
    "# åˆ›å»ºæœç´¢å¯¹è±¡\n",
    "search = arxiv.Search(\n",
    "    query=query,\n",
    "    max_results=max_results,\n",
    "    sort_by=arxiv.SortCriterion.Relevance\n",
    ")\n",
    "\n",
    "client = arxiv.Client(page_size=batch_size, delay_seconds=3)\n",
    "\n",
    "results_iter = client.results(search)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        paper = next(results_iter)\n",
    "        paper_meta_data = _process_paper(paper)\n",
    "        result_meta_data.append(paper_meta_data)\n",
    "        fetched += 1\n",
    "\n",
    "        # æ¯æŠ“ batch_size æ¡å°±å†™å…¥æ–‡ä»¶\n",
    "        if fetched % batch_size == 0:\n",
    "            # with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            #     json.dump([{\"title\": t, \"pdf_url\": u} for t, u in zip(titles, pdf_urls)],\n",
    "            #               f, ensure_ascii=False, indent=2)\n",
    "            # print(f\"âœ… å·²æŠ“å– {fetched} ç¯‡è®ºæ–‡ï¼Œå·²ä¿å­˜åˆ° {save_path}\")\n",
    "            time.sleep(3 + random.random() * 2) # é˜²é™æµ\n",
    "\n",
    "    except StopIteration:\n",
    "        break\n",
    "\n",
    "    except Exception as e:  # æ•è·ç©ºé¡µç­‰æ‰€æœ‰å¼‚å¸¸\n",
    "        print(f\"âš ï¸ é‡åˆ°å¼‚å¸¸: {e}ï¼Œsleep 10ç§’åç»§ç»­...\")\n",
    "        time.sleep(10)\n",
    "\n",
    "# å†™å…¥æœ€ç»ˆç»“æœ\n",
    "# with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump([{\"title\": t, \"pdf_url\": u} for t, u in zip(titles, pdf_urls)],\n",
    "#               f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"ğŸ‰ æŠ“å–å®Œæˆï¼Œæ€»å…± {fetched} ç¯‡è®ºæ–‡\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a868b97c-381c-46df-bd0e-5405530794d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = arxiv.Search(\n",
    "    query='behavior sequence fraud detection', max_results=10)\n",
    "client = arxiv.Client(page_size=200, delay_seconds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b283807b-9bcb-492f-99ff-b7a17065b0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/zhangmin/Documents/3-å¤§æ¨¡å‹/5-é¡¹ç›®/fraud_research_agent/2201.01004v1.Modeling_Users__Behavior_Sequences_with_Hierarchical_Explainable_Network_for_Cross_domain_Fraud_Detection.pdf'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper = next(client.results(arxiv.Search(id_list=['2201.01004v1'])))\n",
    "paper.download_pdf(dirpath='/Users/zhangmin/Documents/3-å¤§æ¨¡å‹/5-é¡¹ç›®/fraud_research_agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c60cc08-872b-4492-a2ba-31f0bd4e63b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Result._from_feed_entry of arxiv.Result(entry_id='http://arxiv.org/abs/2201.01004v1', updated=datetime.datetime(2022, 1, 4, 6, 37, 16, tzinfo=datetime.timezone.utc), published=datetime.datetime(2022, 1, 4, 6, 37, 16, tzinfo=datetime.timezone.utc), title=\"Modeling Users' Behavior Sequences with Hierarchical Explainable Network for Cross-domain Fraud Detection\", authors=[arxiv.Result.Author('Yongchun Zhu'), arxiv.Result.Author('Dongbo Xi'), arxiv.Result.Author('Bowen Song'), arxiv.Result.Author('Fuzhen Zhuang'), arxiv.Result.Author('Shuai Chen'), arxiv.Result.Author('Xi Gu'), arxiv.Result.Author('Qing He')], summary=\"With the explosive growth of the e-commerce industry, detecting online\\ntransaction fraud in real-world applications has become increasingly important\\nto the development of e-commerce platforms. The sequential behavior history of\\nusers provides useful information in differentiating fraudulent payments from\\nregular ones. Recently, some approaches have been proposed to solve this\\nsequence-based fraud detection problem. However, these methods usually suffer\\nfrom two problems: the prediction results are difficult to explain and the\\nexploitation of the internal information of behaviors is insufficient. To\\ntackle the above two problems, we propose a Hierarchical Explainable Network\\n(HEN) to model users' behavior sequences, which could not only improve the\\nperformance of fraud detection but also make the inference process\\ninterpretable. Meanwhile, as e-commerce business expands to new domains, e.g.,\\nnew countries or new markets, one major problem for modeling user behavior in\\nfraud detection systems is the limitation of data collection, e.g., very few\\ndata/labels available. Thus, in this paper, we further propose a transfer\\nframework to tackle the cross-domain fraud detection problem, which aims to\\ntransfer knowledge from existing domains (source domains) with enough and\\nmature data to improve the performance in the new domain (target domain). Our\\nproposed method is a general transfer framework that could not only be applied\\nupon HEN but also various existing models in the Embedding & MLP paradigm.\\nBased on 90 transfer task experiments, we also demonstrate that our transfer\\nframework could not only contribute to the cross-domain fraud detection task\\nwith HEN, but also be universal and expandable for various existing models.\", comment='TheWebConf(WWW) 2020 Main Conference Long Paper', journal_ref=None, doi='10.1145/3366423.3380172', primary_category='cs.LG', categories=['cs.LG', 'cs.AI', 'cs.IR'], links=[arxiv.Result.Link('http://dx.doi.org/10.1145/3366423.3380172', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2201.01004v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2201.01004v1', title='pdf', rel='related', content_type=None)])>\n"
     ]
    }
   ],
   "source": [
    "r = {'entry_id':[],\n",
    "    'updated':[],\n",
    "     'published':[],\n",
    "     'title':[],\n",
    "     'authors':[],\n",
    "     'summary':[],\n",
    "     'comment':[],\n",
    "     'journal_ref':[],\n",
    "     'doi':[],\n",
    "     'primary_category':[],\n",
    "     'categories':[],\n",
    "     'links':[]\n",
    "}\n",
    "\n",
    "for result in client.results(search):\n",
    "    # print(result.entry_id)\n",
    "    # print(result.updated)\n",
    "    # print(result.published.isoformat())\n",
    "    # print(result.title)\n",
    "    # print([author.name for author in result.authors])\n",
    "    # print(result.summary)\n",
    "    # print(result.comment)\n",
    "    # print(result.journal_ref)\n",
    "    # print(result.doi)\n",
    "    # print(result.primary_category)\n",
    "    # print(result.categories)\n",
    "    # print(result.pdf_url)\n",
    "    \n",
    "    # result.download_pdf('/Users/zhangmin/Documents/3-å¤§æ¨¡å‹/5-é¡¹ç›®/fraud_research_agent')\n",
    "    print(result._from_feed_entry)\n",
    "    break\n",
    "    # print(help(result))\n",
    "    # print(result.get_short_id())\n",
    "    # print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd036146-0d27-4685-9a17-5e3207d85939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itertools.islice"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _process_paper(paper: arxiv.Result) -> Dict[str, Any]:\n",
    "    \"\"\"Process paper information with resource URI.\"\"\"\n",
    "    return {\n",
    "        \"id\": paper.get_short_id(),\n",
    "        \"title\": paper.title,\n",
    "        \"authors\": [author.name for author in paper.authors],\n",
    "        \"abstract\": paper.summary,\n",
    "        \"categories\": paper.categories,\n",
    "        \"published\": paper.published.isoformat(),\n",
    "        \"url\": paper.pdf_url,\n",
    "        \"doi\": paper.doi\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0b814c7-50ca-4424-81f5-856191c0b41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¥ æŠ“å–ç¬¬ 0 ~ 2000 ç¯‡...\n",
      "âš ï¸ æ‰¹æ¬¡æŠ“å–å¤±è´¥: Search.__init__() got an unexpected keyword argument 'start'ï¼Œç­‰å¾… 60 ç§’åé‡è¯•...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 67\u001b[0m, in \u001b[0;36mfetch_all\u001b[0;34m(query, total_limit, chunk_size, save_path)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     chunk_results \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     all_results\u001b[38;5;241m.\u001b[39mextend(chunk_results)\n",
      "Cell \u001b[0;32mIn[24], line 34\u001b[0m, in \u001b[0;36mfetch_chunk\u001b[0;34m(query, start, max_results)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"æŠ“å–ä¸€æ‰¹è®ºæ–‡\"\"\"\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m search \u001b[38;5;241m=\u001b[39m \u001b[43marxiv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marxiv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSortCriterion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRelevance\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m client \u001b[38;5;241m=\u001b[39m arxiv\u001b[38;5;241m.\u001b[39mClient(\n\u001b[1;32m     42\u001b[0m     page_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m     43\u001b[0m     delay_seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     44\u001b[0m     num_retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     45\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: Search.__init__() got an unexpected keyword argument 'start'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 93\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mğŸ‰ æŠ“å–å®Œæˆï¼Œæ€»å…± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ç¯‡è®ºæ–‡ï¼Œå·²ä¿å­˜è‡³ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# è¿è¡Œ\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m \u001b[43mfetch_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQUERY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTOTAL_LIMIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCHUNK_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSAVE_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 78\u001b[0m, in \u001b[0;36mfetch_all\u001b[0;34m(query, total_limit, chunk_size, save_path)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâš ï¸ æ‰¹æ¬¡æŠ“å–å¤±è´¥: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mï¼Œç­‰å¾… 60 ç§’åé‡è¯•...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     81\u001b[0m start \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# ===============================\n",
    "# é…ç½®\n",
    "# ===============================\n",
    "QUERY = \"fraud detection behavior sequence\"\n",
    "BATCH_SIZE = 20          # æ¯æ¬¡è¯·æ±‚å¤šå°‘ç¯‡\n",
    "CHUNK_SIZE = 2000        # æ¯æ‰¹æŠ“å¤šå°‘ç¯‡\n",
    "TOTAL_LIMIT = 10000      # æ€»å…±æœ€å¤šæŠ“å¤šå°‘ç¯‡\n",
    "SAVE_PATH = \"arxiv_results.json\"\n",
    "\n",
    "# ===============================\n",
    "# å·¥å…·å‡½æ•°\n",
    "# ===============================\n",
    "def _process_paper(paper: arxiv.Result) -> Dict[str, Any]:\n",
    "    \"\"\"æŠ½å–è®ºæ–‡å…³é”®ä¿¡æ¯\"\"\"\n",
    "    return {\n",
    "        \"id\": paper.get_short_id(),\n",
    "        \"title\": paper.title.strip(),\n",
    "        \"authors\": [author.name for author in paper.authors],\n",
    "        \"abstract\": paper.summary.strip(),\n",
    "        \"categories\": paper.categories,\n",
    "        \"published\": paper.published.isoformat(),\n",
    "        \"url\": paper.pdf_url,\n",
    "        \"doi\": paper.doi\n",
    "    }\n",
    "\n",
    "def fetch_chunk(query: str, start: int, max_results: int) -> List[Dict[str, Any]]:\n",
    "    \"\"\"æŠ“å–ä¸€æ‰¹è®ºæ–‡\"\"\"\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        start=start,\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    client = arxiv.Client(\n",
    "        page_size=BATCH_SIZE,\n",
    "        delay_seconds=3,\n",
    "        num_retries=5\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    for paper in client.results(search):\n",
    "        results.append(_process_paper(paper))\n",
    "        # æ¯ç¯‡éšæœº sleepï¼Œæ¨¡æ‹Ÿæ­£å¸¸ç”¨æˆ·\n",
    "        time.sleep(random.uniform(1.5, 3.5))\n",
    "\n",
    "    return results\n",
    "\n",
    "# ===============================\n",
    "# ä¸»æµç¨‹ï¼šåˆ†æ‰¹æŠ“å– + åˆå¹¶\n",
    "# ===============================\n",
    "def fetch_all(query: str, total_limit: int, chunk_size: int, save_path: str):\n",
    "    all_results = []\n",
    "    start = 0\n",
    "\n",
    "    while start < total_limit:\n",
    "        batch_size = min(chunk_size, total_limit - start)\n",
    "        print(f\"\\nğŸ“¥ æŠ“å–ç¬¬ {start} ~ {start+batch_size} ç¯‡...\")\n",
    "\n",
    "        try:\n",
    "            chunk_results = fetch_chunk(query, start, batch_size)\n",
    "            all_results.extend(chunk_results)\n",
    "\n",
    "            # å¢é‡ä¿å­˜ï¼Œé˜²æ­¢ä¸­é€”å´©æºƒä¸¢æ•°æ®\n",
    "            with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(all_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "            print(f\"âœ… å·²ç´¯è®¡æŠ“å– {len(all_results)} ç¯‡è®ºæ–‡ï¼Œä¿å­˜è‡³ {save_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ æ‰¹æ¬¡æŠ“å–å¤±è´¥: {e}ï¼Œç­‰å¾… 60 ç§’åé‡è¯•...\")\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "\n",
    "        start += batch_size\n",
    "\n",
    "        # æ‰¹æ¬¡ä¹‹é—´ä¹Ÿéšæœº sleepï¼Œè¿›ä¸€æ­¥é˜²æ­¢é™æµ\n",
    "        time.sleep(random.uniform(15, 30))\n",
    "\n",
    "    print(f\"\\nğŸ‰ æŠ“å–å®Œæˆï¼Œæ€»å…± {len(all_results)} ç¯‡è®ºæ–‡ï¼Œå·²ä¿å­˜è‡³ {save_path}\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# è¿è¡Œ\n",
    "# ===============================\n",
    "\n",
    "fetch_all(QUERY, TOTAL_LIMIT, CHUNK_SIZE, SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63390eea-c06c-4789-b686-3397c7f2a9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Client in module arxiv:\n",
      "\n",
      "class Client(builtins.object)\n",
      " |  Client(page_size: 'int' = 100, delay_seconds: 'float' = 3.0, num_retries: 'int' = 3)\n",
      " |  \n",
      " |  Specifies a strategy for fetching results from arXiv's API.\n",
      " |  \n",
      " |  This class obscures pagination and retry logic, and exposes\n",
      " |  `Client.results`.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, page_size: 'int' = 100, delay_seconds: 'float' = 3.0, num_retries: 'int' = 3)\n",
      " |      Constructs an arXiv API client with the specified options.\n",
      " |      \n",
      " |      Note: the default parameters should provide a robust request strategy\n",
      " |      for most use cases. Extreme page sizes, delays, or retries risk\n",
      " |      violating the arXiv [API Terms of Use](https://arxiv.org/help/api/tou),\n",
      " |      brittle behavior, and inconsistent results.\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self) -> 'str'\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  results(self, search: 'Search', offset: 'int' = 0) -> 'Generator[Result, None, None]'\n",
      " |      Uses this client configuration to fetch one page of the search results\n",
      " |      at a time, yielding the parsed `Result`s, until `max_results` results\n",
      " |      have been yielded or there are no more search results.\n",
      " |      \n",
      " |      If all tries fail, raises an `UnexpectedEmptyPageError` or `HTTPError`.\n",
      " |      \n",
      " |      Setting a nonzero `offset` discards leading records in the result set.\n",
      " |      When `offset` is greater than or equal to `search.max_results`, the full\n",
      " |      result set is discarded.\n",
      " |      \n",
      " |      For more on using generators, see\n",
      " |      [Generators](https://wiki.python.org/moin/Generators).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_last_request_dt': 'datetime', '_session': 'reques...\n",
      " |  \n",
      " |  query_url_format = 'https://export.arxiv.org/api/query?{}'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(arxiv.Client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a666ce52-a105-43f9-b61f-d80abd57a495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method results in module arxiv:\n",
      "\n",
      "results(search: 'Search', offset: 'int' = 0) -> 'Generator[Result, None, None]' method of arxiv.Client instance\n",
      "    Uses this client configuration to fetch one page of the search results\n",
      "    at a time, yielding the parsed `Result`s, until `max_results` results\n",
      "    have been yielded or there are no more search results.\n",
      "    \n",
      "    If all tries fail, raises an `UnexpectedEmptyPageError` or `HTTPError`.\n",
      "    \n",
      "    Setting a nonzero `offset` discards leading records in the result set.\n",
      "    When `offset` is greater than or equal to `search.max_results`, the full\n",
      "    result set is discarded.\n",
      "    \n",
      "    For more on using generators, see\n",
      "    [Generators](https://wiki.python.org/moin/Generators).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b5c82a7-5e6c-40f9-a563-9e02ec931616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "âœ… å·²æŠ“å– 100 ç¯‡ (offset=0)\n",
      "ğŸ‰ æŠ“å–å®Œæˆï¼Œæ€»å…± 100 ç¯‡è®ºæ–‡\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "def _process_paper(paper: arxiv.Result) -> Dict[str, Any]:\n",
    "    \"\"\"æ ¼å¼åŒ–è®ºæ–‡ä¿¡æ¯\"\"\"\n",
    "    return {\n",
    "        \"id\": paper.get_short_id(),\n",
    "        \"title\": paper.title,\n",
    "        \"authors\": [author.name for author in paper.authors],\n",
    "        \"abstract\": paper.summary,\n",
    "        \"categories\": paper.categories,\n",
    "        \"published\": paper.published.isoformat(),\n",
    "        \"url\": paper.pdf_url,\n",
    "        \"doi\": paper.doi\n",
    "    }\n",
    "\n",
    "\n",
    "def fetch_arxiv_papers(query: str, batch_size: int = 50, max_results: int = 500):\n",
    "    client = arxiv.Client(page_size=batch_size, delay_seconds=3, num_retries=3)\n",
    "    # client = arxiv.Client()\n",
    "    all_results = []\n",
    "    offset = 0\n",
    "\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,  # âœ… è®¾ç½®ä¸ºæ€»ç›®æ ‡\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            print(offset)\n",
    "            results_iter = client.results(search, offset)\n",
    "            batch = [_process_paper(p) for p in results_iter]\n",
    "\n",
    "            if not batch:\n",
    "                print(f\"âš ï¸ offset={offset} è¿”å›ç©ºé¡µï¼Œå¯èƒ½åˆ°å¤´äº†ï¼Œåœæ­¢æŠ“å–ã€‚\")\n",
    "                break\n",
    "\n",
    "            all_results.extend(batch)\n",
    "            print(f\"âœ… å·²æŠ“å– {len(all_results)} ç¯‡ (offset={offset})\")\n",
    "\n",
    "            offset += batch_size\n",
    "\n",
    "            if len(all_results) >= max_results:\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ æŠ“å–å¤±è´¥: {e}ï¼Œç­‰å¾… 60 ç§’åé‡è¯•...\")\n",
    "            time.sleep(60)\n",
    "\n",
    "    print(f\"ğŸ‰ æŠ“å–å®Œæˆï¼Œæ€»å…± {len(all_results)} ç¯‡è®ºæ–‡\")\n",
    "    return all_results\n",
    "\n",
    "\n",
    "all_results = fetch_arxiv_papers(\"fraud detection behavior sequence\", batch_size=20, max_results=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a86aaac-4c2a-4b55-9c1e-f663acb76eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"fraud detection behavior sequence\"\n",
    "max_results = 1000\n",
    "search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,  # âœ… è®¾ç½®ä¸ºæ€»ç›®æ ‡\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9561b3e-d53c-427b-968e-10b7537de231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Search.results of arxiv.Search(query='fraud detection behavior sequence', id_list=[], max_results=1000, sort_by=<SortCriterion.Relevance: 'relevance'>, sort_order=<SortOrder.Descending: 'descending'>)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6ef18e7-69f9-46ce-ba36-32f2a16c0554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Client in module arxiv:\n",
      "\n",
      "class Client(builtins.object)\n",
      " |  Client(page_size: 'int' = 100, delay_seconds: 'float' = 3.0, num_retries: 'int' = 3)\n",
      " |  \n",
      " |  Specifies a strategy for fetching results from arXiv's API.\n",
      " |  \n",
      " |  This class obscures pagination and retry logic, and exposes\n",
      " |  `Client.results`.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, page_size: 'int' = 100, delay_seconds: 'float' = 3.0, num_retries: 'int' = 3)\n",
      " |      Constructs an arXiv API client with the specified options.\n",
      " |      \n",
      " |      Note: the default parameters should provide a robust request strategy\n",
      " |      for most use cases. Extreme page sizes, delays, or retries risk\n",
      " |      violating the arXiv [API Terms of Use](https://arxiv.org/help/api/tou),\n",
      " |      brittle behavior, and inconsistent results.\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self) -> 'str'\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  results(self, search: 'Search', offset: 'int' = 0) -> 'Generator[Result, None, None]'\n",
      " |      Uses this client configuration to fetch one page of the search results\n",
      " |      at a time, yielding the parsed `Result`s, until `max_results` results\n",
      " |      have been yielded or there are no more search results.\n",
      " |      \n",
      " |      If all tries fail, raises an `UnexpectedEmptyPageError` or `HTTPError`.\n",
      " |      \n",
      " |      Setting a nonzero `offset` discards leading records in the result set.\n",
      " |      When `offset` is greater than or equal to `search.max_results`, the full\n",
      " |      result set is discarded.\n",
      " |      \n",
      " |      For more on using generators, see\n",
      " |      [Generators](https://wiki.python.org/moin/Generators).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_last_request_dt': 'datetime', '_session': 'reques...\n",
      " |  \n",
      " |  query_url_format = 'https://export.arxiv.org/api/query?{}'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(arxiv.Client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e85f0613-74c8-4165-80d0-389f7ebe2035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method results in module arxiv:\n",
      "\n",
      "results(search: 'Search', offset: 'int' = 0) -> 'Generator[Result, None, None]' method of arxiv.Client instance\n",
      "    Uses this client configuration to fetch one page of the search results\n",
      "    at a time, yielding the parsed `Result`s, until `max_results` results\n",
      "    have been yielded or there are no more search results.\n",
      "    \n",
      "    If all tries fail, raises an `UnexpectedEmptyPageError` or `HTTPError`.\n",
      "    \n",
      "    Setting a nonzero `offset` discards leading records in the result set.\n",
      "    When `offset` is greater than or equal to `search.max_results`, the full\n",
      "    result set is discarded.\n",
      "    \n",
      "    For more on using generators, see\n",
      "    [Generators](https://wiki.python.org/moin/Generators).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ab76b7c-fcc9-4a3e-a675-92eff9a13de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "max_results = 100\n",
    "client = arxiv.Client(page_size=batch_size, delay_seconds=3, num_retries=3)\n",
    "search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,  # âœ… è®¾ç½®ä¸ºæ€»ç›®æ ‡\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "results_iter = client.results(search, offset=0)\n",
    "\n",
    "j = 0\n",
    "i_list = []\n",
    "for i in results_iter:\n",
    "    i_list.append(i.get_short_id())\n",
    "    if j%5 ==0:\n",
    "        print(j)\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "273038ab-6390-44d1-9c44-19b4a790dde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‘ç°å·²æœ‰ 205 æ¡è®°å½•ï¼Œå°†ä» offset=205 ç»§ç»­æŠ“å–\n",
      "âœ… å·²æŠ“å– 305 ç¯‡ (offset=305)\n",
      "âœ… å·²æŠ“å– 405 ç¯‡ (offset=405)\n",
      "âœ… å·²æŠ“å– 505 ç¯‡ (offset=505)\n",
      "âœ… å·²æŠ“å– 605 ç¯‡ (offset=605)\n",
      "âœ… å·²æŠ“å– 705 ç¯‡ (offset=705)\n",
      "âœ… å·²æŠ“å– 805 ç¯‡ (offset=805)\n",
      "âš ï¸ offset=805 è¿”å›ç©ºé¡µï¼Œç­‰å¾… 60 ç§’åé‡è¯•...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 78\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_results\n\u001b[1;32m     77\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfraud detection behavior sequence\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 78\u001b[0m papers \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_arxiv_papers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[68], line 55\u001b[0m, in \u001b[0;36mfetch_arxiv_papers\u001b[0;34m(query, batch_size, max_results, output_file)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batch:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâš ï¸ offset=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moffset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m è¿”å›ç©ºé¡µï¼Œç­‰å¾… 60 ç§’åé‡è¯•...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     58\u001b[0m all_results\u001b[38;5;241m.\u001b[39mextend(batch)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "def fetch_arxiv_papers(query, batch_size=50, max_results=1000, output_file=\"arxiv_results.json\"):\n",
    "    \"\"\"\n",
    "    åˆ†æ‰¹æŠ“å– arXiv è®ºæ–‡ï¼Œè‡ªåŠ¨ä¿å­˜ JSON\n",
    "    \"\"\"\n",
    "    # åˆå§‹åŒ–å®¢æˆ·ç«¯å’Œæœç´¢\n",
    "    client = arxiv.Client(page_size=batch_size, delay_seconds=3, num_retries=3)\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    # å¦‚æœå·²æœ‰æ–‡ä»¶ï¼Œå…ˆè¯»å–å·²æœ‰æ•°æ®\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            all_results = json.load(f)\n",
    "        start_offset = len(all_results)\n",
    "        print(f\"å‘ç°å·²æœ‰ {start_offset} æ¡è®°å½•ï¼Œå°†ä» offset={start_offset} ç»§ç»­æŠ“å–\")\n",
    "    else:\n",
    "        start_offset = 0\n",
    "\n",
    "    offset = start_offset\n",
    "    while offset < max_results:\n",
    "        try:\n",
    "            results_iter = client.results(search, offset=offset)\n",
    "            batch = []\n",
    "            for j, result in enumerate(results_iter, 1):\n",
    "                paper = {\n",
    "                    \"id\": result.get_short_id(),\n",
    "                    \"title\": result.title,\n",
    "                    \"authors\": [a.name for a in result.authors],\n",
    "                    \"summary\": result.summary,\n",
    "                    \"published\": result.published.strftime(\"%Y-%m-%d\"),\n",
    "                    \"updated\": result.updated.strftime(\"%Y-%m-%d\"),\n",
    "                    \"primary_category\": result.primary_category,\n",
    "                    \"categories\": result.categories,\n",
    "                    \"pdf_url\": result.pdf_url\n",
    "                }\n",
    "                batch.append(paper)\n",
    "\n",
    "                # æ¯ batch_size æ¡å¤„ç†ä¸€æ¬¡\n",
    "                if j % batch_size == 0:\n",
    "                    time.sleep(3 + random.random() * 2)\n",
    "                    break\n",
    "\n",
    "            if not batch:\n",
    "                print(f\"âš ï¸ offset={offset} è¿”å›ç©ºé¡µï¼Œç­‰å¾… 60 ç§’åé‡è¯•...\")\n",
    "                time.sleep(60)\n",
    "                continue\n",
    "\n",
    "            all_results.extend(batch)\n",
    "            offset += len(batch)\n",
    "\n",
    "            # ä¿å­˜åˆ° JSON\n",
    "            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(all_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "            print(f\"âœ… å·²æŠ“å– {len(all_results)} ç¯‡ (offset={offset})\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ æŠ“å–å¤±è´¥: {e}, ç­‰å¾… 60 ç§’åé‡è¯•...\")\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "\n",
    "    print(f\"ğŸ‰ æŠ“å–å®Œæˆï¼Œæ€»å…± {len(all_results)} ç¯‡è®ºæ–‡ï¼Œå·²ä¿å­˜åˆ° {output_file}\")\n",
    "    return all_results\n",
    "\n",
    "\n",
    "\n",
    "query = \"fraud detection behavior sequence\"\n",
    "papers = fetch_arxiv_papers(query, batch_size=100, max_results=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "64453415-e1a2-418b-b4ff-6f716387722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2000-01-01 -> 2000-01-31\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2000-01-31 -> 2000-03-01\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2000-03-01 -> 2000-03-31\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2000-03-31 -> 2000-04-30\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2000-04-30 -> 2000-05-30\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2000-05-30 -> 2000-06-29\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2000-06-29 -> 2000-07-29\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2000-07-29 -> 2000-08-28\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2000-08-28 -> 2000-09-27\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2000-09-27 -> 2000-10-27\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2000-10-27 -> 2000-11-26\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2000-11-26 -> 2000-12-26\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2000-12-26 -> 2001-01-25\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2001-01-25 -> 2001-02-24\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2001-02-24 -> 2001-03-26\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2001-03-26 -> 2001-04-25\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2001-04-25 -> 2001-05-25\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2001-05-25 -> 2001-06-24\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2001-06-24 -> 2001-07-24\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2001-07-24 -> 2001-08-23\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2001-08-23 -> 2001-09-22\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2001-09-22 -> 2001-10-22\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2001-10-22 -> 2001-11-21\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2001-11-21 -> 2001-12-21\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2001-12-21 -> 2002-01-20\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2002-01-20 -> 2002-02-19\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2002-02-19 -> 2002-03-21\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2002-03-21 -> 2002-04-20\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2002-04-20 -> 2002-05-20\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2002-05-20 -> 2002-06-19\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2002-06-19 -> 2002-07-19\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2002-07-19 -> 2002-08-18\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2002-08-18 -> 2002-09-17\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2002-09-17 -> 2002-10-17\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2002-10-17 -> 2002-11-16\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2002-11-16 -> 2002-12-16\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2002-12-16 -> 2003-01-15\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2003-01-15 -> 2003-02-14\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2003-02-14 -> 2003-03-16\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2003-03-16 -> 2003-04-15\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2003-04-15 -> 2003-05-15\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2003-05-15 -> 2003-06-14\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2003-06-14 -> 2003-07-14\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2003-07-14 -> 2003-08-13\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2003-08-13 -> 2003-09-12\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2003-09-12 -> 2003-10-12\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2003-10-12 -> 2003-11-11\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2003-11-11 -> 2003-12-11\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2003-12-11 -> 2004-01-10\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2004-01-10 -> 2004-02-09\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2004-02-09 -> 2004-03-10\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2004-03-10 -> 2004-04-09\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2004-04-09 -> 2004-05-09\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2004-05-09 -> 2004-06-08\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2004-06-08 -> 2004-07-08\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2004-07-08 -> 2004-08-07\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2004-08-07 -> 2004-09-06\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2004-09-06 -> 2004-10-06\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2004-10-06 -> 2004-11-05\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2004-11-05 -> 2004-12-05\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2004-12-05 -> 2005-01-04\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2005-01-04 -> 2005-02-03\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2005-02-03 -> 2005-03-05\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2005-03-05 -> 2005-04-04\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2005-04-04 -> 2005-05-04\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2005-05-04 -> 2005-06-03\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2005-06-03 -> 2005-07-03\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2005-07-03 -> 2005-08-02\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2005-08-02 -> 2005-09-01\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2005-09-01 -> 2005-10-01\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2005-10-01 -> 2005-10-31\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2005-10-31 -> 2005-11-30\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2005-11-30 -> 2005-12-30\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2005-12-30 -> 2006-01-29\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2006-01-29 -> 2006-02-28\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2006-02-28 -> 2006-03-30\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2006-03-30 -> 2006-04-29\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2006-04-29 -> 2006-05-29\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2006-05-29 -> 2006-06-28\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2006-06-28 -> 2006-07-28\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2006-07-28 -> 2006-08-27\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2006-08-27 -> 2006-09-26\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2006-09-26 -> 2006-10-26\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2006-10-26 -> 2006-11-25\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2006-11-25 -> 2006-12-25\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2006-12-25 -> 2007-01-24\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2007-01-24 -> 2007-02-23\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2007-02-23 -> 2007-03-25\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2007-03-25 -> 2007-04-24\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2007-04-24 -> 2007-05-24\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2007-05-24 -> 2007-06-23\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2007-06-23 -> 2007-07-23\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2007-07-23 -> 2007-08-22\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2007-08-22 -> 2007-09-21\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2007-09-21 -> 2007-10-21\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2007-10-21 -> 2007-11-20\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2007-11-20 -> 2007-12-20\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2007-12-20 -> 2008-01-19\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2008-01-19 -> 2008-02-18\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2008-02-18 -> 2008-03-19\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2008-03-19 -> 2008-04-18\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2008-04-18 -> 2008-05-18\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2008-05-18 -> 2008-06-17\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2008-06-17 -> 2008-07-17\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2008-07-17 -> 2008-08-16\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2008-08-16 -> 2008-09-15\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2008-09-15 -> 2008-10-15\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2008-10-15 -> 2008-11-14\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2008-11-14 -> 2008-12-14\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2008-12-14 -> 2009-01-13\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2009-01-13 -> 2009-02-12\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2009-02-12 -> 2009-03-14\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2009-03-14 -> 2009-04-13\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2009-04-13 -> 2009-05-13\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2009-05-13 -> 2009-06-12\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2009-06-12 -> 2009-07-12\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2009-07-12 -> 2009-08-11\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2009-08-11 -> 2009-09-10\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2009-09-10 -> 2009-10-10\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2009-10-10 -> 2009-11-09\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2009-11-09 -> 2009-12-09\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2009-12-09 -> 2010-01-08\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2010-01-08 -> 2010-02-07\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2010-02-07 -> 2010-03-09\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2010-03-09 -> 2010-04-08\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2010-04-08 -> 2010-05-08\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2010-05-08 -> 2010-06-07\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2010-06-07 -> 2010-07-07\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2010-07-07 -> 2010-08-06\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2010-08-06 -> 2010-09-05\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2010-09-05 -> 2010-10-05\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2010-10-05 -> 2010-11-04\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2010-11-04 -> 2010-12-04\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2010-12-04 -> 2011-01-03\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2011-01-03 -> 2011-02-02\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2011-02-02 -> 2011-03-04\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2011-03-04 -> 2011-04-03\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2011-04-03 -> 2011-05-03\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2011-05-03 -> 2011-06-02\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2011-06-02 -> 2011-07-02\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2011-07-02 -> 2011-08-01\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2011-08-01 -> 2011-08-31\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2011-08-31 -> 2011-09-30\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2011-09-30 -> 2011-10-30\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2011-10-30 -> 2011-11-29\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2011-11-29 -> 2011-12-29\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2011-12-29 -> 2012-01-28\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2012-01-28 -> 2012-02-27\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2012-02-27 -> 2012-03-28\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2012-03-28 -> 2012-04-27\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2012-04-27 -> 2012-05-27\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2012-05-27 -> 2012-06-26\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2012-06-26 -> 2012-07-26\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2012-07-26 -> 2012-08-25\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2012-08-25 -> 2012-09-24\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2012-09-24 -> 2012-10-24\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2012-10-24 -> 2012-11-23\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2012-11-23 -> 2012-12-23\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2012-12-23 -> 2013-01-22\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2013-01-22 -> 2013-02-21\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2013-02-21 -> 2013-03-23\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2013-03-23 -> 2013-04-22\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2013-04-22 -> 2013-05-22\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2013-05-22 -> 2013-06-21\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2013-06-21 -> 2013-07-21\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2013-07-21 -> 2013-08-20\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2013-08-20 -> 2013-09-19\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2013-09-19 -> 2013-10-19\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2013-10-19 -> 2013-11-18\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2013-11-18 -> 2013-12-18\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2013-12-18 -> 2014-01-17\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2014-01-17 -> 2014-02-16\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2014-02-16 -> 2014-03-18\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2014-03-18 -> 2014-04-17\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2014-04-17 -> 2014-05-17\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2014-05-17 -> 2014-06-16\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2014-06-16 -> 2014-07-16\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2014-07-16 -> 2014-08-15\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2014-08-15 -> 2014-09-14\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2014-09-14 -> 2014-10-14\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2014-10-14 -> 2014-11-13\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2014-11-13 -> 2014-12-13\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2014-12-13 -> 2015-01-12\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2015-01-12 -> 2015-02-11\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2015-02-11 -> 2015-03-13\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2015-03-13 -> 2015-04-12\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2015-04-12 -> 2015-05-12\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2015-05-12 -> 2015-06-11\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2015-06-11 -> 2015-07-11\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2015-07-11 -> 2015-08-10\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2015-08-10 -> 2015-09-09\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2015-09-09 -> 2015-10-09\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2015-10-09 -> 2015-11-08\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2015-11-08 -> 2015-12-08\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2015-12-08 -> 2016-01-07\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2016-01-07 -> 2016-02-06\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2016-02-06 -> 2016-03-07\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2016-03-07 -> 2016-04-06\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2016-04-06 -> 2016-05-06\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2016-05-06 -> 2016-06-05\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2016-06-05 -> 2016-07-05\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2016-07-05 -> 2016-08-04\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2016-08-04 -> 2016-09-03\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2016-09-03 -> 2016-10-03\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2016-10-03 -> 2016-11-02\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2016-11-02 -> 2016-12-02\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2016-12-02 -> 2017-01-01\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2017-01-01 -> 2017-01-31\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2017-01-31 -> 2017-03-02\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2017-03-02 -> 2017-04-01\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2017-04-01 -> 2017-05-01\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2017-05-01 -> 2017-05-31\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2017-05-31 -> 2017-06-30\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2017-06-30 -> 2017-07-30\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2017-07-30 -> 2017-08-29\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2017-08-29 -> 2017-09-28\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2017-09-28 -> 2017-10-28\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2017-10-28 -> 2017-11-27\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2017-11-27 -> 2017-12-27\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2017-12-27 -> 2018-01-26\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2018-01-26 -> 2018-02-25\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2018-02-25 -> 2018-03-27\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2018-03-27 -> 2018-04-26\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2018-04-26 -> 2018-05-26\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2018-05-26 -> 2018-06-25\n",
      "âœ… å·²æŠ“å– 3 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2018-06-25 -> 2018-07-25\n",
      "âœ… å·²æŠ“å– 3 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2018-07-25 -> 2018-08-24\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2018-08-24 -> 2018-09-23\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2018-09-23 -> 2018-10-23\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2018-10-23 -> 2018-11-22\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2018-11-22 -> 2018-12-22\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2018-12-22 -> 2019-01-21\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2019-01-21 -> 2019-02-20\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2019-02-20 -> 2019-03-22\n",
      "âœ… å·²æŠ“å– 4 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2019-03-22 -> 2019-04-21\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2019-04-21 -> 2019-05-21\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2019-05-21 -> 2019-06-20\n",
      "âœ… å·²æŠ“å– 3 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2019-06-20 -> 2019-07-20\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2019-07-20 -> 2019-08-19\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2019-08-19 -> 2019-09-18\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2019-09-18 -> 2019-10-18\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2019-10-18 -> 2019-11-17\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2019-11-17 -> 2019-12-17\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2019-12-17 -> 2020-01-16\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2020-01-16 -> 2020-02-15\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2020-02-15 -> 2020-03-16\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2020-03-16 -> 2020-04-15\n",
      "âœ… å·²æŠ“å– 3 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2020-04-15 -> 2020-05-15\n",
      "âœ… å·²æŠ“å– 3 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2020-05-15 -> 2020-06-14\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2020-06-14 -> 2020-07-14\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2020-07-14 -> 2020-08-13\n",
      "âœ… å·²æŠ“å– 4 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2020-08-13 -> 2020-09-12\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2020-09-12 -> 2020-10-12\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2020-10-12 -> 2020-11-11\n",
      "âœ… å·²æŠ“å– 4 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2020-11-11 -> 2020-12-11\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2020-12-11 -> 2021-01-10\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2021-01-10 -> 2021-02-09\n",
      "âœ… å·²æŠ“å– 3 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2021-02-09 -> 2021-03-11\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2021-03-11 -> 2021-04-10\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2021-04-10 -> 2021-05-10\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2021-05-10 -> 2021-06-09\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2021-06-09 -> 2021-07-09\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2021-07-09 -> 2021-08-08\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2021-08-08 -> 2021-09-07\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2021-09-07 -> 2021-10-07\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2021-10-07 -> 2021-11-06\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2021-11-06 -> 2021-12-06\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2021-12-06 -> 2022-01-05\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2022-01-05 -> 2022-02-04\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2022-02-04 -> 2022-03-06\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2022-03-06 -> 2022-04-05\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2022-04-05 -> 2022-05-05\n",
      "âœ… å·²æŠ“å– 4 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2022-05-05 -> 2022-06-04\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2022-06-04 -> 2022-07-04\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2022-07-04 -> 2022-08-03\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2022-08-03 -> 2022-09-02\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2022-09-02 -> 2022-10-02\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2022-10-02 -> 2022-11-01\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2022-11-01 -> 2022-12-01\n",
      "âœ… å·²æŠ“å– 4 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2022-12-01 -> 2022-12-31\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2022-12-31 -> 2023-01-30\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2023-01-30 -> 2023-03-01\n",
      "âœ… å·²æŠ“å– 3 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2023-03-01 -> 2023-03-31\n",
      "âœ… å·²æŠ“å– 3 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2023-03-31 -> 2023-04-30\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2023-04-30 -> 2023-05-30\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2023-05-30 -> 2023-06-29\n",
      "âœ… å·²æŠ“å– 4 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2023-06-29 -> 2023-07-29\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2023-07-29 -> 2023-08-28\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2023-08-28 -> 2023-09-27\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2023-09-27 -> 2023-10-27\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2023-10-27 -> 2023-11-26\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2023-11-26 -> 2023-12-26\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2023-12-26 -> 2024-01-25\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2024-01-25 -> 2024-02-24\n",
      "âœ… å·²æŠ“å– 1 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2024-02-24 -> 2024-03-25\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2024-03-25 -> 2024-04-24\n",
      "âœ… å·²æŠ“å– 3 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2024-04-24 -> 2024-05-24\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2024-05-24 -> 2024-06-23\n",
      "âœ… å·²æŠ“å– 3 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2024-06-23 -> 2024-07-23\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2024-07-23 -> 2024-08-22\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2024-08-22 -> 2024-09-21\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2024-09-21 -> 2024-10-21\n",
      "âœ… å·²æŠ“å– 6 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2024-10-21 -> 2024-11-20\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2024-11-20 -> 2024-12-20\n",
      "âœ… å·²æŠ“å– 4 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2024-12-20 -> 2025-01-19\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2025-01-19 -> 2025-02-18\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2025-02-18 -> 2025-03-20\n",
      "âœ… å·²æŠ“å– 3 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2025-03-20 -> 2025-04-19\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2025-04-19 -> 2025-05-19\n",
      "âœ… å·²æŠ“å– 3 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2025-05-19 -> 2025-06-18\n",
      "âœ… å·²æŠ“å– 4 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2025-06-18 -> 2025-07-18\n",
      "âœ… å·²æŠ“å– 4 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2025-07-18 -> 2025-08-17\n",
      "âœ… å·²æŠ“å– 10 ç¯‡ (offset=0)\n",
      "\n",
      "â³ æŠ“å–æ—¶é—´çª—å£: 2025-08-17 -> 2025-09-08\n",
      "âœ… å·²æŠ“å– 2 ç¯‡ (offset=0)\n",
      "\n",
      "ğŸ‰ æŠ“å–å®Œæˆï¼Œæ€»å…± 167 ç¯‡è®ºæ–‡ï¼Œå·²ä¿å­˜åˆ° arxiv_results.json\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def fetch_arxiv_auto_window(\n",
    "    query,\n",
    "    batch_size=50,\n",
    "    save_path=\"arxiv_results.json\",\n",
    "    start_date=datetime(2020, 1, 1),\n",
    "    max_retries=3,\n",
    "    delay_seconds=3,\n",
    "    window_days=1\n",
    "):\n",
    "    \"\"\"\n",
    "    è‡ªåŠ¨æŒ‰æ—¶é—´çª—å£æŠ“å– Arxiv è®ºæ–‡ï¼Œç›´åˆ°æœ€æ–°\n",
    "    \"\"\"\n",
    "    client = arxiv.Client(page_size=batch_size, delay_seconds=delay_seconds, num_retries=max_retries)\n",
    "\n",
    "    # è¯»å–å·²æœ‰ç»“æœï¼Œæ”¯æŒæ–­ç‚¹ç»­æŠ“\n",
    "    try:\n",
    "        with open(save_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            all_results = json.load(f)\n",
    "            if all_results:\n",
    "                # å·²æŠ“å–çš„æœ€æ–°æ—¶é—´\n",
    "                latest_date = max(datetime.fromisoformat(p['published']) for p in all_results)\n",
    "                start_date = latest_date + timedelta(seconds=1)\n",
    "    except FileNotFoundError:\n",
    "        all_results = []\n",
    "\n",
    "    # query_keywords = '((ti:\"{query}\") OR (abs:\"{query}\"))'.format(query=query)\n",
    "    query_keywords = '((abs:fraud detection behavior sequence) OR (ti:fraud detection behavior sequence))'\n",
    "    query_keywords = '((ti:fraud AND ti:detection AND ti:behavior AND ti:sequence) OR (abs:fraud AND abs:detection AND abs:behavior AND abs:sequence))'\n",
    "    query_keywords = '((ti: fraud AND detection AND behavior AND sequence) OR (abs: fraud AND detection AND behavior AND sequence))'\n",
    "    query_keywords = 'fraud AND detection AND behavior AND sequence'\n",
    "    query_keywords = '((behavior AND sequence AND fraud AND detection) OR (user AND behavior AND sequence AND fraud) OR (sequential AND behavior AND fraud AND detection) OR (temporal AND sequence AND fraud AND detection) OR (fraud AND detection AND behavioral AND patterns) OR (sequence AND mining AND fraud AND detection) OR (RNN AND fraud AND detection AND behavior) OR (LSTM AND fraud AND detection AND sequence) OR (Transformer AND fraud AND detection AND behavior) OR (anomaly AND detection AND behavior AND sequence) OR (financial AND fraud AND behavior AND sequence) OR (e-commerce AND fraud AND behavior AND sequence) OR (clickstream AND fraud AND detection) OR (user AND action AND sequence AND fraud))'\n",
    "    category_filter = ' AND cat:cs'\n",
    "    \n",
    "    today = datetime.utcnow()\n",
    "    current_start = start_date\n",
    "\n",
    "    while current_start < today:\n",
    "        current_end = min(current_start + timedelta(days=window_days), today)\n",
    "        time_filter = f\" AND submittedDate:[{current_start.strftime('%Y%m%d0000')} TO {current_end.strftime('%Y%m%d2359')}]\"\n",
    "        # search_query = query + time_filter + category_filter\n",
    "        search_query = query_keywords + time_filter\n",
    "\n",
    "        print(f\"\\nâ³ æŠ“å–æ—¶é—´çª—å£: {current_start.date()} -> {current_end.date()}\")\n",
    "\n",
    "        search = arxiv.Search(\n",
    "            query=search_query,\n",
    "            max_results=batch_size * 100,  # è®¾ç½®è¶³å¤Ÿå¤§ï¼Œåˆ†æ‰¹æŠ“å–\n",
    "            sort_by=arxiv.SortCriterion.SubmittedDate\n",
    "        )\n",
    "\n",
    "        offset = 0\n",
    "        while True:\n",
    "            retries = 0\n",
    "            while retries < max_retries:\n",
    "                try:\n",
    "                    results_iter = client.results(search, offset=offset)\n",
    "                    batch = []\n",
    "                    for i, result in enumerate(results_iter):\n",
    "                        batch.append({\n",
    "                            \"id\": result.get_short_id(),\n",
    "                            \"title\": result.title,\n",
    "                            \"authors\": [a.name for a in result.authors],\n",
    "                            \"abstract\": result.summary,\n",
    "                            \"categories\": result.categories,\n",
    "                            \"published\": result.published.isoformat(),\n",
    "                            \"updated\": result.updated.isoformat(),\n",
    "                            \"url\": result.pdf_url\n",
    "                        })\n",
    "                        if len(batch) >= batch_size:\n",
    "                            break\n",
    "\n",
    "                    if not batch:\n",
    "                        # ç©ºé¡µç»“æŸå½“å‰æ—¶é—´çª—å£\n",
    "                        break\n",
    "\n",
    "                    # ä¿å­˜å¢é‡ç»“æœ\n",
    "                    all_results.extend(batch)\n",
    "                    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                        json.dump(all_results, f, ensure_ascii=False, indent=2)\n",
    "                    \n",
    "                    print(f\"âœ… å·²æŠ“å– {len(batch)} ç¯‡ (offset={offset})\")\n",
    "                    offset += len(batch)\n",
    "                    time.sleep(delay_seconds)\n",
    "                    break  # æˆåŠŸè·³å‡ºé‡è¯•\n",
    "\n",
    "                except Exception as e:\n",
    "                    retries += 1\n",
    "                    wait_time = delay_seconds * 2 ** retries\n",
    "                    print(f\"âš ï¸ æŠ“å–å¤±è´¥: {e}, é‡è¯• {retries}/{max_retries}, ç­‰å¾… {wait_time} ç§’...\")\n",
    "                    time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"âŒ å¤šæ¬¡é‡è¯•ä»å¤±è´¥ï¼Œè·³è¿‡ offset={offset}\")\n",
    "                offset += batch_size\n",
    "\n",
    "            # å½“æŠ“å–ç»“æœå°‘äº batch_sizeï¼Œè¯´æ˜è¯¥çª—å£æŠ“å®Œ\n",
    "            if len(batch) < batch_size:\n",
    "                break\n",
    "\n",
    "        current_start = current_end\n",
    "\n",
    "    print(f\"\\nğŸ‰ æŠ“å–å®Œæˆï¼Œæ€»å…± {len(all_results)} ç¯‡è®ºæ–‡ï¼Œå·²ä¿å­˜åˆ° {save_path}\")\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# ç¤ºä¾‹è°ƒç”¨\n",
    "# ===========================\n",
    "\n",
    "papers = fetch_arxiv_auto_window(\n",
    "    query=\"fraud detection behavior sequence\",\n",
    "    batch_size=20,\n",
    "    start_date=datetime(2000, 1, 1),\n",
    "    save_path=\"arxiv_results.json\",\n",
    "    window_days=30\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffbdf13-8f9c-4d00-aa0e-17f81a323853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸå§‹å…³é”®è¯\n",
    "query_keywords = '(ti:\"{query}\") OR (abs:\"{query}\")'.format(query=query)\n",
    "\n",
    "# æ—¶é—´çª—å£\n",
    "time_filter = ' AND submittedDate:[2023-01-01 TO 2025-09-08]'\n",
    "\n",
    "# æŒ‡å®šç±»åˆ«\n",
    "category_filter = ' AND (cat:cs.CR OR cat:stat.ML)'\n",
    "\n",
    "# æœ€ç»ˆ arXiv æŸ¥è¯¢\n",
    "search_query = query_keywords + time_filter + category_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "87abd2c9-62a5-4d62-aa39-c3423e88b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['behavior sequence fraud detection', 'user behavior sequence fraud', 'sequential behavior fraud detection', 'temporal sequence fraud detection', 'fraud detection behavioral patterns', 'sequence mining fraud detection', 'RNN fraud detection behavior', 'LSTM fraud detection sequence', 'Transformer fraud detection behavior', 'anomaly detection behavior sequence', 'financial fraud behavior sequence', 'e-commerce fraud behavior sequence', 'clickstream fraud detection', 'user action sequence fraud']\n",
    "# x = [' AND '.join(i.split(' ')) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e1ce6887-903f-4a05-ab12-e2236b9357c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['behavior AND sequence AND fraud AND detection',\n",
       " 'user AND behavior AND sequence AND fraud',\n",
       " 'sequential AND behavior AND fraud AND detection',\n",
       " 'temporal AND sequence AND fraud AND detection',\n",
       " 'fraud AND detection AND behavioral AND patterns',\n",
       " 'sequence AND mining AND fraud AND detection',\n",
       " 'RNN AND fraud AND detection AND behavior',\n",
       " 'LSTM AND fraud AND detection AND sequence',\n",
       " 'Transformer AND fraud AND detection AND behavior',\n",
       " 'anomaly AND detection AND behavior AND sequence',\n",
       " 'financial AND fraud AND behavior AND sequence',\n",
       " 'e-commerce AND fraud AND behavior AND sequence',\n",
       " 'clickstream AND fraud AND detection',\n",
       " 'user AND action AND sequence AND fraud']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8fdef326-f90a-4a4f-89a1-9d3ce91ab7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = x\n",
    "query_keywords = '(('+') OR ('.join([' AND '.join(i.split(' ')) for i in query])+'))'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "75b8a10d-112a-4b21-ad21-eb9ccb50dfca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'((behavior AND sequence AND fraud AND detection) OR (user AND behavior AND sequence AND fraud) OR (sequential AND behavior AND fraud AND detection) OR (temporal AND sequence AND fraud AND detection) OR (fraud AND detection AND behavioral AND patterns) OR (sequence AND mining AND fraud AND detection) OR (RNN AND fraud AND detection AND behavior) OR (LSTM AND fraud AND detection AND sequence) OR (Transformer AND fraud AND detection AND behavior) OR (anomaly AND detection AND behavior AND sequence) OR (financial AND fraud AND behavior AND sequence) OR (e-commerce AND fraud AND behavior AND sequence) OR (clickstream AND fraud AND detection) OR (user AND action AND sequence AND fraud))'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "64c4b66a-7a4d-4b5c-9276-51726b7aa3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'behavior AND sequence AND fraud AND detection) OR (user AND behavior AND sequence AND fraud) OR (sequential AND behavior AND fraud AND detection) OR (temporal AND sequence AND fraud AND detection) OR (fraud AND detection AND behavioral AND patterns) OR (sequence AND mining AND fraud AND detection) OR (RNN AND fraud AND detection AND behavior) OR (LSTM AND fraud AND detection AND sequence) OR (Transformer AND fraud AND detection AND behavior) OR (anomaly AND detection AND behavior AND sequence) OR (financial AND fraud AND behavior AND sequence) OR (e-commerce AND fraud AND behavior AND sequence) OR (clickstream AND fraud AND detection) OR (user AND action AND sequence AND fraud'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "') OR ('.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c8dbe9-8b86-41b5-8fbe-4c7ad52d87b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "((behavior AND sequence AND fraud AND detection) OR (user AND behavior AND sequence AND fraud) OR (sequential AND behavior AND fraud AND detection) OR (temporal AND sequence AND fraud AND detection) OR (fraud AND detection AND behavioral AND patterns) OR (sequence AND mining AND fraud AND detection) OR (RNN AND fraud AND detection AND behavior) OR (LSTM AND fraud AND detection AND sequence) OR (Transformer AND fraud AND detection AND behavior) OR (anomaly AND detection AND behavior AND sequence) OR (financial AND fraud AND behavior AND sequence) OR (e-commerce AND fraud AND behavior AND sequence) OR (clickstream AND fraud AND detection) OR (user AND action AND sequence AND fraud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b699d304-16de-4477-87b0-562b54c4e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp_tools import arxiv_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "480bfc8b-2b80-4d73-bd78-59c9386441b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = ['behavior sequence fraud detection', 'user behavior sequence fraud', 'sequential behavior fraud detection', 'temporal sequence fraud detection', 'fraud detection behavioral patterns', 'sequence mining fraud detection', 'RNN fraud detection behavior', 'LSTM fraud detection sequence', 'Transformer fraud detection behavior', 'anomaly detection behavior sequence', 'financial fraud behavior sequence', 'e-commerce fraud behavior sequence', 'clickstream fraud detection', 'user action sequence fraud']\n",
    "# query_result = arxiv_tool.search_arxiv(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8e96339-e210-4d79-b6cb-3c8b86d3cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.llm_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b67c800f-6431-4838-a491-cfe1ec38af02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# æ‰“å¼€æ–‡ä»¶å¹¶è§£æ JSON\n",
    "with open(\"data/raw/arxiv_results.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    papers = json.load(f)\n",
    "\n",
    "print(type(papers))\n",
    "print(len(papers))  # å¦‚æœæ˜¯listï¼Œè¾“å‡ºè®ºæ–‡æ•°é‡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1156bd6e-4b94-4f8d-81ba-605840015cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '2001.04734v1',\n",
       " 'title': 'Change Detection in Dynamic Attributed Networks',\n",
       " 'authors': ['Isuru Udayangani Hewapathirana'],\n",
       " 'abstract': 'A network provides powerful means of representing complex relationships\\nbetween entities by abstracting entities as vertices, and relationships as\\nedges connecting vertices in a graph. Beyond the presence or absence of\\nrelationships, a network may contain additional information that can be\\nattributed to the entities and their relationships. Attaching these additional\\nattribute data to the corresponding vertices and edges yields an attributed\\ngraph. Moreover, in the majority of real-world applications, such as online\\nsocial networks, financial networks and transactional networks, relationships\\nbetween entities evolve over time.\\n  Change detection in dynamic attributed networks is an important problem in\\nmany areas, such as fraud detection, cyber intrusion detection and health care\\nmonitoring. It is a challenging problem because it involves a time sequence of\\nattributed graphs, each of which is usually very large and can contain many\\nattributes attached to the vertices and edges, resulting in a complex, high\\ndimensional mathematical object.\\n  In this survey we provide an overview of some of the existing change\\ndetection methods that utilize attribute information. We categorize these\\nmethods based on the levels of structure in the graph that are exploited to\\ndetect changes. These levels are vertices, edges, subgraphs, communities and\\nthe overall graph. We focus our attention on the strengths and weaknesses of\\nthese methods, including performance and scalability. Finally we discuss some\\npublicly available dynamic network datasets and give a brief overview of\\nsimulation models to generate synthetic dynamic attributed networks.',\n",
       " 'categories': ['cs.SI', 'stat.AP'],\n",
       " 'published': '2020-01-14T12:07:37+00:00',\n",
       " 'updated': '2020-01-14T12:07:37+00:00',\n",
       " 'url': 'http://arxiv.org/pdf/2001.04734v1'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae99307-a93a-4800-a974-6f77cc8de90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_classified = run_classification_chain(papers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "861c449f-5158-440f-a72f-6ec0be21e640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_source_type': ['social networks',\n",
       "  'financial networks',\n",
       "  'transactional networks'],\n",
       " 'data_source_name': [],\n",
       " 'fraud_type': 'change detection in dynamic attributed networks',\n",
       " 'technical_approach_category': ['survey',\n",
       "  'anomaly detection',\n",
       "  'graph analysis'],\n",
       " 'technical_approach_method': [],\n",
       " 'technical_approach_description': 'This survey paper provides an overview of existing change detection methods in dynamic attributed networks that utilize attribute information. Methods are categorized based on the levels of graph structure exploited: vertices, edges, subgraphs, communities, and overall graph. The paper analyzes strengths, weaknesses, performance, and scalability of these approaches.',\n",
       " 'innovation_points': 'Categorization of change detection methods based on structural levels in attributed graphs, comprehensive analysis of performance and scalability trade-offs, and overview of available datasets and simulation models for dynamic attributed networks.',\n",
       " 'github_repo': ''}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b44f144-b610-48d2-897c-baa108d60eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå¹¶å­—å…¸\n",
    "merged_dict = {**papers[0], **paper_classified}  # å¦‚æœé”®é‡å¤ï¼Œdict2çš„å€¼ä¼šè¦†ç›–dict1\n",
    "\n",
    "# è½¬æ¢å›JSONå­—ç¬¦ä¸²\n",
    "merged_json = json.dumps(merged_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecaaeaf2-fc34-43dd-8642-5397b38cc28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\": \"2001.04734v1\", \"title\": \"Change Detection in Dynamic Attributed Networks\", \"authors\": [\"Isuru Udayangani Hewapathirana\"], \"abstract\": \"A network provides powerful means of representing complex relationships\\\\nbetween entities by abstracting entities as vertices, and relationships as\\\\nedges connecting vertices in a graph. Beyond the presence or absence of\\\\nrelationships, a network may contain additional information that can be\\\\nattributed to the entities and their relationships. Attaching these additional\\\\nattribute data to the corresponding vertices and edges yields an attributed\\\\ngraph. Moreover, in the majority of real-world applications, such as online\\\\nsocial networks, financial networks and transactional networks, relationships\\\\nbetween entities evolve over time.\\\\n  Change detection in dynamic attributed networks is an important problem in\\\\nmany areas, such as fraud detection, cyber intrusion detection and health care\\\\nmonitoring. It is a challenging problem because it involves a time sequence of\\\\nattributed graphs, each of which is usually very large and can contain many\\\\nattributes attached to the vertices and edges, resulting in a complex, high\\\\ndimensional mathematical object.\\\\n  In this survey we provide an overview of some of the existing change\\\\ndetection methods that utilize attribute information. We categorize these\\\\nmethods based on the levels of structure in the graph that are exploited to\\\\ndetect changes. These levels are vertices, edges, subgraphs, communities and\\\\nthe overall graph. We focus our attention on the strengths and weaknesses of\\\\nthese methods, including performance and scalability. Finally we discuss some\\\\npublicly available dynamic network datasets and give a brief overview of\\\\nsimulation models to generate synthetic dynamic attributed networks.\", \"categories\": [\"cs.SI\", \"stat.AP\"], \"published\": \"2020-01-14T12:07:37+00:00\", \"updated\": \"2020-01-14T12:07:37+00:00\", \"url\": \"http://arxiv.org/pdf/2001.04734v1\", \"data_source_type\": [\"social networks\", \"financial networks\", \"transactional networks\"], \"data_source_name\": [], \"fraud_type\": \"change detection in dynamic attributed networks\", \"technical_approach_category\": [\"survey\", \"anomaly detection\", \"graph analysis\"], \"technical_approach_method\": [], \"technical_approach_description\": \"This survey paper provides an overview of existing change detection methods in dynamic attributed networks that utilize attribute information. Methods are categorized based on the levels of graph structure exploited: vertices, edges, subgraphs, communities, and overall graph. The paper analyzes strengths, weaknesses, performance, and scalability of these approaches.\", \"innovation_points\": \"Categorization of change detection methods based on structural levels in attributed graphs, comprehensive analysis of performance and scalability trade-offs, and overview of available datasets and simulation models for dynamic attributed networks.\", \"github_repo\": \"\"}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63844590-7fee-4df9-9ec2-c575be445972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m----> 5\u001b[0m classification \u001b[38;5;241m=\u001b[39m \u001b[43mrun_classification_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m merged_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpaper, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclassification}\n\u001b[1;32m      7\u001b[0m merged_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(merged_dict)\n",
      "File \u001b[0;32m~/Documents/3-å¤§æ¨¡å‹/5-é¡¹ç›®/fraud_research_agent/utils/llm_utils.py:135\u001b[0m, in \u001b[0;36mrun_classification_chain\u001b[0;34m(paper)\u001b[0m\n\u001b[1;32m    125\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mè¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–è®ºæ–‡ä¿¡æ¯ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§ JSON è¾“å‡ºï¼š\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{paper}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{format_instructions}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m )\n\u001b[1;32m    129\u001b[0m classification_chain \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    130\u001b[0m     prompt\u001b[38;5;241m.\u001b[39mpartial(format_instructions\u001b[38;5;241m=\u001b[39mparser\u001b[38;5;241m.\u001b[39mget_format_instructions())\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;241m|\u001b[39m llm\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;241m|\u001b[39m parser\n\u001b[1;32m    133\u001b[0m )\n\u001b[0;32m--> 135\u001b[0m classification_result \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpaper\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaper\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m classification_result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/langchain_core/runnables/base.py:3082\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3081\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3082\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3083\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:393\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    389\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    390\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 393\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    403\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1019\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m   1012\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1017\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m   1018\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m-> 1019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:837\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    836\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 837\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    843\u001b[0m         )\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    845\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1085\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1083\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1085\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1089\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/langchain_deepseek/chat_models.py:323\u001b[0m, in \u001b[0;36mChatDeepSeek._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    321\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 323\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    330\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    331\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSeek API returned an invalid response. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check the API status and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    333\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:1178\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[1;32m   1172\u001b[0m             response,\n\u001b[1;32m   1173\u001b[0m             schema\u001b[38;5;241m=\u001b[39moriginal_schema_obj,\n\u001b[1;32m   1174\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mgeneration_info,\n\u001b[1;32m   1175\u001b[0m             output_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_version,\n\u001b[1;32m   1176\u001b[0m         )\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m         raw_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_raw_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1179\u001b[0m         response \u001b[38;5;241m=\u001b[39m raw_response\u001b[38;5;241m.\u001b[39mparse()\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/openai/_legacy_response.py:364\u001b[0m, in \u001b[0;36mto_raw_response_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m extra_headers[RAW_RESPONSE_HEADER] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    362\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m extra_headers\n\u001b[0;32m--> 364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/openai/_utils/_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:1147\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m   1145\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/openai/_base_client.py:982\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    980\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    988\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/httpx/_client.py:928\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    927\u001b[0m     response\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 928\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/httpx/_client.py:922\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 922\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/httpx/_models.py:881\u001b[0m, in \u001b[0;36mResponse.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03mRead and return the response content.\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_content\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/httpx/_models.py:897\u001b[0m, in \u001b[0;36mResponse.iter_bytes\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    895\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_raw():\n\u001b[1;32m    898\u001b[0m         decoded \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(raw_bytes)\n\u001b[1;32m    899\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(decoded):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/httpx/_models.py:951\u001b[0m, in \u001b[0;36mResponse.iter_raw\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    948\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_stream_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream:\n\u001b[1;32m    952\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_bytes_downloaded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(raw_stream_bytes)\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(raw_stream_bytes):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/httpx/_client.py:153\u001b[0m, in \u001b[0;36mBoundSyncStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/httpx/_transports/default.py:127\u001b[0m, in \u001b[0;36mResponseStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpcore_stream:\n\u001b[1;32m    128\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m part\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:407\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:403\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[1;32m    404\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m part\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/httpcore/_sync/http11.py:342\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 342\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/httpcore/_sync/http11.py:334\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, kwargs):\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39m_receive_response_body(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/httpcore/_sync/http11.py:203\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    200\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mData):\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# æ‰“å¼€æ–‡ä»¶å¹¶è§£æ JSON\n",
    "with open(\"data/raw/arxiv_results.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    papers = json.load(f)\n",
    "\n",
    "paper_classification = []\n",
    "for i, paper in enumerate(papers):\n",
    "    if i%10 == 0:\n",
    "        print(i)\n",
    "    classification = run_classification_chain(paper)\n",
    "    merged_dict = {**paper, **classification}\n",
    "    merged_json = json.dumps(merged_dict)\n",
    "    \n",
    "    paper_classification.append(merged_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4160248-5e99-4027-9c10-7a4fad5025c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db8e7f3c-eeec-446f-b065-f4cffb0dade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.llm_utils import get_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cc1e10e-9136-433f-8500-df8c8c347892",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = get_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31faeb51-165b-4412-9246-38cab33171a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data/processed/arxiv_results.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    papers = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2262fbe9-8c7a-4ccf-88ff-d31ad72fc28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d21ba37-93a6-4ef8-a885-b29d2cf22f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change Detection in Dynamic Attributed Networks\n",
      "Change Detection in Dynamic Attributed Networks\n",
      "Detecting Deep-Fake Videos from Appearance and Behavior\n",
      "Detecting Deep-Fake Videos from Appearance and Behavior\n",
      "Multi-IF : An Approach to Anomaly Detection in Self-Driving Systems\n",
      "Multi-IF : An Approach to Anomaly Detection in Self-Driving Systems\n",
      "Sequential Anomaly Detection using Inverse Reinforcement Learning\n",
      "Sequential Anomaly Detection using Inverse Reinforcement Learning\n",
      "Analyze and Development System with Multiple Biometric Identification\n",
      "Analyze and Development System with Multiple Biometric Identification\n"
     ]
    }
   ],
   "source": [
    "query = 'è¡Œä¸ºåºåˆ—åœ¨åæ¬ºè¯ˆé¢†åŸŸçš„ç ”ç©¶'\n",
    "filtered_papers = []\n",
    "for paper in papers[0:5]:\n",
    "    papers_str = json.dumps(paper, ensure_ascii=False, indent=2)\n",
    "    print(paper['title'])\n",
    "    prompt = \"åˆ¤æ–­è¿™ç¯‡è®ºæ–‡æ˜¯å¦ä¸ç”¨æˆ·æŸ¥è¯¢ '{query}' ç›¸å…³: '{paper}'ï¼Œç›¸å…³è¾“å‡ºä¸º1ï¼Œå¦åˆ™è¾“å‡º0\".format(query=query, paper=papers_str)\n",
    "    match = llm.invoke(prompt)\n",
    "    if match:\n",
    "        print(paper['title'])\n",
    "        filtered_papers.append(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15bd5b1e-4a81-416d-b004-ee7bea7defb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_papers = papers\n",
    "clustering_prompt = f\"\"\"\n",
    "    æˆ‘æœ‰ {len(filtered_papers)} ç¯‡è®ºæ–‡, æ¯ç¯‡è®ºæ–‡åŒ…å«ä¸‰ä¸ªå­—æ®µ:\n",
    "    data_source_type, fraud_type, technical_approach_categoryã€‚\n",
    "    è¯·å°†æ¯ä¸ªå­—æ®µçš„å€¼èšç±»æˆå¤§çº¦10ç±»ï¼Œä¸è¦è¶…è¿‡20ç±»ï¼Œå¹¶ç»Ÿè®¡æ¯ç±»æ•°é‡ã€‚\n",
    "    è¿”å› JSON æ ¼å¼:\n",
    "    {{\n",
    "        \"data_source_type\": {{}},\n",
    "        \"fraud_type\": {{}},\n",
    "        \"technical_approach_category\": {{}}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "filtered_papers_str = json.dumps(filtered_papers, ensure_ascii=False, indent=2)\n",
    "clustering_prompt += \"\\n\" + str(filtered_papers)\n",
    "cluster_stats = llm.invoke(clustering_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d1a97bd-30f5-465c-9ac3-b5d86eed667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_str = cluster_stats.content\n",
    "clean_str = raw_str.strip()\n",
    "if clean_str.startswith(\"```json\"):\n",
    "    clean_str = clean_str[len(\"```json\"):].strip()\n",
    "if clean_str.endswith(\"```\"):\n",
    "    clean_str = clean_str[:-3].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "61e2773b-b226-43c1-91b8-b4cc4749ce60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "source": [
    "clean_json = json.loads(clean_str)['data_source_type']\n",
    "i = 0\n",
    "for k in clean_json:\n",
    "    i+=int(clean_json[k])\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09d281b3-ef73-4357-b8bc-9982c95d7199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "clean_json = json.loads(clean_str)['fraud_type']\n",
    "i = 0\n",
    "for k in clean_json:\n",
    "    i+=int(clean_json[k])\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8df0fa3-c491-4189-96f8-20c51a99dcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n"
     ]
    }
   ],
   "source": [
    "clean_json = json.loads(clean_str)['technical_approach_category']\n",
    "i = 0\n",
    "for k in clean_json:\n",
    "    i+=int(clean_json[k])\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b632f9f5-b520-4a82-af95-d88f2f9635b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anomaly detection': 42,\n",
       " 'deep learning/neural networks': 38,\n",
       " 'graph neural networks (GNN)': 27,\n",
       " 'sequence modeling/RNN/LSTM': 25,\n",
       " 'unsupervised learning': 22,\n",
       " 'feature engineering': 19,\n",
       " 'Transformer/attention mechanisms': 18,\n",
       " 'reinforcement learning': 9,\n",
       " 'probabilistic modeling': 8,\n",
       " 'clustering/pattern mining': 12,\n",
       " 'explainable AI/interpretability': 11,\n",
       " 'transfer learning/domain adaptation': 10,\n",
       " 'multimodal fusion': 13,\n",
       " 'self-supervised learning': 11,\n",
       " 'generative models (GAN/VAE)': 9,\n",
       " 'statistical methods': 8,\n",
       " 'ensemble methods': 7,\n",
       " 'computer vision': 11,\n",
       " 'natural language processing': 8}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(clean_str)['technical_approach_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3755f77-51ae-4b49-a801-346dd41dac3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fraud_research_agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01magent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m paper_search_agent\n",
      "File \u001b[0;32m~/Documents/3-å¤§æ¨¡å‹/5-é¡¹ç›®/fraud_research_agent/agent/paper_search_agent.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Dict\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfraud_research_agent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchain_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_generate_queries_chain\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfraud_research_agent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marxiv_tool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m search_arxiv\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpaper_search_agent\u001b[39m(user_topic: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Dict]:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fraud_research_agent'"
     ]
    }
   ],
   "source": [
    "from agent import paper_search_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024fca1a-c276-44d2-be41-323cce65c27a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
