[
  {
    "id": "2201.11486v1",
    "title": "FinGAN: Generative Adversarial Network for Analytical Customer Relationship Management in Banking and Insurance",
    "authors": [
      "Prateek Kate",
      "Vadlamani Ravi",
      "Akhilesh Gangwar"
    ],
    "abstract": "Churn prediction in credit cards, fraud detection in insurance, and loan\ndefault prediction are important analytical customer relationship management\n(ACRM) problems. Since frauds, churns and defaults happen less frequently, the\ndatasets for these problems turn out to be naturally highly unbalanced.\nConsequently, all supervised machine learning classifiers tend to yield\nsubstantial false-positive rates when trained on such unbalanced datasets. We\npropose two ways of data balancing. In the first, we propose an oversampling\nmethod to generate synthetic samples of minority class using Generative\nAdversarial Network (GAN). We employ Vanilla GAN [1], Wasserstein GAN [2] and\nCTGAN [3] separately to oversample the minority class samples. In order to\nassess the efficacy of our proposed approach, we use a host of machine learning\nclassifiers, including Random Forest, Decision Tree, support vector machine\n(SVM), and Logistic Regression on the data balanced by GANs. In the second\nmethod, we introduce a hybrid method to handle data imbalance. In this second\nway, we utilize the power of undersampling and over-sampling together by\naugmenting the synthetic minority class data oversampled by GAN with the\nundersampled majority class data obtained by one-class support vigor machine\n(OCSVM) [4]. We combine both over-sampled data generated by GAN and the data\nunder-sampled by OCSVM [4] and pass the resultant data to classifiers. When we\ncompared our results to those of Farquad et al. [5], Sundarkumar, Ravi, and\nSiddeshwar [6], our proposed methods outperform the previous results in terms\nof the area under the ROC curve (AUC) on all datasets.",
    "categories": [
      "cs.LG",
      "cs.CE",
      "cs.NE",
      "91-04",
      "I.2.6"
    ],
    "published": "2022-01-27T12:43:00+00:00",
    "updated": "2022-01-27T12:43:00+00:00",
    "url": "http://arxiv.org/pdf/2201.11486v1"
  },
  {
    "id": "2201.10407v1",
    "title": "A Sybil-Resistant and Decentralized Market Place",
    "authors": [
      "Naqib Zarin",
      "Dirk van Bokkem",
      "Justin Segond",
      "Stefanie Roos"
    ],
    "abstract": "Existing centralised market places such as Ebay enable companies to gather\nlarge amounts of personal data that can be used to manipulate users.\nFurthermore, users can frequently perform fraud without severe consequence.\nReputation systems only solve this problem partially as malicious users can\nre-join the network with a new identity if their reputation is too low. By\nperforming a Sybil attack, i.e., joining with multiple seemingly distinct\nidentities, malicious participants can further boost their own reputation. In\nthis paper, we present MarketPalace. MarketPalace relies on a peer-to-peer\ninfrastructure to realize a decentralized market place during trading. Only\nwhen registering, users communicate with a central server to verify that they\nare not Sybils. More concretely, our system leverages self-sovereign identity\nto detect and undermine repeated joins by the same user. We implemented\nMarketPalace and demonstrated its feasibility for small regional markets.",
    "categories": [
      "cs.DC",
      "cs.NI"
    ],
    "published": "2022-01-25T15:53:57+00:00",
    "updated": "2022-01-25T15:53:57+00:00",
    "url": "http://arxiv.org/pdf/2201.10407v1"
  },
  {
    "id": "2201.09202v1",
    "title": "One-Shot Learning on Attributed Sequences",
    "authors": [
      "Zhongfang Zhuang",
      "Xiangnan Kong",
      "Elke Rundensteiner",
      "Aditya Arora",
      "Jihane Zouaoui"
    ],
    "abstract": "One-shot learning has become an important research topic in the last decade\nwith many real-world applications. The goal of one-shot learning is to classify\nunlabeled instances when there is only one labeled example per class.\nConventional problem setting of one-shot learning mainly focuses on the data\nthat is already in feature space (such as images). However, the data instances\nin real-world applications are often more complex and feature vectors may not\nbe available. In this paper, we study the problem of one-shot learning on\nattributed sequences, where each instance is composed of a set of attributes\n(e.g., user profile) and a sequence of categorical items (e.g., clickstream).\nThis problem is important for a variety of real-world applications ranging from\nfraud prevention to network intrusion detection. This problem is more\nchallenging than conventional one-shot learning since there are dependencies\nbetween attributes and sequences. We design a deep learning framework OLAS to\ntackle this problem. The proposed OLAS utilizes a twin network to generalize\nthe features from pairwise attributed sequence examples. Empirical results on\nreal-world datasets demonstrate the proposed OLAS can outperform the\nstate-of-the-art methods under a rich variety of parameter settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-01-23T07:19:11+00:00",
    "updated": "2022-01-23T07:19:11+00:00",
    "url": "http://arxiv.org/pdf/2201.09202v1"
  },
  {
    "id": "2201.07946v1",
    "title": "Babylon: Reusing Bitcoin Mining to Enhance Proof-of-Stake Security",
    "authors": [
      "Ertem Nusret Tas",
      "David Tse",
      "Fisher Yu",
      "Sreeram Kannan"
    ],
    "abstract": "Bitcoin is the most secure blockchain in the world, supported by the immense\nhash power of its Proof-of-Work miners, but consumes huge amount of energy.\nProof-of-Stake chains are energy-efficient, have fast finality and\naccountability, but face several fundamental security issues: susceptibility to\nnon-slashable long-range safety attacks, non-slashable transaction censorship\nand stalling attacks and difficulty to bootstrap new PoS chains from low token\nvaluation. We propose Babylon, a blockchain platform which combines the best of\nboth worlds by reusing the immense Bitcoin hash power to enhance the security\nof PoS chains. Babylon provides a data-available timestamping service, securing\nPoS chains by allowing them to timestamp data-available block checkpoints,\nfraud proofs and censored transactions on Babylon. Babylon miners merge mine\nwith Bitcoin and thus the platform has zero additional energy cost. The\nsecurity of a Babylon-enhanced PoS protocol is formalized by a cryptoeconomic\nsecurity theorem which shows slashable safety and liveness guarantees.",
    "categories": [
      "cs.CR"
    ],
    "published": "2022-01-20T01:30:05+00:00",
    "updated": "2022-01-20T01:30:05+00:00",
    "url": "http://arxiv.org/pdf/2201.07946v1"
  },
  {
    "id": "2201.07287v2",
    "title": "Polar Coded Merkle Tree: Improved Detection of Data Availability Attacks in Blockchain Systems",
    "authors": [
      "Debarnab Mitra",
      "Lev Tauz",
      "Lara Dolecek"
    ],
    "abstract": "Light nodes in blockchain systems are known to be vulnerable to data\navailability (DA) attacks where they accept an invalid block with unavailable\nportions. Previous works have used LDPC and 2-D Reed Solomon (2D-RS) codes with\nMerkle Trees to mitigate DA attacks. While these codes have demonstrated\nimproved performance across a variety of metrics such as DA detection\nprobability, they are difficult to apply to blockchains with large blocks due\nto generally intractable code guarantees for large codelengths (LDPC), large\ndecoding complexity (2D-RS), or large coding fraud proof sizes (2D-RS). We\naddress these issues by proposing the novel Polar Coded Merkle Tree (PCMT)\nwhich is a Merkle Tree built from the encoding graphs of polar codes and a\nspecialized polar code construction called Sampling-Efficient Freezing (SEF).\nWe demonstrate that the PCMT with SEF polar codes performs well in detecting DA\nattacks for large block sizes.",
    "categories": [
      "cs.IT",
      "cs.CR",
      "math.IT"
    ],
    "published": "2022-01-18T19:54:59+00:00",
    "updated": "2022-05-16T19:23:23+00:00",
    "url": "http://arxiv.org/pdf/2201.07287v2"
  },
  {
    "id": "2201.06759v1",
    "title": "Knowledge Sharing via Domain Adaptation in Customs Fraud Detection",
    "authors": [
      "Sungwon Park",
      "Sundong Kim",
      "Meeyoung Cha"
    ],
    "abstract": "Knowledge of the changing traffic is critical in risk management. Customs\noffices worldwide have traditionally relied on local resources to accumulate\nknowledge and detect tax fraud. This naturally poses countries with weak\ninfrastructure to become tax havens of potentially illicit trades. The current\npaper proposes DAS, a memory bank platform to facilitate knowledge sharing\nacross multi-national customs administrations to support each other. We propose\na domain adaptation method to share transferable knowledge of frauds as\nprototypes while safeguarding the local trade information. Data encompassing\nover 8 million import declarations have been used to test the feasibility of\nthis new system, which shows that participating countries may benefit up to\n2-11 times in fraud detection with the help of shared knowledge. We discuss\nimplications for substantial tax revenue potential and strengthened policy\nagainst illicit trades.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "published": "2022-01-18T06:17:03+00:00",
    "updated": "2022-01-18T06:17:03+00:00",
    "url": "http://arxiv.org/pdf/2201.06759v1"
  },
  {
    "id": "2201.06068v1",
    "title": "Zero Botnets: An Observe-Pursue-Counter Approach",
    "authors": [
      "Jeremy Kepner",
      "Jonathan Bernays",
      "Stephen Buckley",
      "Kenjiro Cho",
      "Cary Conrad",
      "Leslie Daigle",
      "Keeley Erhardt",
      "Vijay Gadepally",
      "Barry Greene",
      "Michael Jones",
      "Robert Knake",
      "Bruce Maggs",
      "Peter Michaleas",
      "Chad Meiners",
      "Andrew Morris",
      "Alex Pentland",
      "Sandeep Pisharody",
      "Sarah Powazek",
      "Andrew Prout",
      "Philip Reiner",
      "Koichi Suzuki",
      "Kenji Takahashi",
      "Tony Tauber",
      "Leah Walker",
      "Douglas Stetson"
    ],
    "abstract": "Adversarial Internet robots (botnets) represent a growing threat to the safe\nuse and stability of the Internet. Botnets can play a role in launching\nadversary reconnaissance (scanning and phishing), influence operations\n(upvoting), and financing operations (ransomware, market manipulation, denial\nof service, spamming, and ad click fraud) while obfuscating tailored tactical\noperations. Reducing the presence of botnets on the Internet, with the\naspirational target of zero, is a powerful vision for galvanizing policy\naction. Setting a global goal, encouraging international cooperation, creating\nincentives for improving networks, and supporting entities for botnet takedowns\nare among several policies that could advance this goal. These policies raise\nsignificant questions regarding proper authorities/access that cannot be\nanswered in the abstract. Systems analysis has been widely used in other\ndomains to achieve sufficient detail to enable these questions to be dealt with\nin concrete terms. Defeating botnets using an observe-pursue-counter\narchitecture is analyzed, the technical feasibility is affirmed, and the\nauthorities/access questions are significantly narrowed. Recommended next steps\ninclude: supporting the international botnet takedown community, expanding\nnetwork observatories, enhancing the underlying network science at scale,\nconducting detailed systems analysis, and developing appropriate policy\nframeworks.",
    "categories": [
      "cs.CR",
      "cs.CY",
      "cs.NI",
      "cs.SI"
    ],
    "published": "2022-01-16T15:17:20+00:00",
    "updated": "2022-01-16T15:17:20+00:00",
    "url": "http://arxiv.org/pdf/2201.06068v1"
  },
  {
    "id": "2201.05226v1",
    "title": "Towards a Data Privacy-Predictive Performance Trade-off",
    "authors": [
      "Tânia Carvalho",
      "Nuno Moniz",
      "Pedro Faria",
      "Luís Antunes"
    ],
    "abstract": "Machine learning is increasingly used in the most diverse applications and\ndomains, whether in healthcare, to predict pathologies, or in the financial\nsector to detect fraud. One of the linchpins for efficiency and accuracy in\nmachine learning is data utility. However, when it contains personal\ninformation, full access may be restricted due to laws and regulations aiming\nto protect individuals' privacy. Therefore, data owners must ensure that any\ndata shared guarantees such privacy. Removal or transformation of private\ninformation (de-identification) are among the most common techniques.\nIntuitively, one can anticipate that reducing detail or distorting information\nwould result in losses for model predictive performance. However, previous work\nconcerning classification tasks using de-identified data generally demonstrates\nthat predictive performance can be preserved in specific applications. In this\npaper, we aim to evaluate the existence of a trade-off between data privacy and\npredictive performance in classification tasks. We leverage a large set of\nprivacy-preserving techniques and learning algorithms to provide an assessment\nof re-identification ability and the impact of transformed variants on\npredictive performance. Unlike previous literature, we confirm that the higher\nthe level of privacy (lower re-identification risk), the higher the impact on\npredictive performance, pointing towards clear evidence of a trade-off.",
    "categories": [
      "cs.LG"
    ],
    "published": "2022-01-13T21:48:51+00:00",
    "updated": "2022-01-13T21:48:51+00:00",
    "url": "http://arxiv.org/pdf/2201.05226v1"
  },
  {
    "id": "2201.02773v4",
    "title": "A Survey of Quantum Computing for Finance",
    "authors": [
      "Dylan Herman",
      "Cody Googin",
      "Xiaoyuan Liu",
      "Alexey Galda",
      "Ilya Safro",
      "Yue Sun",
      "Marco Pistoia",
      "Yuri Alexeev"
    ],
    "abstract": "Quantum computers are expected to surpass the computational capabilities of\nclassical computers during this decade and have transformative impact on\nnumerous industry sectors, particularly finance. In fact, finance is estimated\nto be the first industry sector to benefit from quantum computing, not only in\nthe medium and long terms, but even in the short term. This survey paper\npresents a comprehensive summary of the state of the art of quantum computing\nfor financial applications, with particular emphasis on stochastic modeling,\noptimization, and machine learning, describing how these solutions, adapted to\nwork on a quantum computer, can potentially help to solve financial problems,\nsuch as derivative pricing, risk modeling, portfolio optimization, natural\nlanguage processing, and fraud detection, more efficiently and accurately. We\nalso discuss the feasibility of these algorithms on near-term quantum computers\nwith various hardware implementations and demonstrate how they relate to a wide\nrange of use cases in finance. We hope this article will not only serve as a\nreference for academic researchers and industry practitioners but also inspire\nnew ideas for future research.",
    "categories": [
      "quant-ph",
      "q-fin.CP"
    ],
    "published": "2022-01-08T06:16:21+00:00",
    "updated": "2022-06-27T20:26:42+00:00",
    "url": "http://arxiv.org/pdf/2201.02773v4"
  },
  {
    "id": "2201.01004v1",
    "title": "Modeling Users' Behavior Sequences with Hierarchical Explainable Network for Cross-domain Fraud Detection",
    "authors": [
      "Yongchun Zhu",
      "Dongbo Xi",
      "Bowen Song",
      "Fuzhen Zhuang",
      "Shuai Chen",
      "Xi Gu",
      "Qing He"
    ],
    "abstract": "With the explosive growth of the e-commerce industry, detecting online\ntransaction fraud in real-world applications has become increasingly important\nto the development of e-commerce platforms. The sequential behavior history of\nusers provides useful information in differentiating fraudulent payments from\nregular ones. Recently, some approaches have been proposed to solve this\nsequence-based fraud detection problem. However, these methods usually suffer\nfrom two problems: the prediction results are difficult to explain and the\nexploitation of the internal information of behaviors is insufficient. To\ntackle the above two problems, we propose a Hierarchical Explainable Network\n(HEN) to model users' behavior sequences, which could not only improve the\nperformance of fraud detection but also make the inference process\ninterpretable. Meanwhile, as e-commerce business expands to new domains, e.g.,\nnew countries or new markets, one major problem for modeling user behavior in\nfraud detection systems is the limitation of data collection, e.g., very few\ndata/labels available. Thus, in this paper, we further propose a transfer\nframework to tackle the cross-domain fraud detection problem, which aims to\ntransfer knowledge from existing domains (source domains) with enough and\nmature data to improve the performance in the new domain (target domain). Our\nproposed method is a general transfer framework that could not only be applied\nupon HEN but also various existing models in the Embedding & MLP paradigm.\nBased on 90 transfer task experiments, we also demonstrate that our transfer\nframework could not only contribute to the cross-domain fraud detection task\nwith HEN, but also be universal and expandable for various existing models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2022-01-04T06:37:16+00:00",
    "updated": "2022-01-04T06:37:16+00:00",
    "url": "http://arxiv.org/pdf/2201.01004v1"
  },
  {
    "id": "2203.00398v2",
    "title": "Web3: A Decentralized Societal Infrastructure for Identity, Trust, Money, and Data",
    "authors": [
      "Joost Bambacht",
      "Johan Pouwelse"
    ],
    "abstract": "A movement for a more transparent and decentralized Internet is globally\nattracting more attention. People are becoming more privacy-aware of their\nonline identities and data. The Internet is constantly evolving. Web2 focused\non companies that provide services in exchange for personal user data. Web3\ncommits to user-centricity using decentralization and zero-server\narchitectures. The current digital society demands a global change to empower\ncitizens and take back control. Citizens are locked into big-tech for personal\ndata storage and their for-profit digital identity. Protection of data has\nproven to be essential, especially due to increased home Internet traffic\nduring the COVID pandemic. Citizens do not possess their own travel documents.\nThe European Commission aims to transition this governmental property towards\nself-sovereign identity, introducing many new opportunities. Citizens are\nlocked into banks with non-portable IBAN accounts and unsustainable legacy\nbanking infrastructures. Migration to all-digital low-fraud infrastructures and\nhealthier competitive ecosystems is essential. The overall challenge is to\nreturn the power to citizens and users again. The transition to a more\ndecentralized Internet is the first crucial step in the realization of\nuser-centricity. This thesis presents the first exploratory study that\nintegrates governmental-issued travel documents into a (decentralized) societal\ninfrastructure. These self-sovereign identities form the authentic base to a\nprivate and secure transfer of money and data, and can effectively provide\ntrust in authenticity that is currently missing in online conversations. A\nfully operational zero-server infrastructure that incorporates all our\nrequirements has been developed for Android using the P2P network overlay IPv8,\nand a personalized blockchain called TrustChain...",
    "categories": [
      "cs.DC",
      "cs.CR",
      "cs.CY"
    ],
    "published": "2022-03-01T12:49:02+00:00",
    "updated": "2022-03-03T13:51:53+00:00",
    "url": "http://arxiv.org/pdf/2203.00398v2"
  },
  {
    "id": "2202.07787v1",
    "title": "Trustworthy Anomaly Detection: A Survey",
    "authors": [
      "Shuhan Yuan",
      "Xintao Wu"
    ],
    "abstract": "Anomaly detection has a wide range of real-world applications, such as bank\nfraud detection and cyber intrusion detection. In the past decade, a variety of\nanomaly detection models have been developed, which lead to big progress\ntowards accurately detecting various anomalies. Despite the successes, anomaly\ndetection models still face many limitations. The most significant one is\nwhether we can trust the detection results from the models. In recent years,\nthe research community has spent a great effort to design trustworthy machine\nlearning models, such as developing trustworthy classification models. However,\nthe attention to anomaly detection tasks is far from sufficient. Considering\nthat many anomaly detection tasks are life-changing tasks involving human\nbeings, labeling someone as anomalies or fraudsters should be extremely\ncautious. Hence, ensuring the anomaly detection models conducted in a\ntrustworthy fashion is an essential requirement to deploy the models to conduct\nautomatic decisions in the real world. In this brief survey, we summarize the\nexisting efforts and discuss open problems towards trustworthy anomaly\ndetection from the perspectives of interpretability, fairness, robustness, and\nprivacy-preservation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-02-15T23:25:37+00:00",
    "updated": "2022-02-15T23:25:37+00:00",
    "url": "http://arxiv.org/pdf/2202.07787v1"
  },
  {
    "id": "2202.06580v1",
    "title": "Improved Aggregating and Accelerating Training Methods for Spatial Graph Neural Networks on Fraud Detection",
    "authors": [
      "Yufan Zeng",
      "Jiashan Tang"
    ],
    "abstract": "Graph neural networks (GNNs) have been widely applied to numerous fields. A\nrecent work which combines layered structure and residual connection proposes\nan improved deep architecture to extend CAmouflage-REsistant GNN (CARE-GNN) to\ndeep models named as Residual Layered CARE-GNN (RLC-GNN), which forms\nself-correcting and incremental learning mechanism, and achieves significant\nperformance improvements on fraud detection task. However, we spot three issues\nof RLC-GNN, which are the usage of neighboring information reaching limitation,\nthe training difficulty which is inherent problem to deep models and lack of\ncomprehensive consideration about node features and external patterns. In this\nwork, we propose three approaches to solve those three problems respectively.\nFirst, we suggest conducting similarity measure via cosine distance to take\nboth local features and external patterns into consideration. Then, we combine\nthe similarity measure module and the idea of adjacency-wise normalization with\nnode-wise and batch-wise normalization and then propound partial neighborhood\nnormalization methods to overcome the training difficulty while mitigating the\nimpact of too much noise caused by high-density of graph. Finally, we put\nforward intermediate information supplement to solve the information\nlimitation. Experiments are conducted on Yelp and Amazon datasets. And the\nresults show that our proposed methods effectively solve the three problems.\nAfter applying the three methods, we achieve 4.81%, 6.62% and 6.81%\nimprovements in the metrics of recall, AUC and Macro-F1 respectively on the\nYelp dataset. And we obtain 1.65% and 0.29% improvements in recall and AUC\nrespectively on the Amazon datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-02-14T09:51:35+00:00",
    "updated": "2022-02-14T09:51:35+00:00",
    "url": "http://arxiv.org/pdf/2202.06580v1"
  },
  {
    "id": "2202.06096v2",
    "title": "Improving Fraud Detection via Hierarchical Attention-based Graph Neural Network",
    "authors": [
      "Yajing Liu",
      "Zhengya Sun",
      "Wensheng Zhang"
    ],
    "abstract": "Graph neural networks (GNN) have emerged as a powerful tool for fraud\ndetection tasks, where fraudulent nodes are identified by aggregating neighbor\ninformation via different relations. To get around such detection, crafty\nfraudsters resort to camouflage via connecting to legitimate users (i.e.,\nrelation camouflage) or providing seemingly legitimate feedbacks (i.e., feature\ncamouflage). A wide-spread solution reinforces the GNN aggregation process with\nneighbor selectors according to original node features. This method may carry\nlimitations when identifying fraudsters not only with the relation camouflage,\nbut with the feature camouflage making them hard to distinguish from their\nlegitimate neighbors. In this paper, we propose a Hierarchical Attention-based\nGraph Neural Network (HA-GNN) for fraud detection, which incorporates weighted\nadjacency matrices across different relations against camouflage. This is\nmotivated in the Relational Density Theory and is exploited for forming a\nhierarchical attention-based graph neural network. Specifically, we design a\nrelation attention module to reflect the tie strength between two nodes, while\na neighborhood attention module to capture the long-range structural affinity\nassociated with the graph. We generate node embeddings by aggregating\ninformation from local/long-range structures and original node features.\nExperiments on three real-world datasets demonstrate the effectiveness of our\nmodel over the state-of-the-arts.",
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "published": "2022-02-12T16:27:16+00:00",
    "updated": "2022-02-21T08:29:28+00:00",
    "url": "http://arxiv.org/pdf/2202.06096v2"
  },
  {
    "id": "2202.05237v2",
    "title": "Severe testing of Benford's law",
    "authors": [
      "Roy Cerqueti",
      "Claudio Lupi"
    ],
    "abstract": "Benford's law is often used as a support to critical decisions related to\ndata quality or the presence of data manipulations or even fraud. However, many\nauthors argue that conventional statistical tests will reject the null of data\n\"Benford-ness\" if applied in samples of the typical size in this kind of\napplications, even in the presence of tiny and practically unimportant\ndeviations from Benford's law. Therefore, they suggest using alternative\ncriteria that, however, lack solid statistical foundations. This paper\ncontributes to the debate on the \"large $n$\" (or \"excess power\") problem in the\ncontext of Benford's law testing. This issue is discussed in relation with the\nnotion of severity testing for goodness of fit tests, with a specific focus on\ntests for conformity with Benford's law. To do so, we also derive the\nasymptotic distribution of the mean absolute deviation ($MAD$) statistic as\nwell as an asymptotic standard normal test. Finally, the severity testing\nprinciple is applied to six controversial data sets to assess their\n\"Benford-ness\".",
    "categories": [
      "stat.ME",
      "62E20, 62F03"
    ],
    "published": "2022-02-10T18:46:33+00:00",
    "updated": "2022-06-15T13:47:23+00:00",
    "url": "http://arxiv.org/pdf/2202.05237v2"
  },
  {
    "id": "2202.04561v2",
    "title": "Erasing Labor with Labor: Dark Patterns and Lockstep Behaviors on Google Play",
    "authors": [
      "Ashwin Singh",
      "Arvindh Arun",
      "Ayushi Jain",
      "Pooja Desur",
      "Pulak Malhotra",
      "Duen Horng Chau",
      "Ponnurangam Kumaraguru"
    ],
    "abstract": "Google Play's policy forbids the use of incentivized installs, ratings, and\nreviews to manipulate the placement of apps. However, there still exist apps\nthat incentivize installs for other apps on the platform. To understand how\ninstall-incentivizing apps affect users, we examine their ecosystem through a\nsocio-technical lens and perform a mixed-methods analysis of their reviews and\npermissions. Our dataset contains 319K reviews collected daily over five months\nfrom 60 such apps that cumulatively account for over 160.5M installs. We\nperform qualitative analysis of reviews to reveal various types of dark\npatterns that developers incorporate in install-incentivizing apps,\nhighlighting their normative concerns at both user and platform levels.\nPermissions requested by these apps validate our discovery of dark patterns,\nwith over 92% apps accessing sensitive user information. We find evidence of\nfraudulent reviews on install-incentivizing apps, following which we model them\nas an edge stream in a dynamic bipartite graph of apps and reviewers. Our\nproposed reconfiguration of a state-of-the-art microcluster anomaly detection\nalgorithm yields promising preliminary results in detecting this fraud. We\ndiscover highly significant lockstep behaviors exhibited by reviews that aim to\nboost the overall rating of an install-incentivizing app. Upon evaluating the\n50 most suspicious clusters of boosting reviews detected by the algorithm, we\nfind (i) near-identical pairs of reviews across 94% (47 clusters), and (ii)\nover 35% (1,687 of 4,717 reviews) present in the same form near-identical pairs\nwithin their cluster. Finally, we conclude with a discussion on how fraud is\nintertwined with labor and poses a threat to the trust and transparency of\nGoogle Play.",
    "categories": [
      "cs.CY",
      "cs.SI"
    ],
    "published": "2022-02-09T16:54:27+00:00",
    "updated": "2022-05-17T22:10:54+00:00",
    "url": "http://arxiv.org/pdf/2202.04561v2"
  },
  {
    "id": "2202.04369v1",
    "title": "A new perspective on classification: optimally allocating limited resources to uncertain tasks",
    "authors": [
      "Toon Vanderschueren",
      "Bart Baesens",
      "Tim Verdonck",
      "Wouter Verbeke"
    ],
    "abstract": "A central problem in business concerns the optimal allocation of limited\nresources to a set of available tasks, where the payoff of these tasks is\ninherently uncertain. In credit card fraud detection, for instance, a bank can\nonly assign a small subset of transactions to their fraud investigations team.\nTypically, such problems are solved using a classification framework, where the\nfocus is on predicting task outcomes given a set of characteristics. Resources\nare then allocated to the tasks that are predicted to be the most likely to\nsucceed. However, we argue that using classification to address task\nuncertainty is inherently suboptimal as it does not take into account the\navailable capacity. Therefore, we first frame the problem as a type of\nassignment problem. Then, we present a novel solution using learning to rank by\ndirectly optimizing the assignment's expected profit given limited, stochastic\ncapacity. This is achieved by optimizing a specific instance of the net\ndiscounted cumulative gain, a commonly used class of metrics in learning to\nrank. Empirically, we demonstrate that our new method achieves higher expected\nprofit and expected precision compared to a classification approach for a wide\nvariety of application areas and data sets. This illustrates the benefit of an\nintegrated approach and of explicitly considering the available resources when\nlearning a predictive model.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2022-02-09T10:14:45+00:00",
    "updated": "2022-02-09T10:14:45+00:00",
    "url": "http://arxiv.org/pdf/2202.04369v1"
  },
  {
    "id": "2202.03310v2",
    "title": "Exploratory analysis of text duplication in peer-review reveals peer-review fraud and paper mills",
    "authors": [
      "Adam Day"
    ],
    "abstract": "Comments received from referees during peer-review were analysed to determine\nthe rates of duplication and partial duplication. It is very unusual for 2\ndifferent referees to submit identical comments, so the rare cases where this\nhappens are of interest. In some cases, it appears that paper-mills create fake\nreferee accounts and use them to submit fake peer-review reports. These include\ncomments that are copied and pasted across multiple reviews. Searching for\nduplication in referee comments is therefore an effective method to search for\nmisconduct generally, since the forms of misconduct committed by paper-mills go\nbeyond peer-review fraud. These search methods allow the automatic detection of\nmisconduct candidates which may then be investigated carefully to confirm if\nmisconduct has indeed taken place. There are innocent reasons why referees\nmight share template reports, so these methods are not intended to\nautomatically diagnose misconduct.",
    "categories": [
      "cs.DL"
    ],
    "published": "2022-02-07T15:55:24+00:00",
    "updated": "2022-02-15T09:39:03+00:00",
    "url": "http://arxiv.org/pdf/2202.03310v2"
  },
  {
    "id": "2203.12605v1",
    "title": "Grandes fraudes y gobiernos corporativos en la Economía desde mediados del siglo XX",
    "authors": [
      "I Martín-de-Santos"
    ],
    "abstract": "The international financial system is currently not yet prepared to face a\nforeseeable crisis mainly motivated by the dichotomy between the real economy\nand the virtual economy. Skepticism is widespread even when it comes to\ninvestments in sustainable economy. The concentration of capital in a few\npersons is one of the greatest risks for the possible reiteration of economic\ncrises. The benevolent sentences of the courts to some of the fraudsters do not\ncontribute to dispelling the ghost of fraud nor to the disappearance of tax\nhavens. From the diachronic perspective, it is observed that economic crises\nare increasingly frequent and incidents always in the financial field; which\nforces us to rethink an economic model on an international scale in which there\nis a greater weight of the economic policy of governments over the power of\nmultinational companies in the context of globalization. In the context of\nCorporate Social Responsibility, Corporate Governance is listed as one of the\nfundamental levers to curb large business fraud, but its efficiency seems\ninsufficient due to the lack of international regulations and the ignorance of\nhidden forces in what has been known as fiscal and financial engineering. The\napplication of liberal policies in an unorthodox way is causing real social\ngaps in the distribution of income and is undermining the current capitalist\nsystem. The need to implement corporate governments is recommended as one of\nthe essential formulas for sustaining the international economic system.",
    "categories": [
      "q-fin.GN"
    ],
    "published": "2022-02-06T20:16:20+00:00",
    "updated": "2022-02-06T20:16:20+00:00",
    "url": "http://arxiv.org/pdf/2203.12605v1"
  },
  {
    "id": "2203.16274v1",
    "title": "Characterizing YouTube and BitChute Content and Mobilizers During U.S. Election Fraud Discussions on Twitter",
    "authors": [
      "Matthew C. Childs",
      "Cody Buntain",
      "Milo Z. Trujillo",
      "Benjamin D. Horne"
    ],
    "abstract": "In this study, we characterize the cross-platform mobilization of YouTube and\nBitChute videos on Twitter during the 2020 U.S. Election fraud discussions.\nSpecifically, we extend the VoterFraud2020 dataset to describe the prevalence\nof content supplied by both platforms, the mobilizers of that content, the\nsuppliers of that content, and the content itself. We find that while BitChute\nvideos promoting election fraud claims were linked to and engaged with in the\nTwitter discussion, they played a relatively small role compared to YouTube\nvideos promoting fraud claims. This core finding points to the continued need\nfor proactive, consistent, and collaborative content moderation solutions\nrather than the reactive and inconsistent solutions currently being used.\nAdditionally, we find that cross-platform disinformation spread from video\nplatforms was not prominently from bot accounts or political elites, but rather\naverage Twitter users. This finding supports past work arguing that research on\ndisinformation should move beyond a focus on bots and trolls to a focus on\nparticipatory disinformation spread.",
    "categories": [
      "cs.SI"
    ],
    "published": "2022-03-30T13:10:40+00:00",
    "updated": "2022-03-30T13:10:40+00:00",
    "url": "http://arxiv.org/pdf/2203.16274v1"
  },
  {
    "id": "2203.15936v4",
    "title": "Supervised Graph Contrastive Learning for Few-shot Node Classification",
    "authors": [
      "Zhen Tan",
      "Kaize Ding",
      "Ruocheng Guo",
      "Huan Liu"
    ],
    "abstract": "Graphs are present in many real-world applications, such as financial fraud\ndetection, commercial recommendation, and social network analysis. But given\nthe high cost of graph annotation or labeling, we face a severe graph\nlabel-scarcity problem, i.e., a graph might have a few labeled nodes. One\nexample of such a problem is the so-called \\textit{few-shot node\nclassification}. A predominant approach to this problem resorts to\n\\textit{episodic meta-learning}. In this work, we challenge the status quo by\nasking a fundamental question whether meta-learning is a must for few-shot node\nclassification tasks. We propose a new and simple framework under the standard\nfew-shot node classification setting as an alternative to meta-learning to\nlearn an effective graph encoder. The framework consists of supervised graph\ncontrastive learning with novel mechanisms for data augmentation, subgraph\nencoding, and multi-scale contrast on graphs. Extensive experiments on three\nbenchmark datasets (CoraFull, Reddit, Ogbn) show that the new framework\nsignificantly outperforms state-of-the-art meta-learning based methods.",
    "categories": [
      "cs.LG"
    ],
    "published": "2022-03-29T22:30:00+00:00",
    "updated": "2022-08-05T05:52:22+00:00",
    "url": "http://arxiv.org/pdf/2203.15936v4"
  },
  {
    "id": "2203.15884v2",
    "title": "Radial Autoencoders for Enhanced Anomaly Detection",
    "authors": [
      "Mihai-Cezar Augustin",
      "Vivien Bonvin",
      "Regis Houssou",
      "Efstratios Rappos",
      "Stephan Robert-Nicoud"
    ],
    "abstract": "In classification problems, supervised machine-learning methods outperform\ntraditional algorithms, thanks to the ability of neural networks to learn\ncomplex patterns. However, in two-class classification tasks like anomaly or\nfraud detection, unsupervised methods could do even better, because their\nprediction is not limited to previously learned types of anomalies. An\nintuitive approach of anomaly detection can be based on the distances from the\ncenters of mass of the two respective classes. Autoencoders, although trained\nwithout supervision, can also detect anomalies: considering the center of mass\nof the normal points, reconstructions have now radii, with largest radii most\nlikely indicating anomalous points. Of course, radii-based classification were\nalready possible without interposing an autoencoder. In any space, radial\nclassification can be operated, to some extent. In order to outperform it, we\nproceed to radial deformations of data (i.e. centric compression or expansions\nof axes) and autoencoder training. Any autoencoder that makes use of a data\ncenter is here baptized a centric autoencoder (cAE). A special type is the cAE\ntrained with a uniformly compressed dataset, named the centripetal autoencoder\n(cpAE). The new concept is studied here in relation with a schematic artificial\ndataset, and the derived methods show consistent score improvements. But tested\non real banking data, our radial deformation supervised algorithms alone still\nperform better that cAEs, as expected from most supervised methods;\nnonetheless, in hybrid approaches, cAEs can be combined with a radial\ndeformation of space, improving its classification score. We expect that\ncentric autoencoders will become irreplaceable objects in anomaly live\ndetection based on geometry, thanks to their ability to stem naturally on\ngeometrical algorithms and to their native capability of detecting unknown\nanomaly types.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-03-29T20:07:30+00:00",
    "updated": "2022-03-31T08:29:14+00:00",
    "url": "http://arxiv.org/pdf/2203.15884v2"
  },
  {
    "id": "2203.15470v1",
    "title": "Graph similarity learning for change-point detection in dynamic networks",
    "authors": [
      "Deborah Sulem",
      "Henry Kenlay",
      "Mihai Cucuringu",
      "Xiaowen Dong"
    ],
    "abstract": "Dynamic networks are ubiquitous for modelling sequential graph-structured\ndata, e.g., brain connectome, population flows and messages exchanges. In this\nwork, we consider dynamic networks that are temporal sequences of graph\nsnapshots, and aim at detecting abrupt changes in their structure. This task is\noften termed network change-point detection and has numerous applications, such\nas fraud detection or physical motion monitoring. Leveraging a graph neural\nnetwork model, we design a method to perform online network change-point\ndetection that can adapt to the specific network domain and localise changes\nwith no delay. The main novelty of our method is to use a siamese graph neural\nnetwork architecture for learning a data-driven graph similarity function,\nwhich allows to effectively compare the current graph and its recent history.\nImportantly, our method does not require prior knowledge on the network\ngenerative distribution and is agnostic to the type of change-points; moreover,\nit can be applied to a large variety of networks, that include for instance\nedge weights and node attributes. We show on synthetic and real data that our\nmethod enjoys a number of benefits: it is able to learn an adequate graph\nsimilarity function for performing online network change-point detection in\ndiverse types of change-point settings, and requires a shorter data history to\ndetect changes than most existing state-of-the-art baselines.",
    "categories": [
      "stat.ML",
      "cs.LG",
      "q-fin.ST",
      "stat.AP",
      "stat.ME"
    ],
    "published": "2022-03-29T12:16:38+00:00",
    "updated": "2022-03-29T12:16:38+00:00",
    "url": "http://arxiv.org/pdf/2203.15470v1"
  },
  {
    "id": "2203.15563v1",
    "title": "Attacker Attribution of Audio Deepfakes",
    "authors": [
      "Nicolas M. Müller",
      "Franziska Dieckmann",
      "Jennifer Williams"
    ],
    "abstract": "Deepfakes are synthetically generated media often devised with malicious\nintent. They have become increasingly more convincing with large training\ndatasets advanced neural networks. These fakes are readily being misused for\nslander, misinformation and fraud. For this reason, intensive research for\ndeveloping countermeasures is also expanding. However, recent work is almost\nexclusively limited to deepfake detection - predicting if audio is real or\nfake. This is despite the fact that attribution (who created which fake?) is an\nessential building block of a larger defense strategy, as practiced in the\nfield of cybersecurity for a long time. This paper considers the problem of\ndeepfake attacker attribution in the domain of audio. We present several\nmethods for creating attacker signatures using low-level acoustic descriptors\nand machine learning embeddings. We show that speech signal features are\ninadequate for characterizing attacker signatures. However, we also demonstrate\nthat embeddings from a recurrent neural network can successfully characterize\nattacks from both known and unknown attackers. Our attack signature embeddings\nresult in distinct clusters, both for seen and unseen audio deepfakes. We show\nthat these embeddings can be used in downstream-tasks to high-effect, scoring\n97.10% accuracy in attacker-id classification.",
    "categories": [
      "cs.CR",
      "cs.LG",
      "cs.SD"
    ],
    "published": "2022-03-28T09:25:31+00:00",
    "updated": "2022-03-28T09:25:31+00:00",
    "url": "http://arxiv.org/pdf/2203.15563v1"
  },
  {
    "id": "2203.14088v1",
    "title": "Distributed data analytics",
    "authors": [
      "Richard Mortier",
      "Hamed Haddadi",
      "Sandra Servia",
      "Liang Wang"
    ],
    "abstract": "Machine Learning (ML) techniques have begun to dominate data analytics\napplications and services. Recommendation systems are a key component of online\nservice providers. The financial industry has adopted ML to harness large\nvolumes of data in areas such as fraud detection, risk-management, and\ncompliance. Deep Learning is the technology behind voice-based personal\nassistants, etc. Deployment of ML technologies onto cloud computing\ninfrastructures has benefited numerous aspects of our daily life. The\nadvertising and associated online industries in particular have fuelled a rapid\nrise the in deployment of personal data collection and analytics tools.\nTraditionally, behavioural analytics relies on collecting vast amounts of data\nin centralised cloud infrastructure before using it to train machine learning\nmodels that allow user behaviour and preferences to be inferred. A contrasting\napproach, distributed data analytics, where code and models for training and\ninference are distributed to the places where data is collected, has been\nboosted by two recent, ongoing developments: increased processing power and\nmemory capacity available in user devices at the edge of the network, such as\nsmartphones and home assistants; and increased sensitivity to the highly\nintrusive nature of many of these devices and services and the attendant\ndemands for improved privacy. Indeed, the potential for increased privacy is\nnot the only benefit of distributing data analytics to the edges of the\nnetwork: reducing the movement of large volumes of data can also improve energy\nefficiency, helping to ameliorate the ever increasing carbon footprint of our\ndigital infrastructure, enabling much lower latency for service interactions\nthan is possible when services are cloud-hosted. These approaches often\nintroduce challenges in privacy, utility, and efficiency trade-offs, while\nhaving to ensure fruitful user engagement.",
    "categories": [
      "cs.DC",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2022-03-26T14:10:51+00:00",
    "updated": "2022-03-26T14:10:51+00:00",
    "url": "http://arxiv.org/pdf/2203.14088v1"
  },
  {
    "id": "2203.12363v3",
    "title": "Ethereum Fraud Detection with Heterogeneous Graph Neural Networks",
    "authors": [
      "Hiroki Kanezashi",
      "Toyotaro Suzumura",
      "Xin Liu",
      "Takahiro Hirofuchi"
    ],
    "abstract": "While transactions with cryptocurrencies such as Ethereum are becoming more\nprevalent, fraud and other criminal transactions are not uncommon. Graph\nanalysis algorithms and machine learning techniques detect suspicious\ntransactions that lead to phishing in large transaction networks. Many graph\nneural network (GNN) models have been proposed to apply deep learning\ntechniques to graph structures. Although there is research on phishing\ndetection using GNN models in the Ethereum transaction network, models that\naddress the scale of the number of vertices and edges and the imbalance of\nlabels have not yet been studied. In this paper, we compared the model\nperformance of GNN models on the actual Ethereum transaction network dataset\nand phishing reported label data to exhaustively compare and verify which GNN\nmodels and hyperparameters produce the best accuracy. Specifically, we\nevaluated the model performance of representative homogeneous GNN models which\nconsider single-type nodes and edges and heterogeneous GNN models which support\ndifferent types of nodes and edges. We showed that heterogeneous models had\nbetter model performance than homogeneous models. In particular, the RGCN model\nachieved the best performance in the overall metrics.",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.SI"
    ],
    "published": "2022-03-23T12:35:59+00:00",
    "updated": "2022-07-04T08:55:10+00:00",
    "url": "http://arxiv.org/pdf/2203.12363v3"
  },
  {
    "id": "2203.09360v3",
    "title": "Behavior-aware Account De-anonymization on Ethereum Interaction Graph",
    "authors": [
      "Jiajun Zhou",
      "Chenkai Hu",
      "Jianlei Chi",
      "Jiajing Wu",
      "Meng Shen",
      "Qi Xuan"
    ],
    "abstract": "Blockchain technology has the characteristics of decentralization,\ntraceability and tamper-proof, which creates a reliable decentralized trust\nmechanism, further accelerating the development of blockchain finance. However,\nthe anonymization of blockchain hinders market regulation, resulting in\nincreasing illegal activities such as money laundering, gambling and phishing\nfraud on blockchain financial platforms. Thus, financial security has become a\ntop priority in the blockchain ecosystem, calling for effective market\nregulation. In this paper, we consider identifying Ethereum accounts from a\ngraph classification perspective, and propose an end-to-end graph neural\nnetwork framework named Ethident, to characterize the behavior patterns of\naccounts and further achieve account de-anonymization. Specifically, we first\nconstruct an Account Interaction Graph (AIG) using raw Ethereum data. Then we\ndesign a hierarchical graph attention encoder named HGATE as the backbone of\nour framework, which can effectively characterize the node-level account\nfeatures and subgraph-level behavior patterns. For alleviating account label\nscarcity, we further introduce contrastive self-supervision mechanism as\nregularization to jointly train our framework. Comprehensive experiments on\nEthereum datasets demonstrate that our framework achieves superior performance\nin account identification, yielding 1.13% ~ 4.93% relative improvement over\nprevious state-of-the-art. Furthermore, detailed analyses illustrate the\neffectiveness of Ethident in identifying and understanding the behavior of\nknown participants in Ethereum (e.g. exchanges, miners, etc.), as well as that\nof the lawbreakers (e.g. phishing scammers, hackers, etc.), which may aid in\nrisk assessment and market regulation.",
    "categories": [
      "cs.SI"
    ],
    "published": "2022-03-17T14:49:31+00:00",
    "updated": "2022-09-13T08:11:27+00:00",
    "url": "http://arxiv.org/pdf/2203.09360v3"
  },
  {
    "id": "2203.09026v1",
    "title": "Complex Network Analysis of the Bitcoin Transaction Network",
    "authors": [
      "Bishenghui Tao",
      "Hong-Ning Dai",
      "Jiajing Wu",
      "Ivan Wang-Hei Ho",
      "Zibin Zheng",
      "Chak Fong Cheang"
    ],
    "abstract": "In this brief, we conduct a complex-network analysis of the Bitcoin\ntransaction network. In particular, we design a new sampling method, namely\nrandom walk with flying-back (RWFB), to conduct effective data sampling. We\nthen conduct a comprehensive analysis of the Bitcoin network in terms of the\ndegree distribution, clustering coefficient, the shortest-path length,\nconnected component, centrality, assortativity, and the rich-club coefficient.\nWe obtain several important observations including the small-world phenomenon,\nmulti-center status, preferential attachment, and non-rich-club effect of the\ncurrent network. This work brings up an in-depth understanding of the current\nBitcoin blockchain network and offers implications for future directions in\nmalicious activity and fraud detection in cryptocurrency blockchain networks.",
    "categories": [
      "cs.SI",
      "05C40, 05C81, 05C82, 05C90",
      "H.3.3; E.1"
    ],
    "published": "2022-03-17T01:59:12+00:00",
    "updated": "2022-03-17T01:59:12+00:00",
    "url": "http://arxiv.org/pdf/2203.09026v1"
  },
  {
    "id": "2203.08642v2",
    "title": "Understanding motivations and characteristics of financially-motivated cybercriminals",
    "authors": [
      "Claudia Peersman",
      "Emma Williams",
      "Matthew Edwards",
      "Awais Rashid"
    ],
    "abstract": "Background: Cyber offences, such as hacking, malware creation and\ndistribution, and online fraud, present a substantial threat to organizations\nattempting to safeguard their data and information. By understanding the\nevolving characteristics and motivations of individuals involved in these\nactivities, and the threats that they may pose, cyber security practitioners\nwill be better placed to understand and assess current threats to their systems\nand the range of socio-technical mitigations that may best reduce these. Aim:\nThe reported work-in-progress aims to explore the extent to which findings from\nprior academic literature regarding the characteristics and motivations of\noffenders engaging in financially-motivated, cyber-dependent crime are\nsupported by the contemporary experiences and perspectives of practitioners\ncurrently working in the cyber crime field. Method: A targeted, online survey\nwas developed consisting of both closed and open-ended questions relating to\ncurrent cyber threats and the characteristics and motivations of offenders\nengaged in these activities. Sixteen practitioners working in law\nenforcement-related domains in the cyber crime field completed the survey,\nproviding a combination of qualitative and quantitative data for analysis.",
    "categories": [
      "cs.CR"
    ],
    "published": "2022-03-16T14:20:43+00:00",
    "updated": "2022-03-28T07:49:34+00:00",
    "url": "http://arxiv.org/pdf/2203.08642v2"
  },
  {
    "id": "2203.08019v1",
    "title": "Optimal Admission Control for Multiclass Queues with Time-Varying Arrival Rates via State Abstraction",
    "authors": [
      "Marc Rigter",
      "Danial Dervovic",
      "Parisa Hassanzadeh",
      "Jason Long",
      "Parisa Zehtabi",
      "Daniele Magazzeni"
    ],
    "abstract": "We consider a novel queuing problem where the decision-maker must choose to\naccept or reject randomly arriving tasks into a no buffer queue which are\nprocessed by $N$ identical servers. Each task has a price, which is a positive\nreal number, and a class. Each class of task has a different price distribution\nand service rate, and arrives according to an inhomogenous Poisson process. The\nobjective is to decide which tasks to accept so that the total price of tasks\nprocessed is maximised over a finite horizon. We formulate the problem as a\ndiscrete time Markov Decision Process (MDP) with a hybrid state space. We show\nthat the optimal value function has a specific structure, which enables us to\nsolve the hybrid MDP exactly. Moreover, we prove that as the time step is\nreduced, the discrete time solution approaches the optimal solution to the\noriginal continuous time problem. To improve the scalability of our approach to\na greater number of task classes, we present an approximation based on state\nabstraction. We validate our approach on synthetic data, as well as a real\nfinancial fraud data set, which is the motivating application for this work.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "published": "2022-03-14T12:38:13+00:00",
    "updated": "2022-03-14T12:38:13+00:00",
    "url": "http://arxiv.org/pdf/2203.08019v1"
  },
  {
    "id": "2203.05842v1",
    "title": "Multiple Inputs Neural Networks for Medicare fraud Detection",
    "authors": [
      "Mansour Zoubeirou A Mayaki",
      "Michel Riveill"
    ],
    "abstract": "Medicare fraud results in considerable losses for governments and insurance\ncompanies and results in higher premiums from clients. Medicare fraud costs\naround 13 billion euros in Europe and between 21 billion and 71 billion US\ndollars per year in the United States. This study aims to use artificial neural\nnetwork based classifiers to predict medicare fraud. The main difficulty using\nmachine learning techniques in fraud detection or more generally anomaly\ndetection is that the data sets are highly imbalanced. To detect medicare\nfrauds, we propose a multiple inputs deep neural network based classifier with\na Long-short Term Memory (LSTM) autoencoder component. This architecture makes\nit possible to take into account many sources of data without mixing them and\nmakes the classification task easier for the final model. The latent features\nextracted from the LSTM autoencoder have a strong discriminating power and\nseparate the providers into homogeneous clusters. We use the data sets from the\nCenters for Medicaid and Medicare Services (CMS) of the US federal government.\nThe CMS provides publicly available data that brings together all of the cost\nprice requests sent by American hospitals to medicare companies. Our results\nshow that although baseline artificial neural network give good performances,\nthey are outperformed by our multiple inputs neural networks. We have shown\nthat using a LSTM autoencoder to embed the provider behavior gives better\nresults and makes the classifiers more robust to class imbalance.",
    "categories": [
      "cs.LG"
    ],
    "published": "2022-03-11T10:36:53+00:00",
    "updated": "2022-03-11T10:36:53+00:00",
    "url": "http://arxiv.org/pdf/2203.05842v1"
  },
  {
    "id": "2203.02124v1",
    "title": "Abuse and Fraud Detection in Streaming Services Using Heuristic-Aware Machine Learning",
    "authors": [
      "Soheil Esmaeilzadeh",
      "Negin Salajegheh",
      "Amir Ziai",
      "Jeff Boote"
    ],
    "abstract": "This work presents a fraud and abuse detection framework for streaming\nservices by modeling user streaming behavior. The goal is to discover anomalous\nand suspicious incidents and scale the investigation efforts by creating models\nthat characterize the user behavior. We study the use of semi-supervised as\nwell as supervised approaches for anomaly detection. In the semi-supervised\napproach, by leveraging only a set of authenticated anomaly-free data samples,\nwe show the use of one-class classification algorithms as well as autoencoder\ndeep neural networks for anomaly detection. In the supervised anomaly detection\ntask, we present a so-called heuristic-aware data labeling strategy for\ncreating labeled data samples. We carry out binary classification as well as\nmulti-class multi-label classification tasks for not only detecting the\nanomalous samples but also identifying the underlying anomaly behavior(s)\nassociated with each one. Finally, using a systematic feature importance study\nwe provide insights into the underlying set of features that characterize\ndifferent streaming fraud categories. To the best of our knowledge, this is the\nfirst paper to use machine learning methods for fraud and abuse detection in\nreal-world scale streaming services.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-03-04T03:57:58+00:00",
    "updated": "2022-03-04T03:57:58+00:00",
    "url": "http://arxiv.org/pdf/2203.02124v1"
  },
  {
    "id": "2204.14025v1",
    "title": "Data+Shift: Supporting visual investigation of data distribution shifts by data scientists",
    "authors": [
      "João Palmeiro",
      "Beatriz Malveiro",
      "Rita Costa",
      "David Polido",
      "Ricardo Moreira",
      "Pedro Bizarro"
    ],
    "abstract": "Machine learning on data streams is increasingly more present in multiple\ndomains. However, there is often data distribution shift that can lead machine\nlearning models to make incorrect decisions. While there are automatic methods\nto detect when drift is happening, human analysis, often by data scientists, is\nessential to diagnose the causes of the problem and adjust the system. We\npropose Data+Shift, a visual analytics tool to support data scientists in the\ntask of investigating the underlying factors of shift in data features in the\ncontext of fraud detection. Design requirements were derived from interviews\nwith data scientists. Data+Shift is integrated with JupyterLab and can be used\nalongside other data science tools. We validated our approach with a\nthink-aloud experiment where a data scientist used the tool for a fraud\ndetection use case.",
    "categories": [
      "cs.LG",
      "cs.HC"
    ],
    "published": "2022-04-29T11:50:25+00:00",
    "updated": "2022-04-29T11:50:25+00:00",
    "url": "http://arxiv.org/pdf/2204.14025v1"
  },
  {
    "id": "2204.12347v1",
    "title": "Restricted Black-box Adversarial Attack Against DeepFake Face Swapping",
    "authors": [
      "Junhao Dong",
      "Yuan Wang",
      "Jianhuang Lai",
      "Xiaohua Xie"
    ],
    "abstract": "DeepFake face swapping presents a significant threat to online security and\nsocial media, which can replace the source face in an arbitrary photo/video\nwith the target face of an entirely different person. In order to prevent this\nfraud, some researchers have begun to study the adversarial methods against\nDeepFake or face manipulation. However, existing works focus on the white-box\nsetting or the black-box setting driven by abundant queries, which severely\nlimits the practical application of these methods. To tackle this problem, we\nintroduce a practical adversarial attack that does not require any queries to\nthe facial image forgery model. Our method is built on a substitute model\npersuing for face reconstruction and then transfers adversarial examples from\nthe substitute model directly to inaccessible black-box DeepFake models.\nSpecially, we propose the Transferable Cycle Adversary Generative Adversarial\nNetwork (TCA-GAN) to construct the adversarial perturbation for disrupting\nunknown DeepFake systems. We also present a novel post-regularization module\nfor enhancing the transferability of generated adversarial examples. To\ncomprehensively measure the effectiveness of our approaches, we construct a\nchallenging benchmark of DeepFake adversarial attacks for future development.\nExtensive experiments impressively show that the proposed adversarial attack\nmethod makes the visual quality of DeepFake face images plummet so that they\nare easier to be detected by humans and algorithms. Moreover, we demonstrate\nthat the proposed algorithm can be generalized to offer face image protection\nagainst various face translation methods.",
    "categories": [
      "cs.CV",
      "cs.CR"
    ],
    "published": "2022-04-26T14:36:06+00:00",
    "updated": "2022-04-26T14:36:06+00:00",
    "url": "http://arxiv.org/pdf/2204.12347v1"
  },
  {
    "id": "2204.10085v2",
    "title": "Forgetting Prevention for Cross-regional Fraud Detection with Heterogeneous Trade Graph",
    "authors": [
      "Yujie Li",
      "Yuxuan Yang",
      "Xin Yang",
      "Qiang Gao",
      "Fan Zhou"
    ],
    "abstract": "With the booming growth of e-commerce, detecting financial fraud has become\nan urgent task to avoid transaction risks. Despite the successful applications\nof Graph Neural Networks (GNNs) in fraud detection, the existing solutions are\nonly suitable for a narrow scope due to the limitation in data collection.\nEspecially when expanding a business into new territory, e.g., new cities or\nnew countries, developing a totally new model will bring the cost issue and\nresult in forgetting previous knowledge. Moreover, recent works strive to\ndevise GNNs to expose the implicit interactions behind financial transactions.\nHowever, most existing GNNs-based solutions concentrate on either homogeneous\ngraphs or decomposing heterogeneous interactions into several homogeneous\nconnections for convenience. To this end, this study proposes a novel solution\nbased on heterogeneous trade graphs, namely HTG-CFD, to prevent knowledge\nforgetting of cross-regional fraud detection. In particular, the heterogeneous\ntrade graph (HTG) is meticulously constructed from original transaction records\nto explore the complex semantics among different types of entities and\nrelationships. And motivated by recent continual learning, we present a\npractical and task-oriented forgetting prevention method to alleviate knowledge\nforgetting in the context of cross-regional detection. Extensive experiments\ndemonstrate that the proposed HTG-CFD not only promotes the performance in\ncross-regional scenarios but also significantly contributes to single-regional\nfraud detection.",
    "categories": [
      "cs.CE"
    ],
    "published": "2022-04-21T13:25:22+00:00",
    "updated": "2022-05-22T12:10:56+00:00",
    "url": "http://arxiv.org/pdf/2204.10085v2"
  },
  {
    "id": "2204.09825v1",
    "title": "A Revealing Large-Scale Evaluation of Unsupervised Anomaly Detection Algorithms",
    "authors": [
      "Maxime Alvarez",
      "Jean-Charles Verdier",
      "D'Jeff K. Nkashama",
      "Marc Frappier",
      "Pierre-Martin Tardif",
      "Froduald Kabanza"
    ],
    "abstract": "Anomaly detection has many applications ranging from bank-fraud detection and\ncyber-threat detection to equipment maintenance and health monitoring. However,\nchoosing a suitable algorithm for a given application remains a challenging\ndesign decision, often informed by the literature on anomaly detection\nalgorithms. We extensively reviewed twelve of the most popular unsupervised\nanomaly detection methods. We observed that, so far, they have been compared\nusing inconsistent protocols - the choice of the class of interest or the\npositive class, the split of training and test data, and the choice of\nhyperparameters - leading to ambiguous evaluations. This observation led us to\ndefine a coherent evaluation protocol which we then used to produce an updated\nand more precise picture of the relative performance of the twelve methods on\nfive widely used tabular datasets. While our evaluation cannot pinpoint a\nmethod that outperforms all the others on all datasets, it identifies those\nthat stand out and revise misconceived knowledge about their relative\nperformances.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2022-04-21T00:17:12+00:00",
    "updated": "2022-04-21T00:17:12+00:00",
    "url": "http://arxiv.org/pdf/2204.09825v1"
  },
  {
    "id": "2205.06742v2",
    "title": "Neurochaos Feature Transformation and Classification for Imbalanced Learning",
    "authors": [
      "Deeksha Sethi",
      "Nithin Nagaraj",
      "Harikrishnan N B"
    ],
    "abstract": "Learning from limited and imbalanced data is a challenging problem in the\nArtificial Intelligence community. Real-time scenarios demand decision-making\nfrom rare events wherein the data are typically imbalanced. These situations\ncommonly arise in medical applications, cybersecurity, catastrophic predictions\netc. This motivates the development of learning algorithms capable of learning\nfrom imbalanced data. Human brain effortlessly learns from imbalanced data.\nInspired by the chaotic neuronal firing in the human brain, a novel learning\nalgorithm namely Neurochaos Learning (NL) was recently proposed. NL is\ncategorized in three blocks: Feature Transformation, Neurochaos Feature\nExtraction (CFX), and Classification. In this work, the efficacy of neurochaos\nfeature transformation and extraction for classification in imbalanced learning\nis studied. We propose a unique combination of neurochaos based feature\ntransformation and extraction with traditional ML algorithms. The explored\ndatasets in this study revolve around medical diagnosis, banknote fraud\ndetection, environmental applications and spoken-digit classification. In this\nstudy, experiments are performed in both high and low training sample regime.\nIn the former, five out of nine datasets have shown a performance boost in\nterms of macro F1-score after using CFX features. The highest performance boost\nobtained is 25.97% for Statlog (Heart) dataset using CFX+Decision Tree. In the\nlow training sample regime (from just one to nine training samples per class),\nthe highest performance boost of 144.38% is obtained for Haberman's Survival\ndataset using CFX+Random Forest. NL offers enormous flexibility of combining\nCFX with any ML classifier to boost its performance, especially for learning\ntasks with limited and imbalanced data.",
    "categories": [
      "cs.NE",
      "cs.LG"
    ],
    "published": "2022-04-20T16:11:45+00:00",
    "updated": "2022-05-16T15:13:54+00:00",
    "url": "http://arxiv.org/pdf/2205.06742v2"
  },
  {
    "id": "2204.08916v1",
    "title": "Heterogeneous Feature Augmentation for Ponzi Detection in Ethereum",
    "authors": [
      "Chengxiang Jin",
      "Jie Jin",
      "Jiajun Zhou",
      "Jiajing Wu",
      "Qi Xuan"
    ],
    "abstract": "While blockchain technology triggers new industrial and technological\nrevolutions, it also brings new challenges. Recently, a large number of new\nscams with a \"blockchain\" sock-puppet continue to emerge, such as Ponzi\nschemes, money laundering, etc., seriously threatening financial security.\nExisting fraud detection methods in blockchain mainly concentrate on manual\nfeature and graph analytics, which first construct a homogeneous transaction\ngraph using partial blockchain data and then use graph analytics to detect\nanomaly, resulting in a loss of pattern information. In this paper, we mainly\nfocus on Ponzi scheme detection and propose HFAug, a generic Heterogeneous\nFeature Augmentation module that can capture the heterogeneous information\nassociated with account behavior patterns and can be combined with existing\nPonzi detection methods. HFAug learns the metapath-based behavior\ncharacteristics in an auxiliary heterogeneous interaction graph, and aggregates\nthe heterogeneous features to corresponding account nodes in the homogeneous\none where the Ponzi detection methods are performed. Comprehensive experimental\nresults demonstrate that our HFAug can help existing Ponzi detection methods\nachieve significant performance improvement on Ethereum datasets, suggesting\nthe effectiveness of heterogeneous information on detecting Ponzi schemes.",
    "categories": [
      "cs.CR",
      "cs.SI"
    ],
    "published": "2022-04-19T14:27:23+00:00",
    "updated": "2022-04-19T14:27:23+00:00",
    "url": "http://arxiv.org/pdf/2204.08916v1"
  },
  {
    "id": "2204.08896v1",
    "title": "Model Checking Strategic Abilities in Information-sharing Systems",
    "authors": [
      "Francesco Belardinelli",
      "Ioana Boureanu",
      "Catalin Dima",
      "Vadim Malvone"
    ],
    "abstract": "We introduce a subclass of concurrent game structures (CGS) with imperfect\ninformation in which agents are endowed with private data-sharing capabilities.\nImportantly, our CGSs are such that it is still decidable to model-check these\nCGSs against a relevant fragment of ATL. These systems can be thought as a\ngeneralisation of architectures allowing information forks, in the sense that,\nin the initial states of the system, we allow information forks from agents\noutside a given set A to agents inside this A. For this reason, together with\nthe fact that the communication in our models underpins a specialised form of\nbroadcast, we call our formalism A-cast systems. To underline, the fragment of\nATL for which we show the model-checking problem to be decidable over A-cast is\na large and significant one; it expresses coalitions over agents in any subset\nof the set A. Indeed, as we show, our systems and this ATL fragments can encode\nsecurity problems that are notoriously hard to express faithfully:\nterrorist-fraud attacks in identity schemes.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "published": "2022-04-19T13:47:56+00:00",
    "updated": "2022-04-19T13:47:56+00:00",
    "url": "http://arxiv.org/pdf/2204.08896v1"
  },
  {
    "id": "2204.08194v1",
    "title": "Phishing Fraud Detection on Ethereum using Graph Neural Network",
    "authors": [
      "Panpan Li",
      "Yunyi Xie",
      "Xinyao Xu",
      "Jiajun Zhou",
      "Qi Xuan"
    ],
    "abstract": "Blockchain has widespread applications in the financial field but has also\nattracted increasing cybercrimes. Recently, phishing fraud has emerged as a\nmajor threat to blockchain security, calling for the development of effective\nregulatory strategies. Nowadays network science has been widely used in\nmodeling Ethereum transaction data, further introducing the network\nrepresentation learning technology to analyze the transaction patterns. In this\npaper, we consider phishing detection as a graph classification task and\npropose an end-to-end Phishing Detection Graph Neural Network framework\n(PDGNN). Specifically, we first construct a lightweight Ethereum transaction\nnetwork and extract transaction subgraphs of collected phishing accounts. Then\nwe propose an end-to-end detection model based on Chebyshev-GCN to precisely\ndistinguish between normal and phishing accounts. Extensive experiments on five\nEthereum datasets demonstrate that our PDGNN significantly outperforms general\nphishing detection methods and scales well in large transaction networks.",
    "categories": [
      "cs.SI"
    ],
    "published": "2022-04-18T07:16:52+00:00",
    "updated": "2022-04-18T07:16:52+00:00",
    "url": "http://arxiv.org/pdf/2204.08194v1"
  },
  {
    "id": "2204.07016v1",
    "title": "The de Finetti problem with unknown competition",
    "authors": [
      "Erik Ekström",
      "Alessandro Milazzo",
      "Marcus Olofsson"
    ],
    "abstract": "We consider a resource extraction problem which extends the classical de\nFinetti problem for a Wiener process to include the case when a competitor, who\nis equipped with the possibility to extract all the remaining resources in one\npiece, may exist; we interpret this unknown competition as the agent being\nsubject to possible fraud. This situation is modelled as a\ncontroller-and-stopper non-zero-sum stochastic game with incomplete\ninformation. In order to allow the fraudster to hide his existence, we consider\nstrategies where his action time is randomised. Under these conditions, we\nprovide a Nash equilibrium which is fully described in terms of the\ncorresponding single-player de Finetti problem. In this equilibrium, the agent\nand the fraudster use singular strategies in such a way that a two-dimensional\nprocess, which represents available resources and the filtering estimate of\nactive competition, reflects in a specific direction along a given boundary.",
    "categories": [
      "math.OC"
    ],
    "published": "2022-04-14T15:13:27+00:00",
    "updated": "2022-04-14T15:13:27+00:00",
    "url": "http://arxiv.org/pdf/2204.07016v1"
  },
  {
    "id": "2204.06109v1",
    "title": "Prediction of motor insurance claims occurrence as an imbalanced machine learning problem",
    "authors": [
      "Sebastian Baran",
      "Przemysław Rola"
    ],
    "abstract": "The insurance industry, with its large datasets, is a natural place to use\nbig data solutions. However it must be stressed, that significant number of\napplications for machine learning in insurance industry, like fraud detection\nor claim prediction, deals with the problem of machine learning on an\nimbalanced data set. This is due to the fact that frauds or claims are rare\nevents when compared with the entire population of drivers. The problem of\nimbalanced learning is often hard to overcome. Therefore, the main goal of this\nwork is to present and apply various methods of dealing with an imbalanced\ndataset in the context of claim occurrence prediction in car insurance. In\naddition, the above techniques are used to compare the results of machine\nlearning algorithms in the context of claim occurrence prediction in car\ninsurance. Our study covers the following techniques: logistic-regression,\ndecision tree, random forest, xgBoost, feed-forward network. The problem is the\nclassification one.",
    "categories": [
      "q-fin.ST",
      "cs.LG"
    ],
    "published": "2022-04-12T22:41:47+00:00",
    "updated": "2022-04-12T22:41:47+00:00",
    "url": "http://arxiv.org/pdf/2204.06109v1"
  },
  {
    "id": "2204.05265v1",
    "title": "The Importance of Future Information in Credit Card Fraud Detection",
    "authors": [
      "Van Bach Nguyen",
      "Kanishka Ghosh Dastidar",
      "Michael Granitzer",
      "Wissam Siblini"
    ],
    "abstract": "Fraud detection systems (FDS) mainly perform two tasks: (i) real-time\ndetection while the payment is being processed and (ii) posterior detection to\nblock the card retrospectively and avoid further frauds. Since human\nverification is often necessary and the payment processing time is limited, the\nsecond task manages the largest volume of transactions. In the literature,\nfraud detection challenges and algorithms performance are widely studied but\nthe very formulation of the problem is never disrupted: it aims at predicting\nif a transaction is fraudulent based on its characteristics and the past\ntransactions of the cardholder. Yet, in posterior detection, verification often\ntakes days, so new payments on the card become available before a decision is\ntaken. This is our motivation to propose a new paradigm: posterior fraud\ndetection with \"future\" information. We start by providing evidence of the\non-time availability of subsequent transactions, usable as extra context to\nimprove detection. We then design a Bidirectional LSTM to make use of these\ntransactions. On a real-world dataset with over 30 million transactions, it\nachieves higher performance than a regular LSTM, which is the state-of-the-art\nclassifier for fraud detection that only uses the past context. We also\nintroduce new metrics to show that the proposal catches more frauds, more\ncompromised cards, and based on their earliest frauds. We believe that future\nworks on this new paradigm will have a significant impact on the detection of\ncompromised cards.",
    "categories": [
      "cs.LG"
    ],
    "published": "2022-04-11T17:11:34+00:00",
    "updated": "2022-04-11T17:11:34+00:00",
    "url": "http://arxiv.org/pdf/2204.05265v1"
  },
  {
    "id": "2205.15300v1",
    "title": "A Combination of Deep Neural Networks and K-Nearest Neighbors for Credit Card Fraud Detection",
    "authors": [
      "Dinara Rzayeva",
      "Saber Malekzadeh"
    ],
    "abstract": "Detection of a Fraud transaction on credit cards became one of the major\nproblems for financial institutions, organizations and companies. As the global\nfinancial system is highly connected to non-cash transactions and online\noperations fraud makers invent more effective ways to access customers'\nfinances. The main problem in credit card fraud detection is that the number of\nfraud transactions is significantly lower than genuine ones. The aim of the\npaper is to implement new techniques, which contains of under-sampling\nalgorithms, K-nearest Neighbor Algorithm (KNN) and Deep Neural Network (KNN) on\nnew obtained dataset. The performance evaluation showed that DNN model gives\nprecise high accuracy (98.12%), which shows the good ability of presented\nmethod to detect fraudulent transactions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-05-27T10:33:27+00:00",
    "updated": "2022-05-27T10:33:27+00:00",
    "url": "http://arxiv.org/pdf/2205.15300v1"
  },
  {
    "id": "2205.13845v1",
    "title": "Raising the Bar in Graph-level Anomaly Detection",
    "authors": [
      "Chen Qiu",
      "Marius Kloft",
      "Stephan Mandt",
      "Maja Rudolph"
    ],
    "abstract": "Graph-level anomaly detection has become a critical topic in diverse areas,\nsuch as financial fraud detection and detecting anomalous activities in social\nnetworks. While most research has focused on anomaly detection for visual data\nsuch as images, where high detection accuracies have been obtained, existing\ndeep learning approaches for graphs currently show considerably worse\nperformance. This paper raises the bar on graph-level anomaly detection, i.e.,\nthe task of detecting abnormal graphs in a set of graphs. By drawing on ideas\nfrom self-supervised learning and transformation learning, we present a new\ndeep learning approach that significantly improves existing deep one-class\napproaches by fixing some of their known problems, including hypersphere\ncollapse and performance flip. Experiments on nine real-world data sets\ninvolving nine techniques reveal that our method achieves an average\nperformance improvement of 11.8% AUC compared to the best existing approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-05-27T09:17:57+00:00",
    "updated": "2022-05-27T09:17:57+00:00",
    "url": "http://arxiv.org/pdf/2205.13845v1"
  },
  {
    "id": "2205.13084v2",
    "title": "BRIGHT -- Graph Neural Networks in Real-Time Fraud Detection",
    "authors": [
      "Mingxuan Lu",
      "Zhichao Han",
      "Susie Xi Rao",
      "Zitao Zhang",
      "Yang Zhao",
      "Yinan Shan",
      "Ramesh Raghunathan",
      "Ce Zhang",
      "Jiawei Jiang"
    ],
    "abstract": "Detecting fraudulent transactions is an essential component to control risk\nin e-commerce marketplaces. Apart from rule-based and machine learning filters\nthat are already deployed in production, we want to enable efficient real-time\ninference with graph neural networks (GNNs), which is useful to catch multihop\nrisk propagation in a transaction graph. However, two challenges arise in the\nimplementation of GNNs in production. First, future information in a dynamic\ngraph should not be considered in message passing to predict the past. Second,\nthe latency of graph query and GNN model inference is usually up to hundreds of\nmilliseconds, which is costly for some critical online services. To tackle\nthese challenges, we propose a Batch and Real-time Inception GrapH Topology\n(BRIGHT) framework to conduct an end-to-end GNN learning that allows efficient\nonline real-time inference. BRIGHT framework consists of a graph transformation\nmodule (Two-Stage Directed Graph) and a corresponding GNN architecture (Lambda\nNeural Network). The Two-Stage Directed Graph guarantees that the information\npassed through neighbors is only from the historical payment transactions. It\nconsists of two subgraphs representing historical relationships and real-time\nlinks, respectively. The Lambda Neural Network decouples inference into two\nstages: batch inference of entity embeddings and real-time inference of\ntransaction prediction. Our experiments show that BRIGHT outperforms the\nbaseline models by >2\\% in average w.r.t.~precision. Furthermore, BRIGHT is\ncomputationally efficient for real-time fraud detection. Regarding end-to-end\nperformance (including neighbor query and inference), BRIGHT can reduce the P99\nlatency by >75\\%. For the inference stage, our speedup is on average\n7.8$\\times$ compared to the traditional GNN.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-05-25T23:51:27+00:00",
    "updated": "2022-08-24T07:32:16+00:00",
    "url": "http://arxiv.org/pdf/2205.13084v2"
  },
  {
    "id": "2205.12706v4",
    "title": "Maximum Mean Discrepancy on Exponential Windows for Online Change Detection",
    "authors": [
      "Florian Kalinke",
      "Marco Heyden",
      "Georg Gntuni",
      "Edouard Fouché",
      "Klemens Böhm"
    ],
    "abstract": "Detecting changes is of fundamental importance when analyzing data streams\nand has many applications, e.g., in predictive maintenance, fraud detection, or\nmedicine. A principled approach to detect changes is to compare the\ndistributions of observations within the stream to each other via hypothesis\ntesting. Maximum mean discrepancy (MMD), a (semi-)metric on the space of\nprobability distributions, provides powerful non-parametric two-sample tests on\nkernel-enriched domains. In particular, MMD is able to detect any disparity\nbetween distributions under mild conditions. However, classical MMD estimators\nsuffer from a quadratic runtime complexity, which renders their direct use for\nchange detection in data streams impractical. In this article, we propose a new\nchange detection algorithm, called Maximum Mean Discrepancy on Exponential\nWindows (MMDEW), that combines the benefits of MMD with an efficient\ncomputation based on exponential windows. We prove that MMDEW enjoys\npolylogarithmic runtime and logarithmic memory complexity and show empirically\nthat it outperforms the state of the art on benchmark data streams.",
    "categories": [
      "cs.LG",
      "I.2.6; H.1.1"
    ],
    "published": "2022-05-25T12:02:59+00:00",
    "updated": "2025-02-12T09:33:52+00:00",
    "url": "http://arxiv.org/pdf/2205.12706v4"
  },
  {
    "id": "2205.10075v1",
    "title": "Decentralized Autonomous Organizations for Tax Credit's Tracking",
    "authors": [
      "Giovanni De Gasperis",
      "Sante Dino Facchini",
      "Alessio Susco"
    ],
    "abstract": "Tax credit stimulus and fiscal bonuses had a very important impact on Italian\neconomy in the last decade. Along with a huge expansion in constructions a\nrelevant increase in scams and frauds has come too. The aim of this article is\nto design a possible system to track and control the whole tax credit process\nfrom its generation to its redeem through a Decentralized Autonomous\nOrganization architecture enriched with a Multi Agent Systems to implement\ncontrollers.",
    "categories": [
      "cs.MA"
    ],
    "published": "2022-05-20T10:43:39+00:00",
    "updated": "2022-05-20T10:43:39+00:00",
    "url": "http://arxiv.org/pdf/2205.10075v1"
  },
  {
    "id": "2205.10045v1",
    "title": "ExMo: Explainable AI Model using Inverse Frequency Decision Rules",
    "authors": [
      "Pradip Mainali",
      "Ismini Psychoula",
      "Fabien A. P. Petitcolas"
    ],
    "abstract": "In this paper, we present a novel method to compute decision rules to build a\nmore accurate interpretable machine learning model, denoted as ExMo. The ExMo\ninterpretable machine learning model consists of a list of IF...THEN...\nstatements with a decision rule in the condition. This way, ExMo naturally\nprovides an explanation for a prediction using the decision rule that was\ntriggered. ExMo uses a new approach to extract decision rules from the training\ndata using term frequency-inverse document frequency (TF-IDF) features. With\nTF-IDF, decision rules with feature values that are more relevant to each class\nare extracted. Hence, the decision rules obtained by ExMo can distinguish the\npositive and negative classes better than the decision rules used in the\nexisting Bayesian Rule List (BRL) algorithm, obtained using the frequent\npattern mining approach. The paper also shows that ExMo learns a qualitatively\nbetter model than BRL. Furthermore, ExMo demonstrates that the textual\nexplanation can be provided in a human-friendly way so that the explanation can\nbe easily understood by non-expert users. We validate ExMo on several datasets\nwith different sizes to evaluate its efficacy. Experimental validation on a\nreal-world fraud detection application shows that ExMo is 20% more accurate\nthan BRL and that it achieves accuracy similar to those of deep learning\nmodels.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2022-05-20T09:36:49+00:00",
    "updated": "2022-05-20T09:36:49+00:00",
    "url": "http://arxiv.org/pdf/2205.10045v1"
  },
  {
    "id": "2205.04816v1",
    "title": "Reconstruction Enhanced Multi-View Contrastive Learning for Anomaly Detection on Attributed Networks",
    "authors": [
      "Jiaqiang Zhang",
      "Senzhang Wang",
      "Songcan Chen"
    ],
    "abstract": "Detecting abnormal nodes from attributed networks is of great importance in\nmany real applications, such as financial fraud detection and cyber security.\nThis task is challenging due to both the complex interactions between the\nanomalous nodes with other counterparts and their inconsistency in terms of\nattributes. This paper proposes a self-supervised learning framework that\njointly optimizes a multi-view contrastive learning-based module and an\nattribute reconstruction-based module to more accurately detect anomalies on\nattributed networks. Specifically, two contrastive learning views are firstly\nestablished, which allow the model to better encode rich local and global\ninformation related to the abnormality. Motivated by the attribute consistency\nprinciple between neighboring nodes, a masked autoencoder-based reconstruction\nmodule is also introduced to identify the nodes which have large reconstruction\nerrors, then are regarded as anomalies. Finally, the two complementary modules\nare integrated for more accurately detecting the anomalous nodes. Extensive\nexperiments conducted on five benchmark datasets show our model outperforms\ncurrent state-of-the-art models.",
    "categories": [
      "cs.LG"
    ],
    "published": "2022-05-10T11:35:32+00:00",
    "updated": "2022-05-10T11:35:32+00:00",
    "url": "http://arxiv.org/pdf/2205.04816v1"
  },
  {
    "id": "2205.04646v1",
    "title": "Crypto Pump and Dump Detection via Deep Learning Techniques",
    "authors": [
      "Viswanath Chadalapaka",
      "Kyle Chang",
      "Gireesh Mahajan",
      "Anuj Vasil"
    ],
    "abstract": "Despite the fact that cryptocurrencies themselves have experienced an\nastonishing rate of adoption over the last decade, cryptocurrency fraud\ndetection is a heavily under-researched problem area. Of all fraudulent\nactivity regarding cryptocurrencies, pump and dump schemes are some of the most\ncommon. Though some studies have been done on these kinds of scams in the stock\nmarket, the lack of labelled stock data and the volatility unique to the\ncryptocurrency space constrains the applicability of studies on the stock\nmarket toward this problem domain. Furthermore, the only work done in this\nspace thus far has been either statistical in nature, or has been concerned\nwith classical machine learning models such as random forest trees. We propose\nthe novel application of two existing neural network architectures to this\nproblem domain and show that deep learning solutions can significantly\noutperform all other existing pump and dump detection methods for\ncryptocurrencies.",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "published": "2022-05-10T03:24:32+00:00",
    "updated": "2022-05-10T03:24:32+00:00",
    "url": "http://arxiv.org/pdf/2205.04646v1"
  },
  {
    "id": "2205.04626v1",
    "title": "On some studies of Fraud Detection Pipeline and related issues from the scope of Ensemble Learning and Graph-based Learning",
    "authors": [
      "Tuan Tran"
    ],
    "abstract": "The UK anti-fraud charity Fraud Advisory Panel (FAP) in their review of 2016\nestimates business costs of fraud at 144 billion, and its individual\ncounterpart at 9.7 billion. Banking, insurance, manufacturing, and government\nare the most common industries affected by fraud activities. Designing an\nefficient fraud detection system could avoid losing the money; however,\nbuilding this system is challenging due to many difficult problems,\ne.g.imbalanced data, computing costs, etc. Over the last three decades, there\nare various research relates to fraud detection but no agreement on what is the\nbest approach to build the fraud detection system. In this thesis, we aim to\nanswer some questions such as i) how to build a simplified and effective Fraud\nDetection System that not only easy to implement but also providing reliable\nresults and our proposed Fraud Detection Pipeline is a potential backbone of\nthe system and is easy to be extended or upgraded, ii) when to update models in\nour system (and keep the accuracy stable) in order to reduce the cost of\nupdating process, iii) how to deal with an extreme imbalance in big data\nclassification problem, e.g. fraud detection, since this is the gap between two\ndifficult problems, iv) further, how to apply graph-based semi-supervised\nlearning to detect fraudulent transactions.",
    "categories": [
      "cs.LG"
    ],
    "published": "2022-05-10T02:13:58+00:00",
    "updated": "2022-05-10T02:13:58+00:00",
    "url": "http://arxiv.org/pdf/2205.04626v1"
  },
  {
    "id": "2205.03045v3",
    "title": "Variational quantum algorithm for unconstrained black box binary optimization: Application to feature selection",
    "authors": [
      "Christa Zoufal",
      "Ryan V. Mishmash",
      "Nitin Sharma",
      "Niraj Kumar",
      "Aashish Sheshadri",
      "Amol Deshmukh",
      "Noelle Ibrahim",
      "Julien Gacon",
      "Stefan Woerner"
    ],
    "abstract": "We introduce a variational quantum algorithm to solve unconstrained black box\nbinary optimization problems, i.e., problems in which the objective function is\ngiven as black box. This is in contrast to the typical setting of quantum\nalgorithms for optimization where a classical objective function is provided as\na given Quadratic Unconstrained Binary Optimization problem and mapped to a sum\nof Pauli operators. Furthermore, we provide theoretical justification for our\nmethod based on convergence guarantees of quantum imaginary time evolution. To\ninvestigate the performance of our algorithm and its potential advantages, we\ntackle a challenging real-world optimization problem: feature selection. This\nrefers to the problem of selecting a subset of relevant features to use for\nconstructing a predictive model such as fraud detection. Optimal feature\nselection -- when formulated in terms of a generic loss function -- offers\nlittle structure on which to build classical heuristics, thus resulting\nprimarily in 'greedy methods'. This leaves room for (near-term) quantum\nalgorithms to be competitive to classical state-of-the-art approaches. We apply\nour quantum-optimization-based feature selection algorithm, termed VarQFS, to\nbuild a predictive model for a credit risk data set with 20 and 59 input\nfeatures (qubits) and train the model using quantum hardware and\ntensor-network-based numerical simulations, respectively. We show that the\nquantum method produces competitive and in certain aspects even better\nperformance compared to traditional feature selection techniques used in\ntoday's industry.",
    "categories": [
      "quant-ph"
    ],
    "published": "2022-05-06T07:02:15+00:00",
    "updated": "2023-01-25T10:20:58+00:00",
    "url": "http://arxiv.org/pdf/2205.03045v3"
  },
  {
    "id": "2205.01932v1",
    "title": "Early Detection of Spam Domains with Passive DNS and SPF",
    "authors": [
      "Simon Fernandez",
      "Maciej Korczyński",
      "Andrzej Duda"
    ],
    "abstract": "Spam domains are sources of unsolicited mails and one of the primary vehicles\nfor fraud and malicious activities such as phishing campaigns or malware\ndistribution. Spam domain detection is a race: as soon as the spam mails are\nsent, taking down the domain or blacklisting it is of relative use, as spammers\nhave to register a new domain for their next campaign. To prevent malicious\nactors from sending mails, we need to detect them as fast as possible and,\nideally, even before the campaign is launched. In this paper, using\nnear-real-time passive DNS data from Farsight Security, we monitor the DNS\ntraffic of newly registered domains and the contents of their TXT records, in\nparticular, the configuration of the Sender Policy Framework, an anti-spoofing\nprotocol for domain names and the first line of defense against devastating\nBusiness Email Compromise scams. Because spammers and benign domains have\ndifferent SPF rules and different traffic profiles, we build a new method to\ndetect spam domains using features collected from passive DNS traffic. Using\nthe SPF configuration and the traffic to the TXT records of a domain, we\naccurately detect a significant proportion of spam domains with a low false\npositives rate demonstrating its potential in real-world deployments. Our\nclassification scheme can detect spam domains before they send any mail, using\nonly a single DNS query and later on, it can refine its classification by\nmonitoring more traffic to the domain name.",
    "categories": [
      "cs.CR"
    ],
    "published": "2022-05-04T08:10:11+00:00",
    "updated": "2022-05-04T08:10:11+00:00",
    "url": "http://arxiv.org/pdf/2205.01932v1"
  },
  {
    "id": "2206.15335v1",
    "title": "Byzantine Agreement with Optimal Resilience via Statistical Fraud Detection",
    "authors": [
      "Shang-En Huang",
      "Seth Pettie",
      "Leqi Zhu"
    ],
    "abstract": "Since the mid-1980s it has been known that Byzantine Agreement can be solved\nwith probability 1 asynchronously, even against an omniscient, computationally\nunbounded adversary that can adaptively \\emph{corrupt} up to $f<n/3$ parties.\nMoreover, the problem is insoluble with $f\\geq n/3$ corruptions. However,\nBracha's 1984 protocol achieved $f<n/3$ resilience at the cost of exponential\nexpected latency $2^{\\Theta(n)}$, a bound that has never been improved in this\nmodel with $f=\\lfloor (n-1)/3 \\rfloor$ corruptions.\n  In this paper we prove that Byzantine Agreement in the asynchronous, full\ninformation model can be solved with probability 1 against an adaptive\nadversary that can corrupt $f<n/3$ parties, while incurring only polynomial\nlatency with high probability. Our protocol follows earlier polynomial latency\nprotocols of King and Saia and Huang, Pettie, and Zhu, which had suboptimal\nresilience, namely $f \\approx n/10^9$ and $f<n/4$, respectively.\n  Resilience $f=(n-1)/3$ is uniquely difficult as this is the point at which\nthe influence of the Byzantine and honest players are of roughly equal\nstrength. The core technical problem we solve is to design a collective\ncoin-flipping protocol that eventually lets us flip a coin with an unambiguous\noutcome. In the beginning the influence of the Byzantine players is too\npowerful to overcome and they can essentially fix the coin's behavior at will.\nWe guarantee that after just a polynomial number of executions of the\ncoin-flipping protocol, either (a) the Byzantine players fail to fix the\nbehavior of the coin (thereby ending the game) or (b) we can ``blacklist''\nplayers such that the blacklisting rate for Byzantine players is at least as\nlarge as the blacklisting rate for good players. The blacklisting criterion is\nbased on a simple statistical test of fraud detection.",
    "categories": [
      "cs.DC",
      "cs.DS",
      "math.ST",
      "stat.TH"
    ],
    "published": "2022-06-30T15:06:35+00:00",
    "updated": "2022-06-30T15:06:35+00:00",
    "url": "http://arxiv.org/pdf/2206.15335v1"
  },
  {
    "id": "2206.15162v1",
    "title": "Using Person Embedding to Enrich Features and Data Augmentation for Classification",
    "authors": [
      "Ahmet Tuğrul Bayrak"
    ],
    "abstract": "Today, machine learning is applied in almost any field. In machine learning,\nwhere there are numerous methods, classification is one of the most basic and\ncrucial ones. Various problems can be solved by classification. The feature\nselection for model setup is extremely important, and producing new features\nvia feature engineering also has a vital place in the success of the model. In\nour study, fraud detection classification models are built on a labeled and\nimbalanced dataset as a case-study. Although it is a natural language\nprocessing method, a customer space has been created with word embedding, which\nhas been used in different areas, especially for recommender systems. The\ncustomer vectors in the created space are fed to the classification model as a\nfeature. Moreover, to increase the number of positive labels, rows with similar\ncharacteristics are re-labeled as positive by using customer similarity\ndetermined by embedding. The model in which embedding methods are included in\nthe classification, which provides a better representation of customers, has\nbeen compared with other models. Considering the results, it is observed that\nthe customer embedding method had a positive effect on the success of the\nclassification models.",
    "categories": [
      "cs.LG",
      "cs.IR"
    ],
    "published": "2022-06-30T09:48:27+00:00",
    "updated": "2022-06-30T09:48:27+00:00",
    "url": "http://arxiv.org/pdf/2206.15162v1"
  },
  {
    "id": "2206.13183v1",
    "title": "Prisoners of Their Own Devices: How Models Induce Data Bias in Performative Prediction",
    "authors": [
      "José Pombal",
      "Pedro Saleiro",
      "Mário A. T. Figueiredo",
      "Pedro Bizarro"
    ],
    "abstract": "The unparalleled ability of machine learning algorithms to learn patterns\nfrom data also enables them to incorporate biases embedded within. A biased\nmodel can then make decisions that disproportionately harm certain groups in\nsociety. Much work has been devoted to measuring unfairness in static ML\nenvironments, but not in dynamic, performative prediction ones, in which most\nreal-world use cases operate. In the latter, the predictive model itself plays\na pivotal role in shaping the distribution of the data. However, little\nattention has been heeded to relating unfairness to these interactions. Thus,\nto further the understanding of unfairness in these settings, we propose a\ntaxonomy to characterize bias in the data, and study cases where it is shaped\nby model behaviour. Using a real-world account opening fraud detection case\nstudy as an example, we study the dangers to both performance and fairness of\ntwo typical biases in performative prediction: distribution shifts, and the\nproblem of selective labels.",
    "categories": [
      "cs.LG"
    ],
    "published": "2022-06-27T10:56:04+00:00",
    "updated": "2022-06-27T10:56:04+00:00",
    "url": "http://arxiv.org/pdf/2206.13183v1"
  },
  {
    "id": "2206.13152v1",
    "title": "Evaluating resampling methods on a real-life highly imbalanced online credit card payments dataset",
    "authors": [
      "François de la Bourdonnaye",
      "Fabrice Daniel"
    ],
    "abstract": "Various problems of any credit card fraud detection based on machine learning\ncome from the imbalanced aspect of transaction datasets. Indeed, the number of\nfrauds compared to the number of regular transactions is tiny and has been\nshown to damage learning performances, e.g., at worst, the algorithm can learn\nto classify all the transactions as regular. Resampling methods and\ncost-sensitive approaches are known to be good candidates to leverage this\nissue of imbalanced datasets. This paper evaluates numerous state-of-the-art\nresampling methods on a large real-life online credit card payments dataset. We\nshow they are inefficient because methods are intractable or because metrics do\nnot exhibit substantial improvements. Our work contributes to this domain in\n(1) that we compare many state-of-the-art resampling methods on a large-scale\ndataset and in (2) that we use a real-life online credit card payments dataset.",
    "categories": [
      "cs.LG"
    ],
    "published": "2022-06-27T09:57:08+00:00",
    "updated": "2022-06-27T09:57:08+00:00",
    "url": "http://arxiv.org/pdf/2206.13152v1"
  },
  {
    "id": "2206.13503v4",
    "title": "On the Importance of Application-Grounded Experimental Design for Evaluating Explainable ML Methods",
    "authors": [
      "Kasun Amarasinghe",
      "Kit T. Rodolfa",
      "Sérgio Jesus",
      "Valerie Chen",
      "Vladimir Balayan",
      "Pedro Saleiro",
      "Pedro Bizarro",
      "Ameet Talwalkar",
      "Rayid Ghani"
    ],
    "abstract": "Most existing evaluations of explainable machine learning (ML) methods rely\non simplifying assumptions or proxies that do not reflect real-world use cases;\nthe handful of more robust evaluations on real-world settings have shortcomings\nin their design, resulting in limited conclusions of methods' real-world\nutility. In this work, we seek to bridge this gap by conducting a study that\nevaluates three popular explainable ML methods in a setting consistent with the\nintended deployment context. We build on a previous study on e-commerce fraud\ndetection and make crucial modifications to its setup relaxing the simplifying\nassumptions made in the original work that departed from the deployment\ncontext. In doing so, we draw drastically different conclusions from the\nearlier work and find no evidence for the incremental utility of the tested\nmethods in the task. Our results highlight how seemingly trivial experimental\ndesign choices can yield misleading conclusions, with lessons about the\nnecessity of not only evaluating explainable ML methods using tasks, data,\nusers, and metrics grounded in the intended deployment contexts but also\ndeveloping methods tailored to specific applications. In addition, we believe\nthe design of this experiment can serve as a template for future study designs\nevaluating explainable ML methods in other real-world contexts.",
    "categories": [
      "cs.LG",
      "cs.HC"
    ],
    "published": "2022-06-24T14:46:19+00:00",
    "updated": "2023-02-21T20:26:40+00:00",
    "url": "http://arxiv.org/pdf/2206.13503v4"
  },
  {
    "id": "2206.12415v1",
    "title": "A novel approach to increase scalability while training machine learning algorithms using Bfloat 16 in credit card fraud detection",
    "authors": [
      "Bushra Yousuf",
      "Rejwan Bin Sulaiman",
      "Musarrat Saberin Nipun"
    ],
    "abstract": "The use of credit cards has become quite common these days as digital banking\nhas become the norm. With this increase, fraud in credit cards also has a huge\nproblem and loss to the banks and customers alike. Normal fraud detection\nsystems, are not able to detect the fraud since fraudsters emerge with new\ntechniques to commit fraud. This creates the need to use machine learning-based\nsoftware to detect frauds. Currently, the machine learning softwares that are\navailable focuses only on the accuracy of detecting frauds but does not focus\non the cost or time factors to detect. This research focuses on machine\nlearning scalability for banks' credit card fraud detection systems. We have\ncompared the existing machine learning algorithms and methods that are\navailable with the newly proposed technique. The goal is to prove that using\nfewer bits for training a machine learning algorithm will result in a more\nscalable system, that will reduce the time and will also be less costly to\nimplement.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-06-24T01:22:17+00:00",
    "updated": "2022-06-24T01:22:17+00:00",
    "url": "http://arxiv.org/pdf/2206.12415v1"
  },
  {
    "id": "2206.10953v1",
    "title": "Toward An Optimal Selection of Dialogue Strategies: A Target-Driven Approach for Intelligent Outbound Robots",
    "authors": [
      "Ruifeng Qian",
      "Shijie Li",
      "Mengjiao Bao",
      "Huan Chen",
      "Yu Che"
    ],
    "abstract": "With the growth of the economy and society, enterprises, especially in the\nFinTech industry, have increasing demands of outbound calls for customers such\nas debt collection, marketing, anti-fraud calls, and so on. But a large amount\nof repetitive and mechanical work occupies most of the time of human agents, so\nthe cost of equipment and labor for enterprises is increasing accordingly. At\nthe same time, with the development of artificial intelligence technology in\nthe past few decades, it has become quite common for companies to use new\ntechnologies such as Big Data and artificial intelligence to empower outbound\ncall businesses. The intelligent outbound robot is a typical application of the\nartificial intelligence technology in the field of outbound call businesses. It\nis mainly used to communicate with customers in order to accomplish a certain\ntarget. It has the characteristics of low cost, high reuse, and easy\ncompliance, which has attracted more attention from the industry.\n  At present, there are two kinds of intelligent outbound robots in the\nindustry but both of them still leave large room for improvement. One kind of\nthem is based on a finite state machine relying on the configuration of jump\nconditions and corresponding nodes based on manual experience. This kind of\nintelligent outbound robot is also called a flow-based robot. For example, the\nschematic diagram of the working model of a flow-based robot for debt\ncollection is shown in Fig.\\ref{fig:label}. In each round, the robot will reply\nto the user with the words corresponding to each node.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2022-06-22T09:49:30+00:00",
    "updated": "2022-06-22T09:49:30+00:00",
    "url": "http://arxiv.org/pdf/2206.10953v1"
  },
  {
    "id": "2206.09677v5",
    "title": "GraphFramEx: Towards Systematic Evaluation of Explainability Methods for Graph Neural Networks",
    "authors": [
      "Kenza Amara",
      "Rex Ying",
      "Zitao Zhang",
      "Zhihao Han",
      "Yinan Shan",
      "Ulrik Brandes",
      "Sebastian Schemm",
      "Ce Zhang"
    ],
    "abstract": "As one of the most popular machine learning models today, graph neural\nnetworks (GNNs) have attracted intense interest recently, and so does their\nexplainability. Users are increasingly interested in a better understanding of\nGNN models and their outcomes. Unfortunately, today's evaluation frameworks for\nGNN explainability often rely on few inadequate synthetic datasets, leading to\nconclusions of limited scope due to a lack of complexity in the problem\ninstances. As GNN models are deployed to more mission-critical applications, we\nare in dire need for a common evaluation protocol of explainability methods of\nGNNs. In this paper, we propose, to our best knowledge, the first systematic\nevaluation framework for GNN explainability, considering explainability on\nthree different \"user needs\". We propose a unique metric that combines the\nfidelity measures and classifies explanations based on their quality of being\nsufficient or necessary. We scope ourselves to node classification tasks and\ncompare the most representative techniques in the field of input-level\nexplainability for GNNs. For the inadequate but widely used synthetic\nbenchmarks, surprisingly shallow techniques such as personalized PageRank have\nthe best performance for a minimum computation time. But when the graph\nstructure is more complex and nodes have meaningful features, gradient-based\nmethods are the best according to our evaluation criteria. However, none\ndominates the others on all evaluation dimensions and there is always a\ntrade-off. We further apply our evaluation protocol in a case study for frauds\nexplanation on eBay transaction graphs to reflect the production environment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-06-20T09:33:12+00:00",
    "updated": "2024-05-22T12:11:48+00:00",
    "url": "http://arxiv.org/pdf/2206.09677v5"
  },
  {
    "id": "2206.09388v1",
    "title": "Privacy-Preserving Analytics on Decentralized Social Graphs: The Case of Eigendecomposition",
    "authors": [
      "Songlei Wang",
      "Yifeng Zheng",
      "Xiaohua Jia",
      "Xun Yi"
    ],
    "abstract": "Analytics over social graphs allows to extract valuable knowledge and\ninsights for many fields like community detection, fraud detection, and\ninterest mining. In practice, decentralized social graphs frequently arise,\nwhere the social graph is not available to a single entity and is decentralized\namong a large number of users, each holding only a limited local view about the\nwhole graph. Collecting the local views for analytics of decentralized social\ngraphs raises critical privacy concerns, as they encode private information\nabout the social interactions among individuals. In this paper, we design,\nimplement, and evaluate PrivGED, a new system aimed at privacy-preserving\nanalytics over decentralized social graphs. PrivGED focuses on the support for\neigendecomposition, one popular and fundamental graph analytics task producing\neigenvalues/eigenvectors over the adjacency matrix of a social graph and\nbenefits various practical applications. PrivGED is built from a delicate\nsynergy of insights on graph analytics, lightweight cryptography, and\ndifferential privacy, allowing users to securely contribute their local views\non a decentralized social graph for a cloud-based eigendecomposition analytics\nservice while gaining strong privacy protection. Extensive experiments over\nreal-world social graph datasets demonstrate that PrivGED achieves accuracy\ncomparable to the plaintext domain, with practically affordable performance\nsuperior to prior art.",
    "categories": [
      "cs.CR"
    ],
    "published": "2022-06-19T12:14:36+00:00",
    "updated": "2022-06-19T12:14:36+00:00",
    "url": "http://arxiv.org/pdf/2206.09388v1"
  },
  {
    "id": "2206.08093v1",
    "title": "Applications of Machine Learning to the Identification of Anomalous ER Claims",
    "authors": [
      "Jesse B. Crawford",
      "Nicholas Petela"
    ],
    "abstract": "Improper health insurance payments resulting from fraud and upcoding result\nin tens of billions of dollars in excess health care costs annually in the\nUnited States, motivating machine learning researchers to build anomaly\ndetection models for health insurance claims. This article describes two such\nstrategies specifically for ER claims. The first is an upcoding model based on\nseverity code distributions, stratified by hierarchical diagnosis code\nclusters. A statistically significant difference in mean upcoding anomaly\nscores is observed between free-standing ERs and acute care hospitals, with\nfree-standing ERs being more anomalous. The second model is a random forest\nthat minimizes improper payments by optimally sorting ER claims within review\nqueues. Depending on the percentage of claims reviewed, the random forest saved\n12% to 40% above a baseline approach that prioritized claims by billed amount.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2022-06-16T11:19:04+00:00",
    "updated": "2022-06-16T11:19:04+00:00",
    "url": "http://arxiv.org/pdf/2206.08093v1"
  },
  {
    "id": "2206.05840v1",
    "title": "GAN based Data Augmentation to Resolve Class Imbalance",
    "authors": [
      "Sairamvinay Vijayaraghavan",
      "Terry Guan",
      "Jason",
      "Song"
    ],
    "abstract": "The number of credit card fraud has been growing as technology grows and\npeople can take advantage of it. Therefore, it is very important to implement a\nrobust and effective method to detect such frauds. The machine learning\nalgorithms are appropriate for these tasks since they try to maximize the\naccuracy of predictions and hence can be relied upon. However, there is an\nimpending flaw where in machine learning models may not perform well due to the\npresence of an imbalance across classes distribution within the sample set. So,\nin many related tasks, the datasets have a very small number of observed fraud\ncases (sometimes around 1 percent positive fraud instances found). Therefore,\nthis imbalance presence may impact any learning model's behavior by predicting\nall labels as the majority class, hence allowing no scope for generalization in\nthe predictions made by the model. We trained Generative Adversarial\nNetwork(GAN) to generate a large number of convincing (and reliable) synthetic\nexamples of the minority class that can be used to alleviate the class\nimbalance within the training set and hence generalize the learning of the data\nmore effectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-06-12T21:21:55+00:00",
    "updated": "2022-06-12T21:21:55+00:00",
    "url": "http://arxiv.org/pdf/2206.05840v1"
  },
  {
    "id": "2206.05778v3",
    "title": "Learning-Based Data Storage [Vision] (Technical Report)",
    "authors": [
      "Xiang Lian",
      "Xiaofei Zhang"
    ],
    "abstract": "Deep neural network (DNN) and its variants have been extensively used for a\nwide spectrum of real applications such as image classification, face/speech\nrecognition, fraud detection, and so on. In addition to many important machine\nlearning tasks, as artificial networks emulating the way brain cells function,\nDNNs also show the capability of storing non-linear relationships between input\nand output data, which exhibits the potential of storing data via DNNs. We\nenvision a new paradigm of data storage, \"DNN-as-a-Database\", where data are\nencoded in well-trained machine learning models. Compared with conventional\ndata storage that directly records data in raw formats, learning-based\nstructures (e.g., DNN) can implicitly encode data pairs of inputs and outputs\nand compute/materialize actual output data of different resolutions only if\ninput data are provided. This new paradigm can greatly enhance the data\nsecurity by allowing flexible data privacy settings on different levels,\nachieve low space consumption and fast computation with the acceleration of new\nhardware (e.g., Diffractive Neural Network and AI chips), and can be\ngeneralized to distributed DNN-based storage/computing. In this paper, we\npropose this novel concept of learning-based data storage, which utilizes a\nlearning structure called learning-based memory unit (LMU), to store, organize,\nand retrieve data. As a case study, we use DNNs as the engine in the LMU, and\nstudy the data capacity and accuracy of the DNN-based data storage. Our\npreliminary experimental results show the feasibility of the learning-based\ndata storage by achieving high (100%) accuracy of the DNN storage. We explore\nand design effective solutions to utilize the DNN-based data storage to manage\nand query relational tables. We discuss how to generalize our solutions to\nother data types (e.g., graphs) and environments such as distributed DNN\nstorage/computing.",
    "categories": [
      "cs.DB",
      "cs.LG",
      "E.2; H.2.1; I.2.0; I.2.11"
    ],
    "published": "2022-06-12T16:14:16+00:00",
    "updated": "2023-01-23T02:21:51+00:00",
    "url": "http://arxiv.org/pdf/2206.05778v3"
  },
  {
    "id": "2206.04460v3",
    "title": "Open ERP System Data For Occupational Fraud Detection",
    "authors": [
      "Julian Tritscher",
      "Fabian Gwinner",
      "Daniel Schlör",
      "Anna Krause",
      "Andreas Hotho"
    ],
    "abstract": "Recent estimates report that companies lose 5% of their revenue to\noccupational fraud. Since most medium-sized and large companies employ\nEnterprise Resource Planning (ERP) systems to track vast amounts of information\nregarding their business process, researchers have in the past shown interest\nin automatically detecting fraud through ERP system data. Current research in\nthis area, however, is hindered by the fact that ERP system data is not\npublicly available for the development and comparison of fraud detection\nmethods. We therefore endeavour to generate public ERP system data that\nincludes both normal business operation and fraud. We propose a strategy for\ngenerating ERP system data through a serious game, model a variety of fraud\nscenarios in cooperation with auditing experts, and generate data from a\nsimulated make-to-stock production company with multiple research participants.\nWe aggregate the generated data into ready to used datasets for fraud detection\nin ERP systems, and supply both the raw and aggregated data to the general\npublic to allow for open development and comparison of fraud detection\napproaches on ERP system data.",
    "categories": [
      "cs.AI"
    ],
    "published": "2022-06-09T12:38:29+00:00",
    "updated": "2022-07-13T07:51:02+00:00",
    "url": "http://arxiv.org/pdf/2206.04460v3"
  },
  {
    "id": "2206.04255v1",
    "title": "ScatterSample: Diversified Label Sampling for Data Efficient Graph Neural Network Learning",
    "authors": [
      "Zhenwei Dai",
      "Vasileios Ioannidis",
      "Soji Adeshina",
      "Zak Jost",
      "Christos Faloutsos",
      "George Karypis"
    ],
    "abstract": "What target labels are most effective for graph neural network (GNN)\ntraining? In some applications where GNNs excel-like drug design or fraud\ndetection, labeling new instances is expensive. We develop a data-efficient\nactive sampling framework, ScatterSample, to train GNNs under an active\nlearning setting. ScatterSample employs a sampling module termed\nDiverseUncertainty to collect instances with large uncertainty from different\nregions of the sample space for labeling. To ensure diversification of the\nselected nodes, DiverseUncertainty clusters the high uncertainty nodes and\nselects the representative nodes from each cluster. Our ScatterSample algorithm\nis further supported by rigorous theoretical analysis demonstrating its\nadvantage compared to standard active sampling methods that aim to simply\nmaximize the uncertainty and not diversify the samples. In particular, we show\nthat ScatterSample is able to efficiently reduce the model uncertainty over the\nwhole sample space. Our experiments on five datasets show that ScatterSample\nsignificantly outperforms the other GNN active learning baselines, specifically\nit reduces the sampling cost by up to 50% while achieving the same test\naccuracy.",
    "categories": [
      "cs.LG"
    ],
    "published": "2022-06-09T04:05:02+00:00",
    "updated": "2022-06-09T04:05:02+00:00",
    "url": "http://arxiv.org/pdf/2206.04255v1"
  },
  {
    "id": "2206.04141v1",
    "title": "Role of Blockchain in Revolutionizing Online Transactional Security",
    "authors": [
      "Rishav Kumar"
    ],
    "abstract": "This paper highlights the necessity to use modern blockchain technology in\ntraditional banking sector to reduce frauds and enable high-security\ntransactions on a permanent blockchain ledger. Reviewing different channels\nthrough which the traditional banking servers could integrate blockchain use,\nit is signified how a huge anti-fraud stand can be taken against bank servers\nallowing fraudulent transactions daily. Usage of a blockchain-based ledger is\nhighly impactful in terms of security of a banking organization.\nBlockchain-based currency tokens, also referred to as Cryptocurrencies are not\nregulated by the government, highly volatile, and anonymous to use.\nFurthermore, there is no security for any funds invested in a cryptocurrency\nmarket. However, the integration of a blockchain ledger in a traditional\nbanking organization would strengthen the security to provide more stability\nand confidence to its customers and at the same time, make blockchain a more\nreliable method to consider due to being trusted by large financial\norganizations.",
    "categories": [
      "cs.CR"
    ],
    "published": "2022-06-08T20:08:15+00:00",
    "updated": "2022-06-08T20:08:15+00:00",
    "url": "http://arxiv.org/pdf/2206.04141v1"
  },
  {
    "id": "2206.03040v1",
    "title": "Learning Backward Compatible Embeddings",
    "authors": [
      "Weihua Hu",
      "Rajas Bansal",
      "Kaidi Cao",
      "Nikhil Rao",
      "Karthik Subbian",
      "Jure Leskovec"
    ],
    "abstract": "Embeddings, low-dimensional vector representation of objects, are fundamental\nin building modern machine learning systems. In industrial settings, there is\nusually an embedding team that trains an embedding model to solve intended\ntasks (e.g., product recommendation). The produced embeddings are then widely\nconsumed by consumer teams to solve their unintended tasks (e.g., fraud\ndetection). However, as the embedding model gets updated and retrained to\nimprove performance on the intended task, the newly-generated embeddings are no\nlonger compatible with the existing consumer models. This means that historical\nversions of the embeddings can never be retired or all consumer teams have to\nretrain their models to make them compatible with the latest version of the\nembeddings, both of which are extremely costly in practice. Here we study the\nproblem of embedding version updates and their backward compatibility. We\nformalize the problem where the goal is for the embedding team to keep updating\nthe embedding version, while the consumer teams do not have to retrain their\nmodels. We develop a solution based on learning backward compatible embeddings,\nwhich allows the embedding model version to be updated frequently, while also\nallowing the latest version of the embedding to be quickly transformed into any\nbackward compatible historical version of it, so that consumer teams do not\nhave to retrain their models. Under our framework, we explore six methods and\nsystematically evaluate them on a real-world recommender system application. We\nshow that the best method, which we call BC-Aligner, maintains backward\ncompatibility with existing unintended tasks even after multiple model version\nupdates. Simultaneously, BC-Aligner achieves the intended task performance\nsimilar to the embedding model that is solely optimized for the intended task.",
    "categories": [
      "stat.ML",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2022-06-07T06:30:34+00:00",
    "updated": "2022-06-07T06:30:34+00:00",
    "url": "http://arxiv.org/pdf/2206.03040v1"
  },
  {
    "id": "2206.02136v3",
    "title": "LDRNet: Enabling Real-time Document Localization on Mobile Devices",
    "authors": [
      "Han Wu",
      "Holland Qian",
      "Huaming Wu",
      "Aad van Moorsel"
    ],
    "abstract": "While Identity Document Verification (IDV) technology on mobile devices\nbecomes ubiquitous in modern business operations, the risk of identity theft\nand fraud is increasing. The identity document holder is normally required to\nparticipate in an online video interview to circumvent impostors. However, the\ncurrent IDV process depends on an additional human workforce to support online\nstep-by-step guidance which is inefficient and expensive. The performance of\nexisting AI-based approaches cannot meet the real-time and lightweight demands\nof mobile devices. In this paper, we address those challenges by designing an\nedge intelligence-assisted approach for real-time IDV. Aiming at improving the\nresponsiveness of the IDV process, we propose a new document localization model\nfor mobile devices, LDRNet, to Localize the identity Document in Real-time. On\nthe basis of a lightweight backbone network, we build three prediction branches\nfor LDRNet, the corner points prediction, the line borders prediction and the\ndocument classification. We design novel supplementary targets, the\nequal-division points, and use a new loss function named Line Loss, to improve\nthe speed and accuracy of our approach. In addition to the IDV process, LDRNet\nis an efficient and reliable document localization alternative for all kinds of\nmobile applications. As a matter of proof, we compare the performance of LDRNet\nwith other popular approaches on localizing general document datasets. The\nexperimental results show that LDRNet runs at a speed up to 790 FPS which is\n47x faster, while still achieving comparable Jaccard Index(JI) in single-model\nand single-scale tests.",
    "categories": [
      "cs.CV",
      "cs.PF"
    ],
    "published": "2022-06-05T09:39:12+00:00",
    "updated": "2023-10-12T13:55:06+00:00",
    "url": "http://arxiv.org/pdf/2206.02136v3"
  },
  {
    "id": "2206.01932v2",
    "title": "Demeter: A Fast and Energy-Efficient Food Profiler using Hyperdimensional Computing in Memory",
    "authors": [
      "Taha Shahroodi",
      "Mahdi Zahedi",
      "Can Firtina",
      "Mohammed Alser",
      "Stephan Wong",
      "Onur Mutlu",
      "Said Hamdioui"
    ],
    "abstract": "Food profiling is an essential step in any food monitoring system needed to\nprevent health risks and potential frauds in the food industry. Significant\nimprovements in sequencing technologies are pushing food profiling to become\nthe main computational bottleneck. State-of-the-art profilers are unfortunately\ntoo costly for food profiling.\n  Our goal is to design a food profiler that solves the main limitations of\nexisting profilers, namely (1) working on massive data structures and (2)\nincurring considerable data movement for a real-time monitoring system. To this\nend, we propose Demeter, the first platform-independent framework for food\nprofiling. Demeter overcomes the first limitation through the use of\nhyperdimensional computing (HDC) and efficiently performs the accurate\nfew-species classification required in food profiling. We overcome the second\nlimitation by using an in-memory hardware accelerator for Demeter (named\nAcc-Demeter) based on memristor devices. Acc-Demeter actualizes several\ndomain-specific optimizations and exploits the inherent characteristics of\nmemristors to improve the overall performance and energy consumption of\nAcc-Demeter.\n  We compare Demeter's accuracy with other industrial food profilers using\ndetailed software modeling. We synthesize Acc-Demeter's required hardware using\nUMC's 65nm library by considering an accurate PCM model based on silicon-based\nprototypes. Our evaluations demonstrate that Acc-Demeter achieves a (1)\nthroughput improvement of 192x and 724x and (2) memory reduction of 36x and 33x\ncompared to Kraken2 and MetaCache (2 state-of-the-art profilers), respectively,\non typical food-related databases. Demeter maintains an acceptable profiling\naccuracy (within 2% of existing tools) and incurs a very low area overhead.",
    "categories": [
      "cs.AR",
      "q-bio.GN"
    ],
    "published": "2022-06-04T07:50:37+00:00",
    "updated": "2022-08-24T07:50:15+00:00",
    "url": "http://arxiv.org/pdf/2206.01932v2"
  },
  {
    "id": "2206.01413v2",
    "title": "Impact of the composition of feature extraction and class sampling in medicare fraud detection",
    "authors": [
      "Akrity Kumari",
      "Narinder Singh Punn",
      "Sanjay Kumar Sonbhadra",
      "Sonali Agarwal"
    ],
    "abstract": "With healthcare being critical aspect, health insurance has become an\nimportant scheme in minimizing medical expenses. Following this, the healthcare\nindustry has seen a significant increase in fraudulent activities owing to\nincreased insurance, and fraud has become a significant contributor to rising\nmedical care expenses, although its impact can be mitigated using fraud\ndetection techniques. To detect fraud, machine learning techniques are used.\nThe Centers for Medicaid and Medicare Services (CMS) of the United States\nfederal government released \"Medicare Part D\" insurance claims is utilized in\nthis study to develop fraud detection system. Employing machine learning\nalgorithms on a class-imbalanced and high dimensional medicare dataset is a\nchallenging task. To compact such challenges, the present work aims to perform\nfeature extraction following data sampling, afterward applying various\nclassification algorithms, to get better performance. Feature extraction is a\ndimensionality reduction approach that converts attributes into linear or\nnon-linear combinations of the actual attributes, generating a smaller and more\ndiversified set of attributes and thus reducing the dimensions. Data sampling\nis commonlya used to address the class imbalance either by expanding the\nfrequency of minority class or reducing the frequency of majority class to\nobtain approximately equal numbers of occurrences for both classes. The\nproposed approach is evaluated through standard performance metrics. Thus, to\ndetect fraud efficiently, this study applies autoencoder as a feature\nextraction technique, synthetic minority oversampling technique (SMOTE) as a\ndata sampling technique, and various gradient boosted decision tree-based\nclassifiers as a classification algorithm. The experimental results show the\ncombination of autoencoders followed by SMOTE on the LightGBM classifier\nachieved best results.",
    "categories": [
      "cs.LG"
    ],
    "published": "2022-06-03T06:57:08+00:00",
    "updated": "2022-06-28T07:54:08+00:00",
    "url": "http://arxiv.org/pdf/2206.01413v2"
  },
  {
    "id": "2207.14394v2",
    "title": "Logic and Accuracy Testing: A Fifty-State Review",
    "authors": [
      "Josiah Walker",
      "Nakul Bajaj",
      "Braden L. Crimmins",
      "J. Alex Halderman"
    ],
    "abstract": "Pre-election logic and accuracy (L&A) testing is a process in which election\nofficials validate the behavior of voting equipment by casting a known set of\ntest ballots and confirming the expected results. Ideally, such testing can\nserve to detect certain forms of human error or fraud and help bolster voter\nconfidence. We present the first detailed analysis of L&A testing practices\nacross the United States. We find that while all states require L&A testing\nbefore every election, their implementations vary dramatically in scope,\ntransparency, and rigorousness. We summarize each state's requirements and\nscore them according to uniform criteria. We also highlight best practices and\nflag opportunities for improvement, in hopes of encouraging broader adoption of\nmore effective L&A processes.",
    "categories": [
      "cs.CY"
    ],
    "published": "2022-07-28T22:21:37+00:00",
    "updated": "2022-08-01T15:53:35+00:00",
    "url": "http://arxiv.org/pdf/2207.14394v2"
  },
  {
    "id": "2207.14355v1",
    "title": "Multiple Attribute Fairness: Application to Fraud Detection",
    "authors": [
      "Meghanath Macha Y",
      "Sriram Ravindran",
      "Deepak Pai",
      "Anish Narang",
      "Vijay Srivastava"
    ],
    "abstract": "We propose a fairness measure relaxing the equality conditions in the popular\nequal odds fairness regime for classification. We design an iterative,\nmodel-agnostic, grid-based heuristic that calibrates the outcomes per sensitive\nattribute value to conform to the measure. The heuristic is designed to handle\nhigh arity attribute values and performs a per attribute sanitization of\noutcomes across different protected attribute values. We also extend our\nheuristic for multiple attributes. Highlighting our motivating application,\nfraud detection, we show that the proposed heuristic is able to achieve\nfairness across multiple values of a single protected attribute, multiple\nprotected attributes. When compared to current fairness techniques, that focus\non two groups, we achieve comparable performance across several public data\nsets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2022-07-28T19:19:45+00:00",
    "updated": "2022-07-28T19:19:45+00:00",
    "url": "http://arxiv.org/pdf/2207.14355v1"
  },
  {
    "id": "2207.14017v1",
    "title": "Unsupervised Frequent Pattern Mining for CEP",
    "authors": [
      "Guy Shapira",
      "Assaf Schuster"
    ],
    "abstract": "Complex Event Processing (CEP) is a set of methods that allow efficient\nknowledge extraction from massive data streams using complex and highly\ndescriptive patterns. Numerous applications, such as online finance, healthcare\nmonitoring and fraud detection use CEP technologies to capture critical alerts,\npotential threats, or vital notifications in real time. As of today, in many\nfields, patterns are manually defined by human experts. However, desired\npatterns often contain convoluted relations that are difficult for humans to\ndetect, and human expertise is scarce in many domains.\n  We present REDEEMER (REinforcement baseD cEp pattErn MinER), a novel\nreinforcement and active learning approach aimed at mining CEP patterns that\nallow expansion of the knowledge extracted while reducing the human effort\nrequired. This approach includes a novel policy gradient method for vast\nmultivariate spaces and a new way to combine reinforcement and active learning\nfor CEP rule learning while minimizing the number of labels needed for\ntraining.\n  REDEEMER aims to enable CEP integration in domains that could not utilize it\nbefore. To the best of our knowledge, REDEEMER is the first system that\nsuggests new CEP rules that were not observed beforehand, and is the first\nmethod aimed for increasing pattern knowledge in fields where experts do not\npossess sufficient information required for CEP tools.\n  Our experiments on diverse data-sets demonstrate that REDEEMER is able to\nextend pattern knowledge while outperforming several state-of-the-art\nreinforcement learning methods for pattern mining.",
    "categories": [
      "cs.LG"
    ],
    "published": "2022-07-28T11:24:05+00:00",
    "updated": "2022-07-28T11:24:05+00:00",
    "url": "http://arxiv.org/pdf/2207.14017v1"
  },
  {
    "id": "2207.11950v1",
    "title": "One-off Negative Sequential Pattern Mining",
    "authors": [
      "Youxi Wu",
      "Mingjie Chen",
      "Yan Li",
      "Jing Liu",
      "Zhao Li",
      "Jinyan Li",
      "Xindong Wu"
    ],
    "abstract": "Negative sequential pattern mining (SPM) is an important SPM research topic.\nUnlike positive SPM, negative SPM can discover events that should have occurred\nbut have not occurred, and it can be used for financial risk management and\nfraud detection. However, existing methods generally ignore the repetitions of\nthe pattern and do not consider gap constraints, which can lead to mining\nresults containing a large number of patterns that users are not interested in.\nTo solve this problem, this paper discovers frequent one-off negative\nsequential patterns (ONPs). This problem has the following two characteristics.\nFirst, the support is calculated under the one-off condition, which means that\nany character in the sequence can only be used once at most. Second, the gap\nconstraint can be given by the user. To efficiently mine patterns, this paper\nproposes the ONP-Miner algorithm, which employs depth-first and backtracking\nstrategies to calculate the support. Therefore, ONP-Miner can effectively avoid\ncreating redundant nodes and parent-child relationships. Moreover, to\neffectively reduce the number of candidate patterns, ONP-Miner uses pattern\njoin and pruning strategies to generate and further prune the candidate\npatterns, respectively. Experimental results show that ONP-Miner not only\nimproves the mining efficiency, but also has better mining performance than the\nstate-of-the-art algorithms. More importantly, ONP mining can find more\ninteresting patterns in traffic volume data to predict future traffic.",
    "categories": [
      "cs.DB"
    ],
    "published": "2022-07-25T07:37:13+00:00",
    "updated": "2022-07-25T07:37:13+00:00",
    "url": "http://arxiv.org/pdf/2207.11950v1"
  },
  {
    "id": "2207.11466v1",
    "title": "Anomaly Detection for Fraud in Cryptocurrency Time Series",
    "authors": [
      "Eran Kaufman",
      "Andrey Iaremenko"
    ],
    "abstract": "Since the inception of Bitcoin in 2009, the market of cryptocurrencies has\ngrown beyond initial expectations as daily trades exceed $10 billion. As\nindustries become automated, the need for an automated fraud detector becomes\nvery apparent. Detecting anomalies in real time prevents potential accidents\nand economic losses. Anomaly detection in multivariate time series data poses a\nparticular challenge because it requires simultaneous consideration of temporal\ndependencies and relationships between variables. Identifying an anomaly in\nreal time is not an easy task specifically because of the exact anomalistic\nbehavior they observe. Some points may present pointwise global or local\nanomalistic behavior, while others may be anomalistic due to their frequency or\nseasonal behavior or due to a change in the trend. In this paper we suggested\nworking on real time series of trades of Ethereum from specific accounts and\nsurveyed a large variety of different algorithms traditional and new. We\ncategorized them according to the strategy and the anomalistic behavior which\nthey search and showed that when bundling them together to different groups,\nthey can prove to be a good real-time detector with an alarm time of no longer\nthan a few seconds and with very high confidence.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2022-07-23T08:58:57+00:00",
    "updated": "2022-07-23T08:58:57+00:00",
    "url": "http://arxiv.org/pdf/2207.11466v1"
  },
  {
    "id": "2207.09335v1",
    "title": "Blindfold: Keeping Private Keys in PKIs and CDNs out of Sight",
    "authors": [
      "Hisham Galal",
      "Mohammad Mannan",
      "Amr Youssef"
    ],
    "abstract": "Public key infrastructure (PKI) is a certificate-based technology that helps\nin authenticating systems identities. HTTPS/TLS relies mainly on PKI to\nminimize fraud over the Internet. Nowadays, websites utilize CDNs to improve\nuser experience, performance, and resilience against cyber attacks. However,\ncombining HTTPS/TLS with CDNs has raised new security challenges. In any PKI\nsystem, keeping private keys private is of utmost importance. However, it has\nbecome the norm for CDN-powered websites to violate that fundamental\nassumption. Several solutions have been proposed to make HTTPS CDN-friendly.\nHowever, protection of private keys from the very instance of generation; and\nhow they can be made secure against exposure by malicious (CDN) administrators\nand malware remain unexplored. We utilize trusted execution environments to\nprotect private keys by never exposing them to human operators or untrusted\nsoftware. We design Blindfold to protect private keys in HTTPS/TLS\ninfrastructures, including CAs, website on-premise servers, and CDNs. We\nimplemented a prototype to assess Blindfold's performance and performed several\nexperiments on both the micro and macro levels. We found that Blindfold\nslightly outperforms SoftHSM in key generation by 1% while lagging by 0.01% for\ncertificate issuance operations.",
    "categories": [
      "cs.CR"
    ],
    "published": "2022-07-19T15:44:45+00:00",
    "updated": "2022-07-19T15:44:45+00:00",
    "url": "http://arxiv.org/pdf/2207.09335v1"
  },
  {
    "id": "2207.09320v1",
    "title": "Group Validation in Recommender Systems: Framework for Multi-layer Performance Evaluation",
    "authors": [
      "Wissam Al Jurdi",
      "Jacques Bou Abdo",
      "Jacques Demerjian",
      "Abdallah Makhoul"
    ],
    "abstract": "Interpreting the performance results of models that attempt to realize user\nbehavior in platforms that employ recommenders is a big challenge that\nresearchers and practitioners continue to face. Although current evaluation\ntools possess the capacity to provide solid general overview of a system's\nperformance, they still lack consistency and effectiveness in their use as\nevident in most recent studies on the topic. Current traditional assessment\ntechniques tend to fail to detect variations that could occur on smaller\nsubsets of the data and lack the ability to explain how such variations affect\nthe overall performance. In this article, we focus on the concept of data\nclustering for evaluation in recommenders and apply a neighborhood assessment\nmethod for the datasets of recommender system applications. This new method,\nnamed neighborhood-based evaluation, aids in better understanding critical\nperformance variations in more compact subsets of the system to help spot\nweaknesses where such variations generally go unnoticed with conventional\nmetrics and are typically averaged out. This new modular evaluation layer\ncomplements the existing assessment mechanisms and provides the possibility of\nseveral applications to the recommender ecosystem such as model evolution\ntests, fraud/attack detection and a possibility for hosting a hybrid model\nsetup.",
    "categories": [
      "cs.IR"
    ],
    "published": "2022-07-19T15:19:03+00:00",
    "updated": "2022-07-19T15:19:03+00:00",
    "url": "http://arxiv.org/pdf/2207.09320v1"
  },
  {
    "id": "2207.06273v1",
    "title": "Understanding Unfairness in Fraud Detection through Model and Data Bias Interactions",
    "authors": [
      "José Pombal",
      "André F. Cruz",
      "João Bravo",
      "Pedro Saleiro",
      "Mário A. T. Figueiredo",
      "Pedro Bizarro"
    ],
    "abstract": "In recent years, machine learning algorithms have become ubiquitous in a\nmultitude of high-stakes decision-making applications. The unparalleled ability\nof machine learning algorithms to learn patterns from data also enables them to\nincorporate biases embedded within. A biased model can then make decisions that\ndisproportionately harm certain groups in society -- limiting their access to\nfinancial services, for example. The awareness of this problem has given rise\nto the field of Fair ML, which focuses on studying, measuring, and mitigating\nunfairness in algorithmic prediction, with respect to a set of protected groups\n(e.g., race or gender). However, the underlying causes for algorithmic\nunfairness still remain elusive, with researchers divided between blaming\neither the ML algorithms or the data they are trained on. In this work, we\nmaintain that algorithmic unfairness stems from interactions between models and\nbiases in the data, rather than from isolated contributions of either of them.\nTo this end, we propose a taxonomy to characterize data bias and we study a set\nof hypotheses regarding the fairness-accuracy trade-offs that fairness-blind ML\nalgorithms exhibit under different data bias settings. On our real-world\naccount-opening fraud use case, we find that each setting entails specific\ntrade-offs, affecting fairness in expected value and variance -- the latter\noften going unnoticed. Moreover, we show how algorithms compare differently in\nterms of accuracy and fairness, depending on the biases affecting the data.\nFinally, we note that under specific data bias conditions, simple\npre-processing interventions can successfully balance group-wise error rates,\nwhile the same techniques fail in more complex settings.",
    "categories": [
      "cs.LG",
      "cs.CY",
      "q-fin.ST"
    ],
    "published": "2022-07-13T15:18:30+00:00",
    "updated": "2022-07-13T15:18:30+00:00",
    "url": "http://arxiv.org/pdf/2207.06273v1"
  },
  {
    "id": "2207.05524v2",
    "title": "Application of Benford-Newcomb Law with Base Change to Electoral Fraud Detection",
    "authors": [
      "Eduardo Gueron",
      "Jeronimo Pellegrini"
    ],
    "abstract": "The invariance of Benford-Newcomb law under base changing is employed to test\nwhether or not some data follow such distribution. Taking into account the\nBrazilian senate election in 1994, changes in the numerical base were able to\nevidence probable fraud.",
    "categories": [
      "stat.AP",
      "62P25"
    ],
    "published": "2022-07-12T13:29:55+00:00",
    "updated": "2022-07-18T23:26:08+00:00",
    "url": "http://arxiv.org/pdf/2207.05524v2"
  },
  {
    "id": "2207.04459v1",
    "title": "A Decentralised Real Estate Transfer Verification Based on Self-Sovereign Identity and Smart Contracts",
    "authors": [
      "Abubakar-Sadiq Shehu",
      "Antonio Pinto",
      "Manuel E. Correia"
    ],
    "abstract": "Since its first introduction in late 90s, the use of marketplaces has\ncontinued to grow, today virtually everything from physical assets to services\ncan be purchased on digital marketplaces, real estate is not an exception. Some\nmarketplaces allow acclaimed asset owners to advertise their products, to which\nthe services gets commission/percentage from proceeds of sale/lease. Despite\nthe success recorded in the use of the marketplaces, they are not without\nlimitations which include identity and property fraud, impersonation and the\nuse of centralised technology with trusted parties that are prone to single\npoint of failures (SPOF). Being one of the most valuable assets, real estate\nhas been a target for marketplace fraud as impersonators take pictures of\nproperties they do not own, upload them on marketplace with promising prices\nthat lures innocent or naive buyers. This paper addresses these issues by\nproposing a self sovereign identity (SSI) and smart contract based framework\nfor identity verification and verified transaction management on secure digital\nmarketplaces. First, the use of SSI technology enable methods for acquiring\nverified credential (VC) that are verifiable on a decentralised blockchain\nregistry to identify both real estate owner(s) and real estate property.\nSecond, the smart contracts are used to negotiate the secure transfer of real\nestate property deeds on the marketplace. To assess the viability of our\nproposal we define an application scenario and compare our work with other\napproaches",
    "categories": [
      "cs.CR"
    ],
    "published": "2022-07-10T13:12:40+00:00",
    "updated": "2022-07-10T13:12:40+00:00",
    "url": "http://arxiv.org/pdf/2207.04459v1"
  },
  {
    "id": "2207.02506v2",
    "title": "You have been warned: Abusing 5G's Warning and Emergency Systems",
    "authors": [
      "Evangelos Bitsikas",
      "Christina Pöpper"
    ],
    "abstract": "The Public Warning System (PWS) is an essential part of cellular networks and\na country's civil protection. Warnings can notify users of hazardous events\n(e.g., floods, earthquakes) and crucial national matters that require immediate\nattention. PWS attacks disseminating fake warnings or concealing precarious\nevents can have a serious impact, causing fraud, panic, physical harm, or\nunrest to users within an affected area. In this work, we conduct the first\ncomprehensive investigation of PWS security in 5G networks. We demonstrate five\npractical attacks that may impact the security of 5G-based Commercial Mobile\nAlert System (CMAS) as well as Earthquake and Tsunami Warning System (ETWS)\nalerts. Additional to identifying the vulnerabilities, we investigate two PWS\nspoofing and three PWS suppression attacks, with or without a man-in-the-middle\n(MitM) attacker. We discover that MitM-based attacks have more severe impact\nthan their non-MitM counterparts. Our PWS barring attack is an effective\ntechnique to eliminate legitimate warning messages. We perform a rigorous\nanalysis of the roaming aspect of the PWS, incl. its potentially secure\nversion, and report the implications of our attacks on other emergency features\n(e.g., 911 SIP calls). We discuss possible countermeasures and note that\neradicating the attacks necessitates a scrupulous reevaluation of the PWS\ndesign and a secure implementation.",
    "categories": [
      "cs.CR",
      "cs.NI"
    ],
    "published": "2022-07-06T08:15:12+00:00",
    "updated": "2022-10-28T14:29:19+00:00",
    "url": "http://arxiv.org/pdf/2207.02506v2"
  },
  {
    "id": "2207.01994v1",
    "title": "Local Multi-Label Explanations for Random Forest",
    "authors": [
      "Nikolaos Mylonas",
      "Ioannis Mollas",
      "Nick Bassiliades",
      "Grigorios Tsoumakas"
    ],
    "abstract": "Multi-label classification is a challenging task, particularly in domains\nwhere the number of labels to be predicted is large. Deep neural networks are\noften effective at multi-label classification of images and textual data. When\ndealing with tabular data, however, conventional machine learning algorithms,\nsuch as tree ensembles, appear to outperform competition. Random forest, being\na popular ensemble algorithm, has found use in a wide range of real-world\nproblems. Such problems include fraud detection in the financial domain, crime\nhotspot detection in the legal sector, and in the biomedical field, disease\nprobability prediction when patient records are accessible. Since they have an\nimpact on people's lives, these domains usually require decision-making systems\nto be explainable. Random Forest falls short on this property, especially when\na large number of tree predictors are used. This issue was addressed in a\nrecent research named LionForests, regarding single label classification and\nregression. In this work, we adapt this technique to multi-label classification\nproblems, by employing three different strategies regarding the labels that the\nexplanation covers. Finally, we provide a set of qualitative and quantitative\nexperiments to assess the efficacy of this approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.0; I.2.6"
    ],
    "published": "2022-07-05T12:21:55+00:00",
    "updated": "2022-07-05T12:21:55+00:00",
    "url": "http://arxiv.org/pdf/2207.01994v1"
  },
  {
    "id": "2207.01035v1",
    "title": "Towards Real-Time Counting Shortest Cycles on Dynamic Graphs: A Hub Labeling Approach",
    "authors": [
      "Qingshuai Feng",
      "You Peng",
      "Wenjie Zhang",
      "Ying Zhang",
      "Xuemin Lin"
    ],
    "abstract": "With the ever-increasing prevalence of graph data in a wide spectrum of\napplications, it becomes essential to analyze structural trends in dynamic\ngraphs on a continual basis. The shortest cycle is a fundamental pattern in\ngraph analytics. In this paper, we investigate the problem of shortest cycle\ncounting for a given vertex in dynamic graphs in light of its applicability to\nproblems such as fraud detection. To address such queries efficiently, we\npropose a 2-hop labeling based algorithm called Counting Shortest Cycle (CSC\nfor short). Additionally, techniques for dynamically updating the CSC index are\nexplored. Comprehensive experiments are conducted to demonstrate the efficiency\nand effectiveness of our method. In particular, CSC enables query evaluation in\na few hundreds of microseconds for graphs with millions of edges, and improves\nquery efficiency by two orders of magnitude when compared to the baseline\nsolutions. Also, the update algorithm could efficiently cope with edge\ninsertions (deletions).",
    "categories": [
      "cs.SI"
    ],
    "published": "2022-07-03T13:13:33+00:00",
    "updated": "2022-07-03T13:13:33+00:00",
    "url": "http://arxiv.org/pdf/2207.01035v1"
  },
  {
    "id": "2206.15335v1",
    "title": "Byzantine Agreement with Optimal Resilience via Statistical Fraud Detection",
    "authors": [
      "Shang-En Huang",
      "Seth Pettie",
      "Leqi Zhu"
    ],
    "abstract": "Since the mid-1980s it has been known that Byzantine Agreement can be solved\nwith probability 1 asynchronously, even against an omniscient, computationally\nunbounded adversary that can adaptively \\emph{corrupt} up to $f<n/3$ parties.\nMoreover, the problem is insoluble with $f\\geq n/3$ corruptions. However,\nBracha's 1984 protocol achieved $f<n/3$ resilience at the cost of exponential\nexpected latency $2^{\\Theta(n)}$, a bound that has never been improved in this\nmodel with $f=\\lfloor (n-1)/3 \\rfloor$ corruptions.\n  In this paper we prove that Byzantine Agreement in the asynchronous, full\ninformation model can be solved with probability 1 against an adaptive\nadversary that can corrupt $f<n/3$ parties, while incurring only polynomial\nlatency with high probability. Our protocol follows earlier polynomial latency\nprotocols of King and Saia and Huang, Pettie, and Zhu, which had suboptimal\nresilience, namely $f \\approx n/10^9$ and $f<n/4$, respectively.\n  Resilience $f=(n-1)/3$ is uniquely difficult as this is the point at which\nthe influence of the Byzantine and honest players are of roughly equal\nstrength. The core technical problem we solve is to design a collective\ncoin-flipping protocol that eventually lets us flip a coin with an unambiguous\noutcome. In the beginning the influence of the Byzantine players is too\npowerful to overcome and they can essentially fix the coin's behavior at will.\nWe guarantee that after just a polynomial number of executions of the\ncoin-flipping protocol, either (a) the Byzantine players fail to fix the\nbehavior of the coin (thereby ending the game) or (b) we can ``blacklist''\nplayers such that the blacklisting rate for Byzantine players is at least as\nlarge as the blacklisting rate for good players. The blacklisting criterion is\nbased on a simple statistical test of fraud detection.",
    "categories": [
      "cs.DC",
      "cs.DS",
      "math.ST",
      "stat.TH"
    ],
    "published": "2022-06-30T15:06:35+00:00",
    "updated": "2022-06-30T15:06:35+00:00",
    "url": "http://arxiv.org/pdf/2206.15335v1"
  },
  {
    "id": "2206.15162v1",
    "title": "Using Person Embedding to Enrich Features and Data Augmentation for Classification",
    "authors": [
      "Ahmet Tuğrul Bayrak"
    ],
    "abstract": "Today, machine learning is applied in almost any field. In machine learning,\nwhere there are numerous methods, classification is one of the most basic and\ncrucial ones. Various problems can be solved by classification. The feature\nselection for model setup is extremely important, and producing new features\nvia feature engineering also has a vital place in the success of the model. In\nour study, fraud detection classification models are built on a labeled and\nimbalanced dataset as a case-study. Although it is a natural language\nprocessing method, a customer space has been created with word embedding, which\nhas been used in different areas, especially for recommender systems. The\ncustomer vectors in the created space are fed to the classification model as a\nfeature. Moreover, to increase the number of positive labels, rows with similar\ncharacteristics are re-labeled as positive by using customer similarity\ndetermined by embedding. The model in which embedding methods are included in\nthe classification, which provides a better representation of customers, has\nbeen compared with other models. Considering the results, it is observed that\nthe customer embedding method had a positive effect on the success of the\nclassification models.",
    "categories": [
      "cs.LG",
      "cs.IR"
    ],
    "published": "2022-06-30T09:48:27+00:00",
    "updated": "2022-06-30T09:48:27+00:00",
    "url": "http://arxiv.org/pdf/2206.15162v1"
  },
  {
    "id": "2208.13207v1",
    "title": "Maximum $k$-Biplex Search on Bipartite Graphs: A Symmetric-BK Branching Approach",
    "authors": [
      "Kaiqiang Yu",
      "Cheng Long"
    ],
    "abstract": "Enumerating maximal $k$-biplexes (MBPs) of a bipartite graph has been used\nfor applications such as fraud detection. Nevertheless, there usually exists an\nexponential number of MBPs, which brings up two issues when enumerating MBPs,\nnamely the effectiveness issue (many MBPs are of low values) and the efficiency\nissue (enumerating all MBPs is not affordable on large graphs). Existing\nproposals of tackling this problem impose constraints on the number of vertices\nof each MBP to be enumerated, yet they are still not sufficient (e.g., they\nrequire to specify the constraints, which is often not user-friendly, and\ncannot control the number of MBPs to be enumerated directly). Therefore, in\nthis paper, we study the problem of finding $K$ MBPs with the most edges called\nMaxBPs, where $K$ is a positive integral user parameter. The new proposal well\navoids the drawbacks of existing proposals. We formally prove the NP-hardness\nof the problem. We then design two branch-and-bound algorithms, among which,\nthe better one called FastBB improves the worst-case time complexity to\n$O^*(\\gamma_k^ n)$, where $O^*$ suppresses the polynomials, $\\gamma_k$ is a\nreal number that relies on $k$ and is strictly smaller than 2, and $n$ is the\nnumber of vertices in the graph. For example, for $k=1$, $\\gamma_k$ is equal to\n$1.754$. We further introduce three techniques for boosting the performance of\nthe branch-and-bound algorithms, among which, the best one called PBIE can\nfurther improve the time complexity to $O^*(\\gamma_k^{d^3})$ for large sparse\ngraphs, where $d$ is the maximum degree of the graph. We conduct extensive\nexperiments on both real and synthetic datasets, and the results show that our\nalgorithm is up to four orders of magnitude faster than all baselines and\nfinding MaxBPs works better than finding all MBPs for a fraud detection\napplication.",
    "categories": [
      "cs.DB"
    ],
    "published": "2022-08-28T12:18:21+00:00",
    "updated": "2022-08-28T12:18:21+00:00",
    "url": "http://arxiv.org/pdf/2208.13207v1"
  },
  {
    "id": "2208.13058v2",
    "title": "Adversarial Robustness for Tabular Data through Cost and Utility Awareness",
    "authors": [
      "Klim Kireev",
      "Bogdan Kulynych",
      "Carmela Troncoso"
    ],
    "abstract": "Many safety-critical applications of machine learning, such as fraud or abuse\ndetection, use data in tabular domains. Adversarial examples can be\nparticularly damaging for these applications. Yet, existing works on\nadversarial robustness primarily focus on machine-learning models in image and\ntext domains. We argue that, due to the differences between tabular data and\nimages or text, existing threat models are not suitable for tabular domains.\nThese models do not capture that the costs of an attack could be more\nsignificant than imperceptibility, or that the adversary could assign different\nvalues to the utility obtained from deploying different adversarial examples.\nWe demonstrate that, due to these differences, the attack and defense methods\nused for images and text cannot be directly applied to tabular settings. We\naddress these issues by proposing new cost and utility-aware threat models that\nare tailored to the adversarial capabilities and constraints of attackers\ntargeting tabular domains. We introduce a framework that enables us to design\nattack and defense mechanisms that result in models protected against cost and\nutility-aware adversaries, for example, adversaries constrained by a certain\nfinancial budget. We show that our approach is effective on three datasets\ncorresponding to applications for which adversarial examples can have economic\nand social implications.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2022-08-27T17:37:35+00:00",
    "updated": "2023-02-24T17:35:25+00:00",
    "url": "http://arxiv.org/pdf/2208.13058v2"
  },
  {
    "id": "2208.13771v2",
    "title": "Fast Bayesian Optimization of Needle-in-a-Haystack Problems using Zooming Memory-Based Initialization (ZoMBI)",
    "authors": [
      "Alexander E. Siemenn",
      "Zekun Ren",
      "Qianxiao Li",
      "Tonio Buonassisi"
    ],
    "abstract": "Needle-in-a-Haystack problems exist across a wide range of applications\nincluding rare disease prediction, ecological resource management, fraud\ndetection, and material property optimization. A Needle-in-a-Haystack problem\narises when there is an extreme imbalance of optimum conditions relative to the\nsize of the dataset. For example, only $0.82\\%$ out of $146$k total materials\nin the open-access Materials Project database have a negative Poisson's ratio.\nHowever, current state-of-the-art optimization algorithms are not designed with\nthe capabilities to find solutions to these challenging multidimensional\nNeedle-in-a-Haystack problems, resulting in slow convergence to a global\noptimum or pigeonholing into a local minimum. In this paper, we present a\nZooming Memory-Based Initialization algorithm, entitled ZoMBI. ZoMBI actively\nextracts knowledge from the previously best-performing evaluated experiments to\niteratively zoom in the sampling search bounds towards the global optimum\n\"needle\" and then prunes the memory of low-performing historical experiments to\naccelerate compute times by reducing the algorithm time complexity from\n$O(n^3)$ to $O(\\phi^3)$ for $\\phi$ forward experiments per activation, which\ntrends to a constant $O(1)$ over several activations. Additionally, ZoMBI\nimplements two custom adaptive acquisition functions to further guide the\nsampling of new experiments toward the global optimum. We validate the\nalgorithm's optimization performance on three real-world datasets exhibiting\nNeedle-in-a-Haystack and further stress-test the algorithm's performance on an\nadditional 174 analytical datasets. The ZoMBI algorithm demonstrates compute\ntime speed-ups of 400x compared to traditional Bayesian optimization as well as\nefficiently discovering optima in under 100 experiments that are up to 3x more\nhighly optimized than those discovered by similar methods MiP-EGO, TuRBO, and\nHEBO.",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "math.OC"
    ],
    "published": "2022-08-26T23:57:41+00:00",
    "updated": "2023-02-03T03:02:13+00:00",
    "url": "http://arxiv.org/pdf/2208.13771v2"
  },
  {
    "id": "2208.11904v1",
    "title": "Empirical study of Machine Learning Classifier Evaluation Metrics behavior in Massively Imbalanced and Noisy data",
    "authors": [
      "Gayan K. Kulatilleke",
      "Sugandika Samarakoon"
    ],
    "abstract": "With growing credit card transaction volumes, the fraud percentages are also\nrising, including overhead costs for institutions to combat and compensate\nvictims. The use of machine learning into the financial sector permits more\neffective protection against fraud and other economic crime. Suitably trained\nmachine learning classifiers help proactive fraud detection, improving\nstakeholder trust and robustness against illicit transactions. However, the\ndesign of machine learning based fraud detection algorithms has been\nchallenging and slow due the massively unbalanced nature of fraud data and the\nchallenges of identifying the frauds accurately and completely to create a gold\nstandard ground truth. Furthermore, there are no benchmarks or standard\nclassifier evaluation metrics to measure and identify better performing\nclassifiers, thus keeping researchers in the dark.\n  In this work, we develop a theoretical foundation to model human annotation\nerrors and extreme imbalance typical in real world fraud detection data sets.\nBy conducting empirical experiments on a hypothetical classifier, with a\nsynthetic data distribution approximated to a popular real world credit card\nfraud data set, we simulate human annotation errors and extreme imbalance to\nobserve the behavior of popular machine learning classifier evaluation\nmatrices. We demonstrate that a combined F1 score and g-mean, in that specific\norder, is the best evaluation metric for typical imbalanced fraud detection\nmodel classification.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2022-08-25T07:30:31+00:00",
    "updated": "2022-08-25T07:30:31+00:00",
    "url": "http://arxiv.org/pdf/2208.11904v1"
  },
  {
    "id": "2208.11900v1",
    "title": "Credit card fraud detection - Classifier selection strategy",
    "authors": [
      "Gayan K. Kulatilleke"
    ],
    "abstract": "Machine learning has opened up new tools for financial fraud detection. Using\na sample of annotated transactions, a machine learning classification algorithm\nlearns to detect frauds. With growing credit card transaction volumes and\nrising fraud percentages there is growing interest in finding appropriate\nmachine learning classifiers for detection. However, fraud data sets are\ndiverse and exhibit inconsistent characteristics. As a result, a model\neffective on a given data set is not guaranteed to perform on another. Further,\nthe possibility of temporal drift in data patterns and characteristics over\ntime is high. Additionally, fraud data has massive and varying imbalance. In\nthis work, we evaluate sampling methods as a viable pre-processing mechanism to\nhandle imbalance and propose a data-driven classifier selection strategy for\ncharacteristic highly imbalanced fraud detection data sets. The model derived\nbased on our selection strategy surpasses peer models, whilst working in more\nrealistic conditions, establishing the effectiveness of the strategy.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2022-08-25T07:13:42+00:00",
    "updated": "2022-08-25T07:13:42+00:00",
    "url": "http://arxiv.org/pdf/2208.11900v1"
  },
  {
    "id": "2208.10943v1",
    "title": "Challenges and Complexities in Machine Learning based Credit Card Fraud Detection",
    "authors": [
      "Gayan K. Kulatilleke"
    ],
    "abstract": "Credit cards play an exploding role in modern economies. Its popularity and\nubiquity have created a fertile ground for fraud, assisted by the cross boarder\nreach and instantaneous confirmation. While transactions are growing, the fraud\npercentages are also on the rise as well as the true cost of a dollar fraud.\nVolume of transactions, uniqueness of frauds and ingenuity of the fraudster are\nmain challenges in detecting frauds. The advent of machine learning, artificial\nintelligence and big data has opened up new tools in the fight against frauds.\nGiven past transactions, a machine learning algorithm has the ability to\n'learn' infinitely complex characteristics in order to identify frauds in\nreal-time, surpassing the best human investigators. However, the developments\nin fraud detection algorithms has been challenging and slow due the massively\nunbalanced nature of fraud data, absence of benchmarks and standard evaluation\nmetrics to identify better performing classifiers, lack of sharing and\ndisclosure of research findings and the difficulties in getting access to\nconfidential transaction data for research. This work investigates the\nproperties of typical massively imbalanced fraud data sets, their availability,\nsuitability for research use while exploring the widely varying nature of fraud\ndistributions. Furthermore, we show how human annotation errors compound with\nmachine classification errors. We also carry out experiments to determine the\neffect of PCA obfuscation (as a means of disseminating sensitive transaction\ndata for research and machine learning) on algorithmic performance of\nclassifiers and show that while PCA does not significantly degrade performance,\ncare should be taken to use the appropriate principle component size\n(dimensions) to avoid overfitting.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2022-08-20T07:53:51+00:00",
    "updated": "2022-08-20T07:53:51+00:00",
    "url": "http://arxiv.org/pdf/2208.10943v1"
  },
  {
    "id": "2208.10916v1",
    "title": "Application of Causal Inference to Analytical Customer Relationship Management in Banking and Insurance",
    "authors": [
      "Satyam Kumar",
      "Vadlamani Ravi"
    ],
    "abstract": "Of late, in order to have better acceptability among various domain,\nresearchers have argued that machine intelligence algorithms must be able to\nprovide explanations that humans can understand causally. This aspect, also\nknown as causability, achieves a specific level of human-level explainability.\nA specific class of algorithms known as counterfactuals may be able to provide\ncausability. In statistics, causality has been studied and applied for many\nyears, but not in great detail in artificial intelligence (AI). In a\nfirst-of-its-kind study, we employed the principles of causal inference to\nprovide explainability for solving the analytical customer relationship\nmanagement (ACRM) problems. In the context of banking and insurance, current\nresearch on interpretability tries to address causality-related questions like\nwhy did this model make such decisions, and was the model's choice influenced\nby a particular factor? We propose a solution in the form of an intervention,\nwherein the effect of changing the distribution of features of ACRM datasets is\nstudied on the target feature. Subsequently, a set of counterfactuals is also\nobtained that may be furnished to any customer who demands an explanation of\nthe decision taken by the bank/insurance company. Except for the credit card\nchurn prediction dataset, good quality counterfactuals were generated for the\nloan default, insurance fraud detection, and credit card fraud detection\ndatasets, where changes in no more than three features are observed.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "68Txx, 62D20, 91-08",
      "I.2"
    ],
    "published": "2022-08-19T05:57:58+00:00",
    "updated": "2022-08-19T05:57:58+00:00",
    "url": "http://arxiv.org/pdf/2208.10916v1"
  },
  {
    "id": "2208.07963v1",
    "title": "Mixed Quantum-Classical Method For Fraud Detection with Quantum Feature Selection",
    "authors": [
      "Michele Grossi",
      "Noelle Ibrahim",
      "Voica Radescu",
      "Robert Loredo",
      "Kirsten Voigt",
      "Constantin Von Altrock",
      "Andreas Rudnik"
    ],
    "abstract": "This paper presents a first end-to-end application of a Quantum Support\nVector Machine (QSVM) algorithm for a classification problem in the financial\npayment industry using the IBM Safer Payments and IBM Quantum Computers via the\nQiskit software stack. Based on real card payment data, a thorough comparison\nis performed to assess the complementary impact brought in by the current\nstate-of-the-art Quantum Machine Learning algorithms with respect to the\nClassical Approach. A new method to search for best features is explored using\nthe Quantum Support Vector Machine's feature map characteristics. The results\nare compared using fraud specific key performance indicators: Accuracy, Recall,\nand False Positive Rate, extracted from analyses based on human expertise (rule\ndecisions), classical machine learning algorithms (Random Forest, XGBoost) and\nquantum based machine learning algorithms using QSVM. In addition, a hybrid\nclassical-quantum approach is explored by using an ensemble model that combines\nclassical and quantum algorithms to better improve the fraud prevention\ndecision. We found, as expected, that the results highly depend on feature\nselections and algorithms that are used to select them. The QSVM provides a\ncomplementary exploration of the feature space which led to an improved\naccuracy of the mixed quantum-classical method for fraud detection, on a\ndrastically reduced data set to fit current state of Quantum Hardware.",
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "published": "2022-08-16T21:46:04+00:00",
    "updated": "2022-08-16T21:46:04+00:00",
    "url": "http://arxiv.org/pdf/2208.07963v1"
  },
  {
    "id": "2208.07310v1",
    "title": "Placement Laundering and the Complexities of Attribution in Online Advertising",
    "authors": [
      "Jeffery Kline",
      "Aaron Cahn",
      "Paul Barford"
    ],
    "abstract": "A basic assumption in online advertising is that it is possible to attribute\na view of a particular ad creative (i.e., an impression) to a particular web\npage. In practice, however, the seemingly simple task of ad attribution is\nchallenging due to the scale, complexity and diversity of ad delivery systems.\nIn this paper, we describe a new form of fraud that we call placement\nlaundering, which exploits vulnerabilities in attribution mechanisms. Placement\nlaundering allows malicious actors to inflate revenue by making ad calls that\nappear to originate from high quality publishers. We describe the basic aspects\nof placement laundering and give details of two instances found in the wild.\nOne of the instances that we describe abuses the intended functionality of the\nwidely-deployed SafeFrame environment. We describe a placement laundering\ndetection method that is capable of identifying a general class of laundering\nschemes, and provide results on tests with that method.",
    "categories": [
      "cs.CR",
      "cs.SI"
    ],
    "published": "2022-08-15T16:18:01+00:00",
    "updated": "2022-08-15T16:18:01+00:00",
    "url": "http://arxiv.org/pdf/2208.07310v1"
  },
  {
    "id": "2208.06093v1",
    "title": "Scalable and Sparsity-Aware Privacy-Preserving K-means Clustering with Application to Fraud Detection",
    "authors": [
      "Yingting Liu",
      "Chaochao Chen",
      "Jamie Cui",
      "Li Wang",
      "Lei Wang"
    ],
    "abstract": "K-means is one of the most widely used clustering models in practice. Due to\nthe problem of data isolation and the requirement for high model performance,\nhow to jointly build practical and secure K-means for multiple parties has\nbecome an important topic for many applications in the industry. Existing work\non this is mainly of two types. The first type has efficiency advantages, but\ninformation leakage raises potential privacy risks. The second type is provable\nsecure but is inefficient and even helpless for the large-scale data sparsity\nscenario. In this paper, we propose a new framework for efficient\nsparsity-aware K-means with three characteristics. First, our framework is\ndivided into a data-independent offline phase and a much faster online phase,\nand the offline phase allows to pre-compute almost all cryptographic\noperations. Second, we take advantage of the vectorization techniques in both\nonline and offline phases. Third, we adopt a sparse matrix multiplication for\nthe data sparsity scenario to improve efficiency further. We conduct\ncomprehensive experiments on three synthetic datasets and deploy our model in a\nreal-world fraud detection task. Our experimental results show that, compared\nwith the state-of-the-art solution, our model achieves competitive performance\nin terms of both running time and communication size, especially on sparse\ndatasets.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2022-08-12T02:58:26+00:00",
    "updated": "2022-08-12T02:58:26+00:00",
    "url": "http://arxiv.org/pdf/2208.06093v1"
  },
  {
    "id": "2208.02484v3",
    "title": "Customs Import Declaration Datasets",
    "authors": [
      "Chaeyoon Jeong",
      "Sundong Kim",
      "Jaewoo Park",
      "Yeonsoo Choi"
    ],
    "abstract": "Given the huge volume of cross-border flows, effective and efficient control\nof trade becomes more crucial in protecting people and society from illicit\ntrade. However, limited accessibility of the transaction-level trade datasets\nhinders the progress of open research, and lots of customs administrations have\nnot benefited from the recent progress in data-based risk management. In this\npaper, we introduce an import declaration dataset to facilitate the\ncollaboration between domain experts in customs administrations and researchers\nfrom diverse domains, such as data science and machine learning. The dataset\ncontains 54,000 artificially generated trades with 22 key attributes, and it is\nsynthesized with conditional tabular GAN while maintaining correlated features.\nSynthetic data has several advantages. First, releasing the dataset is free\nfrom restrictions that do not allow disclosing the original import data. The\nfabrication step minimizes the possible identity risk which may exist in trade\nstatistics. Second, the published data follow a similar distribution to the\nsource data so that it can be used in various downstream tasks. Hence, our\ndataset can be used as a benchmark for testing the performance of any\nclassification algorithm. With the provision of data and its generation\nprocess, we open baseline codes for fraud detection tasks, as we empirically\nshow that more advanced algorithms can better detect fraud.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.OT"
    ],
    "published": "2022-08-04T06:20:20+00:00",
    "updated": "2023-09-04T05:48:50+00:00",
    "url": "http://arxiv.org/pdf/2208.02484v3"
  },
  {
    "id": "2208.01203v1",
    "title": "Unsupervised quantum machine learning for fraud detection",
    "authors": [
      "Oleksandr Kyriienko",
      "Einar B. Magnusson"
    ],
    "abstract": "We develop quantum protocols for anomaly detection and apply them to the task\nof credit card fraud detection (FD). First, we establish classical benchmarks\nbased on supervised and unsupervised machine learning methods, where average\nprecision is chosen as a robust metric for detecting anomalous data. We focus\non kernel-based approaches for ease of direct comparison, basing our\nunsupervised modelling on one-class support vector machines (OC-SVM). Next, we\nemploy quantum kernels of different type for performing anomaly detection, and\nobserve that quantum FD can challenge equivalent classical protocols at\nincreasing number of features (equal to the number of qubits for data\nembedding). Performing simulations with registers up to 20 qubits, we find that\nquantum kernels with re-uploading demonstrate better average precision, with\nthe advantage increasing with system size. Specifically, at 20 qubits we reach\nthe quantum-classical separation of average precision being equal to 15%. We\ndiscuss the prospects of fraud detection with near- and mid-term quantum\nhardware, and describe possible future improvements.",
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn"
    ],
    "published": "2022-08-02T02:08:52+00:00",
    "updated": "2022-08-02T02:08:52+00:00",
    "url": "http://arxiv.org/pdf/2208.01203v1"
  },
  {
    "id": "2208.00493v1",
    "title": "Scrutinizing Shipment Records To Thwart Illegal Timber Trade",
    "authors": [
      "Debanjan Datta",
      "Sathappan Muthiah",
      "John Simeone",
      "Amelia Meadows",
      "Naren Ramakrishnan"
    ],
    "abstract": "Timber and forest products made from wood, like furniture, are valuable\ncommodities, and like the global trade of many highly-valued natural resources,\nface challenges of corruption, fraud, and illegal harvesting. These grey and\nblack market activities in the wood and forest products sector are not limited\nto the countries where the wood was harvested, but extend throughout the global\nsupply chain and have been tied to illicit financial flows, like trade-based\nmoney laundering, document fraud, species mislabeling, and other illegal\nactivities. The task of finding such fraudulent activities using trade data, in\nthe absence of ground truth, can be modelled as an unsupervised anomaly\ndetection problem. However existing approaches suffer from certain shortcomings\nin their applicability towards large scale trade data. Trade data is\nheterogeneous, with both categorical and numerical attributes in a tabular\nformat. The overall challenge lies in the complexity, volume and velocity of\ndata, with large number of entities and lack of ground truth labels. To\nmitigate these, we propose a novel unsupervised anomaly detection --\nContrastive Learning based Heterogeneous Anomaly Detection (CHAD) that is\ngenerally applicable for large-scale heterogeneous tabular data. We demonstrate\nour model CHAD performs favorably against multiple comparable baselines for\npublic benchmark datasets, and outperforms them in the case of trade data. More\nimportantly we demonstrate our approach reduces assumptions and efforts\nrequired hyperparameter tuning, which is a key challenging aspect in an\nunsupervised training paradigm. Specifically, our overarching objective\npertains to detecting suspicious timber shipments and patterns using Bill of\nLading trade record data. Detecting anomalous transactions in shipment records\ncan enable further investigation by government agencies and supply chain\nconstituents.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-07-31T18:54:52+00:00",
    "updated": "2022-07-31T18:54:52+00:00",
    "url": "http://arxiv.org/pdf/2208.00493v1"
  },
  {
    "id": "2209.14071v1",
    "title": "Towards Auditable Distributed Systems",
    "authors": [
      "Lev Sorokin"
    ],
    "abstract": "The emerging trend towards distributed (cloud) systems (DS) has widely\narrived whether in the automotive, public or the financial sector, but the\nexecution of services of heterogeneous service providers is exposed to several\nrisks. Beside hardware/software faults or cyber attacks that can influence the\ncorrectness of the system, fraud is also an issue. In such case it is not only\nimportant to verify the correctness of the system, but also have evidence which\ncomponent and participant behaves faulty. This makes it possible, e.g. to claim\nfor compensation after systems execution but also to assure information for\nverification can be trusted. The main goal of our research is to assure the\nmonitoring of DS based on auditable information. We follow a decentralized\nmonitoring strategy and envision a distributed monitoring approach of system\nproperties based on distributedlogic programs that consider auditability. The\nexpected contribution of this work is to establish with the application of our\nframework the mutual trust of distributed parties, as well as trust of clients\nin the systems execution. We showcase our ideas on a DS for booking services\nwith unmanned air vehicles.",
    "categories": [
      "cs.SE"
    ],
    "published": "2022-09-28T13:13:26+00:00",
    "updated": "2022-09-28T13:13:26+00:00",
    "url": "http://arxiv.org/pdf/2209.14071v1"
  },
  {
    "id": "2209.10658v2",
    "title": "Explaining Anomalies using Denoising Autoencoders for Financial Tabular Data",
    "authors": [
      "Timur Sattarov",
      "Dayananda Herurkar",
      "Jörn Hees"
    ],
    "abstract": "Recent advances in Explainable AI (XAI) increased the demand for deployment\nof safe and interpretable AI models in various industry sectors. Despite the\nlatest success of deep neural networks in a variety of domains, understanding\nthe decision-making process of such complex models still remains a challenging\ntask for domain experts. Especially in the financial domain, merely pointing to\nan anomaly composed of often hundreds of mixed type columns, has limited value\nfor experts. Hence, in this paper, we propose a framework for explaining\nanomalies using denoising autoencoders designed for mixed type tabular data. We\nspecifically focus our technique on anomalies that are erroneous observations.\nThis is achieved by localizing individual sample columns (cells) with potential\nerrors and assigning corresponding confidence scores. In addition, the model\nprovides the expected cell value estimates to fix the errors. We evaluate our\napproach based on three standard public tabular datasets (Credit Default,\nAdult, IEEE Fraud) and one proprietary dataset (Holdings). We find that\ndenoising autoencoders applied to this task already outperform other approaches\nin the cell error detection rates as well as in the expected value rates.\nAdditionally, we analyze how a specialized loss designed for cell error\ndetection can further improve these metrics. Our framework is designed for a\ndomain expert to understand abnormal characteristics of an anomaly, as well as\nto improve in-house data quality management processes.",
    "categories": [
      "cs.LG",
      "cs.CE"
    ],
    "published": "2022-09-21T21:02:22+00:00",
    "updated": "2022-10-03T11:35:17+00:00",
    "url": "http://arxiv.org/pdf/2209.10658v2"
  },
  {
    "id": "2210.07770v1",
    "title": "Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning",
    "authors": [
      "Xiaoli Tang",
      "Han Yu"
    ],
    "abstract": "Artificial intelligence-empowred Real-Time Bidding (AIRTB) is regarded as one\nof the most enabling technologies for online advertising. It has attracted\nsignificant research attention from diverse fields such as pattern recognition,\ngame theory and mechanism design. Despite of its remarkable development and\ndeployment, the AIRTB system can sometimes harm the interest of its\nparticipants (e.g., depleting the advertisers' budget with various kinds of\nfraud). As such, building trustworthy AIRTB auctioning systems has emerged as\nan important direction of research in this field in recent years. Due to the\nhighly interdisciplinary nature of this field and a lack of a comprehensive\nsurvey, it is a challenge for researchers to enter this field and contribute\ntowards building trustworthy AIRTB technologies. This paper bridges this\nimportant gap in trustworthy AIRTB literature. We start by analysing the key\nconcerns of various AIRTB stakeholders and identify three main dimensions of\ntrust building in AIRTB, namely security, robustness and fairness. For each of\nthese dimensions, we propose a unique taxonomy of the state of the art, trace\nthe root causes of possible breakdown of trust, and discuss the necessity of\nthe given dimension. This is followed by a comprehensive review of existing\nstrategies for fulfilling the requirements of each trust dimension. In\naddition, we discuss the promising future directions of research essential\ntowards building trustworthy AIRTB systems to benefit the field of online\nadvertising.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2022-09-21T08:21:51+00:00",
    "updated": "2022-09-21T08:21:51+00:00",
    "url": "http://arxiv.org/pdf/2210.07770v1"
  },
  {
    "id": "2209.08659v1",
    "title": "A new approach to Statistical analysis of election results",
    "authors": [
      "Ivan H. Krykun"
    ],
    "abstract": "In this paper, a new method of detection of election fraud is proposed. This\nmethod is based on the calculation of the ratio of two standard normal random\nvariables; estimation of parameters of obtained sample and comparison of these\nestimates with known theoretical values of parameters. Also in the paper, there\nis an example of the application of the method.",
    "categories": [
      "stat.ME",
      "math.PR",
      "62E17 (Primary), 62P25 (Secondary)"
    ],
    "published": "2022-09-18T21:15:52+00:00",
    "updated": "2022-09-18T21:15:52+00:00",
    "url": "http://arxiv.org/pdf/2209.08659v1"
  },
  {
    "id": "2209.05909v1",
    "title": "TDB: Breaking All Hop-Constrained Cycles in Billion-Scale Directed Graphs",
    "authors": [
      "You Peng",
      "Xuemin Lin",
      "Michael Yu",
      "Wenjie Zhang",
      "Lu Qin"
    ],
    "abstract": "The Feedback vertex set with the minimum size is one of Karp's 21 NP-complete\nproblems targeted at breaking all the cycles in a graph. This problem is\napplicable to a broad variety of domains, including E-commerce networks,\ndatabase systems, and program analysis. In reality, users are frequently most\nconcerned with the hop-constrained cycles (i.e., cycles with a limited number\nof hops). For instance, in the E-commerce networks, the fraud detection team\nwould discard cycles with a high number of hops since they are less relevant\nand grow exponentially in size. Thus, it is quite reasonable to investigate the\nfeedback vertex set problem in the context of hop-constrained cycles, namely\nhop-constrained cycle cover problem. It is concerned with determining a set of\nvertices that covers all hop-constrained cycles in a given directed graph. A\ncommon method to solve this is to use a bottom-up algorithm, where it\niteratively selects cover vertices into the result set. Based on this paradigm,\nthe existing works mainly focus on the vertices orders and several heuristic\nstrategies. In this paper, a totally opposite cover process topdown is proposed\nand bounds are presented on it. Surprisingly, both theoretical time complexity\nand practical performance are improved.",
    "categories": [
      "cs.DB"
    ],
    "published": "2022-09-13T11:45:08+00:00",
    "updated": "2022-09-13T11:45:08+00:00",
    "url": "http://arxiv.org/pdf/2209.05909v1"
  },
  {
    "id": "2209.05049v1",
    "title": "Hyperbolic Self-supervised Contrastive Learning Based Network Anomaly Detection",
    "authors": [
      "Yuanjun Shi"
    ],
    "abstract": "Anomaly detection on the attributed network has recently received increasing\nattention in many research fields, such as cybernetic anomaly detection and\nfinancial fraud detection. With the wide application of deep learning on graph\nrepresentations, existing approaches choose to apply euclidean graph encoders\nas their backbone, which may lose important hierarchical information,\nespecially in complex networks. To tackle this problem, we propose an efficient\nanomaly detection framework using hyperbolic self-supervised contrastive\nlearning. Specifically, we first conduct the data augmentation by performing\nsubgraph sampling. Then we utilize the hierarchical information in hyperbolic\nspace through exponential mapping and logarithmic mapping and obtain the\nanomaly score by subtracting scores of the positive pairs from the negative\npairs via a discriminating process. Finally, extensive experiments on four\nreal-world datasets demonstrate that our approach performs superior over\nrepresentative baseline approaches.",
    "categories": [
      "cs.SI",
      "cs.LG"
    ],
    "published": "2022-09-12T07:08:34+00:00",
    "updated": "2022-09-12T07:08:34+00:00",
    "url": "http://arxiv.org/pdf/2209.05049v1"
  },
  {
    "id": "2209.04635v1",
    "title": "A Comparative Study on Unsupervised Anomaly Detection for Time Series: Experiments and Analysis",
    "authors": [
      "Yan Zhao",
      "Liwei Deng",
      "Xuanhao Chen",
      "Chenjuan Guo",
      "Bin Yang",
      "Tung Kieu",
      "Feiteng Huang",
      "Torben Bach Pedersen",
      "Kai Zheng",
      "Christian S. Jensen"
    ],
    "abstract": "The continued digitization of societal processes translates into a\nproliferation of time series data that cover applications such as fraud\ndetection, intrusion detection, and energy management, where anomaly detection\nis often essential to enable reliability and safety. Many recent studies target\nanomaly detection for time series data. Indeed, area of time series anomaly\ndetection is characterized by diverse data, methods, and evaluation strategies,\nand comparisons in existing studies consider only part of this diversity, which\nmakes it difficult to select the best method for a particular problem setting.\nTo address this shortcoming, we introduce taxonomies for data, methods, and\nevaluation strategies, provide a comprehensive overview of unsupervised time\nseries anomaly detection using the taxonomies, and systematically evaluate and\ncompare state-of-the-art traditional as well as deep learning techniques. In\nthe empirical study using nine publicly available datasets, we apply the most\ncommonly-used performance evaluation metrics to typical methods under a fair\nimplementation standard. Based on the structuring offered by the taxonomies, we\nreport on empirical studies and provide guidelines, in the form of comparative\ntables, for choosing the methods most suitable for particular application\nsettings. Finally, we propose research directions for this dynamic field.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-09-10T10:44:25+00:00",
    "updated": "2022-09-10T10:44:25+00:00",
    "url": "http://arxiv.org/pdf/2209.04635v1"
  },
  {
    "id": "2209.03319v1",
    "title": "Measurement of the Usage of Web Clips in Underground Economy",
    "authors": [
      "Qinyu Hu",
      "Songyang Wu",
      "Wenqi Sun",
      "Zhushou Tang",
      "Chaofan Chen",
      "Zhiguo Ding",
      "Xiaomei Zhang"
    ],
    "abstract": "In this paper, we study the ecosystem of the abused Web Clips in underground\neconomy. Through this study, we find the Web Clips is wildly used by\nperpetrators to penetrate iOS devices to gain profit. This work starts with\n1,800 user complaint documents about cyber crimes over Web Clips. We firstly\nlook into the ecosystem of abused Web Clips and point out the main participants\nand workflow. In addition, what is the Web Clips used for is demystified. Then\nthe main participants, including creators, distributors, and operators are\ndeeply studied based on our dataset. We try to reveal the prominent features of\nthe illicit Web Clips and give some mitigation measures.\n  Analysis reveals that 1) SSL certificate is overwhelmingly preferred for\nsigning Web Clips instances compared with certificate issued by Apple. The\nwildly used SSL certificates can be aggregated into a limited group. 2) The\ncontent of the abused Web Clips falls into a few categories, `Gambling',\n`Fraud', and `Pornography' are among the top categories. 3) Instant messenger\n(IM) and live streaming platform are the most popular medium to trick victims\ninto deploying the Web Clips. 4) The Web Clips are operated by a small amount\nof perpetrators, and the perpetrators tend to evade detection by taking\ntechnical approach, such as registering domain names through oversea domain\nname service provider, preferring easy-to-acquire new gTLD (global Top Level\nDomain), and deploying anti-crawler tricks.\n  Our study gives hints on investigation of cyber crime over Web Clips, we hope\nthat this work can help stakeholders to stay ahead of the threat.",
    "categories": [
      "cs.CR"
    ],
    "published": "2022-09-07T17:26:22+00:00",
    "updated": "2022-09-07T17:26:22+00:00",
    "url": "http://arxiv.org/pdf/2209.03319v1"
  },
  {
    "id": "2209.02007v1",
    "title": "Stop the [Image] Steal: The Role and Dynamics of Visual Content in the 2020 U.S. Election Misinformation Campaign",
    "authors": [
      "Hana Matatov",
      "Mor Naaman",
      "Ofra Amir"
    ],
    "abstract": "Images are powerful. Visual information can attract attention, improve\npersuasion, trigger stronger emotions, and is easy to share and spread. We\nexamine the characteristics of the popular images shared on Twitter as part of\n\"Stop the Steal\", the widespread misinformation campaign during the 2020 U.S.\nelection. We analyze the spread of the forty most popular images shared on\nTwitter as part of this campaign. Using a coding process, we categorize and\nlabel the images according to their type, content, origin, and role, and\nperform a mixed-method analysis of these images' spread on Twitter. Our results\nshow that popular images include both photographs and text rendered as image.\nOnly very few of these popular images included alleged photographic evidence of\nfraud; and none of the popular photographs had been manipulated. Most images\nreached a significant portion of their total spread within several hours from\ntheir first appearance, and both popular- and less-popular accounts were\ninvolved in various stages of their spread.",
    "categories": [
      "cs.SI"
    ],
    "published": "2022-09-05T15:16:33+00:00",
    "updated": "2022-09-05T15:16:33+00:00",
    "url": "http://arxiv.org/pdf/2209.02007v1"
  },
  {
    "id": "2209.01945v1",
    "title": "BiRank vs PageRank: Using SNA on Company Register Data for Fiscal Risk Prediction",
    "authors": [
      "Bernhard Göschlberger",
      "Dragos Deliu"
    ],
    "abstract": "Efficient financial administrations need to ensure compliant behavior of all\ntax subjects without excessive personnel costs or obstruction of compliant\ncompanies. To do so, accurate prediction of non-compliance or fraud is crucial.\nSocial Network Analysis (SNA) provides powerful tools for fraud prediction as\nfraudulence is often clustered in certain areas of real world social networks.\nIn this paper we present our results of comparing PageRank and the more recent\nBiRank to infer risk-ranks based on network structure and prior fraud\ninformation. Specifically, we model our social network from company register\ndata. We find that in this case study BiRank outperforms PageRank in both\nquality of the resulting ranks for fraud prediction and run time. The results\nshow that this class of algorithms is generally useful for fraud and risk\nprediction and more specifically also illustrate the potential of BiRank in\ncomparison, as it opens up new modeling opportunities. Our results show that\nselecting companies for tax audits based on BiRank yields a precision of 16.38%\nfor the top 20.000 subjects selecting 83.4% of all fraud cases (recall).",
    "categories": [
      "cs.SI"
    ],
    "published": "2022-09-05T12:53:33+00:00",
    "updated": "2022-09-05T12:53:33+00:00",
    "url": "http://arxiv.org/pdf/2209.01945v1"
  },
  {
    "id": "2209.01642v1",
    "title": "Fraud Detection Using Optimized Machine Learning Tools Under Imbalance Classes",
    "authors": [
      "Mary Isangediok",
      "Kelum Gajamannage"
    ],
    "abstract": "Fraud detection is a challenging task due to the changing nature of fraud\npatterns over time and the limited availability of fraud examples to learn such\nsophisticated patterns. Thus, fraud detection with the aid of smart versions of\nmachine learning (ML) tools is essential to assure safety. Fraud detection is a\nprimary ML classification task; however, the optimum performance of the\ncorresponding ML tool relies on the usage of the best hyperparameter values.\nMoreover, classification under imbalanced classes is quite challenging as it\ncauses poor performance in minority classes, which most ML classification\ntechniques ignore. Thus, we investigate four state-of-the-art ML techniques,\nnamely, logistic regression, decision trees, random forest, and extreme\ngradient boost, that are suitable for handling imbalance classes to maximize\nprecision and simultaneously reduce false positives. First, these classifiers\nare trained on two original benchmark unbalanced fraud detection datasets,\nnamely, phishing website URLs and fraudulent credit card transactions. Then,\nthree synthetically balanced datasets are produced for each original data set\nby implementing the sampling frameworks, namely, RandomUnderSampler, SMOTE, and\nSMOTEENN. The optimum hyperparameters for all the 16 experiments are revealed\nusing the method RandomzedSearchCV. The validity of the 16 approaches in the\ncontext of fraud detection is compared using two benchmark performance metrics,\nnamely, area under the curve of receiver operating characteristics (AUC ROC)\nand area under the curve of precision and recall (AUC PR). For both phishing\nwebsite URLs and credit card fraud transaction datasets, the results indicate\nthat extreme gradient boost trained on the original data shows trustworthy\nperformance in the imbalanced dataset and manages to outperform the other three\nmethods in terms of both AUC ROC and AUC PR.",
    "categories": [
      "cs.LG",
      "68T09",
      "I.2.0"
    ],
    "published": "2022-09-04T15:30:23+00:00",
    "updated": "2022-09-04T15:30:23+00:00",
    "url": "http://arxiv.org/pdf/2209.01642v1"
  },
  {
    "id": "2209.00131v1",
    "title": "On the incorrect use of Carlisle's method for dichotomous variables",
    "authors": [
      "Daniel V. Tausk"
    ],
    "abstract": "In 2017, J. B. Carlisle has proposed a method for fraud detection in\nrandomized controlled trials based on a comparison of reported baseline data\nbetween treatment groups. While Carlisle has only used the method for\ncontinuous variables, some authors have recently employed a naive adaption of\nthe method for dichotomous variables. We explain why such adaptation leads to\np-values that are wrong by orders of magnitude and we make a simple concrete\nproposal for correction of the method.",
    "categories": [
      "stat.AP",
      "62P10"
    ],
    "published": "2022-08-31T21:50:51+00:00",
    "updated": "2022-08-31T21:50:51+00:00",
    "url": "http://arxiv.org/pdf/2209.00131v1"
  },
  {
    "id": "2208.14417v3",
    "title": "Fraud Dataset Benchmark and Applications",
    "authors": [
      "Prince Grover",
      "Julia Xu",
      "Justin Tittelfitz",
      "Anqi Cheng",
      "Zheng Li",
      "Jakub Zablocki",
      "Jianbo Liu",
      "Hao Zhou"
    ],
    "abstract": "Standardized datasets and benchmarks have spurred innovations in computer\nvision, natural language processing, multi-modal and tabular settings. We note\nthat, as compared to other well researched fields, fraud detection has unique\nchallenges: high-class imbalance, diverse feature types, frequently changing\nfraud patterns, and adversarial nature of the problem. Due to these, the\nmodeling approaches evaluated on datasets from other research fields may not\nwork well for the fraud detection. In this paper, we introduce Fraud Dataset\nBenchmark (FDB), a compilation of publicly available datasets catered to fraud\ndetection FDB comprises variety of fraud related tasks, ranging from\nidentifying fraudulent card-not-present transactions, detecting bot attacks,\nclassifying malicious URLs, estimating risk of loan default to content\nmoderation. The Python based library for FDB provides a consistent API for data\nloading with standardized training and testing splits. We demonstrate several\napplications of FDB that are of broad interest for fraud detection, including\nfeature engineering, comparison of supervised learning algorithms, label noise\nremoval, class-imbalance treatment and semi-supervised learning. We hope that\nFDB provides a common playground for researchers and practitioners in the fraud\ndetection domain to develop robust and customized machine learning techniques\ntargeting various fraud use cases.",
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ],
    "published": "2022-08-30T17:35:39+00:00",
    "updated": "2023-09-22T14:50:22+00:00",
    "url": "http://arxiv.org/pdf/2208.14417v3"
  },
  {
    "id": "2210.15912v1",
    "title": "Decontamination of the scientific literature",
    "authors": [
      "Guillaume Cabanac"
    ],
    "abstract": "Research misconduct and frauds pollute the scientific literature. Honest\nerrors and malevolent data fabrication, image manipulation, journal hijacking,\nand plagiarism passed peer review unnoticed. Problematic papers deceive\nreaders, authors citing them, and AI-powered literature-based discovery.\nFlagship publishers accepted hundreds flawed papers despite claiming to enforce\npeer review. This application ambitions to decontaminate the scientific\nliterature using curative and preventive actions.",
    "categories": [
      "cs.DL",
      "cs.IR"
    ],
    "published": "2022-10-28T05:47:13+00:00",
    "updated": "2022-10-28T05:47:13+00:00",
    "url": "http://arxiv.org/pdf/2210.15912v1"
  },
  {
    "id": "2210.15043v2",
    "title": "Active Countermeasures for Email Fraud",
    "authors": [
      "Wentao Chen",
      "Fuzhou Wang",
      "Matthew Edwards"
    ],
    "abstract": "As a major component of online crime, email-based fraud is a threat that\ncauses substantial economic losses every year. To counteract these scammers,\nvolunteers called scam-baiters play the roles of victims, reply to scammers,\nand try to waste their time and attention with long and unproductive\nconversations. To curb email fraud and magnify the effectiveness of\nscam-baiting, we developed and deployed an expandable scam-baiting mailserver\nthat can conduct scam-baiting activities automatically. We implemented three\nreply strategies using three different models and conducted a one-month-long\nexperiment during which we elicited 150 messages from 130 different scammers.\nWe compare the performance of each strategy at attracting and holding the\nattention of scammers, finding tradeoffs between human-written and\nautomatically-generated response strategies. We also demonstrate that scammers\ncan be engaged concurrently by multiple servers deploying these strategies in a\nsecond experiment, which used two server instances to contact 92 different\nscammers over 12 days. We release both our platform and a dataset containing\nconversations between our automatic scam-baiters and real human scammers, to\nsupport future work in preventing online fraud.",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "published": "2022-10-26T21:20:13+00:00",
    "updated": "2023-06-01T19:39:30+00:00",
    "url": "http://arxiv.org/pdf/2210.15043v2"
  },
  {
    "id": "2210.15030v2",
    "title": "A Hierarchical Approach to Conditional Random Fields for System Anomaly Detection",
    "authors": [
      "Srishti Mishra",
      "Tvarita Jain",
      "Dinkar Sitaram"
    ],
    "abstract": "Anomaly detection to recognize unusual events in large scale systems in a\ntime sensitive manner is critical in many industries, eg. bank fraud,\nenterprise systems, medical alerts, etc. Large-scale systems often grow in size\nand complexity over time, and anomaly detection algorithms need to adapt to\nchanging structures. A hierarchical approach takes advantage of the implicit\nrelationships in complex systems and localized context. The features in complex\nsystems may vary drastically in data distribution, capturing different aspects\nfrom multiple data sources, and when put together provide a more complete view\nof the system. In this paper, two datasets are considered, the 1st comprising\nof system metrics from machines running on a cloud service, and the 2nd of\napplication metrics from a large-scale distributed software system with\ninherent hierarchies and interconnections amongst its system nodes. Comparing\nalgorithms, across the changepoint based PELT algorithm, cognitive\nlearning-based Hierarchical Temporal Memory algorithms, Support Vector Machines\nand Conditional Random Fields provides a basis for proposing a Hierarchical\nGlobal-Local Conditional Random Field approach to accurately capture anomalies\nin complex systems across various features. Hierarchical algorithms can learn\nboth the intricacies of specific features, and utilize these in a global\nabstracted representation to detect anomalous patterns robustly across\nmulti-source feature data and distributed systems. A graphical network analysis\non complex systems can further fine-tune datasets to mine relationships based\non available features, which can benefit hierarchical models. Furthermore,\nhierarchical solutions can adapt well to changes at a localized level, learning\non new data and changing environments when parts of a system are over-hauled,\nand translate these learnings to a global view of the system over time.",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "published": "2022-10-26T21:02:47+00:00",
    "updated": "2022-10-28T05:33:51+00:00",
    "url": "http://arxiv.org/pdf/2210.15030v2"
  },
  {
    "id": "2210.13023v2",
    "title": "FairGen: Fair Synthetic Data Generation",
    "authors": [
      "Bhushan Chaudhari",
      "Himanshu Chaudhary",
      "Aakash Agarwal",
      "Kamna Meena",
      "Tanmoy Bhowmik"
    ],
    "abstract": "With the rising adoption of Machine Learning across the domains like banking,\npharmaceutical, ed-tech, etc, it has become utmost important to adopt\nresponsible AI methods to ensure models are not unfairly discriminating against\nany group. Given the lack of clean training data, generative adversarial\ntechniques are preferred to generate synthetic data with several\nstate-of-the-art architectures readily available across various domains from\nunstructured data such as text, images to structured datasets modelling fraud\ndetection and many more. These techniques overcome several challenges such as\nclass imbalance, limited training data, restricted access to data due to\nprivacy issues. Existing work focusing on generating fair data either works for\na certain GAN architecture or is very difficult to tune across the GANs. In\nthis paper, we propose a pipeline to generate fairer synthetic data independent\nof the GAN architecture. The proposed paper utilizes a pre-processing algorithm\nto identify and remove bias inducing samples. In particular, we claim that\nwhile generating synthetic data most GANs amplify bias present in the training\ndata but by removing these bias inducing samples, GANs essentially focuses more\non real informative samples. Our experimental evaluation on two open-source\ndatasets demonstrates how the proposed pipeline is generating fair data along\nwith improved performance in some cases.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2022-10-24T08:13:47+00:00",
    "updated": "2022-12-01T10:28:50+00:00",
    "url": "http://arxiv.org/pdf/2210.13023v2"
  },
  {
    "id": "2210.12609v1",
    "title": "Blockchain and Machine Learning for Fraud Detection: A Privacy-Preserving and Adaptive Incentive Based Approach",
    "authors": [
      "Tahmid Hasan Pranto",
      "Kazi Tamzid Akhter Md Hasib",
      "Tahsinur Rahman",
      "AKM Bahalul Haque",
      "A. K. M. Najmul Islam",
      "Rashedur M. Rahman"
    ],
    "abstract": "Financial fraud cases are on the rise even with the current technological\nadvancements. Due to the lack of inter-organization synergy and because of\nprivacy concerns, authentic financial transaction data is rarely available. On\nthe other hand, data-driven technologies like machine learning need authentic\ndata to perform precisely in real-world systems. This study proposes a\nblockchain and smart contract-based approach to achieve robust Machine Learning\n(ML) algorithm for e-commerce fraud detection by facilitating\ninter-organizational collaboration. The proposed method uses blockchain to\nsecure the privacy of the data. Smart contract deployed inside the network\nfully automates the system. An ML model is incrementally upgraded from\ncollaborative data provided by the organizations connected to the blockchain.\nTo incentivize the organizations, we have introduced an incentive mechanism\nthat is adaptive to the difficulty level in updating a model. The organizations\nreceive incentives based on the difficulty faced in updating the ML model. A\nmining criterion has been proposed to mine the block efficiently. And finally,\nthe blockchain network istested under different difficulty levels and under\ndifferent volumes of data to test its efficiency. The model achieved 98.93%\ntesting accuracy and 98.22% Fbeta score (recall-biased f measure) over eight\nincremental updates. Our experiment shows that both data volume and difficulty\nlevel of blockchain impacts the mining time. For difficulty level less than\nfive, mining time and difficulty level has a positive correlation. For\ndifficulty level two and three, less than a second is required to mine a block\nin our system. Difficulty level five poses much more difficulties to mine the\nblocks.",
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "published": "2022-10-23T04:01:13+00:00",
    "updated": "2022-10-23T04:01:13+00:00",
    "url": "http://arxiv.org/pdf/2210.12609v1"
  },
  {
    "id": "2210.12384v1",
    "title": "The Devil is in the Conflict: Disentangled Information Graph Neural Networks for Fraud Detection",
    "authors": [
      "Zhixun Li",
      "Dingshuo Chen",
      "Qiang Liu",
      "Shu Wu"
    ],
    "abstract": "Graph-based fraud detection has heretofore received considerable attention.\nOwning to the great success of Graph Neural Networks (GNNs), many approaches\nadopting GNNs for fraud detection has been gaining momentum. However, most\nexisting methods are based on the strong inductive bias of homophily, which\nindicates that the context neighbors tend to have same labels or similar\nfeatures. In real scenarios, fraudsters often engage in camouflage behaviors in\norder to avoid detection system. Therefore, the homophilic assumption no longer\nholds, which is known as the inconsistency problem. In this paper, we argue\nthat the performance degradation is mainly attributed to the inconsistency\nbetween topology and attribute. To address this problem, we propose to\ndisentangle the fraud network into two views, each corresponding to topology\nand attribute respectively. Then we propose a simple and effective method that\nuses the attention mechanism to adaptively fuse two views which captures\ndata-specific preference. In addition, we further improve it by introducing\nmutual information constraints for topology and attribute. To this end, we\npropose a Disentangled Information Graph Neural Network (DIGNN) model, which\nutilizes variational bounds to find an approximate solution to our proposed\noptimization objective function. Extensive experiments demonstrate that our\nmodel can significantly outperform stateof-the-art baselines on real-world\nfraud detection datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "published": "2022-10-22T08:21:49+00:00",
    "updated": "2022-10-22T08:21:49+00:00",
    "url": "http://arxiv.org/pdf/2210.12384v1"
  },
  {
    "id": "2210.10694v2",
    "title": "Verification of the Socio-Technical Aspects of Voting: The Case of the Polish Postal Vote 2020",
    "authors": [
      "Wojciech Jamroga",
      "Peter Y. A. Ryan",
      "Yan Kim"
    ],
    "abstract": "Voting procedures are designed and implemented by people, for people, and\nwith significant human involvement. Thus, one should take into account the\nhuman factors in order to comprehensively analyze properties of an election and\ndetect threats. In particular, it is essential to assess how actions and\nstrategies of the involved agents (voters, municipal office employees, mail\nclerks) can influence the outcome of other agents' actions as well as the\noverall outcome of the election. In this paper, we present our first attempt to\ncapture those aspects in a formal multi-agent model of the Polish presidential\nelection 2020. The election marked the first time when postal vote was\nuniversally available in Poland. Unfortunately, the voting scheme was prepared\nunder time pressure and political pressure, and without the involvement of\nexperts. This might have opened up possibilities for various kinds of ballot\nfraud, in-house coercion, etc. We propose a preliminary scalable model of the\nprocedure in the form of a Multi-Agent Graph, and formalize selected integrity\nand security properties by formulas of agent logics. Then, we transform the\nmodels and formulas so that they can be input to the state-of-art model checker\nUppaal. The first series of experiments demonstrates that verification scales\nrather badly due to the state-space explosion. However, we show that a recently\ndeveloped technique of user-friendly model reduction by variable abstraction\nallows us to verify more complex scenarios.",
    "categories": [
      "cs.MA"
    ],
    "published": "2022-10-19T16:15:53+00:00",
    "updated": "2023-10-18T15:51:30+00:00",
    "url": "http://arxiv.org/pdf/2210.10694v2"
  },
  {
    "id": "2210.10451v1",
    "title": "An Empirical Analysis of SMS Scam Detection Systems",
    "authors": [
      "Muhammad Salman",
      "Muhammad Ikram",
      "Mohamed Ali Kaafar"
    ],
    "abstract": "The short message service (SMS) was introduced a generation ago to the mobile\nphone users. They make up the world's oldest large-scale network, with billions\nof users and therefore attracts a lot of fraud. Due to the convergence of\nmobile network with internet, SMS based scams can potentially compromise the\nsecurity of internet services as well. In this study, we present a new SMS scam\ndataset consisting of 153,551 SMSes. This dataset that we will release publicly\nfor research purposes represents the largest publicly-available SMS scam\ndataset. We evaluate and compare the performance achieved by several\nestablished machine learning methods on the new dataset, ranging from shallow\nmachine learning approaches to deep neural networks to syntactic and semantic\nfeature models. We then study the existing models from an adversarial viewpoint\nby assessing its robustness against different level of adversarial\nmanipulation. This perspective consolidates the current state of the art in SMS\nSpam filtering, highlights the limitations and the opportunities to improve the\nexisting approaches.",
    "categories": [
      "cs.CR"
    ],
    "published": "2022-10-19T10:33:10+00:00",
    "updated": "2022-10-19T10:33:10+00:00",
    "url": "http://arxiv.org/pdf/2210.10451v1"
  },
  {
    "id": "2210.08274v1",
    "title": "CLARE: A Semi-supervised Community Detection Algorithm",
    "authors": [
      "Xixi Wu",
      "Yun Xiong",
      "Yao Zhang",
      "Yizhu Jiao",
      "Caihua Shan",
      "Yiheng Sun",
      "Yangyong Zhu",
      "Philip S. Yu"
    ],
    "abstract": "Community detection refers to the task of discovering closely related\nsubgraphs to understand the networks. However, traditional community detection\nalgorithms fail to pinpoint a particular kind of community. This limits its\napplicability in real-world networks, e.g., distinguishing fraud groups from\nnormal ones in transaction networks. Recently, semi-supervised community\ndetection emerges as a solution. It aims to seek other similar communities in\nthe network with few labeled communities as training data. Existing works can\nbe regarded as seed-based: locate seed nodes and then develop communities\naround seeds. However, these methods are quite sensitive to the quality of\nselected seeds since communities generated around a mis-detected seed may be\nirrelevant. Besides, they have individual issues, e.g., inflexibility and high\ncomputational overhead. To address these issues, we propose CLARE, which\nconsists of two key components, Community Locator and Community Rewriter. Our\nidea is that we can locate potential communities and then refine them.\nTherefore, the community locator is proposed for quickly locating potential\ncommunities by seeking subgraphs that are similar to training ones in the\nnetwork. To further adjust these located communities, we devise the community\nrewriter. Enhanced by deep reinforcement learning, it suggests intelligent\ndecisions, such as adding or dropping nodes, to refine community structures\nflexibly. Extensive experiments verify both the effectiveness and efficiency of\nour work compared with prior state-of-the-art approaches on multiple real-world\ndatasets.",
    "categories": [
      "cs.SI"
    ],
    "published": "2022-10-15T12:37:46+00:00",
    "updated": "2022-10-15T12:37:46+00:00",
    "url": "http://arxiv.org/pdf/2210.08274v1"
  },
  {
    "id": "2210.07546v1",
    "title": "Transformer-Based Speech Synthesizer Attribution in an Open Set Scenario",
    "authors": [
      "Emily R. Bartusiak",
      "Edward J. Delp"
    ],
    "abstract": "Speech synthesis methods can create realistic-sounding speech, which may be\nused for fraud, spoofing, and misinformation campaigns. Forensic methods that\ndetect synthesized speech are important for protection against such attacks.\nForensic attribution methods provide even more information about the nature of\nsynthesized speech signals because they identify the specific speech synthesis\nmethod (i.e., speech synthesizer) used to create a speech signal. Due to the\nincreasing number of realistic-sounding speech synthesizers, we propose a\nspeech attribution method that generalizes to new synthesizers not seen during\ntraining. To do so, we investigate speech synthesizer attribution in both a\nclosed set scenario and an open set scenario. In other words, we consider some\nspeech synthesizers to be \"known\" synthesizers (i.e., part of the closed set)\nand others to be \"unknown\" synthesizers (i.e., part of the open set). We\nrepresent speech signals as spectrograms and train our proposed method, known\nas compact attribution transformer (CAT), on the closed set for multi-class\nclassification. Then, we extend our analysis to the open set to attribute\nsynthesized speech signals to both known and unknown synthesizers. We utilize a\nt-distributed stochastic neighbor embedding (tSNE) on the latent space of the\ntrained CAT to differentiate between each unknown synthesizer. Additionally, we\nexplore poly-1 loss formulations to improve attribution results. Our proposed\napproach successfully attributes synthesized speech signals to their respective\nspeech synthesizers in both closed and open set scenarios.",
    "categories": [
      "cs.SD",
      "cs.CV",
      "eess.AS"
    ],
    "published": "2022-10-14T05:55:21+00:00",
    "updated": "2022-10-14T05:55:21+00:00",
    "url": "http://arxiv.org/pdf/2210.07546v1"
  },
  {
    "id": "2210.06968v1",
    "title": "Behavioral graph fraud detection in E-commerce",
    "authors": [
      "Hang Yin",
      "Zitao Zhang",
      "Zhurong Wang",
      "Yilmazcan Ozyurt",
      "Weiming Liang",
      "Wenyu Dong",
      "Yang Zhao",
      "Yinan Shan"
    ],
    "abstract": "In e-commerce industry, graph neural network methods are the new trends for\ntransaction risk modeling.The power of graph algorithms lie in the capability\nto catch transaction linking network information, which is very hard to be\ncaptured by other algorithms.However, in most existing approaches, transaction\nor user connections are defined by hard link strategies on shared properties,\nsuch as same credit card, same device, same ip address, same shipping address,\netc. Those types of strategies will result in sparse linkages by entities with\nstrong identification characteristics (ie. device) and over-linkages by\nentities that could be widely shared (ie. ip address), making it more difficult\nto learn useful information from graph. To address aforementioned problems, we\npresent a novel behavioral biometric based method to establish transaction\nlinkings based on user behavioral similarities, then train an unsupervised GNN\nto extract embedding features for downstream fraud prediction tasks. To our\nknowledge, this is the first time similarity based soft link has been used in\ngraph embedding applications. To speed up similarity calculation, we apply an\nin-house GPU based HDBSCAN clustering method to remove highly concentrated and\nisolated nodes before graph construction. Our experiments show that embedding\nfeatures learned from similarity based behavioral graph have achieved\nsignificant performance increase to the baseline fraud detection model in\nvarious business scenarios. In new guest buyer transaction scenario, this\nsegment is a challenge for traditional method, we can make precision increase\nfrom 0.82 to 0.86 at the same recall of 0.27, which means we can decrease false\npositive rate using this method.",
    "categories": [
      "cs.LG"
    ],
    "published": "2022-10-13T12:47:09+00:00",
    "updated": "2022-10-13T12:47:09+00:00",
    "url": "http://arxiv.org/pdf/2210.06968v1"
  },
  {
    "id": "2211.07747v1",
    "title": "Detection of fraudulent financial papers by picking a collection of characteristics using optimization algorithms and classification techniques based on squirrels",
    "authors": [
      "Peyman Mohammadzadeh germi",
      "Mohsen Najarbashi"
    ],
    "abstract": "To produce important investment decisions, investors require financial\nrecords and economic information. However, most companies manipulate investors\nand financial institutions by inflating their financial statements. Fraudulent\nFinancial Activities exist in any monetary or financial transaction scenario,\nwhether physical or electronic. A challenging problem that arises in this\ndomain is the issue that affects and troubles individuals and institutions.\nThis problem has attracted more attention in the field in part owing to the\nprevalence of financial fraud and the paucity of previous research. For this\npurpose, in this study, the main approach to solve this problem, an anomaly\ndetection-based approach based on a combination of feature selection based on\nsquirrel optimization pattern and classification methods have been used. The\naim is to develop this method to provide a model for detecting anomalies in\nfinancial statements using a combination of selected features with the nearest\nneighbor classifications, neural networks, support vector machine, and\nBayesian. Anomaly samples are then analyzed and compared to recommended\ntechniques using assessment criteria. Squirrel optimization's meta-exploratory\ncapability, along with the approach's ability to identify abnormalities in\nfinancial data, has been shown to be effective in implementing the suggested\nstrategy. They discovered fake financial statements because of their expertise.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2022-10-12T12:34:40+00:00",
    "updated": "2022-10-12T12:34:40+00:00",
    "url": "http://arxiv.org/pdf/2211.07747v1"
  },
  {
    "id": "2212.12300v1",
    "title": "Matrix Based Adaptive Short Block Cipher",
    "authors": [
      "Awnon Bhowmik"
    ],
    "abstract": "Every day, millions of credit cards are swiped and transactions are carried\nout across the world. Due to numerous forms of unethical digital activities,\nusers are vulnerable to credit card fraud, phishing, identity theft, etc. This\npaper outlines a novel block encryption algorithm involving multiple private\nkeys and a resilient trapdoor function that ensures data security while\nmaintaining an optimal run time and space complexity. The proposed scheme\nconsists of an irrepressible trapdoor based on a depressed cubic function and a\nunique key generation algorithm that uses Fibonacci sequences and invertible\nsquare matrices for improved security. The paper involves data obtained from\ncomprehensive cryptanalysis exploiting the strengths and weaknesses of the\nsystem and comments on its potential large-scale industry applications.",
    "categories": [
      "cs.CR",
      "94A60, 11Y40"
    ],
    "published": "2022-10-09T05:50:47+00:00",
    "updated": "2022-10-09T05:50:47+00:00",
    "url": "http://arxiv.org/pdf/2212.12300v1"
  },
  {
    "id": "2210.02851v2",
    "title": "Anomaly detection using data depth: multivariate case",
    "authors": [
      "Pavlo Mozharovskyi",
      "Romain Valla"
    ],
    "abstract": "Anomaly detection is a branch of data analysis and machine learning which\naims at identifying observations that exhibit abnormal behaviour. Be it\nmeasurement errors, disease development, severe weather, production quality\ndefault(s) (items) or failed equipment, financial frauds or crisis events,\ntheir on-time identification, isolation and explanation constitute an important\ntask in almost any branch of science and industry. By providing a robust\nordering, data depth - statistical function that measures belongingness of any\npoint of the space to a data set - becomes a particularly useful tool for\ndetection of anomalies. Already known for its theoretical properties, data\ndepth has undergone substantial computational developments in the last decade\nand particularly recent years, which has made it applicable for\ncontemporary-sized problems of data analysis and machine learning.\n  In this article, data depth is studied as an efficient anomaly detection\ntool, assigning abnormality labels to observations with lower depth values, in\na multivariate setting. Practical questions of necessity and reasonability of\ninvariances and shape of the depth function, its robustness and computational\ncomplexity, choice of the threshold are discussed. Illustrations include\nuse-cases that underline advantageous behaviour of data depth in various\nsettings.",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.AP"
    ],
    "published": "2022-10-06T12:14:25+00:00",
    "updated": "2024-07-10T08:02:03+00:00",
    "url": "http://arxiv.org/pdf/2210.02851v2"
  },
  {
    "id": "2210.01944v4",
    "title": "A Framework for Large Scale Synthetic Graph Dataset Generation",
    "authors": [
      "Sajad Darabi",
      "Piotr Bigaj",
      "Dawid Majchrowski",
      "Artur Kasymov",
      "Pawel Morkisz",
      "Alex Fit-Florea"
    ],
    "abstract": "Recently there has been increasing interest in developing and deploying deep\ngraph learning algorithms for many tasks, such as fraud detection and\nrecommender systems. Albeit, there is a limited number of publicly available\ngraph-structured datasets, most of which are tiny compared to production-sized\napplications or are limited in their application domain. This work tackles this\nshortcoming by proposing a scalable synthetic graph generation tool to scale\nthe datasets to production-size graphs with trillions of edges and billions of\nnodes. The tool learns a series of parametric models from proprietary datasets\nthat can be released to researchers to study various graph methods on the\nsynthetic data increasing prototype development and novel applications. We\ndemonstrate the generalizability of the framework across a series of datasets,\nmimicking structural and feature distributions as well as the ability to scale\nthem across varying sizes demonstrating their usefulness for benchmarking and\nmodel development. Code can be found on\nhttps://github.com/NVIDIA/DeepLearningExamples/tree/master/Tools/DGLPyTorch/SyntheticGraphGeneration.",
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "published": "2022-10-04T22:41:33+00:00",
    "updated": "2023-10-05T05:22:43+00:00",
    "url": "http://arxiv.org/pdf/2210.01944v4"
  },
  {
    "id": "2209.14692v1",
    "title": "Digital and Physical Face Attacks: Reviewing and One Step Further",
    "authors": [
      "Chenqi Kong",
      "Shiqi Wang",
      "Haoliang Li"
    ],
    "abstract": "With the rapid progress over the past five years, face authentication has\nbecome the most pervasive biometric recognition method. Thanks to the\nhigh-accuracy recognition performance and user-friendly usage, automatic face\nrecognition (AFR) has exploded into a plethora of practical applications over\ndevice unlocking, checking-in, and financial payment. In spite of the\ntremendous success of face authentication, a variety of face presentation\nattacks (FPA), such as print attacks, replay attacks, and 3D mask attacks, have\nraised pressing mistrust concerns. Besides physical face attacks, face\nvideos/images are vulnerable to a wide variety of digital attack techniques\nlaunched by malicious hackers, causing potential menace to the public at large.\nDue to the unrestricted access to enormous digital face images/videos and\ndisclosed easy-to-use face manipulation tools circulating on the internet,\nnon-expert attackers without any prior professional skills are able to readily\ncreate sophisticated fake faces, leading to numerous dangerous applications\nsuch as financial fraud, impersonation, and identity theft. This survey aims to\nbuild the integrity of face forensics by providing thorough analyses of\nexisting literature and highlighting the issues requiring further attention. In\nthis paper, we first comprehensively survey both physical and digital face\nattack types and datasets. Then, we review the latest and most advanced\nprogress on existing counter-attack methodologies and highlight their current\nlimits. Moreover, we outline possible future research directions for existing\nand upcoming challenges in the face forensics community. Finally, the necessity\nof joint physical and digital face attack detection has been discussed, which\nhas never been studied in previous surveys.",
    "categories": [
      "cs.CV",
      "cs.CR"
    ],
    "published": "2022-09-29T11:25:52+00:00",
    "updated": "2022-09-29T11:25:52+00:00",
    "url": "http://arxiv.org/pdf/2209.14692v1"
  },
  {
    "id": "2209.14071v1",
    "title": "Towards Auditable Distributed Systems",
    "authors": [
      "Lev Sorokin"
    ],
    "abstract": "The emerging trend towards distributed (cloud) systems (DS) has widely\narrived whether in the automotive, public or the financial sector, but the\nexecution of services of heterogeneous service providers is exposed to several\nrisks. Beside hardware/software faults or cyber attacks that can influence the\ncorrectness of the system, fraud is also an issue. In such case it is not only\nimportant to verify the correctness of the system, but also have evidence which\ncomponent and participant behaves faulty. This makes it possible, e.g. to claim\nfor compensation after systems execution but also to assure information for\nverification can be trusted. The main goal of our research is to assure the\nmonitoring of DS based on auditable information. We follow a decentralized\nmonitoring strategy and envision a distributed monitoring approach of system\nproperties based on distributedlogic programs that consider auditability. The\nexpected contribution of this work is to establish with the application of our\nframework the mutual trust of distributed parties, as well as trust of clients\nin the systems execution. We showcase our ideas on a DS for booking services\nwith unmanned air vehicles.",
    "categories": [
      "cs.SE"
    ],
    "published": "2022-09-28T13:13:26+00:00",
    "updated": "2022-09-28T13:13:26+00:00",
    "url": "http://arxiv.org/pdf/2209.14071v1"
  },
  {
    "id": "2211.14667v1",
    "title": "Deep Fake Detection, Deterrence and Response: Challenges and Opportunities",
    "authors": [
      "Amin Azmoodeh",
      "Ali Dehghantanha"
    ],
    "abstract": "According to the 2020 cyber threat defence report, 78% of Canadian\norganizations experienced at least one successful cyberattack in 2020. The\nconsequences of such attacks vary from privacy compromises to immersing damage\ncosts for individuals, companies, and countries. Specialists predict that the\nglobal loss from cybercrime will reach 10.5 trillion US dollars annually by\n2025. Given such alarming statistics, the need to prevent and predict\ncyberattacks is as high as ever. Our increasing reliance on Machine\nLearning(ML)-based systems raises serious concerns about the security and\nsafety of these systems. Especially the emergence of powerful ML techniques to\ngenerate fake visual, textual, or audio content with a high potential to\ndeceive humans raised serious ethical concerns. These artificially crafted\ndeceiving videos, images, audio, or texts are known as Deepfakes garnered\nattention for their potential use in creating fake news, hoaxes, revenge porn,\nand financial fraud. Diversity and the widespread of deepfakes made their\ntimely detection a significant challenge. In this paper, we first offer\nbackground information and a review of previous works on the detection and\ndeterrence of deepfakes. Afterward, we offer a solution that is capable of 1)\nmaking our AI systems robust against deepfakes during development and\ndeployment phases; 2) detecting video, image, audio, and textual deepfakes; 3)\nidentifying deepfakes that bypass detection (deepfake hunting); 4) leveraging\navailable intelligence for timely identification of deepfake campaigns launched\nby state-sponsored hacking teams; 5) conducting in-depth forensic analysis of\nidentified deepfake payloads. Our solution would address important elements of\nthe Canada National Cyber Security Action Plan(2019-2024) in increasing the\ntrustworthiness of our critical services.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2022-11-26T21:23:30+00:00",
    "updated": "2022-11-26T21:23:30+00:00",
    "url": "http://arxiv.org/pdf/2211.14667v1"
  },
  {
    "id": "2211.13542v1",
    "title": "A Privacy-Preserving Outsourced Data Model in Cloud Environment",
    "authors": [
      "Rishabh Gupta",
      "Ashutosh Kumar Singh"
    ],
    "abstract": "Nowadays, more and more machine learning applications, such as medical\ndiagnosis, online fraud detection, email spam filtering, etc., services are\nprovided by cloud computing. The cloud service provider collects the data from\nthe various owners to train or classify the machine learning system in the\ncloud environment. However, multiple data owners may not entirely rely on the\ncloud platform that a third party engages. Therefore, data security and privacy\nproblems are among the critical hindrances to using machine learning tools,\nparticularly with multiple data owners. In addition, unauthorized entities can\ndetect the statistical input data and infer the machine learning model\nparameters. Therefore, a privacy-preserving model is proposed, which protects\nthe privacy of the data without compromising machine learning efficiency. In\norder to protect the data of data owners, the epsilon-differential privacy is\nused, and fog nodes are used to address the problem of the lower bandwidth and\nlatency in this proposed scheme. The noise is produced by the\nepsilon-differential mechanism, which is then added to the data. Moreover, the\nnoise is injected at the data owner site to protect the owners data. Fog nodes\ncollect the noise-added data from the data owners, then shift it to the cloud\nplatform for storage, computation, and performing the classification tasks\npurposes.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2022-11-24T11:27:30+00:00",
    "updated": "2022-11-24T11:27:30+00:00",
    "url": "http://arxiv.org/pdf/2211.13542v1"
  },
  {
    "id": "2211.13358v2",
    "title": "Turning the Tables: Biased, Imbalanced, Dynamic Tabular Datasets for ML Evaluation",
    "authors": [
      "Sérgio Jesus",
      "José Pombal",
      "Duarte Alves",
      "André Cruz",
      "Pedro Saleiro",
      "Rita P. Ribeiro",
      "João Gama",
      "Pedro Bizarro"
    ],
    "abstract": "Evaluating new techniques on realistic datasets plays a crucial role in the\ndevelopment of ML research and its broader adoption by practitioners. In recent\nyears, there has been a significant increase of publicly available unstructured\ndata resources for computer vision and NLP tasks. However, tabular data --\nwhich is prevalent in many high-stakes domains -- has been lagging behind. To\nbridge this gap, we present Bank Account Fraud (BAF), the first publicly\navailable privacy-preserving, large-scale, realistic suite of tabular datasets.\nThe suite was generated by applying state-of-the-art tabular data generation\ntechniques on an anonymized,real-world bank account opening fraud detection\ndataset. This setting carries a set of challenges that are commonplace in\nreal-world applications, including temporal dynamics and significant class\nimbalance. Additionally, to allow practitioners to stress test both performance\nand fairness of ML methods, each dataset variant of BAF contains specific types\nof data bias. With this resource, we aim to provide the research community with\na more realistic, complete, and robust test bed to evaluate novel and existing\nmethods.",
    "categories": [
      "cs.LG"
    ],
    "published": "2022-11-24T00:03:29+00:00",
    "updated": "2022-11-28T11:17:46+00:00",
    "url": "http://arxiv.org/pdf/2211.13358v2"
  },
  {
    "id": "2211.13039v3",
    "title": "Approximate complex amplitude encoding algorithm and its application to data classification problems",
    "authors": [
      "Naoki Mitsuda",
      "Tatsuhiro Ichimura",
      "Kouhei Nakaji",
      "Yohichi Suzuki",
      "Tomoki Tanaka",
      "Rudy Raymond",
      "Hiroyuki Tezuka",
      "Tamiya Onodera",
      "Naoki Yamamoto"
    ],
    "abstract": "Quantum computing has a potential to accelerate the data processing\nefficiency, especially in machine learning, by exploiting special features such\nas the quantum interference. The major challenge in this application is that,\nin general, the task of loading a classical data vector into a quantum state\nrequires an exponential number of quantum gates. The approximate amplitude\nencoding (AAE) method, which uses a variational means to approximately load a\ngiven real-valued data vector into the amplitude of a quantum state, was\nrecently proposed as a general approach to this problem mainly for near-term\ndevices. However, AAE cannot load a complex-valued data vector, which narrows\nits application range. In this work, we extend AAE so that it can handle a\ncomplex-valued data vector. The key idea is to employ the fidelity distance as\na cost function for optimizing a parameterized quantum circuit, where the\nclassical shadow technique is used to efficiently estimate the fidelity and its\ngradient. We apply this algorithm to realize the complex-valued-kernel binary\nclassifier called the compact Hadamard classifier, and then give a numerical\nexperiment showing that it enables classification of Iris dataset and credit\ncard fraud detection.",
    "categories": [
      "quant-ph"
    ],
    "published": "2022-11-23T15:46:29+00:00",
    "updated": "2024-05-27T11:20:11+00:00",
    "url": "http://arxiv.org/pdf/2211.13039v3"
  },
  {
    "id": "2211.13123v2",
    "title": "Motif-aware temporal GCN for fraud detection in signed cryptocurrency trust networks",
    "authors": [
      "Song Li",
      "Jiandong Zhou",
      "Chong MO",
      "Jin LI",
      "Geoffrey K. F. Tso",
      "Yuxing Tian"
    ],
    "abstract": "Graph convolutional networks (GCNs) is a class of artificial neural networks\nfor processing data that can be represented as graphs. Since financial\ntransactions can naturally be constructed as graphs, GCNs are widely applied in\nthe financial industry, especially for financial fraud detection. In this\npaper, we focus on fraud detection on cryptocurrency truct networks. In the\nliterature, most works focus on static networks. Whereas in this study, we\nconsider the evolving nature of cryptocurrency networks, and use local\nstructural as well as the balance theory to guide the training process. More\nspecifically, we compute motif matrices to capture the local topological\ninformation, then use them in the GCN aggregation process. The generated\nembedding at each snapshot is a weighted average of embeddings within a time\nwindow, where the weights are learnable parameters. Since the trust networks is\nsigned on each edge, balance theory is used to guide the training process.\nExperimental results on bitcoin-alpha and bitcoin-otc datasets show that the\nproposed model outperforms those in the literature.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "q-fin.TR"
    ],
    "published": "2022-11-22T02:03:27+00:00",
    "updated": "2023-03-29T04:01:17+00:00",
    "url": "http://arxiv.org/pdf/2211.13123v2"
  },
  {
    "id": "2211.10595v1",
    "title": "Explainable Artificial Intelligence and Causal Inference based ATM Fraud Detection",
    "authors": [
      "Yelleti Vivek",
      "Vadlamani Ravi",
      "Abhay Anand Mane",
      "Laveti Ramesh Naidu"
    ],
    "abstract": "Gaining the trust of customers and providing them empathy are very critical\nin the financial domain. Frequent occurrence of fraudulent activities affects\nthese two factors. Hence, financial organizations and banks must take utmost\ncare to mitigate them. Among them, ATM fraudulent transaction is a common\nproblem faced by banks. There following are the critical challenges involved in\nfraud datasets: the dataset is highly imbalanced, the fraud pattern is\nchanging, etc. Owing to the rarity of fraudulent activities, Fraud detection\ncan be formulated as either a binary classification problem or One class\nclassification (OCC). In this study, we handled these techniques on an ATM\ntransactions dataset collected from India. In binary classification, we\ninvestigated the effectiveness of various over-sampling techniques, such as the\nSynthetic Minority Oversampling Technique (SMOTE) and its variants, Generative\nAdversarial Networks (GAN), to achieve oversampling. Further, we employed\nvarious machine learning techniques viz., Naive Bayes (NB), Logistic Regression\n(LR), Support Vector Machine (SVM), Decision Tree (DT), Random Forest (RF),\nGradient Boosting Tree (GBT), Multi-layer perceptron (MLP). GBT outperformed\nthe rest of the models by achieving 0.963 AUC, and DT stands second with 0.958\nAUC. DT is the winner if the complexity and interpretability aspects are\nconsidered. Among all the oversampling approaches, SMOTE and its variants were\nobserved to perform better. In OCC, IForest attained 0.959 CR, and OCSVM\nsecured second place with 0.947 CR. Further, we incorporated explainable\nartificial intelligence (XAI) and causal inference (CI) in the fraud detection\nframework and studied it through various analyses.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T99, 62D20, 91-08",
      "I.2"
    ],
    "published": "2022-11-19T06:01:08+00:00",
    "updated": "2022-11-19T06:01:08+00:00",
    "url": "http://arxiv.org/pdf/2211.10595v1"
  },
  {
    "id": "2211.08604v7",
    "title": "PU GNN: Chargeback Fraud Detection in P2E MMORPGs via Graph Attention Networks with Imbalanced PU Labels",
    "authors": [
      "Jiho Choi",
      "Junghoon Park",
      "Woocheol Kim",
      "Jin-Hyeok Park",
      "Yumin Suh",
      "Minchang Sung"
    ],
    "abstract": "The recent advent of play-to-earn (P2E) systems in massively multiplayer\nonline role-playing games (MMORPGs) has made in-game goods interchangeable with\nreal-world values more than ever before. The goods in the P2E MMORPGs can be\ndirectly exchanged with cryptocurrencies such as Bitcoin, Ethereum, or Klaytn\nvia blockchain networks. Unlike traditional in-game goods, once they had been\nwritten to the blockchains, P2E goods cannot be restored by the game operation\nteams even with chargeback fraud such as payment fraud, cancellation, or\nrefund. To tackle the problem, we propose a novel chargeback fraud prediction\nmethod, PU GNN, which leverages graph attention networks with PU loss to\ncapture both the players' in-game behavior with P2E token transaction patterns.\nWith the adoption of modified GraphSMOTE, the proposed model handles the\nimbalanced distribution of labels in chargeback fraud datasets. The conducted\nexperiments on three real-world P2E MMORPG datasets demonstrate that PU GNN\nachieves superior performances over previously suggested methods.",
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "published": "2022-11-16T01:26:57+00:00",
    "updated": "2023-06-23T05:01:32+00:00",
    "url": "http://arxiv.org/pdf/2211.08604v7"
  },
  {
    "id": "2211.06977v1",
    "title": "Spade: A Real-Time Fraud Detection Framework on Evolving Graphs (Complete Version)",
    "authors": [
      "Jiaxin Jiang",
      "Yuan Li",
      "Bingsheng He",
      "Bryan Hooi",
      "Jia Chen",
      "Johan Kok Zhi Kang"
    ],
    "abstract": "Real-time fraud detection is a challenge for most financial and electronic\ncommercial platforms. To identify fraudulent communities, Grab, one of the\nlargest technology companies in Southeast Asia, forms a graph from a set of\ntransactions and detects dense subgraphs arising from abnormally large numbers\nof connections among fraudsters. Existing dense subgraph detection approaches\nfocus on static graphs without considering the fact that transaction graphs are\nhighly dynamic. Moreover, detecting dense subgraphs from scratch with graph\nupdates is time consuming and cannot meet the real-time requirement in\nindustry. To address this problem, we introduce an incremental real-time fraud\ndetection framework called Spade. Spade can detect fraudulent communities in\nhundreds of microseconds on million-scale graphs by incrementally maintaining\ndense subgraphs. Furthermore, Spade supports batch updates and edge grouping to\nreduce response latency. Lastly, Spade provides simple but expressive APIs for\nthe design of evolving fraud detection semantics. Developers plug their\ncustomized suspiciousness functions into Spade which incrementalizes their\nsemantics without recasting their algorithms. Extensive experiments show that\nSpade detects fraudulent communities in real time on million-scale graphs.\nPeeling algorithms incrementalized by Spade are up to a million times faster\nthan the static version.",
    "categories": [
      "cs.DB"
    ],
    "published": "2022-11-13T18:06:36+00:00",
    "updated": "2022-11-13T18:06:36+00:00",
    "url": "http://arxiv.org/pdf/2211.06977v1"
  },
  {
    "id": "2211.06675v1",
    "title": "Privacy-Preserving Credit Card Fraud Detection using Homomorphic Encryption",
    "authors": [
      "David Nugent"
    ],
    "abstract": "Credit card fraud is a problem continuously faced by financial institutions\nand their customers, which is mitigated by fraud detection systems. However,\nthese systems require the use of sensitive customer transaction data, which\nintroduces both a lack of privacy for the customer and a data breach\nvulnerability to the card provider. This paper proposes a system for private\nfraud detection on encrypted transactions using homomorphic encryption. Two\nmodels, XGBoost and a feedforward classifier neural network, are trained as\nfraud detectors on plaintext data. They are then converted to models which use\nhomomorphic encryption for private inference. Latency, storage, and detection\nresults are discussed, along with use cases and feasibility of deployment. The\nXGBoost model has better performance, with an encrypted inference as low as\n6ms, compared to 296ms for the neural network. However, the neural network\nimplementation may still be preferred, as it is simpler to deploy securely. A\ncodebase for the system is also provided, for simulation and further\ndevelopment.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2022-11-12T14:28:17+00:00",
    "updated": "2022-11-12T14:28:17+00:00",
    "url": "http://arxiv.org/pdf/2211.06675v1"
  },
  {
    "id": "2212.11766v1",
    "title": "Long bet will lose: demystifying seemingly fair gambling via two-armed Futurity bandit",
    "authors": [
      "Zengjing Chen",
      "Huaijin Liang",
      "Wei Wang",
      "Xiaodong Yan"
    ],
    "abstract": "No matter how much some gamblers occasionally win, as long as they continue\nto gamble, sooner or later they will lose more to the casino, which is the\nso-called long bet will lose. Our results demonstrate the counter-intuitive\nphenomenon, that gamblers involved in long bets will lose but casinos always\nadvertise their unprofitable circumstances. Here we expose the law of\ninevitability behind long bet will loss by theoretically and experimentally\ndemystifying the profitable mystery behind casinos under two-armed antique\nMills Futurity slot machine. The main results straightforwardly elucidate that\nall casino projects are seemingly a fair gamble but essentially unfair, i.e.,\nthe casino's win rate is greater than 50%. We anticipate our assay to be a\nstarting point for studying the fairness of more sophisticated multi-armed\nFuturity bandits based on the mathematical tool. In application, a fairness\nstudy of the Futurity bandits not only exposes the fraud of casinos for\ngamblers but also discloses discount marketing, bundled sales, or other induced\nconsumption tactics.",
    "categories": [
      "q-fin.GN",
      "math.PR"
    ],
    "published": "2022-11-12T01:01:28+00:00",
    "updated": "2022-11-12T01:01:28+00:00",
    "url": "http://arxiv.org/pdf/2212.11766v1"
  },
  {
    "id": "2211.05913v4",
    "title": "Twitter Spam and False Accounts Prevalence, Detection and Characterization: A Survey",
    "authors": [
      "Emilio Ferrara"
    ],
    "abstract": "The issue of quantifying and characterizing various forms of social media\nmanipulation and abuse has been at the forefront of the computational social\nscience research community for over a decade. In this paper, I provide a\n(non-comprehensive) survey of research efforts aimed at estimating the\nprevalence of spam and false accounts on Twitter, as well as characterizing\ntheir use, activity, and behavior. I propose a taxonomy of spam and false\naccounts, enumerating known techniques used to create and detect them. Then, I\nsummarize studies estimating the prevalence of spam and false accounts on\nTwitter. Finally, I report on research that illustrates how spam and false\naccounts are used for scams and frauds, stock market manipulation, political\ndisinformation and deception, conspiracy amplification, coordinated influence,\npublic health misinformation campaigns, radical propaganda and recruitment, and\nmore. I will conclude with a set of recommendations aimed at charting the path\nforward to combat these problems.",
    "categories": [
      "cs.SI"
    ],
    "published": "2022-11-10T23:17:08+00:00",
    "updated": "2023-02-07T19:44:10+00:00",
    "url": "http://arxiv.org/pdf/2211.05913v4"
  },
  {
    "id": "2211.02927v3",
    "title": "Unsupervised Machine Learning for Explainable Health Care Fraud Detection",
    "authors": [
      "Shubhranshu Shekhar",
      "Jetson Leder-Luis",
      "Leman Akoglu"
    ],
    "abstract": "The US federal government spends more than a trillion dollars per year on\nhealth care, largely provided by private third parties and reimbursed by the\ngovernment. A major concern in this system is overbilling, waste and fraud by\nproviders, who face incentives to misreport on their claims in order to receive\nhigher payments. In this paper, we develop novel machine learning tools to\nidentify providers that overbill Medicare, the US federal health insurance\nprogram for elderly adults and the disabled. Using large-scale Medicare claims\ndata, we identify patterns consistent with fraud or overbilling among inpatient\nhospitalizations. Our proposed approach for Medicare fraud detection is fully\nunsupervised, not relying on any labeled training data, and is explainable to\nend users, providing reasoning and interpretable insights into the potentially\nsuspicious behavior of the flagged providers. Data from the Department of\nJustice on providers facing anti-fraud lawsuits and several case studies\nvalidate our approach and findings both quantitatively and qualitatively.",
    "categories": [
      "cs.CY",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2022-11-05T15:37:51+00:00",
    "updated": "2023-02-24T04:33:23+00:00",
    "url": "http://arxiv.org/pdf/2211.02927v3"
  },
  {
    "id": "2211.06315v2",
    "title": "Fraudulent User Detection Via Behavior Information Aggregation Network (BIAN) On Large-Scale Financial Social Network",
    "authors": [
      "Hanyi Hu",
      "Long Zhang",
      "Shuan Li",
      "Zhi Liu",
      "Yao Yang",
      "Chongning Na"
    ],
    "abstract": "Financial frauds cause billions of losses annually and yet it lacks efficient\napproaches in detecting frauds considering user profile and their behaviors\nsimultaneously in social network . A social network forms a graph structure\nwhilst Graph neural networks (GNN), a promising research domain in Deep\nLearning, can seamlessly process non-Euclidean graph data . In financial fraud\ndetection, the modus operandi of criminals can be identified by analyzing user\nprofile and their behaviors such as transaction, loaning etc. as well as their\nsocial connectivity. Currently, most GNNs are incapable of selecting important\nneighbors since the neighbors' edge attributes (i.e., behaviors) are ignored.\nIn this paper, we propose a novel behavior information aggregation network\n(BIAN) to combine the user behaviors with other user features. Different from\nits close \"relatives\" such as Graph Attention Networks (GAT) and Graph\nTransformer Networks (GTN), it aggregates neighbors based on neighboring edge\nattribute distribution, namely, user behaviors in financial social network. The\nexperimental results on a real-world large-scale financial social network\ndataset, DGraph, show that BIAN obtains the 10.2% gain in AUROC comparing with\nthe State-Of-The-Art models.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "published": "2022-11-04T08:33:06+00:00",
    "updated": "2023-03-26T10:04:27+00:00",
    "url": "http://arxiv.org/pdf/2211.06315v2"
  },
  {
    "id": "2211.01692v1",
    "title": "Data-efficient End-to-end Information Extraction for Statistical Legal Analysis",
    "authors": [
      "Wonseok Hwang",
      "Saehee Eom",
      "Hanuhl Lee",
      "Hai Jin Park",
      "Minjoon Seo"
    ],
    "abstract": "Legal practitioners often face a vast amount of documents. Lawyers, for\ninstance, search for appropriate precedents favorable to their clients, while\nthe number of legal precedents is ever-growing. Although legal search engines\ncan assist finding individual target documents and narrowing down the number of\ncandidates, retrieved information is often presented as unstructured text and\nusers have to examine each document thoroughly which could lead to information\noverloading. This also makes their statistical analysis challenging. Here, we\npresent an end-to-end information extraction (IE) system for legal documents.\nBy formulating IE as a generation task, our system can be easily applied to\nvarious tasks without domain-specific engineering effort. The experimental\nresults of four IE tasks on Korean precedents shows that our IE system can\nachieve competent scores (-2.3 on average) compared to the rule-based baseline\nwith as few as 50 training examples per task and higher score (+5.4 on average)\nwith 200 examples. Finally, our statistical analysis on two case\ncategories--drunk driving and fraud--with 35k precedents reveals the resulting\nstructured information from our IE system faithfully reflects the macroscopic\nfeatures of Korean legal system.",
    "categories": [
      "cs.CL"
    ],
    "published": "2022-11-03T10:27:37+00:00",
    "updated": "2022-11-03T10:27:37+00:00",
    "url": "http://arxiv.org/pdf/2211.01692v1"
  },
  {
    "id": "2211.00098v1",
    "title": "Synthetic ID Card Image Generation for Improving Presentation Attack Detection",
    "authors": [
      "Daniel Benalcazar",
      "Juan E. Tapia",
      "Sebastian Gonzalez",
      "Christoph Busch"
    ],
    "abstract": "Currently, it is ever more common to access online services for activities\nwhich formerly required physical attendance. From banking operations to visa\napplications, a significant number of processes have been digitised, especially\nsince the advent of the COVID-19 pandemic, requiring remote biometric\nauthentication of the user. On the downside, some subjects intend to interfere\nwith the normal operation of remote systems for personal profit by using fake\nidentity documents, such as passports and ID cards. Deep learning solutions to\ndetect such frauds have been presented in the literature. However, due to\nprivacy concerns and the sensitive nature of personal identity documents,\ndeveloping a dataset with the necessary number of examples for training deep\nneural networks is challenging. This work explores three methods for\nsynthetically generating ID card images to increase the amount of data while\ntraining fraud-detection networks. These methods include computer vision\nalgorithms and Generative Adversarial Networks. Our results indicate that\ndatabases can be supplemented with synthetic images without any loss in\nperformance for the print/scan Presentation Attack Instrument Species (PAIS)\nand a loss in performance of 1% for the screen capture PAIS.",
    "categories": [
      "cs.CV",
      "cs.CR"
    ],
    "published": "2022-10-31T19:07:30+00:00",
    "updated": "2022-10-31T19:07:30+00:00",
    "url": "http://arxiv.org/pdf/2211.00098v1"
  },
  {
    "id": "2210.15912v1",
    "title": "Decontamination of the scientific literature",
    "authors": [
      "Guillaume Cabanac"
    ],
    "abstract": "Research misconduct and frauds pollute the scientific literature. Honest\nerrors and malevolent data fabrication, image manipulation, journal hijacking,\nand plagiarism passed peer review unnoticed. Problematic papers deceive\nreaders, authors citing them, and AI-powered literature-based discovery.\nFlagship publishers accepted hundreds flawed papers despite claiming to enforce\npeer review. This application ambitions to decontaminate the scientific\nliterature using curative and preventive actions.",
    "categories": [
      "cs.DL",
      "cs.IR"
    ],
    "published": "2022-10-28T05:47:13+00:00",
    "updated": "2022-10-28T05:47:13+00:00",
    "url": "http://arxiv.org/pdf/2210.15912v1"
  },
  {
    "id": "2212.12439v1",
    "title": "Permissionless Refereed Tournaments",
    "authors": [
      "Diego Nehab",
      "Augusto Teixeira"
    ],
    "abstract": "Scalability problems in programmable blockchains have created a strong demand\nfor secure methods that move the bulk of computation outside the blockchain.\nOne of the preferred solutions to this problem involves off-chain computers\nthat compete interactively to prove to the limited blockchain that theirs is\nthe correct result of a given intensive computation. Each off-chain computer\nspends effort linear on the cost of the computation, while the blockchain\nadjudicates disputes spending only logarithmic effort. However, this effort is\nmultiplied by the number of competitors, rendering disputes that involve a\nsignificant number of parties impractical and susceptible to Sybil attacks. In\nthis paper, we propose a practical dispute resolution algorithm by which a\nsingle honest competitor can win disputes while spending effort linear on the\ncost of the computation, but only logarithmic on the number of dishonest\ncompetitors. This algorithm is a novel, stronger primitive for building\npermissionless fraud-proof protocols, which doesn't rely on complex economic\nincentives to be enforced.",
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "published": "2022-12-23T16:14:43+00:00",
    "updated": "2022-12-23T16:14:43+00:00",
    "url": "http://arxiv.org/pdf/2212.12439v1"
  },
  {
    "id": "2212.07802v1",
    "title": "Chaotic Variational Auto Encoder based One Class Classifier for Insurance Fraud Detection",
    "authors": [
      "K. S. N. V. K. Gangadhar",
      "B. Akhil Kumar",
      "Yelleti Vivek",
      "Vadlamani Ravi"
    ],
    "abstract": "Of late, insurance fraud detection has assumed immense significance owing to\nthe huge financial & reputational losses fraud entails and the phenomenal\nsuccess of the fraud detection techniques. Insurance is majorly divided into\ntwo categories: (i) Life and (ii) Non-life. Non-life insurance in turn includes\nhealth insurance and auto insurance among other things. In either of the\ncategories, the fraud detection techniques should be designed in such a way\nthat they capture as many fraudulent transactions as possible. Owing to the\nrarity of fraudulent transactions, in this paper, we propose a chaotic\nvariational autoencoder (C-VAE to perform one-class classification (OCC) on\ngenuine transactions. Here, we employed the logistic chaotic map to generate\nrandom noise in the latent space. The effectiveness of C-VAE is demonstrated on\nthe health insurance fraud and auto insurance datasets. We considered vanilla\nVariational Auto Encoder (VAE) as the baseline. It is observed that C-VAE\noutperformed VAE in both datasets. C-VAE achieved a classification rate of\n77.9% and 87.25% in health and automobile insurance datasets respectively.\nFurther, the t-test conducted at 1% level of significance and 18 degrees of\nfreedom infers that C-VAE is statistically significant than the VAE.",
    "categories": [
      "cs.LG",
      "68T07",
      "I.2"
    ],
    "published": "2022-12-15T13:15:45+00:00",
    "updated": "2022-12-15T13:15:45+00:00",
    "url": "http://arxiv.org/pdf/2212.07802v1"
  },
  {
    "id": "2212.06322v1",
    "title": "Privacy-Preserving Collaborative Learning through Feature Extraction",
    "authors": [
      "Alireza Sarmadi",
      "Hao Fu",
      "Prashanth Krishnamurthy",
      "Siddharth Garg",
      "Farshad Khorrami"
    ],
    "abstract": "We propose a framework in which multiple entities collaborate to build a\nmachine learning model while preserving privacy of their data. The approach\nutilizes feature embeddings from shared/per-entity feature extractors\ntransforming data into a feature space for cooperation between entities. We\npropose two specific methods and compare them with a baseline method. In Shared\nFeature Extractor (SFE) Learning, the entities use a shared feature extractor\nto compute feature embeddings of samples. In Locally Trained Feature Extractor\n(LTFE) Learning, each entity uses a separate feature extractor and models are\ntrained using concatenated features from all entities. As a baseline, in\nCooperatively Trained Feature Extractor (CTFE) Learning, the entities train\nmodels by sharing raw data. Secure multi-party algorithms are utilized to train\nmodels without revealing data or features in plain text. We investigate the\ntrade-offs among SFE, LTFE, and CTFE in regard to performance, privacy leakage\n(using an off-the-shelf membership inference attack), and computational cost.\nLTFE provides the most privacy, followed by SFE, and then CTFE. Computational\ncost is lowest for SFE and the relative speed of CTFE and LTFE depends on\nnetwork architecture. CTFE and LTFE provide the best accuracy. We use MNIST, a\nsynthetic dataset, and a credit card fraud detection dataset for evaluations.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2022-12-13T02:04:47+00:00",
    "updated": "2022-12-13T02:04:47+00:00",
    "url": "http://arxiv.org/pdf/2212.06322v1"
  },
  {
    "id": "2212.04329v1",
    "title": "Fraud Analytics: A Decade of Research -- Organizing Challenges and Solutions in the Field",
    "authors": [
      "Christopher Bockel-Rickermann",
      "Tim Verdonck",
      "Wouter Verbeke"
    ],
    "abstract": "The literature on fraud analytics and fraud detection has seen a substantial\nincrease in output in the past decade. This has led to a wide range of research\ntopics and overall little organization of the many aspects of fraud analytical\nresearch. The focus of academics ranges from identifying fraudulent credit card\npayments to spotting illegitimate insurance claims. In addition, there is a\nwide range of methods and research objectives. This paper aims to provide an\noverview of fraud analytics in research and aims to more narrowly organize the\ndiscipline and its many subfields. We analyze a sample of almost 300 records on\nfraud analytics published between 2011 and 2020. In a systematic way, we\nidentify the most prominent domains of application, challenges faced,\nperformance metrics, and methods used. In addition, we build a framework for\nfraud analytical methods and propose a keywording strategy for future research.\nOne of the key challenges in fraud analytics is access to public datasets. To\nfurther aid the community, we provide eight requirements for suitable data sets\nin research motivated by our research. We structure our sample of the\nliterature in an online database. The database is available online for fellow\nresearchers to investigate and potentially build upon.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2022-12-07T10:34:19+00:00",
    "updated": "2022-12-07T10:34:19+00:00",
    "url": "http://arxiv.org/pdf/2212.04329v1"
  },
  {
    "id": "2212.02679v1",
    "title": "Self-supervised Graph Representation Learning for Black Market Account Detection",
    "authors": [
      "Zequan Xu",
      "Lianyun Li",
      "Hui Li",
      "Qihang Sun",
      "Shaofeng Hu",
      "Rongrong Ji"
    ],
    "abstract": "Nowadays, Multi-purpose Messaging Mobile App (MMMA) has become increasingly\nprevalent. MMMAs attract fraudsters and some cybercriminals provide support for\nfrauds via black market accounts (BMAs). Compared to fraudsters, BMAs are not\ndirectly involved in frauds and are more difficult to detect. This paper\nillustrates our BMA detection system SGRL (Self-supervised Graph Representation\nLearning) used in WeChat, a representative MMMA with over a billion users. We\ntailor Graph Neural Network and Graph Self-supervised Learning in SGRL for BMA\ndetection. The workflow of SGRL contains a pretraining phase that utilizes\nstructural information, node attribute information and available human\nknowledge, and a lightweight detection phase. In offline experiments, SGRL\noutperforms state-of-the-art methods by 16.06%-58.17% on offline evaluation\nmeasures. We deploy SGRL in the online environment to detect BMAs on the\nbillion-scale WeChat graph, and it exceeds the alternative by 7.27% on the\nonline evaluation measure. In conclusion, SGRL can alleviate label reliance,\ngeneralize well to unseen data, and effectively detect BMAs in WeChat.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "published": "2022-12-06T00:42:00+00:00",
    "updated": "2022-12-06T00:42:00+00:00",
    "url": "http://arxiv.org/pdf/2212.02679v1"
  },
  {
    "id": "2212.02620v1",
    "title": "Benchmarking Offline Reinforcement Learning Algorithms for E-Commerce Order Fraud Evaluation",
    "authors": [
      "Soysal Degirmenci",
      "Chris Jones"
    ],
    "abstract": "Amazon and other e-commerce sites must employ mechanisms to protect their\nmillions of customers from fraud, such as unauthorized use of credit cards. One\nsuch mechanism is order fraud evaluation, where systems evaluate orders for\nfraud risk, and either \"pass\" the order, or take an action to mitigate high\nrisk. Order fraud evaluation systems typically use binary classification models\nthat distinguish fraudulent and legitimate orders, to assess risk and take\naction. We seek to devise a system that considers both financial losses of\nfraud and long-term customer satisfaction, which may be impaired when incorrect\nactions are applied to legitimate customers. We propose that taking actions to\noptimize long-term impact can be formulated as a Reinforcement Learning (RL)\nproblem. Standard RL methods require online interaction with an environment to\nlearn, but this is not desirable in high-stakes applications like order fraud\nevaluation. Offline RL algorithms learn from logged data collected from the\nenvironment, without the need for online interaction, making them suitable for\nour use case. We show that offline RL methods outperform traditional binary\nclassification solutions in SimStore, a simplified e-commerce simulation that\nincorporates order fraud risk. We also propose a novel approach to training\noffline RL policies that adds a new loss term during training, to better align\npolicy exploration with taking correct actions.",
    "categories": [
      "cs.LG"
    ],
    "published": "2022-12-05T22:10:13+00:00",
    "updated": "2022-12-05T22:10:13+00:00",
    "url": "http://arxiv.org/pdf/2212.02620v1"
  },
  {
    "id": "2211.16023v1",
    "title": "Novelty Detection for Election Fraud: A Case Study with Agent-Based Simulation Data",
    "authors": [
      "Khurram Yamin",
      "Nima Jadali",
      "Dima Nazzal",
      "Yao Xie"
    ],
    "abstract": "In this paper, we propose a robust election simulation model and\nindependently developed election anomaly detection algorithm that demonstrates\nthe simulation's utility. The simulation generates artificial elections with\nsimilar properties and trends as elections from the real world, while giving\nusers control and knowledge over all the important components of the elections.\nWe generate a clean election results dataset without fraud as well as datasets\nwith varying degrees of fraud. We then measure how well the algorithm is able\nto successfully detect the level of fraud present. The algorithm determines how\nsimilar actual election results are as compared to the predicted results from\npolling and a regression model of other regions that have similar demographics.\nWe use k-means to partition electoral regions into clusters such that\ndemographic homogeneity is maximized among clusters. We then use a novelty\ndetection algorithm implemented as a one-class Support Vector Machine where the\nclean data is provided in the form of polling predictions and regression\npredictions. The regression predictions are built from the actual data in such\na way that the data supervises itself. We show both the effectiveness of the\nsimulation technique and the machine learning model in its success in\nidentifying fraudulent regions.",
    "categories": [
      "cs.LG",
      "cs.MA",
      "cs.SI"
    ],
    "published": "2022-11-29T08:46:36+00:00",
    "updated": "2022-11-29T08:46:36+00:00",
    "url": "http://arxiv.org/pdf/2211.16023v1"
  },
  {
    "id": "2301.10888v1",
    "title": "Experimenting with an Evaluation Framework for Imbalanced Data Learning (EFIDL)",
    "authors": [
      "Chenyu Li",
      "Xia Jiang"
    ],
    "abstract": "Introduction Data imbalance is one of the crucial issues in big data analysis\nwith fewer labels. For example, in real-world healthcare data, spam detection\nlabels, and financial fraud detection datasets. Many data balance methods were\nintroduced to improve machine learning algorithms' performance. Research claims\nSMOTE and SMOTE-based data-augmentation (generate new data points) methods\ncould improve algorithm performance. However, we found in many online\ntutorials, the valuation methods were applied based on synthesized datasets\nthat introduced bias into the evaluation, and the performance got a false\nimprovement. In this study, we proposed, a new evaluation framework for\nimbalanced data learning methods. We have experimented on five data balance\nmethods and whether the performance of algorithms will improve or not. Methods\nWe collected 8 imbalanced healthcare datasets with different imbalanced rates\nfrom different domains. Applied 6 data augmentation methods with 11 machine\nlearning methods testing if the data augmentation will help with improving\nmachine learning performance. We compared the traditional data augmentation\nevaluation methods with our proposed cross-validation evaluation framework\nResults Using traditional data augmentation evaluation meta hods will give a\nfalse impression of improving the performance. However, our proposed evaluation\nmethod shows data augmentation has limited ability to improve the results.\nConclusion EFIDL is more suitable for evaluating the prediction performance of\nan ML method when data are augmented. Using an unsuitable evaluation framework\nwill give false results. Future researchers should consider the evaluation\nframework we proposed when dealing with augmented datasets. Our experiments\nshowed data augmentation does not help improve ML prediction performance.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-01-26T01:16:02+00:00",
    "updated": "2023-01-26T01:16:02+00:00",
    "url": "http://arxiv.org/pdf/2301.10888v1"
  },
  {
    "id": "2301.10628v1",
    "title": "Incentive-weighted Anomaly Detection for False Data Injection Attacks Against Smart Meter Load Profiles",
    "authors": [
      "Martin Higgins",
      "Bruce Stephen",
      "David Wallom"
    ],
    "abstract": "Spot pricing is often suggested as a method of increasing demand-side\nflexibility in electrical power load. However, few works have considered the\nvulnerability of spot pricing to financial fraud via false data injection (FDI)\nstyle attacks. In this paper, we consider attacks which aim to alter the\nconsumer load profile to exploit intraday price dips. We examine an anomaly\ndetection protocol for cyber-attacks that seek to leverage spot prices for\nfinancial gain. In this way we outline a methodology for detecting attacks on\nindustrial load smart meters. We first create a feature clustering model of the\nunderlying business, segregated by business type. We then use these clusters to\ncreate an incentive-weighted anomaly detection protocol for false data attacks\nagainst load profiles. This clustering-based methodology incorporates both the\nload profile and spot pricing considerations for the detection of injected load\nprofiles. To reduce false positives, we model incentive-based detection, which\nincludes knowledge of spot prices, into the anomaly tracking, enabling the\nmethodology to account for changes in the load profile which are unlikely to be\nattacks.",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "published": "2023-01-25T15:11:15+00:00",
    "updated": "2023-01-25T15:11:15+00:00",
    "url": "http://arxiv.org/pdf/2301.10628v1"
  },
  {
    "id": "2301.09317v1",
    "title": "A Survey on Actionable Knowledge",
    "authors": [
      "Sayed Erfan Arefin"
    ],
    "abstract": "Actionable Knowledge Discovery (AKD) is a crucial aspect of data mining that\nis gaining popularity and being applied in a wide range of domains. This is\nbecause AKD can extract valuable insights and information, also known as\nknowledge, from large datasets. The goal of this paper is to examine different\nresearch studies that focus on various domains and have different objectives.\nThe paper will review and discuss the methods used in these studies in detail.\nAKD is a process of identifying and extracting actionable insights from data,\nwhich can be used to make informed decisions and improve business outcomes. It\nis a powerful tool for uncovering patterns and trends in data that can be used\nfor various applications such as customer relationship management, marketing,\nand fraud detection. The research studies reviewed in this paper will explore\ndifferent techniques and approaches for AKD in different domains, such as\nhealthcare, finance, and telecommunications. The paper will provide a thorough\nanalysis of the current state of AKD in the field and will review the main\nmethods used by various research studies. Additionally, the paper will evaluate\nthe advantages and disadvantages of each method and will discuss any novel or\nnew solutions presented in the field. Overall, this paper aims to provide a\ncomprehensive overview of the methods and techniques used in AKD and the impact\nthey have on different domains.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-01-23T08:26:28+00:00",
    "updated": "2023-01-23T08:26:28+00:00",
    "url": "http://arxiv.org/pdf/2301.09317v1"
  },
  {
    "id": "2301.08295v1",
    "title": "Polar Coded Merkle Tree: Mitigating Data Availability Attacks in Blockchain Systems Using Informed Polar Code Design",
    "authors": [
      "Debarnab Mitra",
      "Lev Tauz",
      "Lara Dolecek"
    ],
    "abstract": "Data availability (DA) attack is a well-known problem in certain blockchains\nwhere users accept an invalid block with unavailable portions. Previous works\nhave used LDPC and 2-D Reed Solomon (2DRS) codes with Merkle trees to mitigate\nDA attacks. These codes perform well across various metrics such as DA\ndetection probability and communication cost. However, these codes are\ndifficult to apply to blockchains with large blocks due to large decoding\ncomplexity and coding fraud proof size (2D-RS codes), and intractable code\nguarantees for large code lengths (LDPC codes). In this paper, we focus on\nlarge block size applications and address the above challenges by proposing the\nnovel Polar Coded Merkle Tree (PCMT): a Merkle tree encoded using the encoding\ngraph of polar codes. We provide a specialized polar code design algorithm\ncalled Sampling Efficient Freezing and an algorithm to prune the polar encoding\ngraph. We demonstrate that the PCMT built using the above techniques results in\na better DA detection probability and communication cost compared to LDPC\ncodes, has a lower coding fraud proof size compared to LDPC and 2D-RS codes,\nprovides tractable code guarantees at large code lengths (similar to 2D-RS\ncodes), and has comparable decoding complexity to 2D-RS and LDPC codes.",
    "categories": [
      "cs.IT",
      "cs.CR",
      "math.IT"
    ],
    "published": "2023-01-19T20:12:28+00:00",
    "updated": "2023-01-19T20:12:28+00:00",
    "url": "http://arxiv.org/pdf/2301.08295v1"
  },
  {
    "id": "2301.07791v2",
    "title": "Temporal Motifs for Financial Networks: A Study on Mercari, JPMC, and Venmo Platforms",
    "authors": [
      "Penghang Liu",
      "Bahadir Altun",
      "Rupam Acharyya",
      "Robert E. Tillman",
      "Shunya Kimura",
      "Naoki Masuda",
      "Ahmet Erdem Sarıyüce"
    ],
    "abstract": "Understanding the dynamics of financial transactions among people is critical\nfor various applications such as fraud detection. One important aspect of\nfinancial transaction networks is temporality. The order and repetition of\ntransactions can offer new insights when considered within the graph structure.\nTemporal motifs, defined as a set of nodes that interact with each other in a\nshort time period, are a promising tool in this context. In this work, we study\nthree unique temporal financial networks: transactions in Mercari, an online\nmarketplace, payments in a synthetic network generated by J.P. Morgan Chase,\nand payments and friendships among Venmo users. We consider the fraud detection\nproblem on the Mercari and J.P. Morgan Chase networks, for which the ground\ntruth is available. We show that temporal motifs offer superior performance to\nseveral baselines, including a previous method that considers simple graph\nfeatures and two node embedding techniques (LINE and node2vec), while being\npractical in terms of runtime performance. For the Venmo network, we\ninvestigate the interplay between financial and social relations on three\ntasks: friendship prediction, vendor identification, and analysis of temporal\ncycles. For friendship prediction, temporal motifs yield better results than\ngeneral heuristics, such as Jaccard and Adamic-Adar measures. We are also able\nto identify vendors with high accuracy and observe interesting patterns in rare\nmotifs, such as temporal cycles. We believe that the analysis, datasets, and\nlessons from this work will be beneficial for future research on financial\ntransaction networks.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "published": "2023-01-18T21:22:57+00:00",
    "updated": "2025-07-11T03:26:29+00:00",
    "url": "http://arxiv.org/pdf/2301.07791v2"
  },
  {
    "id": "2301.07526v1",
    "title": "AutoFraudNet: A Multimodal Network to Detect Fraud in the Auto Insurance Industry",
    "authors": [
      "Azin Asgarian",
      "Rohit Saha",
      "Daniel Jakubovitz",
      "Julia Peyre"
    ],
    "abstract": "In the insurance industry detecting fraudulent claims is a critical task with\na significant financial impact. A common strategy to identify fraudulent claims\nis looking for inconsistencies in the supporting evidence. However, this is a\nlaborious and cognitively heavy task for human experts as insurance claims\ntypically come with a plethora of data from different modalities (e.g. images,\ntext and metadata). To overcome this challenge, the research community has\nfocused on multimodal machine learning frameworks that can efficiently reason\nthrough multiple data sources. Despite recent advances in multimodal learning,\nthese frameworks still suffer from (i) challenges of joint-training caused by\nthe different characteristics of different modalities and (ii) overfitting\ntendencies due to high model complexity. In this work, we address these\nchallenges by introducing a multimodal reasoning framework, AutoFraudNet\n(Automobile Insurance Fraud Detection Network), for detecting fraudulent\nauto-insurance claims. AutoFraudNet utilizes a cascaded slow fusion framework\nand state-of-the-art fusion block, BLOCK Tucker, to alleviate the challenges of\njoint-training. Furthermore, it incorporates a light-weight architectural\ndesign along with additional losses to prevent overfitting. Through extensive\nexperiments conducted on a real-world dataset, we demonstrate: (i) the merits\nof multimodal approaches, when compared to unimodal and bimodal methods, and\n(ii) the effectiveness of AutoFraudNet in fusing various modalities to boost\nperformance (over 3\\% in PR AUC).",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-01-15T13:50:32+00:00",
    "updated": "2023-01-15T13:50:32+00:00",
    "url": "http://arxiv.org/pdf/2301.07526v1"
  },
  {
    "id": "2301.05412v3",
    "title": "Evolve Path Tracer: Early Detection of Malicious Addresses in Cryptocurrency",
    "authors": [
      "Ling Cheng",
      "Feida Zhu",
      "Yong Wang",
      "Ruicheng Liang",
      "Huiwen Liu"
    ],
    "abstract": "With the ever-increasing boom of Cryptocurrency, detecting fraudulent\nbehaviors and associated malicious addresses draws significant research effort.\nHowever, most existing studies still rely on the full history features or\nfull-fledged address transaction networks, thus cannot meet the requirements of\nearly malicious address detection, which is urgent but seldom discussed by\nexisting studies. To detect fraud behaviors of malicious addresses in the early\nstage, we present Evolve Path Tracer, which consists of Evolve Path Encoder\nLSTM, Evolve Path Graph GCN, and Hierarchical Survival Predictor. Specifically,\nin addition to the general address features, we propose asset transfer paths\nand corresponding path graphs to characterize early transaction patterns.\nFurther, since the transaction patterns are changing rapidly during the early\nstage, we propose Evolve Path Encoder LSTM and Evolve Path Graph GCN to encode\nasset transfer path and path graph under an evolving structure setting.\nHierarchical Survival Predictor then predicts addresses' labels with nice\nscalability and faster prediction speed. We investigate the effectiveness and\nversatility of Evolve Path Tracer on three real-world illicit bitcoin datasets.\nOur experimental results demonstrate that Evolve Path Tracer outperforms the\nstate-of-the-art methods. Extensive scalability experiments demonstrate the\nmodel's adaptivity under a dynamic prediction setting.",
    "categories": [
      "cs.AI"
    ],
    "published": "2023-01-13T06:59:52+00:00",
    "updated": "2023-06-03T05:59:42+00:00",
    "url": "http://arxiv.org/pdf/2301.05412v3"
  },
  {
    "id": "2301.01836v1",
    "title": "A Quantum-Inspired Binary Optimization Algorithm for Representative Selection",
    "authors": [
      "Anna G. Hughes",
      "Jack S. Baker",
      "Santosh Kumar Radha"
    ],
    "abstract": "Advancements in quantum computing are fuelling emerging applications across\ndisciplines, including finance, where quantum and quantum-inspired algorithms\ncan now make market predictions, detect fraud, and optimize portfolios.\nExpanding this toolbox, we propose the selector algorithm: a method for\nselecting the most representative subset of data from a larger dataset. The\nselected subset includes data points that simultaneously meet the two\nrequirements of being maximally close to neighboring data points and maximally\nfar from more distant data points where the precise notion of distance is given\nby any kernel or generalized similarity function. The cost function encoding\nthe above requirements naturally presents itself as a Quadratic Unconstrained\nBinary Optimization (QUBO) problem, which is well-suited for quantum\noptimization algorithms - including quantum annealing. While the selector\nalgorithm has applications in multiple areas, it is particularly useful in\nfinance, where it can be used to build a diversified portfolio from a more\nextensive selection of assets. After experimenting with synthetic datasets, we\nshow two use cases for the selector algorithm with real data: (1) approximately\nreconstructing the NASDAQ 100 index using a subset of stocks, and (2)\ndiversifying a portfolio of cryptocurrencies. In our analysis of use case (2),\nwe compare the performance of two quantum annealers provided by D-Wave Systems.",
    "categories": [
      "quant-ph",
      "physics.comp-ph",
      "q-fin.CP"
    ],
    "published": "2023-01-04T22:07:22+00:00",
    "updated": "2023-01-04T22:07:22+00:00",
    "url": "http://arxiv.org/pdf/2301.01836v1"
  },
  {
    "id": "2303.17511v1",
    "title": "On pitfalls (and advantages) of sophisticated large language models",
    "authors": [
      "Anna Strasser"
    ],
    "abstract": "Natural language processing based on large language models (LLMs) is a\nbooming field of AI research. After neural networks have proven to outperform\nhumans in games and practical domains based on pattern recognition, we might\nstand now at a road junction where artificial entities might eventually enter\nthe realm of human communication. However, this comes with serious risks. Due\nto the inherent limitations regarding the reliability of neural networks,\noverreliance on LLMs can have disruptive consequences. Since it will be\nincreasingly difficult to distinguish between human-written and\nmachine-generated text, one is confronted with new ethical challenges. This\nbegins with the no longer undoubtedly verifiable human authorship and continues\nwith various types of fraud, such as a new form of plagiarism. This also\nconcerns the violation of privacy rights, the possibility of circulating\ncounterfeits of humans, and, last but not least, it makes a massive spread of\nmisinformation possible.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2023-02-25T11:14:39+00:00",
    "updated": "2023-02-25T11:14:39+00:00",
    "url": "http://arxiv.org/pdf/2303.17511v1"
  },
  {
    "id": "2302.12959v1",
    "title": "Chaotic Variational Auto encoder-based Adversarial Machine Learning",
    "authors": [
      "Pavan Venkata Sainadh Reddy",
      "Yelleti Vivek",
      "Gopi Pranay",
      "Vadlamani Ravi"
    ],
    "abstract": "Machine Learning (ML) has become the new contrivance in almost every field.\nThis makes them a target of fraudsters by various adversary attacks, thereby\nhindering the performance of ML models. Evasion and Data-Poison-based attacks\nare well acclaimed, especially in finance, healthcare, etc. This motivated us\nto propose a novel computationally less expensive attack mechanism based on the\nadversarial sample generation by Variational Auto Encoder (VAE). It is well\nknown that Wavelet Neural Network (WNN) is considered computationally efficient\nin solving image and audio processing, speech recognition, and time-series\nforecasting. This paper proposed VAE-Deep-Wavelet Neural Network\n(VAE-Deep-WNN), where Encoder and Decoder employ WNN networks. Further, we\nproposed chaotic variants of both VAE with Multi-layer perceptron (MLP) and\nDeep-WNN and named them C-VAE-MLP and C-VAE-Deep-WNN, respectively. Here, we\nemployed a Logistic map to generate random noise in the latent space. In this\npaper, we performed VAE-based adversary sample generation and applied it to\nvarious problems related to finance and cybersecurity domain-related problems\nsuch as loan default, credit card fraud, and churn modelling, etc., We\nperformed both Evasion and Data-Poison attacks on Logistic Regression (LR) and\nDecision Tree (DT) models. The results indicated that VAE-Deep-WNN outperformed\nthe rest in the majority of the datasets and models. However, its chaotic\nvariant C-VAE-Deep-WNN performed almost similarly to VAE-Deep-WNN in the\nmajority of the datasets.",
    "categories": [
      "cs.LG",
      "cs.CR",
      "68T01, 68M25",
      "I.2.6; K.6.5"
    ],
    "published": "2023-02-25T02:06:15+00:00",
    "updated": "2023-02-25T02:06:15+00:00",
    "url": "http://arxiv.org/pdf/2302.12959v1"
  },
  {
    "id": "2302.11286v1",
    "title": "Neural-based classification rule learning for sequential data",
    "authors": [
      "Marine Collery",
      "Philippe Bonnard",
      "François Fages",
      "Remy Kusters"
    ],
    "abstract": "Discovering interpretable patterns for classification of sequential data is\nof key importance for a variety of fields, ranging from genomics to fraud\ndetection or more generally interpretable decision-making. In this paper, we\npropose a novel differentiable fully interpretable method to discover both\nlocal and global patterns (i.e. catching a relative or absolute temporal\ndependency) for rule-based binary classification. It consists of a\nconvolutional binary neural network with an interpretable neural filter and a\ntraining strategy based on dynamically-enforced sparsity. We demonstrate the\nvalidity and usefulness of the approach on synthetic datasets and on an\nopen-source peptides dataset. Key to this end-to-end differentiable method is\nthat the expressive patterns used in the rules are learned alongside the rules\nthemselves.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2023-02-22T11:05:05+00:00",
    "updated": "2023-02-22T11:05:05+00:00",
    "url": "http://arxiv.org/pdf/2302.11286v1"
  },
  {
    "id": "2302.10407v1",
    "title": "Label Information Enhanced Fraud Detection against Low Homophily in Graphs",
    "authors": [
      "Yuchen Wang",
      "Jinghui Zhang",
      "Zhengjie Huang",
      "Weibin Li",
      "Shikun Feng",
      "Ziheng Ma",
      "Yu Sun",
      "Dianhai Yu",
      "Fang Dong",
      "Jiahui Jin",
      "Beilun Wang",
      "Junzhou Luo"
    ],
    "abstract": "Node classification is a substantial problem in graph-based fraud detection.\nMany existing works adopt Graph Neural Networks (GNNs) to enhance fraud\ndetectors. While promising, currently most GNN-based fraud detectors fail to\ngeneralize to the low homophily setting. Besides, label utilization has been\nproved to be significant factor for node classification problem. But we find\nthey are less effective in fraud detection tasks due to the low homophily in\ngraphs. In this work, we propose GAGA, a novel Group AGgregation enhanced\nTrAnsformer, to tackle the above challenges. Specifically, the group\naggregation provides a portable method to cope with the low homophily issue.\nSuch an aggregation explicitly integrates the label information to generate\ndistinguishable neighborhood information. Along with group aggregation, an\nattempt towards end-to-end trainable group encoding is proposed which augments\nthe original feature space with the class labels. Meanwhile, we devise two\nadditional learnable encodings to recognize the structural and relational\ncontext. Then, we combine the group aggregation and the learnable encodings\ninto a Transformer encoder to capture the semantic information. Experimental\nresults clearly show that GAGA outperforms other competitive graph-based fraud\ndetectors by up to 24.39% on two trending public datasets and a real-world\nindustrial dataset from Anonymous. Even more, the group aggregation is\ndemonstrated to outperform other label utilization methods (e.g., C&S,\nBoT/UniMP) in the low homophily setting.",
    "categories": [
      "cs.AI"
    ],
    "published": "2023-02-21T02:42:28+00:00",
    "updated": "2023-02-21T02:42:28+00:00",
    "url": "http://arxiv.org/pdf/2302.10407v1"
  },
  {
    "id": "2302.07832v2",
    "title": "Deep Anomaly Detection under Labeling Budget Constraints",
    "authors": [
      "Aodong Li",
      "Chen Qiu",
      "Marius Kloft",
      "Padhraic Smyth",
      "Stephan Mandt",
      "Maja Rudolph"
    ],
    "abstract": "Selecting informative data points for expert feedback can significantly\nimprove the performance of anomaly detection (AD) in various contexts, such as\nmedical diagnostics or fraud detection. In this paper, we determine a set of\ntheoretical conditions under which anomaly scores generalize from labeled\nqueries to unlabeled data. Motivated by these results, we propose a data\nlabeling strategy with optimal data coverage under labeling budget constraints.\nIn addition, we propose a new learning framework for semi-supervised AD.\nExtensive experiments on image, tabular, and video data sets show that our\napproach results in state-of-the-art semi-supervised AD performance under\nlabeling budget constraints.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2023-02-15T18:18:35+00:00",
    "updated": "2023-07-04T18:33:10+00:00",
    "url": "http://arxiv.org/pdf/2302.07832v2"
  },
  {
    "id": "2302.07467v1",
    "title": "Demystifying security and compatibility issues in Android Apps",
    "authors": [
      "Xiaoyu Sun"
    ],
    "abstract": "Never before has any OS been so popular as Android. Existing mobile phones\nare not simply devices for making phone calls and receiving SMS messages, but\npowerful communication and entertainment platforms for web surfing, social\nnetworking, etc. Even though the Android OS offers powerful communication and\napplication execution capabilities, it is riddled with defects (e.g., security\nrisks, and compatibility issues), new vulnerabilities come to light daily, and\nbugs cost the economy tens of billions of dollars annually. For example,\nmalicious apps (e.g., back-doors, fraud apps, ransomware, spyware, etc.) are\nreported [Google, 2022] to exhibit malicious behaviours, including privacy\nstealing, unwanted programs installed, etc. To counteract these threats, many\nworks have been proposed that rely on static analysis techniques to detect such\nissues. However, static techniques are not sufficient on their own to detect\nsuch defects precisely. This will likely yield false positive results as static\nanalysis has to make some trade-offs when handling complicated cases (e.g.,\nobject-sensitive vs. object-insensitive). In addition, static analysis\ntechniques will also likely suffer from soundness issues because some\ncomplicated features (e.g., reflection, obfuscation, and hardening) are\ndifficult to be handled [Sun et al., 2021b, Samhi et al., 2022].",
    "categories": [
      "cs.CR",
      "cs.SE"
    ],
    "published": "2023-02-15T04:43:24+00:00",
    "updated": "2023-02-15T04:43:24+00:00",
    "url": "http://arxiv.org/pdf/2302.07467v1"
  },
  {
    "id": "2302.07444v2",
    "title": "A Case Study on Designing Evaluations of ML Explanations with Simulated User Studies",
    "authors": [
      "Ada Martin",
      "Valerie Chen",
      "Sérgio Jesus",
      "Pedro Saleiro"
    ],
    "abstract": "When conducting user studies to ascertain the usefulness of model\nexplanations in aiding human decision-making, it is important to use real-world\nuse cases, data, and users. However, this process can be resource-intensive,\nallowing only a limited number of explanation methods to be evaluated.\nSimulated user evaluations (SimEvals), which use machine learning models as a\nproxy for human users, have been proposed as an intermediate step to select\npromising explanation methods. In this work, we conduct the first SimEvals on a\nreal-world use case to evaluate whether explanations can better support\nML-assisted decision-making in e-commerce fraud detection. We study whether\nSimEvals can corroborate findings from a user study conducted in this fraud\ndetection context. In particular, we find that SimEvals suggest that all\nconsidered explainers are equally performant, and none beat a baseline without\nexplanations -- this matches the conclusions of the original user study. Such\ncorrespondences between our results and the original user study provide initial\nevidence in favor of using SimEvals before running user studies. We also\nexplore the use of SimEvals as a cheap proxy to explore an alternative user\nstudy set-up. We hope that this work motivates further study of when and how\nSimEvals should be used to aid in the design of real-world evaluations.",
    "categories": [
      "cs.LG",
      "cs.HC"
    ],
    "published": "2023-02-15T03:27:55+00:00",
    "updated": "2023-03-20T20:36:48+00:00",
    "url": "http://arxiv.org/pdf/2302.07444v2"
  },
  {
    "id": "2302.05918v2",
    "title": "Efficient Fraud Detection Using Deep Boosting Decision Trees",
    "authors": [
      "Biao Xu",
      "Yao Wang",
      "Xiuwu Liao",
      "Kaidong Wang"
    ],
    "abstract": "Fraud detection is to identify, monitor, and prevent potentially fraudulent\nactivities from complex data. The recent development and success in AI,\nespecially machine learning, provides a new data-driven way to deal with fraud.\nFrom a methodological point of view, machine learning based fraud detection can\nbe divided into two categories, i.e., conventional methods (decision tree,\nboosting...) and deep learning, both of which have significant limitations in\nterms of the lack of representation learning ability for the former and\ninterpretability for the latter. Furthermore, due to the rarity of detected\nfraud cases, the associated data is usually imbalanced, which seriously\ndegrades the performance of classification algorithms. In this paper, we\npropose deep boosting decision trees (DBDT), a novel approach for fraud\ndetection based on gradient boosting and neural networks. In order to combine\nthe advantages of both conventional methods and deep learning, we first\nconstruct soft decision tree (SDT), a decision tree structured model with\nneural networks as its nodes, and then ensemble SDTs using the idea of gradient\nboosting. In this way we embed neural networks into gradient boosting to\nimprove its representation learning capability and meanwhile maintain the\ninterpretability. Furthermore, aiming at the rarity of detected fraud cases, in\nthe model training phase we propose a compositional AUC maximization approach\nto deal with data imbalances at algorithm level. Extensive experiments on\nseveral real-life fraud detection datasets show that DBDT can significantly\nimprove the performance and meanwhile maintain good interpretability. Our code\nis available at https://github.com/freshmanXB/DBDT.",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.AP"
    ],
    "published": "2023-02-12T14:02:58+00:00",
    "updated": "2023-05-18T11:19:24+00:00",
    "url": "http://arxiv.org/pdf/2302.05918v2"
  },
  {
    "id": "2302.05863v1",
    "title": "NFTDisk: Visual Detection of Wash Trading in NFT Markets",
    "authors": [
      "Xiaolin Wen",
      "Yong Wang",
      "Xuanwu Yue",
      "Feida Zhu",
      "Min Zhu"
    ],
    "abstract": "With the growing popularity of Non-Fungible Tokens (NFT), a new type of\ndigital assets, various fraudulent activities have appeared in NFT markets.\nAmong them, wash trading has become one of the most common frauds in NFT\nmarkets, which attempts to mislead investors by creating fake trading volumes.\nDue to the sophisticated patterns of wash trading, only a subset of them can be\ndetected by automatic algorithms, and manual inspection is usually required. We\npropose NFTDisk, a novel visualization for investors to identify wash trading\nactivities in NFT markets, where two linked visualization modules are\npresented: a radial visualization module with a disk metaphor to overview NFT\ntransactions and a flow-based visualization module to reveal detailed NFT flows\nat multiple levels. We conduct two case studies and an in-depth user interview\nwith 14 NFT investors to evaluate NFTDisk. The results demonstrate its\neffectiveness in exploring wash trading activities in NFT markets.",
    "categories": [
      "cs.HC"
    ],
    "published": "2023-02-12T06:32:16+00:00",
    "updated": "2023-02-12T06:32:16+00:00",
    "url": "http://arxiv.org/pdf/2302.05863v1"
  },
  {
    "id": "2302.05788v1",
    "title": "Fairness-aware Multi-view Clustering",
    "authors": [
      "Lecheng Zheng",
      "Yada Zhu",
      "Jingrui He"
    ],
    "abstract": "In the era of big data, we are often facing the challenge of data\nheterogeneity and the lack of label information simultaneously. In the\nfinancial domain (e.g., fraud detection), the heterogeneous data may include\nnot only numerical data (e.g., total debt and yearly income), but also text and\nimages (e.g., financial statement and invoice images). At the same time, the\nlabel information (e.g., fraud transactions) may be missing for building\npredictive models. To address these challenges, many state-of-the-art\nmulti-view clustering methods have been proposed and achieved outstanding\nperformance. However, these methods typically do not take into consideration\nthe fairness aspect and are likely to generate biased results using sensitive\ninformation such as race and gender. Therefore, in this paper, we propose a\nfairness-aware multi-view clustering method named FairMVC. It incorporates the\ngroup fairness constraint into the soft membership assignment for each cluster\nto ensure that the fraction of different groups in each cluster is\napproximately identical to the entire data set. Meanwhile, we adopt the idea of\nboth contrastive learning and non-contrastive learning and propose novel\nregularizers to handle heterogeneous data in complex scenarios with missing\ndata or noisy features. Experimental results on real-world data sets\ndemonstrate the effectiveness and efficiency of the proposed framework. We also\nderive insights regarding the relative performance of the proposed regularizers\nin various scenarios.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2023-02-11T21:36:42+00:00",
    "updated": "2023-02-11T21:36:42+00:00",
    "url": "http://arxiv.org/pdf/2302.05788v1"
  },
  {
    "id": "2302.05727v1",
    "title": "Flexible-modal Deception Detection with Audio-Visual Adapter",
    "authors": [
      "Zhaoxu Li",
      "Zitong Yu",
      "Nithish Muthuchamy Selvaraj",
      "Xiaobao Guo",
      "Bingquan Shen",
      "Adams Wai-Kin Kong",
      "Alex Kot"
    ],
    "abstract": "Detecting deception by human behaviors is vital in many fields such as custom\nsecurity and multimedia anti-fraud. Recently, audio-visual deception detection\nattracts more attention due to its better performance than using only a single\nmodality. However, in real-world multi-modal settings, the integrity of data\ncan be an issue (e.g., sometimes only partial modalities are available). The\nmissing modality might lead to a decrease in performance, but the model still\nlearns the features of the missed modality. In this paper, to further improve\nthe performance and overcome the missing modality problem, we propose a novel\nTransformer-based framework with an Audio-Visual Adapter (AVA) to fuse temporal\nfeatures across two modalities efficiently. Extensive experiments conducted on\ntwo benchmark datasets demonstrate that the proposed method can achieve\nsuperior performance compared with other multi-modal fusion methods under\nflexible-modal (multiple and missing modalities) settings.",
    "categories": [
      "cs.CV"
    ],
    "published": "2023-02-11T15:47:20+00:00",
    "updated": "2023-02-11T15:47:20+00:00",
    "url": "http://arxiv.org/pdf/2302.05727v1"
  },
  {
    "id": "2302.04549v1",
    "title": "Weakly Supervised Anomaly Detection: A Survey",
    "authors": [
      "Minqi Jiang",
      "Chaochuan Hou",
      "Ao Zheng",
      "Xiyang Hu",
      "Songqiao Han",
      "Hailiang Huang",
      "Xiangnan He",
      "Philip S. Yu",
      "Yue Zhao"
    ],
    "abstract": "Anomaly detection (AD) is a crucial task in machine learning with various\napplications, such as detecting emerging diseases, identifying financial\nfrauds, and detecting fake news. However, obtaining complete, accurate, and\nprecise labels for AD tasks can be expensive and challenging due to the cost\nand difficulties in data annotation. To address this issue, researchers have\ndeveloped AD methods that can work with incomplete, inexact, and inaccurate\nsupervision, collectively summarized as weakly supervised anomaly detection\n(WSAD) methods. In this study, we present the first comprehensive survey of\nWSAD methods by categorizing them into the above three weak supervision\nsettings across four data modalities (i.e., tabular, graph, time-series, and\nimage/video data). For each setting, we provide formal definitions, key\nalgorithms, and potential future directions. To support future research, we\nconduct experiments on a selected setting and release the source code, along\nwith a collection of WSAD methods and data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2023-02-09T10:27:21+00:00",
    "updated": "2023-02-09T10:27:21+00:00",
    "url": "http://arxiv.org/pdf/2302.04549v1"
  },
  {
    "id": "2302.04430v1",
    "title": "A Comparison of Decision Forest Inference Platforms from A Database Perspective",
    "authors": [
      "Hong Guan",
      "Mahidhar Reddy Dwarampudi",
      "Venkatesh Gunda",
      "Hong Min",
      "Lei Yu",
      "Jia Zou"
    ],
    "abstract": "Decision forest, including RandomForest, XGBoost, and LightGBM, is one of the\nmost popular machine learning techniques used in many industrial scenarios,\nsuch as credit card fraud detection, ranking, and business intelligence.\nBecause the inference process is usually performance-critical, a number of\nframeworks were developed and dedicated for decision forest inference, such as\nONNX, TreeLite from Amazon, TensorFlow Decision Forest from Google, HummingBird\nfrom Microsoft, Nvidia FIL, and lleaves. However, these frameworks are all\ndecoupled with data management frameworks. It is unclear whether in-database\ninference will improve the overall performance. In addition, these frameworks\nused different algorithms, optimization techniques, and parallelism models. It\nis unclear how these implementations will affect the overall performance and\nhow to make design decisions for an in-database inference framework.\n  In this work, we investigated the above questions by comprehensively\ncomparing the end-to-end performance of the aforementioned inference frameworks\nand netsDB, an in-database inference framework we implemented. Through this\nstudy, we identified that netsDB is best suited for handling small-scale models\non large-scale datasets and all-scale models on small-scale datasets, for which\nit achieved up to hundreds of times of speedup. In addition, the\nrelation-centric representation we proposed significantly improved netsDB's\nperformance in handling large-scale models, while the model reuse optimization\nwe proposed further improved netsDB's performance in handling small-scale\ndatasets.",
    "categories": [
      "cs.DB",
      "cs.LG",
      "cs.PF"
    ],
    "published": "2023-02-09T04:07:50+00:00",
    "updated": "2023-02-09T04:07:50+00:00",
    "url": "http://arxiv.org/pdf/2302.04430v1"
  },
  {
    "id": "2302.03877v1",
    "title": "Blockchain-based certificate authentication system with enabling correction",
    "authors": [
      "Md. Mijanur Rahman",
      "Md Tanzinul Kabir Tonmoy",
      "Saifur Rahman Shihab",
      "Riya Farhana"
    ],
    "abstract": "Blockchain has proven to be an emerging technology in the digital world,\nchanging the way everyone thinks about data security and bringing efficiency to\nseveral industries. It has already been applied to a wide range of\napplications, from financial services and supply chain management to voting\nsystems and identity verification. An organization must verify its candidates\nbefore selecting them. Choosing an unqualified candidate can ruin an\norganization's reputation. In this digital era, many key fraudulent schemes are\nrampant in many companies and one of them is certificate fraud. It is possible\nto validate a candidate's qualifications using traditional methods, but there\nare drawbacks such as security issues and time consumption. In this paper, a\nblockchain-based academic certificate authentication system will be used to\nensure authenticity and make the assertion of the decentralized system secure.\nHowever, the system will generate, authenticate and make corrections on\nacademic certificates. Ultimately, some blockchain-based authentication systems\nalready exist, they can't correct any errors that occur during generation. The\nproposed system will help in many ways, such as providing a user-friendly\nuniversity admission, and smooth job hiring process, etc. In conclusion, our\nproposed system can permanently eradicate certificate forgeries and create and\npromote trust in society.",
    "categories": [
      "cs.CR",
      "cs.NI"
    ],
    "published": "2023-02-08T04:42:48+00:00",
    "updated": "2023-02-08T04:42:48+00:00",
    "url": "http://arxiv.org/pdf/2302.03877v1"
  },
  {
    "id": "2302.00504v1",
    "title": "Anomaly, reciprocity, and community detection in networks",
    "authors": [
      "Hadiseh Safdari",
      "Martina Contisciani",
      "Caterina De Bacco"
    ],
    "abstract": "Anomaly detection algorithms are a valuable tool in network science for\nidentifying unusual patterns in a network. These algorithms have numerous\npractical applications, including detecting fraud, identifying network security\nthreats, and uncovering significant interactions within a dataset. In this\nproject, we propose a probabilistic generative approach that incorporates\ncommunity membership and reciprocity as key factors driving regular behavior in\na network, which can be used to identify potential anomalies that deviate from\nexpected patterns. We model pairs of edges in a network with exact two-edge\njoint distributions. As a result, our approach captures the exact relationship\nbetween pairs of edges and provides a more comprehensive view of social\nnetworks. Additionally, our study highlights the role of reciprocity in network\nanalysis and can inform the design of future models and algorithms. We also\ndevelop an efficient algorithmic implementation that takes advantage of the\nsparsity of the network.",
    "categories": [
      "cs.SI",
      "68-XX",
      "J.4; E.1"
    ],
    "published": "2023-02-01T15:18:59+00:00",
    "updated": "2023-02-01T15:18:59+00:00",
    "url": "http://arxiv.org/pdf/2302.00504v1"
  },
  {
    "id": "2301.12843v1",
    "title": "Oscilloscope: Detecting BGP Hijacks in the Data Plane",
    "authors": [
      "Tobias Bühler",
      "Alexandros Milolidakis",
      "Romain Jacob",
      "Marco Chiesa",
      "Stefano Vissicchio",
      "Laurent Vanbever"
    ],
    "abstract": "The lack of security of the Internet routing protocol (BGP) has allowed\nattackers to divert Internet traffic and consequently perpetrate service\ndisruptions, monetary frauds, and even citizen surveillance for decades.\nState-of-the-art defenses rely on geo-distributed BGP monitors to detect rogue\nBGP announcements. As we show, though, attackers can easily evade detection by\nengineering their announcements.\n  This paper presents Oscilloscope, an approach to accurately detect BGP\nhijacks by relying on real-time traffic analysis. As hijacks inevitably change\nthe characteristics of the diverted traffic, the key idea is to track these\nchanges in real time and flag them. The main challenge is that \"normal\"\nInternet events (e.g., network reconfigurations, link failures, load balancing)\nalso change the underlying traffic characteristics - and they are way more\nfrequent than hijacks. Naive traffic analyses would hence lead to too many\nfalse positives.\n  We observe that hijacks typically target a subset of the prefixes announced\nby Internet service providers and only divert a subset of their traffic. In\ncontrast, normal events lead to more uniform changes across prefixes and\ntraffic. Oscilloscope uses this observation to filter out non-hijack events by\nchecking whether they affect multiple related prefixes or not.\n  Our experimental evaluation demonstrates that Oscilloscope quickly and\naccurately detects hijacks in realistic traffic traces containing hundreds of\nevents.",
    "categories": [
      "cs.NI"
    ],
    "published": "2023-01-30T12:52:49+00:00",
    "updated": "2023-01-30T12:52:49+00:00",
    "url": "http://arxiv.org/pdf/2301.12843v1"
  },
  {
    "id": "2301.12831v3",
    "title": "M3FAS: An Accurate and Robust MultiModal Mobile Face Anti-Spoofing System",
    "authors": [
      "Chenqi Kong",
      "Kexin Zheng",
      "Yibing Liu",
      "Shiqi Wang",
      "Anderson Rocha",
      "Haoliang Li"
    ],
    "abstract": "Face presentation attacks (FPA), also known as face spoofing, have brought\nincreasing concerns to the public through various malicious applications, such\nas financial fraud and privacy leakage. Therefore, safeguarding face\nrecognition systems against FPA is of utmost importance. Although existing\nlearning-based face anti-spoofing (FAS) models can achieve outstanding\ndetection performance, they lack generalization capability and suffer\nsignificant performance drops in unforeseen environments. Many methodologies\nseek to use auxiliary modality data (e.g., depth and infrared maps) during the\npresentation attack detection (PAD) to address this limitation. However, these\nmethods can be limited since (1) they require specific sensors such as depth\nand infrared cameras for data capture, which are rarely available on commodity\nmobile devices, and (2) they cannot work properly in practical scenarios when\neither modality is missing or of poor quality. In this paper, we devise an\naccurate and robust MultiModal Mobile Face Anti-Spoofing system named M3FAS to\novercome the issues above. The primary innovation of this work lies in the\nfollowing aspects: (1) To achieve robust PAD, our system combines visual and\nauditory modalities using three commonly available sensors: camera, speaker,\nand microphone; (2) We design a novel two-branch neural network with three\nhierarchical feature aggregation modules to perform cross-modal feature fusion;\n(3). We propose a multi-head training strategy, allowing the model to output\npredictions from the vision, acoustic, and fusion heads, resulting in a more\nflexible PAD. Extensive experiments have demonstrated the accuracy, robustness,\nand flexibility of M3FAS under various challenging experimental settings. The\nsource code and dataset are available at: https://github.com/ChenqiKONG/M3FAS/",
    "categories": [
      "cs.MM",
      "cs.CV"
    ],
    "published": "2023-01-30T12:37:04+00:00",
    "updated": "2024-03-21T05:39:44+00:00",
    "url": "http://arxiv.org/pdf/2301.12831v3"
  },
  {
    "id": "2301.10888v1",
    "title": "Experimenting with an Evaluation Framework for Imbalanced Data Learning (EFIDL)",
    "authors": [
      "Chenyu Li",
      "Xia Jiang"
    ],
    "abstract": "Introduction Data imbalance is one of the crucial issues in big data analysis\nwith fewer labels. For example, in real-world healthcare data, spam detection\nlabels, and financial fraud detection datasets. Many data balance methods were\nintroduced to improve machine learning algorithms' performance. Research claims\nSMOTE and SMOTE-based data-augmentation (generate new data points) methods\ncould improve algorithm performance. However, we found in many online\ntutorials, the valuation methods were applied based on synthesized datasets\nthat introduced bias into the evaluation, and the performance got a false\nimprovement. In this study, we proposed, a new evaluation framework for\nimbalanced data learning methods. We have experimented on five data balance\nmethods and whether the performance of algorithms will improve or not. Methods\nWe collected 8 imbalanced healthcare datasets with different imbalanced rates\nfrom different domains. Applied 6 data augmentation methods with 11 machine\nlearning methods testing if the data augmentation will help with improving\nmachine learning performance. We compared the traditional data augmentation\nevaluation methods with our proposed cross-validation evaluation framework\nResults Using traditional data augmentation evaluation meta hods will give a\nfalse impression of improving the performance. However, our proposed evaluation\nmethod shows data augmentation has limited ability to improve the results.\nConclusion EFIDL is more suitable for evaluating the prediction performance of\nan ML method when data are augmented. Using an unsuitable evaluation framework\nwill give false results. Future researchers should consider the evaluation\nframework we proposed when dealing with augmented datasets. Our experiments\nshowed data augmentation does not help improve ML prediction performance.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-01-26T01:16:02+00:00",
    "updated": "2023-01-26T01:16:02+00:00",
    "url": "http://arxiv.org/pdf/2301.10888v1"
  },
  {
    "id": "2303.15218v1",
    "title": "Evaluating XGBoost for Balanced and Imbalanced Data: Application to Fraud Detection",
    "authors": [
      "Gissel Velarde",
      "Anindya Sudhir",
      "Sanjay Deshmane",
      "Anuj Deshmunkh",
      "Khushboo Sharma",
      "Vaibhav Joshi"
    ],
    "abstract": "This paper evaluates XGboost's performance given different dataset sizes and\nclass distributions, from perfectly balanced to highly imbalanced. XGBoost has\nbeen selected for evaluation, as it stands out in several benchmarks due to its\ndetection performance and speed. After introducing the problem of fraud\ndetection, the paper reviews evaluation metrics for detection systems or binary\nclassifiers, and illustrates with examples how different metrics work for\nbalanced and imbalanced datasets. Then, it examines the principles of XGBoost.\nIt proposes a pipeline for data preparation and compares a Vanilla XGBoost\nagainst a random search-tuned XGBoost. Random search fine-tuning provides\nconsistent improvement for large datasets of 100 thousand samples, not so for\nmedium and small datasets of 10 and 1 thousand samples, respectively. Besides,\nas expected, XGBoost recognition performance improves as more data is\navailable, and deteriorates detection performance as the datasets become more\nimbalanced. Tests on distributions with 50, 45, 25, and 5 percent positive\nsamples show that the largest drop in detection performance occurs for the\ndistribution with only 5 percent positive samples. Sampling to balance the\ntraining set does not provide consistent improvement. Therefore, future work\nwill include a systematic study of different techniques to deal with data\nimbalance and evaluating other approaches, including graphs, autoencoders, and\ngenerative adversarial methods, to deal with the lack of labels.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2023-03-27T13:59:22+00:00",
    "updated": "2023-03-27T13:59:22+00:00",
    "url": "http://arxiv.org/pdf/2303.15218v1"
  },
  {
    "id": "2303.14836v1",
    "title": "Illuminati: Towards Explaining Graph Neural Networks for Cybersecurity Analysis",
    "authors": [
      "Haoyu He",
      "Yuede Ji",
      "H. Howie Huang"
    ],
    "abstract": "Graph neural networks (GNNs) have been utilized to create multi-layer graph\nmodels for a number of cybersecurity applications from fraud detection to\nsoftware vulnerability analysis. Unfortunately, like traditional neural\nnetworks, GNNs also suffer from a lack of transparency, that is, it is\nchallenging to interpret the model predictions. Prior works focused on specific\nfactor explanations for a GNN model. In this work, we have designed and\nimplemented Illuminati, a comprehensive and accurate explanation framework for\ncybersecurity applications using GNN models. Given a graph and a pre-trained\nGNN model, Illuminati is able to identify the important nodes, edges, and\nattributes that are contributing to the prediction while requiring no prior\nknowledge of GNN models. We evaluate Illuminati in two cybersecurity\napplications, i.e., code vulnerability detection and smart contract\nvulnerability detection. The experiments show that Illuminati achieves more\naccurate explanation results than state-of-the-art methods, specifically, 87.6%\nof subgraphs identified by Illuminati are able to retain their original\nprediction, an improvement of 10.3% over others at 77.3%. Furthermore, the\nexplanation of Illuminati can be easily understood by the domain experts,\nsuggesting the significant usefulness for the development of cybersecurity\napplications.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2023-03-26T22:20:17+00:00",
    "updated": "2023-03-26T22:20:17+00:00",
    "url": "http://arxiv.org/pdf/2303.14836v1"
  },
  {
    "id": "2303.13919v1",
    "title": "Applicability of Trust Management Algorithm in C2C services",
    "authors": [
      "Ryohei Suzuki",
      "Iifan Tyou",
      "Shigenori Ohashi",
      "Kazutoshi Sasahara"
    ],
    "abstract": "The emergence of Consumer-to-Consumer (C2C) platforms has allowed consumers\nto buy and sell goods directly, but it has also created problems, such as\ncommodity fraud and fake reviews. Trust Management Algorithms (TMAs) are\nexpected to be a countermeasure to detect fraudulent users. However, it is\nunknown whether TMAs are as effective as reported as they are designed for\nPeer-to-Peer (P2P) communications between devices on a network. Here we examine\nthe applicability of `EigenTrust', a representative TMA, for the use case of\nC2C services using an agent-based model. First, we defined the transaction\nprocess in C2C services, assumed six types of fraudulent transactions, and then\nanalysed the dynamics of EigenTrust in C2C systems through simulations. We\nfound that EigenTrust could correctly estimate low trust scores for two types\nof simple frauds. Furthermore, we found the oscillation of trust scores for two\ntypes of advanced frauds, which previous research did not address. This\nsuggests that by detecting such oscillations, EigenTrust may be able to detect\nsome (but not all) advanced frauds. Our study helps increase the\ntrustworthiness of transactions in C2C services and provides insights into\nfurther technological development for consumer services.",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "published": "2023-03-24T11:13:47+00:00",
    "updated": "2023-03-24T11:13:47+00:00",
    "url": "http://arxiv.org/pdf/2303.13919v1"
  },
  {
    "id": "2303.13491v1",
    "title": "FraudAuditor: A Visual Analytics Approach for Collusive Fraud in Health Insurance",
    "authors": [
      "Jiehui Zhou",
      "Xumeng Wang",
      "Jie Wang",
      "Hui Ye",
      "Huanliang Wang",
      "Zihan Zhou",
      "Dongming Han",
      "Haochao Ying",
      "Jian Wu",
      "Wei Chen"
    ],
    "abstract": "Collusive fraud, in which multiple fraudsters collude to defraud health\ninsurance funds, threatens the operation of the healthcare system. However,\nexisting statistical and machine learning-based methods have limited ability to\ndetect fraud in the scenario of health insurance due to the high similarity of\nfraudulent behaviors to normal medical visits and the lack of labeled data. To\nensure the accuracy of the detection results, expert knowledge needs to be\nintegrated with the fraud detection process. By working closely with health\ninsurance audit experts, we propose FraudAuditor, a three-stage visual\nanalytics approach to collusive fraud detection in health insurance.\nSpecifically, we first allow users to interactively construct a co-visit\nnetwork to holistically model the visit relationships of different patients.\nSecond, an improved community detection algorithm that considers the strength\nof fraud likelihood is designed to detect suspicious fraudulent groups.\nFinally, through our visual interface, users can compare, investigate, and\nverify suspicious patient behavior with tailored visualizations that support\ndifferent time scales. We conducted case studies in a real-world healthcare\nscenario, i.e., to help locate the actual fraud group and exclude the false\npositive group. The results and expert feedback proved the effectiveness and\nusability of the approach.",
    "categories": [
      "cs.HC"
    ],
    "published": "2023-03-23T17:53:58+00:00",
    "updated": "2023-03-23T17:53:58+00:00",
    "url": "http://arxiv.org/pdf/2303.13491v1"
  },
  {
    "id": "2303.13075v1",
    "title": "Security Analysis on Social Media Networks via STRIDE Model",
    "authors": [
      "Kamal Raj Sharma",
      "Wei-Yang Chiu",
      "Weizhi Meng"
    ],
    "abstract": "Security associated threats are often increased for online social media\nduring a pandemic, such as COVID-19, along with changes in a work environment.\nFor example, employees in many companies and organizations have started to work\nfrom home due to the COVID-19 pandemic. Such working style has increased many\nremote activities and further relied on email for communication, thus creating\nan ideal condition for email fraud schemes. Motivated by this observation, the\nmain purpose of this work is to evaluate the privacy policy of online social\nmedia and identify potential security associated problems. First, we perform a\nrisk analysis of online social media networks such as Facebook, Twitter and\nLinkedIn by using the STRIDE model. This aims to find threats and\nvulnerabilities in the online social media. Then in this analysis, the phishing\nattack was found to be a main threat in online social media, which is a social\nengineering attack, where users are convinced through some fake messages or\nemails to extract their personal credentials.",
    "categories": [
      "cs.CR"
    ],
    "published": "2023-03-23T07:13:46+00:00",
    "updated": "2023-03-23T07:13:46+00:00",
    "url": "http://arxiv.org/pdf/2303.13075v1"
  },
  {
    "id": "2303.12952v1",
    "title": "TSI-GAN: Unsupervised Time Series Anomaly Detection using Convolutional Cycle-Consistent Generative Adversarial Networks",
    "authors": [
      "Shyam Sundar Saravanan",
      "Tie Luo",
      "Mao Van Ngo"
    ],
    "abstract": "Anomaly detection is widely used in network intrusion detection, autonomous\ndriving, medical diagnosis, credit card frauds, etc. However, several key\nchallenges remain open, such as lack of ground truth labels, presence of\ncomplex temporal patterns, and generalizing over different datasets. This paper\nproposes TSI-GAN, an unsupervised anomaly detection model for time-series that\ncan learn complex temporal patterns automatically and generalize well, i.e., no\nneed for choosing dataset-specific parameters, making statistical assumptions\nabout underlying data, or changing model architectures. To achieve these goals,\nwe convert each input time-series into a sequence of 2D images using two\nencoding techniques with the intent of capturing temporal patterns and various\ntypes of deviance. Moreover, we design a reconstructive GAN that uses\nconvolutional layers in an encoder-decoder network and employs\ncycle-consistency loss during training to ensure that inverse mappings are\naccurate as well. In addition, we also instrument a Hodrick-Prescott filter in\npost-processing to mitigate false positives. We evaluate TSI-GAN using 250\nwell-curated and harder-than-usual datasets and compare with 8 state-of-the-art\nbaseline methods. The results demonstrate the superiority of TSI-GAN to all the\nbaselines, offering an overall performance improvement of 13% and 31% over the\nsecond-best performer MERLIN and the third-best performer LSTM-AE,\nrespectively.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2023-03-22T23:24:47+00:00",
    "updated": "2023-03-22T23:24:47+00:00",
    "url": "http://arxiv.org/pdf/2303.12952v1"
  },
  {
    "id": "2303.11181v1",
    "title": "Non-Markovian paths and cycles in NFT trades",
    "authors": [
      "Haaroon Yousaf",
      "Naomi A. Arnold",
      "Renaud Lambiotte",
      "Timothy LaRock",
      "Richard G. Clegg",
      "Peijie Zhong",
      "Alhamza Alnaimi",
      "Ben Steer"
    ],
    "abstract": "Recent years have witnessed the availability of richer and richer datasets in\na variety of domains, where signals often have a multi-modal nature, blending\ntemporal, relational and semantic information. Within this context, several\nworks have shown that standard network models are sometimes not sufficient to\nproperly capture the complexity of real-world interacting systems. For this\nreason, different attempts have been made to enrich the network language,\nleading to the emerging field of higher-order networks. In this work, we\ninvestigate the possibility of applying methods from higher-order networks to\nextract information from the online trade of Non-fungible tokens (NFTs),\nleveraging on their intrinsic temporal and non-Markovian nature. While NFTs as\na technology open up the realms for many exciting applications, its future is\nmarred by challenges of proof of ownership, scams, wash trading and possible\nmoney laundering. We demonstrate that by investigating time-respecting\nnon-Markovian paths exhibited by NFT trades, we provide a practical path-based\napproach to fraud detection.",
    "categories": [
      "cs.SI"
    ],
    "published": "2023-03-20T15:08:38+00:00",
    "updated": "2023-03-20T15:08:38+00:00",
    "url": "http://arxiv.org/pdf/2303.11181v1"
  },
  {
    "id": "2303.09045v1",
    "title": "Web and Mobile Platforms for Managing Elections based on IoT And Machine Learning Algorithms",
    "authors": [
      "G. M. I. K. Galagoda",
      "W. M. C. A. Karunarathne",
      "R. S. Bates",
      "K. M. H. V. P. Gangathilaka",
      "Kanishka Yapa",
      "Erandika Gamage"
    ],
    "abstract": "The global pandemic situation has severely affected all countries. As a\nresult, almost all countries had to adjust to online technologies to continue\ntheir processes. In addition, Sri Lanka is yearly spending ten billion on\nelections. We have examined a proper way of minimizing the cost of hosting\nthese events online. To solve the existing problems and increase the time\npotency and cost reduction we have used IoT and ML-based technologies.\nIoT-based data will identify, register, and be used to secure from fraud, while\nML algorithms manipulate the election data and produce winning predictions,\nweather-based voters attendance, and election violence. All the data will be\nsaved in cloud computing and a standard database to store and access the data.\nThis study mainly focuses on four aspects of an E-voting system. The most\nfrequent problems across the world in E-voting are the security, accuracy, and\nreliability of the systems. E-government systems must be secured against\nvarious cyber-attacks and ensure that only authorized users can access\nvaluable, and sometimes sensitive information. Being able to access a system\nwithout passwords but using biometric details has been there for a while now,\nhowever, our proposed system has a different approach to taking the\ncredentials, processing, and combining the images, reformatting and producing\nthe output, and tracking. In addition, we ensure to enhance e-voting safety.\nWhile ML-based algorithms use different data sets and provide predictions in\nadvance.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2023-03-16T02:31:02+00:00",
    "updated": "2023-03-16T02:31:02+00:00",
    "url": "http://arxiv.org/pdf/2303.09045v1"
  },
  {
    "id": "2303.07584v1",
    "title": "An Adaptive Decision-Making Approach for Better Selection of a Blockchain Platform for Health Insurance Frauds Detection with Smart Contracts: Development and Performance Evaluation",
    "authors": [
      "Rima Kaafarani",
      "Leila Ismail",
      "Oussama Zahwe"
    ],
    "abstract": "Blockchain technology has piqued the interest of businesses of all types,\nwhile consistently improving and adapting to developers and business owners\nrequirements. Therefore, several blockchain platforms have emerged, making it\nchallenging to select a suitable one for a specific type of business. This\npaper presents a classification of over one hundred blockchain platforms. We\ndevelop smart contracts for detecting healthcare insurance frauds using two\nblockchain platforms selected based on our proposed decision-making map\napproach for the selection of the top two suitable platforms for healthcare\ninsurance frauds detection application, followed by an evaluation of their\nperformances. Our classification shows that the largest percentage of\nblockchain platforms could be used for all types of application domains, and\nthe second biggest percentage is to develop financial services only, even\nthough generic platforms can be used, while a small number is for developing in\nother specific application domains. Our decision-making map revealed that\nHyperledger Fabric is the best blockchain platform for detecting healthcare\ninsurance frauds. The performance evaluation of the top two selected platforms\nindicates that Fabric surpassed Neo in all metrics.",
    "categories": [
      "cs.CR",
      "cs.CY",
      "cs.SI",
      "6804, 68M11, 68U35",
      "C.4; D.2.2; D.2.3; D.2.6; D.2.11; H.1.2; I.0; K.6.3; K.6.5"
    ],
    "published": "2023-03-14T02:08:38+00:00",
    "updated": "2023-03-14T02:08:38+00:00",
    "url": "http://arxiv.org/pdf/2303.07584v1"
  },
  {
    "id": "2303.06514v1",
    "title": "Credit Card Fraud Detection Using Enhanced Random Forest Classifier for Imbalanced Data",
    "authors": [
      "AlsharifHasan Mohamad Aburbeian",
      "Huthaifa I. Ashqar"
    ],
    "abstract": "The credit card has become the most popular payment method for both online\nand offline transactions. The necessity to create a fraud detection algorithm\nto precisely identify and stop fraudulent activity arises as a result of both\nthe development of technology and the rise in fraud cases. This paper\nimplements the random forest (RF) algorithm to solve the issue in the hand. A\ndataset of credit card transactions was used in this study. The main problem\nwhen dealing with credit card fraud detection is the imbalanced dataset in\nwhich most of the transaction are non-fraud ones. To overcome the problem of\nthe imbalanced dataset, the synthetic minority over-sampling technique (SMOTE)\nwas used. Implementing the hyperparameters technique to enhance the performance\nof the random forest classifier. The results showed that the RF classifier\ngained an accuracy of 98% and about 98% of F1-score value, which is promising.\nWe also believe that our model is relatively easy to apply and can overcome the\nissue of imbalanced data for fraud detection applications.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "published": "2023-03-11T22:59:37+00:00",
    "updated": "2023-03-11T22:59:37+00:00",
    "url": "http://arxiv.org/pdf/2303.06514v1"
  },
  {
    "id": "2303.06306v1",
    "title": "Blockchain-based decentralized voting system security Perspective: Safe and secure for digital voting system",
    "authors": [
      "Jagbeer Singh",
      "Utkarsh Rastogi",
      "Yash Goel",
      "Brijesh Gupta",
      "Utkarsh"
    ],
    "abstract": "This research study focuses primarily on Block-Chain-based voting systems,\nwhich facilitate participation in and administration of voting for voters,\ncandidates, and officials. Because we used Block-Chain in the backend, which\nenables everyone to trace vote fraud, our system is incredibly safe. This paper\napproach any unique identification the Aadhar Card number or an OTP will be\ngenerated then user can utilise the voting system to cast his/her vote. A\nproposal for Bit-coin, a virtual currency system that is decided by a central\nauthority for producing money, transferring ownership, and validating\ntransactions, included the peer-to-peer network in a Block-Chain system, the\nledger is duplicated across several, identical databases which is hosted and\nupdated by a different process and all other nodes are updated concurrently if\nchanges made to one node and a transaction occurs, the records of the values\nand assets are permanently exchanged, Only the user and the system need to be\nverified no other authentication required. If any transaction carried out on a\nblock chain-based system would be settled in a matter of seconds while still\nbeing safe, verifiable, and transparent. Although block-chain technology is the\nfoundation for Bitcoin and other digital currencies but also it may be applied\nwidely to greatly reduce difficulties in many other sectors, Voting is the\nsector that is battling from a lack of security, centralized-authority,\nmanagement-issues, and many more despite the fact that transactions are kept in\na distributed and safe fashion.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2023-03-11T04:52:46+00:00",
    "updated": "2023-03-11T04:52:46+00:00",
    "url": "http://arxiv.org/pdf/2303.06306v1"
  },
  {
    "id": "2303.06261v3",
    "title": "Interpretable Outlier Summarization",
    "authors": [
      "Yu Wang",
      "Lei Cao",
      "Yizhou Yan",
      "Samuel Madden"
    ],
    "abstract": "Outlier detection is critical in real applications to prevent financial\nfraud, defend network intrusions, or detecting imminent device failures. To\nreduce the human effort in evaluating outlier detection results and effectively\nturn the outliers into actionable insights, the users often expect a system to\nautomatically produce interpretable summarizations of subgroups of outlier\ndetection results. Unfortunately, to date no such systems exist. To fill this\ngap, we propose STAIR which learns a compact set of human understandable rules\nto summarize and explain the anomaly detection results. Rather than use the\nclassical decision tree algorithms to produce these rules, STAIR proposes a new\noptimization objective to produce a small number of rules with least\ncomplexity, hence strong interpretability, to accurately summarize the\ndetection results. The learning algorithm of STAIR produces a rule set by\niteratively splitting the large rules and is optimal in maximizing this\nobjective in each iteration. Moreover, to effectively handle high dimensional,\nhighly complex data sets which are hard to summarize with simple rules, we\npropose a localized STAIR approach, called L-STAIR. Taking data locality into\nconsideration, it simultaneously partitions data and learns a set of localized\nrules for each partition. Our experimental study on many outlier benchmark\ndatasets shows that STAIR significantly reduces the complexity of the rules\nrequired to summarize the outlier detection results, thus more amenable for\nhumans to understand and evaluate, compared to the decision tree methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "published": "2023-03-11T00:53:49+00:00",
    "updated": "2023-09-01T07:49:21+00:00",
    "url": "http://arxiv.org/pdf/2303.06261v3"
  },
  {
    "id": "2303.12745v2",
    "title": "Audio-Visual Deception Detection: DOLOS Dataset and Parameter-Efficient Crossmodal Learning",
    "authors": [
      "Xiaobao Guo",
      "Nithish Muthuchamy Selvaraj",
      "Zitong Yu",
      "Adams Wai-Kin Kong",
      "Bingquan Shen",
      "Alex Kot"
    ],
    "abstract": "Deception detection in conversations is a challenging yet important task,\nhaving pivotal applications in many fields such as credibility assessment in\nbusiness, multimedia anti-frauds, and custom security. Despite this, deception\ndetection research is hindered by the lack of high-quality deception datasets,\nas well as the difficulties of learning multimodal features effectively. To\naddress this issue, we introduce DOLOS\\footnote {The name ``DOLOS\" comes from\nGreek mythology.}, the largest gameshow deception detection dataset with rich\ndeceptive conversations. DOLOS includes 1,675 video clips featuring 213\nsubjects, and it has been labeled with audio-visual feature annotations. We\nprovide train-test, duration, and gender protocols to investigate the impact of\ndifferent factors. We benchmark our dataset on previously proposed deception\ndetection approaches. To further improve the performance by fine-tuning fewer\nparameters, we propose Parameter-Efficient Crossmodal Learning (PECL), where a\nUniform Temporal Adapter (UT-Adapter) explores temporal attention in\ntransformer-based architectures, and a crossmodal fusion module, Plug-in\nAudio-Visual Fusion (PAVF), combines crossmodal information from audio-visual\nfeatures. Based on the rich fine-grained audio-visual annotations on DOLOS, we\nalso exploit multi-task learning to enhance performance by concurrently\npredicting deception and audio-visual features. Experimental results\ndemonstrate the desired quality of the DOLOS dataset and the effectiveness of\nthe PECL. The DOLOS dataset and the source codes are available at\nhttps://github.com/NMS05/Audio-Visual-Deception-Detection-DOLOS-Dataset-and-Parameter-Efficient-Crossmodal-Learning/tree/main.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2023-03-09T08:12:16+00:00",
    "updated": "2023-08-04T03:54:49+00:00",
    "url": "http://arxiv.org/pdf/2303.12745v2"
  },
  {
    "id": "2303.04946v1",
    "title": "ATM Fraud Detection using Streaming Data Analytics",
    "authors": [
      "Yelleti Vivek",
      "Vadlamani Ravi",
      "Abhay Anand Mane",
      "Laveti Ramesh Naidu"
    ],
    "abstract": "Gaining the trust and confidence of customers is the essence of the growth\nand success of financial institutions and organizations. Of late, the financial\nindustry is significantly impacted by numerous instances of fraudulent\nactivities. Further, owing to the generation of large voluminous datasets, it\nis highly essential that underlying framework is scalable and meet real time\nneeds. To address this issue, in the study, we proposed ATM fraud detection in\nstatic and streaming contexts respectively. In the static context, we\ninvestigated a parallel and scalable machine learning algorithms for ATM fraud\ndetection that is built on Spark and trained with a variety of machine learning\n(ML) models including Naive Bayes (NB), Logistic Regression (LR), Support\nVector Machine (SVM), Decision Tree (DT), Random Forest (RF), Gradient Boosting\nTree (GBT), and Multi-layer perceptron (MLP). We also employed several\nbalancing techniques like Synthetic Minority Oversampling Technique (SMOTE) and\nits variants, Generative Adversarial Networks (GAN), to address the rarity in\nthe dataset. In addition, we proposed a streaming based ATM fraud detection in\nthe streaming context. Our sliding window based method collects ATM\ntransactions that are performed within a specified time interval and then\nutilizes to train several ML models, including NB, RF, DT, and K-Nearest\nNeighbour (KNN). We selected these models based on their less model complexity\nand quicker response time. In both contexts, RF turned out to be the best\nmodel. RF obtained the best mean AUC of 0.975 in the static context and mean\nAUC of 0.910 in the streaming context. RF is also empirically proven to be\nstatistically significant than the next-best performing models.",
    "categories": [
      "cs.LG",
      "cs.DC",
      "37M10, 62M10, 91B84",
      "I.2.11; J.4"
    ],
    "published": "2023-03-08T23:40:18+00:00",
    "updated": "2023-03-08T23:40:18+00:00",
    "url": "http://arxiv.org/pdf/2303.04946v1"
  },
  {
    "id": "2303.02836v1",
    "title": "Blockchain-Empowered Lifecycle Management for AI-Generated Content (AIGC) Products in Edge Networks",
    "authors": [
      "Yinqiu Liu",
      "Hongyang Du",
      "Dusit Niyato",
      "Jiawen Kang",
      "Zehui Xiong",
      "Chunyan Miao",
      "Xuemin",
      "Shen",
      "Abbas Jamalipour"
    ],
    "abstract": "The rapid development of Artificial IntelligenceGenerated Content (AIGC) has\nbrought daunting challenges regarding service latency, security, and\ntrustworthiness. Recently, researchers presented the edge AIGC paradigm,\neffectively optimize the service latency by distributing AIGC services to edge\ndevices. However, AIGC products are still unprotected and vulnerable to\ntampering and plagiarization. Moreover, as a kind of online non-fungible\ndigital property, the free circulation of AIGC products is hindered by the lack\nof trustworthiness in open networks. In this article, for the first time, we\npresent a blockchain-empowered framework to manage the lifecycle of edge AIGC\nproducts. Specifically, leveraging fraud proof, we first propose a protocol to\nprotect the ownership and copyright of AIGC, called Proof-of-AIGC. Then, we\ndesign an incentive mechanism to guarantee the legitimate and timely executions\nof the funds-AIGC ownership exchanges among anonymous users. Furthermore, we\nbuild a multi-weight subjective logic-based reputation scheme, with which AIGC\nproducers can determine which edge service provider is trustworthy and reliable\nto handle their services. Through numerical results, the superiority of the\nproposed approach is demonstrated. Last but not least, we discuss important\nopen directions for further research.",
    "categories": [
      "cs.CR"
    ],
    "published": "2023-03-06T02:06:13+00:00",
    "updated": "2023-03-06T02:06:13+00:00",
    "url": "http://arxiv.org/pdf/2303.02836v1"
  },
  {
    "id": "2303.00917v2",
    "title": "Enhancing General Face Forgery Detection via Vision Transformer with Low-Rank Adaptation",
    "authors": [
      "Chenqi Kong",
      "Haoliang Li",
      "Shiqi Wang"
    ],
    "abstract": "Nowadays, forgery faces pose pressing security concerns over fake news,\nfraud, impersonation, etc. Despite the demonstrated success in intra-domain\nface forgery detection, existing detection methods lack generalization\ncapability and tend to suffer from dramatic performance drops when deployed to\nunforeseen domains. To mitigate this issue, this paper designs a more general\nfake face detection model based on the vision transformer(ViT) architecture. In\nthe training phase, the pretrained ViT weights are freezed, and only the\nLow-Rank Adaptation(LoRA) modules are updated. Additionally, the Single Center\nLoss(SCL) is applied to supervise the training process, further improving the\ngeneralization capability of the model. The proposed method achieves\nstate-of-the-arts detection performances in both cross-manipulation and\ncross-dataset evaluations.",
    "categories": [
      "cs.CV"
    ],
    "published": "2023-03-02T02:26:04+00:00",
    "updated": "2023-03-27T07:42:24+00:00",
    "url": "http://arxiv.org/pdf/2303.00917v2"
  },
  {
    "id": "2303.00810v2",
    "title": "Of Degens and Defrauders: Using Open-Source Investigative Tools to Investigate Decentralized Finance Frauds and Money Laundering",
    "authors": [
      "Arianna Trozze",
      "Toby Davies",
      "Bennett Kleinberg"
    ],
    "abstract": "Fraud across the decentralized finance (DeFi) ecosystem is growing, with\nvictims losing billions to DeFi scams every year. However, there is a\ndisconnect between the reported value of these scams and associated legal\nprosecutions. We use open-source investigative tools to (1) investigate\npotential frauds involving Ethereum tokens using on-chain data and token smart\ncontract analysis, and (2) investigate the ways proceeds from these scams were\nsubsequently laundered. The analysis enabled us to (1) uncover\ntransaction-based evidence of several rug pull and pump-and-dump schemes, and\n(2) identify their perpetrators' money laundering tactics and cash-out methods.\nThe rug pulls were less sophisticated than anticipated, money laundering\ntechniques were also rudimentary and many funds ended up at centralized\nexchanges. This study demonstrates how open-source investigative tools can\nextract transaction-based evidence that could be used in a court of law to\nprosecute DeFi frauds. Additionally, we investigate how these funds are\nsubsequently laundered.",
    "categories": [
      "cs.CR"
    ],
    "published": "2023-03-01T20:23:30+00:00",
    "updated": "2023-05-26T16:06:52+00:00",
    "url": "http://arxiv.org/pdf/2303.00810v2"
  },
  {
    "id": "2303.01234v2",
    "title": "Frauds Bargain Attack: Generating Adversarial Text Samples via Word Manipulation Process",
    "authors": [
      "Mingze Ni",
      "Zhensu Sun",
      "Wei Liu"
    ],
    "abstract": "Recent research has revealed that natural language processing (NLP) models\nare vulnerable to adversarial examples. However, the current techniques for\ngenerating such examples rely on deterministic heuristic rules, which fail to\nproduce optimal adversarial examples. In response, this study proposes a new\nmethod called the Fraud's Bargain Attack (FBA), which uses a randomization\nmechanism to expand the search space and produce high-quality adversarial\nexamples with a higher probability of success. FBA uses the Metropolis-Hasting\nsampler, a type of Markov Chain Monte Carlo sampler, to improve the selection\nof adversarial examples from all candidates generated by a customized\nstochastic process called the Word Manipulation Process (WMP). The WMP method\nmodifies individual words in a contextually-aware manner through insertion,\nremoval, or substitution. Through extensive experiments, this study\ndemonstrates that FBA outperforms other methods in terms of attack success\nrate, imperceptibility and sentence quality.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2023-03-01T06:04:25+00:00",
    "updated": "2023-12-27T17:54:38+00:00",
    "url": "http://arxiv.org/pdf/2303.01234v2"
  },
  {
    "id": "2303.00070v1",
    "title": "Tainted Love: A Systematic Review of Online Romance Fraud",
    "authors": [
      "Alexander Bilz",
      "Lynsay A. Shepherd",
      "Graham I. Johnson"
    ],
    "abstract": "Romance fraud involves cybercriminals engineering a romantic relationship on\nonline dating platforms. It is a cruel form of cybercrime whereby victims are\nleft heartbroken, often facing financial ruin. We characterise the literary\nlandscape on romance fraud, advancing the understanding of researchers and\npractitioners by systematically reviewing and synthesising contemporary\nqualitative and quantitative evidence. The systematic review provides an\noverview of the field by establishing influencing factors of victimhood and\nexploring countermeasures for mitigating romance scams. We searched ten\nscholarly databases and websites using terms related to romance fraud. Studies\nidentified were screened, and high-level metadata and findings were extracted,\nsynthesised, and contrasted. The methodology followed the PRISMA guidelines: a\ntotal of 232 papers were screened. Eighty-two papers were assessed for\neligibility, and 44 were included in the final analysis. Three main\ncontributions were identified: profiles of romance scams, countermeasures for\nmitigating romance scams, and factors that predispose an individual to become a\nscammer or a victim. Despite a growing corpus of literature, the total number\nof empirical or experimental examinations remained limited. The paper concludes\nwith avenues for future research and victimhood intervention strategies for\npractitioners, law enforcement, and industry.",
    "categories": [
      "cs.HC",
      "cs.CR",
      "cs.CY"
    ],
    "published": "2023-02-28T20:34:07+00:00",
    "updated": "2023-02-28T20:34:07+00:00",
    "url": "http://arxiv.org/pdf/2303.00070v1"
  },
  {
    "id": "2303.17511v1",
    "title": "On pitfalls (and advantages) of sophisticated large language models",
    "authors": [
      "Anna Strasser"
    ],
    "abstract": "Natural language processing based on large language models (LLMs) is a\nbooming field of AI research. After neural networks have proven to outperform\nhumans in games and practical domains based on pattern recognition, we might\nstand now at a road junction where artificial entities might eventually enter\nthe realm of human communication. However, this comes with serious risks. Due\nto the inherent limitations regarding the reliability of neural networks,\noverreliance on LLMs can have disruptive consequences. Since it will be\nincreasingly difficult to distinguish between human-written and\nmachine-generated text, one is confronted with new ethical challenges. This\nbegins with the no longer undoubtedly verifiable human authorship and continues\nwith various types of fraud, such as a new form of plagiarism. This also\nconcerns the violation of privacy rights, the possibility of circulating\ncounterfeits of humans, and, last but not least, it makes a massive spread of\nmisinformation possible.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2023-02-25T11:14:39+00:00",
    "updated": "2023-02-25T11:14:39+00:00",
    "url": "http://arxiv.org/pdf/2303.17511v1"
  },
  {
    "id": "2302.12959v1",
    "title": "Chaotic Variational Auto encoder-based Adversarial Machine Learning",
    "authors": [
      "Pavan Venkata Sainadh Reddy",
      "Yelleti Vivek",
      "Gopi Pranay",
      "Vadlamani Ravi"
    ],
    "abstract": "Machine Learning (ML) has become the new contrivance in almost every field.\nThis makes them a target of fraudsters by various adversary attacks, thereby\nhindering the performance of ML models. Evasion and Data-Poison-based attacks\nare well acclaimed, especially in finance, healthcare, etc. This motivated us\nto propose a novel computationally less expensive attack mechanism based on the\nadversarial sample generation by Variational Auto Encoder (VAE). It is well\nknown that Wavelet Neural Network (WNN) is considered computationally efficient\nin solving image and audio processing, speech recognition, and time-series\nforecasting. This paper proposed VAE-Deep-Wavelet Neural Network\n(VAE-Deep-WNN), where Encoder and Decoder employ WNN networks. Further, we\nproposed chaotic variants of both VAE with Multi-layer perceptron (MLP) and\nDeep-WNN and named them C-VAE-MLP and C-VAE-Deep-WNN, respectively. Here, we\nemployed a Logistic map to generate random noise in the latent space. In this\npaper, we performed VAE-based adversary sample generation and applied it to\nvarious problems related to finance and cybersecurity domain-related problems\nsuch as loan default, credit card fraud, and churn modelling, etc., We\nperformed both Evasion and Data-Poison attacks on Logistic Regression (LR) and\nDecision Tree (DT) models. The results indicated that VAE-Deep-WNN outperformed\nthe rest in the majority of the datasets and models. However, its chaotic\nvariant C-VAE-Deep-WNN performed almost similarly to VAE-Deep-WNN in the\nmajority of the datasets.",
    "categories": [
      "cs.LG",
      "cs.CR",
      "68T01, 68M25",
      "I.2.6; K.6.5"
    ],
    "published": "2023-02-25T02:06:15+00:00",
    "updated": "2023-02-25T02:06:15+00:00",
    "url": "http://arxiv.org/pdf/2302.12959v1"
  },
  {
    "id": "2304.10436v1",
    "title": "Safety Assessment of Chinese Large Language Models",
    "authors": [
      "Hao Sun",
      "Zhexin Zhang",
      "Jiawen Deng",
      "Jiale Cheng",
      "Minlie Huang"
    ],
    "abstract": "With the rapid popularity of large language models such as ChatGPT and GPT-4,\na growing amount of attention is paid to their safety concerns. These models\nmay generate insulting and discriminatory content, reflect incorrect social\nvalues, and may be used for malicious purposes such as fraud and dissemination\nof misleading information. Evaluating and enhancing their safety is\nparticularly essential for the wide application of large language models\n(LLMs). To further promote the safe deployment of LLMs, we develop a Chinese\nLLM safety assessment benchmark. Our benchmark explores the comprehensive\nsafety performance of LLMs from two perspectives: 8 kinds of typical safety\nscenarios and 6 types of more challenging instruction attacks. Our benchmark is\nbased on a straightforward process in which it provides the test prompts and\nevaluates the safety of the generated responses from the evaluated model. In\nevaluation, we utilize the LLM's strong evaluation ability and develop it as a\nsafety evaluator by prompting. On top of this benchmark, we conduct safety\nassessments and analyze 15 LLMs including the OpenAI GPT series and other\nwell-known Chinese LLMs, where we observe some interesting findings. For\nexample, we find that instruction attacks are more likely to expose safety\nissues of all LLMs. Moreover, to promote the development and deployment of\nsafe, responsible, and ethical AI, we publicly release SafetyPrompts including\n100k augmented prompts and responses by LLMs.",
    "categories": [
      "cs.CL"
    ],
    "published": "2023-04-20T16:27:35+00:00",
    "updated": "2023-04-20T16:27:35+00:00",
    "url": "http://arxiv.org/pdf/2304.10436v1"
  },
  {
    "id": "2304.10105v1",
    "title": "Automatic Procurement Fraud Detection with Machine Learning",
    "authors": [
      "Jin Bai",
      "Tong Qiu"
    ],
    "abstract": "Although procurement fraud is always a critical problem in almost every free\nmarket, audit departments still have a strong reliance on reporting from\ninformed sources when detecting them. With our generous cooperator, SF Express,\nsharing the access to the database related with procurements took place from\n2015 to 2017 in their company, our team studies how machine learning techniques\ncould help with the audition of one of the most profound crime among current\nchinese market, namely procurement frauds. By representing each procurement\nevent as 9 specific features, we construct neural network models to identify\nsuspicious procurements and classify their fraud types. Through testing our\nmodels over 50000 samples collected from the procurement database, we have\nproven that such models -- despite having space for improvements -- are useful\nin detecting procurement frauds.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-04-20T06:22:43+00:00",
    "updated": "2023-04-20T06:22:43+00:00",
    "url": "http://arxiv.org/pdf/2304.10105v1"
  },
  {
    "id": "2304.09468v1",
    "title": "Secure Mobile Payment Architecture Enabling Multi-factor Authentication",
    "authors": [
      "Hosam Alamleh",
      "Ali Abdullah S. AlQahtani",
      "Baker Al Smadi"
    ],
    "abstract": "The rise of smartphones has led to a significant increase in the usage of\nmobile payments. Mobile payments allow individuals to access financial\nresources and make transactions through their mobile devices while on the go.\nHowever, the current mobile payment systems were designed to align with\ntraditional payment structures, which limits the full potential of smartphones,\nincluding their security features. This has become a major concern in the\nrapidly growing mobile payment market. To address these security concerns,in\nthis paper we propose new mobile payment architecture. This architecture\nleverages the advanced capabilities of modern smartphones to verify various\naspects of a payment, such as funds, biometrics, location, and others. The\nproposed system aims to guarantee the legitimacy of transactions and protect\nagainst identity theft by verifying multiple elements of a payment. The\nsecurity of mobile payment systems is crucial, given the rapid growth of the\nmarket. Evaluating mobile payment systems based on their authentication,\nencryption, and fraud detection capabilities is of utmost importance. The\nproposed architecture provides a secure mobile payment solution that enhances\nthe overall payment experience by taking advantage of the advanced capabilities\nof modern smartphones. This will not only improve the security of mobile\npayments but also offer a more user-friendly payment experience for consumers.",
    "categories": [
      "cs.CR",
      "cs.NI"
    ],
    "published": "2023-04-19T07:30:18+00:00",
    "updated": "2023-04-19T07:30:18+00:00",
    "url": "http://arxiv.org/pdf/2304.09468v1"
  },
  {
    "id": "2304.08847v2",
    "title": "BadVFL: Backdoor Attacks in Vertical Federated Learning",
    "authors": [
      "Mohammad Naseri",
      "Yufei Han",
      "Emiliano De Cristofaro"
    ],
    "abstract": "Federated learning (FL) enables multiple parties to collaboratively train a\nmachine learning model without sharing their data; rather, they train their own\nmodel locally and send updates to a central server for aggregation. Depending\non how the data is distributed among the participants, FL can be classified\ninto Horizontal (HFL) and Vertical (VFL). In VFL, the participants share the\nsame set of training instances but only host a different and non-overlapping\nsubset of the whole feature space. Whereas in HFL, each participant shares the\nsame set of features while the training set is split into locally owned\ntraining data subsets.\n  VFL is increasingly used in applications like financial fraud detection;\nnonetheless, very little work has analyzed its security. In this paper, we\nfocus on robustness in VFL, in particular, on backdoor attacks, whereby an\nadversary attempts to manipulate the aggregate model during the training\nprocess to trigger misclassifications. Performing backdoor attacks in VFL is\nmore challenging than in HFL, as the adversary i) does not have access to the\nlabels during training and ii) cannot change the labels as she only has access\nto the feature embeddings. We present a first-of-its-kind clean-label backdoor\nattack in VFL, which consists of two phases: a label inference and a backdoor\nphase. We demonstrate the effectiveness of the attack on three different\ndatasets, investigate the factors involved in its success, and discuss\ncountermeasures to mitigate its impact.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2023-04-18T09:22:32+00:00",
    "updated": "2023-08-23T21:57:10+00:00",
    "url": "http://arxiv.org/pdf/2304.08847v2"
  },
  {
    "id": "2304.08710v1",
    "title": "Quantum Algorithm for Unsupervised Anomaly Detection",
    "authors": [
      "MingChao Guo",
      "ShiJie Pan",
      "WenMin Li",
      "Fei Gao",
      "SuJuan Qin",
      "XiaoLing Yu",
      "XuanWen Zhang",
      "QiaoYan Wen"
    ],
    "abstract": "Anomaly detection, an important branch of machine learning, plays a critical\nrole in fraud detection, health care, intrusion detection, military\nsurveillance, etc. As one of the most commonly used unsupervised anomaly\ndetection algorithms, the Local Outlier Factor algorithm (LOF algorithm) has\nbeen extensively studied. This algorithm contains three steps, i.e.,\ndetermining the k-distance neighborhood for each data point x, computing the\nlocal reachability density of x, and calculating the local outlier factor of x\nto judge whether x is abnormal. The LOF algorithm is computationally expensive\nwhen processing big data sets. Here we present a quantum LOF algorithm\nconsisting of three parts corresponding to the classical algorithm.\nSpecifically, the k-distance neighborhood of x is determined by amplitude\nestimation and minimum search; the local reachability density of each data\npoint is calculated in parallel based on the quantum multiply-adder; the local\noutlier factor of each data point is obtained in parallel using amplitude\nestimation. It is shown that our quantum algorithm achieves exponential speedup\non the dimension of the data points and polynomial speedup on the number of\ndata points compared to its classical counterpart. This work demonstrates the\nadvantage of quantum computing in unsupervised anomaly detection.",
    "categories": [
      "quant-ph"
    ],
    "published": "2023-04-18T03:20:11+00:00",
    "updated": "2023-04-18T03:20:11+00:00",
    "url": "http://arxiv.org/pdf/2304.08710v1"
  },
  {
    "id": "2304.07883v1",
    "title": "Bent & Broken Bicycles: Leveraging synthetic data for damaged object re-identification",
    "authors": [
      "Luca Piano",
      "Filippo Gabriele Pratticò",
      "Alessandro Sebastian Russo",
      "Lorenzo Lanari",
      "Lia Morra",
      "Fabrizio Lamberti"
    ],
    "abstract": "Instance-level object re-identification is a fundamental computer vision\ntask, with applications from image retrieval to intelligent monitoring and\nfraud detection. In this work, we propose the novel task of damaged object\nre-identification, which aims at distinguishing changes in visual appearance\ndue to deformations or missing parts from subtle intra-class variations. To\nexplore this task, we leverage the power of computer-generated imagery to\ncreate, in a semi-automatic fashion, high-quality synthetic images of the same\nbike before and after a damage occurs. The resulting dataset, Bent & Broken\nBicycles (BBBicycles), contains 39,200 images and 2,800 unique bike instances\nspanning 20 different bike models. As a baseline for this task, we propose\nTransReI3D, a multi-task, transformer-based deep network unifying damage\ndetection (framed as a multi-label classification task) with object\nre-identification. The BBBicycles dataset is available at\nhttps://huggingface.co/datasets/GrainsPolito/BBBicycles",
    "categories": [
      "cs.CV",
      "cs.GR",
      "cs.LG"
    ],
    "published": "2023-04-16T20:23:58+00:00",
    "updated": "2023-04-16T20:23:58+00:00",
    "url": "http://arxiv.org/pdf/2304.07883v1"
  },
  {
    "id": "2304.03368v1",
    "title": "From Explanation to Action: An End-to-End Human-in-the-loop Framework for Anomaly Reasoning and Management",
    "authors": [
      "Xueying Ding",
      "Nikita Seleznev",
      "Senthil Kumar",
      "C. Bayan Bruss",
      "Leman Akoglu"
    ],
    "abstract": "Anomalies are often indicators of malfunction or inefficiency in various\nsystems such as manufacturing, healthcare, finance, surveillance, to name a\nfew. While the literature is abundant in effective detection algorithms due to\nthis practical relevance, autonomous anomaly detection is rarely used in\nreal-world scenarios. Especially in high-stakes applications, a\nhuman-in-the-loop is often involved in processes beyond detection such as\nverification and troubleshooting. In this work, we introduce ALARM (for\nAnalyst-in-the-Loop Anomaly Reasoning and Management); an end-to-end framework\nthat supports the anomaly mining cycle comprehensively, from detection to\naction. Besides unsupervised detection of emerging anomalies, it offers anomaly\nexplanations and an interactive GUI for human-in-the-loop processes -- visual\nexploration, sense-making, and ultimately action-taking via designing new\ndetection rules -- that help close ``the loop'' as the new rules complement\nrule-based supervised detection, typical of many deployed systems in practice.\nWe demonstrate \\method's efficacy through a series of case studies with fraud\nanalysts from the financial industry.",
    "categories": [
      "cs.LG",
      "cs.HC"
    ],
    "published": "2023-04-06T20:49:36+00:00",
    "updated": "2023-04-06T20:49:36+00:00",
    "url": "http://arxiv.org/pdf/2304.03368v1"
  },
  {
    "id": "2304.01487v2",
    "title": "To ChatGPT, or not to ChatGPT: That is the question!",
    "authors": [
      "Alessandro Pegoraro",
      "Kavita Kumari",
      "Hossein Fereidooni",
      "Ahmad-Reza Sadeghi"
    ],
    "abstract": "ChatGPT has become a global sensation. As ChatGPT and other Large Language\nModels (LLMs) emerge, concerns of misusing them in various ways increase, such\nas disseminating fake news, plagiarism, manipulating public opinion, cheating,\nand fraud. Hence, distinguishing AI-generated from human-generated becomes\nincreasingly essential. Researchers have proposed various detection\nmethodologies, ranging from basic binary classifiers to more complex\ndeep-learning models. Some detection techniques rely on statistical\ncharacteristics or syntactic patterns, while others incorporate semantic or\ncontextual information to improve accuracy. The primary objective of this study\nis to provide a comprehensive and contemporary assessment of the most recent\ntechniques in ChatGPT detection. Additionally, we evaluated other AI-generated\ntext detection tools that do not specifically claim to detect ChatGPT-generated\ncontent to assess their performance in detecting ChatGPT-generated content. For\nour evaluation, we have curated a benchmark dataset consisting of prompts from\nChatGPT and humans, including diverse questions from medical, open Q&A, and\nfinance domains and user-generated responses from popular social networking\nplatforms. The dataset serves as a reference to assess the performance of\nvarious techniques in detecting ChatGPT-generated content. Our evaluation\nresults demonstrate that none of the existing methods can effectively detect\nChatGPT-generated content.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2023-04-04T03:04:28+00:00",
    "updated": "2023-04-05T04:28:41+00:00",
    "url": "http://arxiv.org/pdf/2304.01487v2"
  },
  {
    "id": "2304.02019v1",
    "title": "Detecting Fake Job Postings Using Bidirectional LSTM",
    "authors": [
      "Aravind Sasidharan Pillai"
    ],
    "abstract": "Fake job postings have become prevalent in the online job market, posing\nsignificant challenges to job seekers and employers. Despite the growing need\nto address this problem, there is limited research that leverages deep learning\ntechniques for the detection of fraudulent job advertisements. This study aims\nto fill the gap by employing a Bidirectional Long Short-Term Memory (Bi-LSTM)\nmodel to identify fake job advertisements. Our approach considers both numeric\nand text features, effectively capturing the underlying patterns and\nrelationships within the data. The proposed model demonstrates a superior\nperformance, achieving a 0.91 ROC AUC score and a 98.71% accuracy rate,\nindicating its potential for practical applications in the online job market.\nThe findings of this research contribute to the development of robust,\nautomated tools that can help combat the proliferation of fake job postings and\nimprove the overall integrity of the job search process. Moreover, we discuss\nchallenges, future research directions, and ethical considerations related to\nour approach, aiming to inspire further exploration and development of\npractical solutions to combat online job fraud.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-04-03T20:05:27+00:00",
    "updated": "2023-04-03T20:05:27+00:00",
    "url": "http://arxiv.org/pdf/2304.02019v1"
  },
  {
    "id": "2303.18130v1",
    "title": "Blockchain-based Immutable Evidence and Decentralized Loss Adjustment for Autonomous Vehicle Accidents in Insurance",
    "authors": [
      "Mehmet Parlak"
    ],
    "abstract": "In case of an accident between two autonomous vehicles equipped with emerging\ntechnologies, how do we apportion liability among the various players? A\nspecial liability regime has not even yet been established for damages that may\narise due to the accidents of autonomous vehicles. Would the immutable,\ntime-stamped sensor records of vehicles on distributed ledger help define the\nintertwined relations of liability subjects right through the accident? What if\nthe synthetic media created through deepfake gets involved in the insurance\nclaims? While integrating AI-powered anomaly or deepfake detection into\nautomated insurance claims processing helps to prevent insurance fraud, it is\nonly a matter of time before deepfake becomes nearly undetectable even to\nelaborate forensic tools. This paper proposes a blockchain-based insurtech\ndecentralized application to check the authenticity and provenance of the\naccident footage and also to decentralize the loss-adjusting process through a\nhybrid of decentralized and centralized databases using smart contracts.",
    "categories": [
      "cs.CR"
    ],
    "published": "2023-03-29T21:50:13+00:00",
    "updated": "2023-03-29T21:50:13+00:00",
    "url": "http://arxiv.org/pdf/2303.18130v1"
  },
  {
    "id": "2303.18138v2",
    "title": "BERT4ETH: A Pre-trained Transformer for Ethereum Fraud Detection",
    "authors": [
      "Sihao Hu",
      "Zhen Zhang",
      "Bingqiao Luo",
      "Shengliang Lu",
      "Bingsheng He",
      "Ling Liu"
    ],
    "abstract": "As various forms of fraud proliferate on Ethereum, it is imperative to\nsafeguard against these malicious activities to protect susceptible users from\nbeing victimized. While current studies solely rely on graph-based fraud\ndetection approaches, it is argued that they may not be well-suited for dealing\nwith highly repetitive, skew-distributed and heterogeneous Ethereum\ntransactions. To address these challenges, we propose BERT4ETH, a universal\npre-trained Transformer encoder that serves as an account representation\nextractor for detecting various fraud behaviors on Ethereum. BERT4ETH features\nthe superior modeling capability of Transformer to capture the dynamic\nsequential patterns inherent in Ethereum transactions, and addresses the\nchallenges of pre-training a BERT model for Ethereum with three practical and\neffective strategies, namely repetitiveness reduction, skew alleviation and\nheterogeneity modeling. Our empirical evaluation demonstrates that BERT4ETH\noutperforms state-of-the-art methods with significant enhancements in terms of\nthe phishing account detection and de-anonymization tasks. The code for\nBERT4ETH is available at: https://github.com/git-disl/BERT4ETH.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2023-03-29T20:30:52+00:00",
    "updated": "2023-10-30T20:03:08+00:00",
    "url": "http://arxiv.org/pdf/2303.18138v2"
  },
  {
    "id": "2303.17334v1",
    "title": "GAT-COBO: Cost-Sensitive Graph Neural Network for Telecom Fraud Detection",
    "authors": [
      "Xinxin Hu",
      "Haotian Chen",
      "Junjie Zhang",
      "Hongchang Chen",
      "Shuxin Liu",
      "Xing Li",
      "Yahui Wang",
      "Xiangyang Xue"
    ],
    "abstract": "Along with the rapid evolution of mobile communication technologies, such as\n5G, there has been a drastically increase in telecom fraud, which significantly\ndissipates individual fortune and social wealth. In recent years, graph mining\ntechniques are gradually becoming a mainstream solution for detecting telecom\nfraud. However, the graph imbalance problem, caused by the Pareto principle,\nbrings severe challenges to graph data mining. This is a new and challenging\nproblem, but little previous work has been noticed. In this paper, we propose a\nGraph ATtention network with COst-sensitive BOosting (GAT-COBO) for the graph\nimbalance problem. First, we design a GAT-based base classifier to learn the\nembeddings of all nodes in the graph. Then, we feed the embeddings into a\nwell-designed cost-sensitive learner for imbalanced learning. Next, we update\nthe weights according to the misclassification cost to make the model focus\nmore on the minority class. Finally, we sum the node embeddings obtained by\nmultiple cost-sensitive learners to obtain a comprehensive node representation,\nwhich is used for the downstream anomaly detection task. Extensive experiments\non two real-world telecom fraud detection datasets demonstrate that our\nproposed method is effective for the graph imbalance problem, outperforming the\nstate-of-the-art GNNs and GNN-based fraud detectors. In addition, our model is\nalso helpful for solving the widespread over-smoothing problem in GNNs. The\nGAT-COBO code and datasets are available at https://github.com/xxhu94/GAT-COBO.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2023-03-29T07:02:50+00:00",
    "updated": "2023-03-29T07:02:50+00:00",
    "url": "http://arxiv.org/pdf/2303.17334v1"
  },
  {
    "id": "2303.17486v1",
    "title": "Cost Sensitive GNN-based Imbalanced Learning for Mobile Social Network Fraud Detection",
    "authors": [
      "Xinxin Hu",
      "Haotian Chen",
      "Hongchang Chen",
      "Shuxin Liu",
      "Xing Li",
      "Shibo Zhang",
      "Yahui Wang",
      "Xiangyang Xue"
    ],
    "abstract": "With the rapid development of mobile networks, the people's social contacts\nhave been considerably facilitated. However, the rise of mobile social network\nfraud upon those networks, has caused a great deal of distress, in case of\ndepleting personal and social wealth, then potentially doing significant\neconomic harm. To detect fraudulent users, call detail record (CDR) data, which\nportrays the social behavior of users in mobile networks, has been widely\nutilized. But the imbalance problem in the aforementioned data, which could\nseverely hinder the effectiveness of fraud detectors based on graph neural\nnetworks(GNN), has hardly been addressed in previous work. In this paper, we\nare going to present a novel Cost-Sensitive Graph Neural Network (CSGNN) by\ncreatively combining cost-sensitive learning and graph neural networks. We\nconduct extensive experiments on two open-source realworld mobile network fraud\ndatasets. The results show that CSGNN can effectively solve the graph imbalance\nproblem and then achieve better detection performance than the state-of-the-art\nalgorithms. We believe that our research can be applied to solve the graph\nimbalance problems in other fields. The CSGNN code and datasets are publicly\navailable at https://github.com/xxhu94/CSGNN.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2023-03-28T01:43:32+00:00",
    "updated": "2023-03-28T01:43:32+00:00",
    "url": "http://arxiv.org/pdf/2303.17486v1"
  },
  {
    "id": "2303.15218v1",
    "title": "Evaluating XGBoost for Balanced and Imbalanced Data: Application to Fraud Detection",
    "authors": [
      "Gissel Velarde",
      "Anindya Sudhir",
      "Sanjay Deshmane",
      "Anuj Deshmunkh",
      "Khushboo Sharma",
      "Vaibhav Joshi"
    ],
    "abstract": "This paper evaluates XGboost's performance given different dataset sizes and\nclass distributions, from perfectly balanced to highly imbalanced. XGBoost has\nbeen selected for evaluation, as it stands out in several benchmarks due to its\ndetection performance and speed. After introducing the problem of fraud\ndetection, the paper reviews evaluation metrics for detection systems or binary\nclassifiers, and illustrates with examples how different metrics work for\nbalanced and imbalanced datasets. Then, it examines the principles of XGBoost.\nIt proposes a pipeline for data preparation and compares a Vanilla XGBoost\nagainst a random search-tuned XGBoost. Random search fine-tuning provides\nconsistent improvement for large datasets of 100 thousand samples, not so for\nmedium and small datasets of 10 and 1 thousand samples, respectively. Besides,\nas expected, XGBoost recognition performance improves as more data is\navailable, and deteriorates detection performance as the datasets become more\nimbalanced. Tests on distributions with 50, 45, 25, and 5 percent positive\nsamples show that the largest drop in detection performance occurs for the\ndistribution with only 5 percent positive samples. Sampling to balance the\ntraining set does not provide consistent improvement. Therefore, future work\nwill include a systematic study of different techniques to deal with data\nimbalance and evaluating other approaches, including graphs, autoencoders, and\ngenerative adversarial methods, to deal with the lack of labels.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2023-03-27T13:59:22+00:00",
    "updated": "2023-03-27T13:59:22+00:00",
    "url": "http://arxiv.org/pdf/2303.15218v1"
  },
  {
    "id": "2306.06108v1",
    "title": "Demystifying Fraudulent Transactions and Illicit Nodes in the Bitcoin Network for Financial Forensics",
    "authors": [
      "Youssef Elmougy",
      "Ling Liu"
    ],
    "abstract": "Blockchain provides the unique and accountable channel for financial\nforensics by mining its open and immutable transaction data. A recent surge has\nbeen witnessed by training machine learning models with cryptocurrency\ntransaction data for anomaly detection, such as money laundering and other\nfraudulent activities. This paper presents a holistic applied data science\napproach to fraud detection in the Bitcoin network with two original\ncontributions. First, we contribute the Elliptic++ dataset, which extends the\nElliptic transaction dataset to include over 822k Bitcoin wallet addresses\n(nodes), each with 56 features, and 1.27M temporal interactions. This enables\nboth the detection of fraudulent transactions and the detection of illicit\naddresses (actors) in the Bitcoin network by leveraging four types of graph\ndata: (i) the transaction-to-transaction graph, representing the money flow in\nthe Bitcoin network, (ii) the address-to-address interaction graph, capturing\nthe types of transaction flows between Bitcoin addresses, (iii) the\naddress-transaction graph, representing the bi-directional money flow between\naddresses and transactions (BTC flow from input address to one or more\ntransactions and BTC flow from a transaction to one or more output addresses),\nand (iv) the user entity graph, capturing clusters of Bitcoin addresses\nrepresenting unique Bitcoin users. Second, we perform fraud detection tasks on\nall four graphs by using diverse machine learning algorithms. We show that\nadding enhanced features from the address-to-address and the\naddress-transaction graphs not only assists in effectively detecting both\nillicit transactions and illicit addresses, but also assists in gaining\nin-depth understanding of the root cause of money laundering vulnerabilities in\ncryptocurrency transactions and the strategies for fraud detection and\nprevention. Released at github.com/git-disl/EllipticPlusPlus.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2023-05-25T18:36:54+00:00",
    "updated": "2023-05-25T18:36:54+00:00",
    "url": "http://arxiv.org/pdf/2306.06108v1"
  },
  {
    "id": "2306.04643v2",
    "title": "Abnormal Trading Detection in the NFT Market",
    "authors": [
      "Mingxiao Song",
      "Yunsong Liu",
      "Agam Shah",
      "Sudheer Chava"
    ],
    "abstract": "The Non-Fungible-Token (NFT) market has experienced explosive growth in\nrecent years. According to DappRadar, the total transaction volume on OpenSea,\nthe largest NFT marketplace, reached 34.7 billion dollars in February 2023.\nHowever, the NFT market is mostly unregulated and there are significant\nconcerns about money laundering, fraud and wash trading. The lack of\nindustry-wide regulations, and the fact that amateur traders and retail\ninvestors comprise a significant fraction of the NFT market, make this market\nparticularly vulnerable to fraudulent activities. Therefore it is essential to\ninvestigate and highlight the relevant risks involved in NFT trading. In this\npaper, we attempted to uncover common fraudulent behaviors such as wash trading\nthat could mislead other traders. Using market data, we designed quantitative\nfeatures from the network, monetary, and temporal perspectives that were fed\ninto K-means clustering unsupervised learning algorithm to sort traders into\ngroups. Lastly, we discussed the clustering results' significance and how\nregulations can reduce undesired behaviors. Our work can potentially help\nregulators narrow down their search space for bad actors in the market as well\nas provide insights for amateur traders to protect themselves from unforeseen\nfrauds.",
    "categories": [
      "q-fin.TR",
      "cs.AI",
      "q-fin.CP"
    ],
    "published": "2023-05-25T15:12:14+00:00",
    "updated": "2023-08-02T18:25:35+00:00",
    "url": "http://arxiv.org/pdf/2306.04643v2"
  },
  {
    "id": "2305.15239v2",
    "title": "Deep Learning and Ethics",
    "authors": [
      "Travis LaCroix",
      "Simon J. D. Prince"
    ],
    "abstract": "This article appears as chapter 21 of Prince (2023, Understanding Deep\nLearning); a complete draft of the textbook is available here:\nhttp://udlbook.com. This chapter considers potential harms arising from the\ndesign and use of AI systems. These include algorithmic bias, lack of\nexplainability, data privacy violations, militarization, fraud, and\nenvironmental concerns. The aim is not to provide advice on being more ethical.\nInstead, the goal is to express ideas and start conversations in key areas that\nhave received attention in philosophy, political science, and the broader\nsocial sciences.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "published": "2023-05-24T15:24:19+00:00",
    "updated": "2023-06-20T15:50:48+00:00",
    "url": "http://arxiv.org/pdf/2305.15239v2"
  },
  {
    "id": "2305.14745v1",
    "title": "Applications of Machine Learning in Detecting Afghan Fake Banknotes",
    "authors": [
      "Hamida Ashna",
      "Ziaullah Momand"
    ],
    "abstract": "Fake currency, unauthorized imitation money lacking government approval,\nconstitutes a form of fraud. Particularly in Afghanistan, the prevalence of\nfake currency poses significant challenges and detrimentally impacts the\neconomy. While banks and commercial establishments employ authentication\nmachines, the public lacks access to such systems, necessitating a program that\ncan detect counterfeit banknotes accessible to all. This paper introduces a\nmethod using image processing to identify counterfeit Afghan banknotes by\nanalyzing specific security features. Extracting first and second order\nstatistical features from input images, the WEKA machine learning tool was\nemployed to construct models and perform classification with Random Forest,\nPART, and Na\\\"ive Bayes algorithms. The Random Forest algorithm achieved\nexceptional accuracy of 99% in detecting fake Afghan banknotes, indicating the\nefficacy of the proposed method as a solution for identifying counterfeit\ncurrency.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-05-24T05:39:46+00:00",
    "updated": "2023-05-24T05:39:46+00:00",
    "url": "http://arxiv.org/pdf/2305.14745v1"
  },
  {
    "id": "2305.18317v1",
    "title": "FOPPA: An Open Database of French Public Procurement Award Notices From 2010--2020",
    "authors": [
      "Lucas Potin",
      "Vincent Labatut",
      "Pierre-Henri Morand",
      "Christine Largeron"
    ],
    "abstract": "Public Procurement refers to governments' purchasing activities of goods,\nservices, and construction of public works. In the European Union (EU), it is\nan essential sector, corresponding to 15% of the GDP. EU public procurement\ngenerates large amounts of data, because award notices related to contracts\nexceeding a predefined threshold must be published on the TED (EU's official\njournal). Under the framework of the DeCoMaP project, which aims at leveraging\nsuch data in order to predict fraud in public procurement, we constitute the\nFOPPA (French Open Public Procurement Award notices) database. It contains the\ndescription of 1,380,965 lots obtained from the TED, covering the 2010--2020\nperiod for France. We detect a number of substantial issues in these data, and\npropose a set of automated and semi-automated methods to solve them and produce\na usable database. It can be leveraged to study public procurement in an\nacademic setting, but also to facilitate the monitoring of public policies, and\nto improve the quality of the data offered to buyers and suppliers.",
    "categories": [
      "cs.CY"
    ],
    "published": "2023-05-22T14:02:37+00:00",
    "updated": "2023-05-22T14:02:37+00:00",
    "url": "http://arxiv.org/pdf/2305.18317v1"
  },
  {
    "id": "2306.05359v2",
    "title": "Safeguarding Physical Sneaker Sale Through a Decentralized Medium",
    "authors": [
      "Marwan Zeggari",
      "Aydin Abadi",
      "Renaud Lambiotte",
      "Mohamad Kassab"
    ],
    "abstract": "Sneakers were designated as the most counterfeited fashion item online, with\nthree times more risk in a trade than any other fashion purchase. As the market\nexpands, the current sneaker scene displays several vulnerabilities and trust\nflaws, mostly related to the legitimacy of assets or actors. In this paper, we\ninvestigate various blockchain-based mechanisms to address these large-scale\ntrust issues. We argue that (i) pre-certified and tracked assets through the\nuse of non-fungible tokens can ensure the genuine nature of an asset and\nauthenticate its owner more effectively during peer-to-peer trading across a\nmarketplace; (ii) a game-theoretic-based system with economic incentives for\nparticipating users can greatly reduce the rate of online fraud and address\nmissed delivery deadlines; (iii) a decentralized dispute resolution system\nbiased in favour of an honest party can solve potential conflicts more\nreliably.",
    "categories": [
      "cs.CR",
      "cs.GT"
    ],
    "published": "2023-05-20T16:59:01+00:00",
    "updated": "2023-06-09T08:52:24+00:00",
    "url": "http://arxiv.org/pdf/2306.05359v2"
  },
  {
    "id": "2305.12188v1",
    "title": "Transparent and Traceable Food Supply Chain Management",
    "authors": [
      "Narayan Subramanian",
      "Atharva Joshi",
      "Daksh Bagga"
    ],
    "abstract": "The food supply chain has a number of challenges, including a lack of\ntransparency and disengagement among stakeholders. By providing a transparent\nand traceable digital ledger of transactions and movements for all supply chain\nactors, blockchain technology can provide a resolution to these problems. We\npropose a blockchain-based system for tracking a product's full path, from its\nraw components to the finished item in the store. Many advantages of the\noffered system include improved quality assessment, increased product\ntransparency and traceability, and sophisticated fraud detection capabilities.\nBy reinventing the way transactions are carried out and enabling stakeholders\nto obtain a complete record of each product's journey, the system has the\npotential to completely alter the food supply chain. Also, by minimising\ninefficiencies, waste, and fraudulent activities that have a negative influence\non the supply chain, the deployment of this system can remove limits imposed by\nthe current supply chain. Overall, the suggested blockchain-based system has\nthe potential to significantly increase the efficiency, transparency, and\ntraceability of the food supply chain.",
    "categories": [
      "cs.CR"
    ],
    "published": "2023-05-20T13:27:37+00:00",
    "updated": "2023-05-20T13:27:37+00:00",
    "url": "http://arxiv.org/pdf/2305.12188v1"
  },
  {
    "id": "2305.11684v1",
    "title": "Self-Reinforcement Attention Mechanism For Tabular Learning",
    "authors": [
      "Kodjo Mawuena Amekoe",
      "Mohamed Djallel Dilmi",
      "Hanene Azzag",
      "Mustapha Lebbah",
      "Zaineb Chelly Dagdia",
      "Gregoire Jaffre"
    ],
    "abstract": "Apart from the high accuracy of machine learning models, what interests many\nresearchers in real-life problems (e.g., fraud detection, credit scoring) is to\nfind hidden patterns in data; particularly when dealing with their challenging\nimbalanced characteristics. Interpretability is also a key requirement that\nneeds to accompany the used machine learning model. In this concern, often,\nintrinsically interpretable models are preferred to complex ones, which are in\nmost cases black-box models. Also, linear models are used in some high-risk\nfields to handle tabular data, even if performance must be sacrificed. In this\npaper, we introduce Self-Reinforcement Attention (SRA), a novel attention\nmechanism that provides a relevance of features as a weight vector which is\nused to learn an intelligible representation. This weight is then used to\nreinforce or reduce some components of the raw input through element-wise\nvector multiplication. Our results on synthetic and real-world imbalanced data\nshow that our proposed SRA block is effective in end-to-end combination with\nbaseline models.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-05-19T14:06:36+00:00",
    "updated": "2023-05-19T14:06:36+00:00",
    "url": "http://arxiv.org/pdf/2305.11684v1"
  },
  {
    "id": "2305.11377v2",
    "title": "GraphFC: Customs Fraud Detection with Label Scarcity",
    "authors": [
      "Karandeep Singh",
      "Yu-Che Tsai",
      "Cheng-Te Li",
      "Meeyoung Cha",
      "Shou-De Lin"
    ],
    "abstract": "Custom officials across the world encounter huge volumes of transactions.\nWith increased connectivity and globalization, the customs transactions\ncontinue to grow every year. Associated with customs transactions is the\ncustoms fraud - the intentional manipulation of goods declarations to avoid the\ntaxes and duties. With limited manpower, the custom offices can only undertake\nmanual inspection of a limited number of declarations. This necessitates the\nneed for automating the customs fraud detection by machine learning (ML)\ntechniques. Due the limited manual inspection for labeling the new-incoming\ndeclarations, the ML approach should have robust performance subject to the\nscarcity of labeled data. However, current approaches for customs fraud\ndetection are not well suited and designed for this real-world setting. In this\nwork, we propose $\\textbf{GraphFC}$ ($\\textbf{Graph}$ neural networks for\n$\\textbf{C}$ustoms $\\textbf{F}$raud), a model-agnostic, domain-specific,\nsemi-supervised graph neural network based customs fraud detection algorithm\nthat has strong semi-supervised and inductive capabilities. With upto 252%\nrelative increase in recall over the present state-of-the-art, extensive\nexperimentation on real customs data from customs administrations of three\ndifferent countries demonstrate that GraphFC consistently outperforms various\nbaselines and the present state-of-art by a large margin.",
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "published": "2023-05-19T01:47:12+00:00",
    "updated": "2023-08-19T13:30:48+00:00",
    "url": "http://arxiv.org/pdf/2305.11377v2"
  },
  {
    "id": "2305.11236v1",
    "title": "Efficient Vertical Federated Learning with Secure Aggregation",
    "authors": [
      "Xinchi Qiu",
      "Heng Pan",
      "Wanru Zhao",
      "Chenyang Ma",
      "Pedro Porto Buarque de Gusmão",
      "Nicholas D. Lane"
    ],
    "abstract": "The majority of work in privacy-preserving federated learning (FL) has been\nfocusing on horizontally partitioned datasets where clients share the same sets\nof features and can train complete models independently. However, in many\ninteresting problems, such as financial fraud detection and disease detection,\nindividual data points are scattered across different clients/organizations in\nvertical federated learning. Solutions for this type of FL require the exchange\nof gradients between participants and rarely consider privacy and security\nconcerns, posing a potential risk of privacy leakage. In this work, we present\na novel design for training vertical FL securely and efficiently using\nstate-of-the-art security modules for secure aggregation. We demonstrate\nempirically that our method does not impact training performance whilst\nobtaining 9.1e2 ~3.8e4 speedup compared to homomorphic encryption (HE).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2023-05-18T18:08:36+00:00",
    "updated": "2023-05-18T18:08:36+00:00",
    "url": "http://arxiv.org/pdf/2305.11236v1"
  },
  {
    "id": "2305.10668v2",
    "title": "MetaGAD: Meta Representation Adaptation for Few-Shot Graph Anomaly Detection",
    "authors": [
      "Xiongxiao Xu",
      "Kaize Ding",
      "Canyu Chen",
      "Kai Shu"
    ],
    "abstract": "Graph anomaly detection has long been an important problem in various domains\npertaining to information security such as financial fraud, social spam and\nnetwork intrusion. The majority of existing methods are performed in an\nunsupervised manner, as labeled anomalies in a large scale are often too\nexpensive to acquire. However, the identified anomalies may turn out to be\nuninteresting data instances due to the lack of prior knowledge. In real-world\nscenarios, it is often feasible to obtain limited labeled anomalies, which have\ngreat potential to advance graph anomaly detection. However, the work exploring\nlimited labeled anomalies and a large amount of unlabeled nodes in graphs to\ndetect anomalies is relatively limited. Therefore, in this paper, we study an\nimportant problem of few-shot graph anomaly detection. Nonetheless, it is\nchallenging to fully leverage the information of few-shot anomalous nodes due\nto the irregularity of anomalies and the overfitting issue in the few-shot\nlearning. To tackle the above challenges, we propose a novel meta-learning\nbased framework, MetaGAD, that learns to adapt the knowledge from\nself-supervised learning to few-shot supervised learning for graph anomaly\ndetection. In specific, we formulate the problem as a bi-level optimization,\nensuring MetaGAD converging to minimizing the validation loss, thus enhancing\nthe generalization capacity. The comprehensive experiments on six real-world\ndatasets with synthetic anomalies and \"organic\" anomalies (available in the\ndatasets) demonstrate the effectiveness of MetaGAD in detecting anomalies with\nfew-shot anomalies. The code is available at\nhttps://github.com/XiongxiaoXu/MetaGAD.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.SI"
    ],
    "published": "2023-05-18T03:04:51+00:00",
    "updated": "2024-08-23T19:31:31+00:00",
    "url": "http://arxiv.org/pdf/2305.10668v2"
  },
  {
    "id": "2306.07972v1",
    "title": "Leveraging Machine Learning for Multichain DeFi Fraud Detection",
    "authors": [
      "Georgios Palaiokrassas",
      "Sandro Scherrers",
      "Iason Ofeidis",
      "Leandros Tassiulas"
    ],
    "abstract": "Since the inception of permissionless blockchains with Bitcoin in 2008, it\nbecame apparent that their most well-suited use case is related to making the\nfinancial system and its advantages available to everyone seamlessly without\ndepending on any trusted intermediaries. Smart contracts across chains provide\nan ecosystem of decentralized finance (DeFi), where users can interact with\nlending pools, Automated Market Maker (AMM) exchanges, stablecoins,\nderivatives, etc. with a cumulative locked value which had exceeded 160B USD.\nWhile DeFi comes with high rewards, it also carries plenty of risks. Many\nfinancial crimes have occurred over the years making the early detection of\nmalicious activity an issue of high priority. The proposed framework introduces\nan effective method for extracting a set of features from different chains,\nincluding the largest one, Ethereum and it is evaluated over an extensive\ndataset we gathered with the transactions of the most widely used DeFi\nprotocols (23 in total, including Aave, Compound, Curve, Lido, and Yearn) based\non a novel dataset in collaboration with Covalent. Different Machine Learning\nmethods were employed, such as XGBoost and a Neural Network for identifying\nfraud accounts detection interacting with DeFi and we demonstrate that the\nintroduction of novel DeFi-related features, significantly improves the\nevaluation results, where Accuracy, Precision, Recall, F1-score and F2-score\nwhere utilized.",
    "categories": [
      "q-fin.GN",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2023-05-17T15:48:21+00:00",
    "updated": "2023-05-17T15:48:21+00:00",
    "url": "http://arxiv.org/pdf/2306.07972v1"
  },
  {
    "id": "2305.09907v2",
    "title": "Incremental Outlier Detection Modelling Using Streaming Analytics in Finance & Health Care",
    "authors": [
      "Vivek Yelleti",
      "Ch Priyanka"
    ],
    "abstract": "In the era of real-time data, traditional methods often struggle to keep pace\nwith the dynamic nature of streaming environments. In this paper, we proposed a\nhybrid framework where in (i) stage-I follows a traditional approach where the\nmodel is built once and evaluated in a real-time environment, and (ii) stage-II\nemploys an incremental learning approach where the model is continuously\nretrained as new data arrives, enabling it to adapt and stay up to date. To\nimplement these frameworks, we employed 8 distinct state-of-the-art outlier\ndetection models, including one-class support vector machine (OCSVM), isolation\nforest adaptive sliding window approach (IForest ASD), exact storm (ES),\nangle-based outlier detection (ABOD), local outlier factor (LOF), Kitsunes\nonline algorithm (KitNet), and K-nearest neighbour conformal density and\ndistance based (KNN CAD). We evaluated the performance of these models across\nseven financial and healthcare prediction tasks, including credit card fraud\ndetection, churn prediction, Ethereum fraud detection, heart stroke prediction,\nand diabetes prediction. The results indicate that our proposed incremental\nlearning framework significantly improves performance, particularly on highly\nimbalanced datasets. Among all models, the IForest ASD model consistently\nranked among the top three best-performing models, demonstrating superior\neffectiveness across various datasets.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-05-17T02:30:28+00:00",
    "updated": "2025-04-04T09:52:35+00:00",
    "url": "http://arxiv.org/pdf/2305.09907v2"
  },
  {
    "id": "2305.06424v4",
    "title": "Bot or Human? Detecting ChatGPT Imposters with A Single Question",
    "authors": [
      "Hong Wang",
      "Xuan Luo",
      "Weizhi Wang",
      "Xifeng Yan"
    ],
    "abstract": "Large language models (LLMs) like GPT-4 have recently demonstrated impressive\ncapabilities in natural language understanding and generation. However, there\nis a concern that they can be misused for malicious purposes, such as fraud or\ndenial-of-service attacks. Therefore, it is crucial to develop methods for\ndetecting whether the party involved in a conversation is a bot or a human. In\nthis paper, we propose a framework named FLAIR, Finding Large Language Model\nAuthenticity via a Single Inquiry and Response, to detect conversational bots\nin an online manner. Specifically, we target a single question scenario that\ncan effectively differentiate human users from bots. The questions are divided\ninto two categories: those that are easy for humans but difficult for bots\n(e.g., counting, substitution, searching, and ASCII art reasoning), and those\nthat are easy for bots but difficult for humans (e.g., memorization and\ncomputation). Our approach shows different strengths of these questions in\ntheir effectiveness, providing a new way for online service providers to\nprotect themselves against nefarious activities. Our code and question set are\navailable at https://github.com/hongwang600/FLAIR.",
    "categories": [
      "cs.CL"
    ],
    "published": "2023-05-10T19:09:24+00:00",
    "updated": "2024-08-11T18:56:50+00:00",
    "url": "http://arxiv.org/pdf/2305.06424v4"
  },
  {
    "id": "2305.07452v1",
    "title": "Implementation of High Availability Message ISO 8583 using F5 Active-Passive Failover Method",
    "authors": [
      "Bahrul Ilham",
      "Yanto Setiawan"
    ],
    "abstract": "In this research, the system was designed to solve problems related to High\nAvailability on FDS (Fraud Detection System) servers that cannot be loaded\nbalanced using the Round Robin method, resulting in changes to ISO 8583\nmessages. As a result, a method that can be used as High availability to\nmaintain the Availability of the FDS Server without changing the message\nreceived is required. High availability will be achieved through the Active\nPassive Failover method, which will transfer data flows in the event of an\noperational failure on the FDS server. The transfer is based on CPU Load\nparameters and ISO 8583 messages, which are checked at each stage. The\nwaterfall method was used in this research. The waterfall is a straightforward\nclassic model with a linear system flow, with the output of each stage serving\nas the input for the next. The primary goals of this research are to ensure\nthat data in ISO 8583 format can be streamed without changing messages, to\nmeasure the effectiveness of the Active Passive Failover method in performing\nHigh availability using ISO 8583 message parameters and CPU Load, and to\nincrease the level of Availability and reliability of the FDS Server. This\nresearch's error rate decreased by 0.83%, and the SLA (Service Level Agreement)\nincreased from 99.13% to 99.96%.",
    "categories": [
      "cs.DC"
    ],
    "published": "2023-04-27T08:52:23+00:00",
    "updated": "2023-04-27T08:52:23+00:00",
    "url": "http://arxiv.org/pdf/2305.07452v1"
  },
  {
    "id": "2306.16424v3",
    "title": "Realistic Synthetic Financial Transactions for Anti-Money Laundering Models",
    "authors": [
      "Erik Altman",
      "Jovan Blanuša",
      "Luc von Niederhäusern",
      "Béni Egressy",
      "Andreea Anghel",
      "Kubilay Atasu"
    ],
    "abstract": "With the widespread digitization of finance and the increasing popularity of\ncryptocurrencies, the sophistication of fraud schemes devised by cybercriminals\nis growing. Money laundering -- the movement of illicit funds to conceal their\norigins -- can cross bank and national boundaries, producing complex\ntransaction patterns. The UN estimates 2-5\\% of global GDP or \\$0.8 - \\$2.0\ntrillion dollars are laundered globally each year. Unfortunately, real data to\ntrain machine learning models to detect laundering is generally not available,\nand previous synthetic data generators have had significant shortcomings. A\nrealistic, standardized, publicly-available benchmark is needed for comparing\nmodels and for the advancement of the area.\n  To this end, this paper contributes a synthetic financial transaction dataset\ngenerator and a set of synthetically generated AML (Anti-Money Laundering)\ndatasets. We have calibrated this agent-based generator to match real\ntransactions as closely as possible and made the datasets public. We describe\nthe generator in detail and demonstrate how the datasets generated can help\ncompare different machine learning models in terms of their AML abilities. In a\nkey way, using synthetic data in these comparisons can be even better than\nusing real data: the ground truth labels are complete, whilst many laundering\ntransactions in real data are never detected.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-fin.CP"
    ],
    "published": "2023-06-22T10:32:51+00:00",
    "updated": "2024-01-25T11:25:09+00:00",
    "url": "http://arxiv.org/pdf/2306.16424v3"
  },
  {
    "id": "2306.11297v1",
    "title": "Decentralized Quantum Federated Learning for Metaverse: Analysis, Design and Implementation",
    "authors": [
      "Dev Gurung",
      "Shiva Raj Pokhrel",
      "Gang Li"
    ],
    "abstract": "With the emerging developments of the Metaverse, a virtual world where people\ncan interact, socialize, play, and conduct their business, it has become\ncritical to ensure that the underlying systems are transparent, secure, and\ntrustworthy. To this end, we develop a decentralized and trustworthy quantum\nfederated learning (QFL) framework. The proposed QFL leverages the power of\nblockchain to create a secure and transparent system that is robust against\ncyberattacks and fraud. In addition, the decentralized QFL system addresses the\nrisks associated with a centralized server-based approach. With extensive\nexperiments and analysis, we evaluate classical federated learning (CFL) and\nQFL in a distributed setting and demonstrate the practicality and benefits of\nthe proposed design. Our theoretical analysis and discussions develop a\ngenuinely decentralized financial system essential for the Metaverse.\nFurthermore, we present the application of blockchain-based QFL in a hybrid\nmetaverse powered by a metaverse observer and world model. Our implementation\ndetails and code are publicly available 1.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-06-20T05:23:30+00:00",
    "updated": "2023-06-20T05:23:30+00:00",
    "url": "http://arxiv.org/pdf/2306.11297v1"
  },
  {
    "id": "2306.10857v1",
    "title": "Pattern Mining for Anomaly Detection in Graphs: Application to Fraud in Public Procurement",
    "authors": [
      "Lucas Potin",
      "Rosa Figueiredo",
      "Vincent Labatut",
      "Christine Largeron"
    ],
    "abstract": "In the context of public procurement, several indicators called red flags are\nused to estimate fraud risk. They are computed according to certain contract\nattributes and are therefore dependent on the proper filling of the contract\nand award notices. However, these attributes are very often missing in\npractice, which prohibits red flags computation. Traditional fraud detection\napproaches focus on tabular data only, considering each contract separately,\nand are therefore very sensitive to this issue. In this work, we adopt a\ngraph-based method allowing leveraging relations between contracts, to\ncompensate for the missing attributes. We propose PANG (Pattern-Based Anomaly\nDetection in Graphs), a general supervised framework relying on pattern\nextraction to detect anomalous graphs in a collection of attributed graphs.\nNotably, it is able to identify induced subgraphs, a type of pattern widely\noverlooked in the literature. When benchmarked on standard datasets, its\npredictive performance is on par with state-of-the-art methods, with the\nadditional advantage of being explainable. These experiments also reveal that\ninduced patterns are more discriminative on certain datasets. When applying\nPANG to public procurement data, the prediction is superior to other methods,\nand it identifies subgraph patterns that are characteristic of fraud-prone\nsituations, thereby making it possible to better understand fraudulent\nbehavior.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2023-06-19T11:18:55+00:00",
    "updated": "2023-06-19T11:18:55+00:00",
    "url": "http://arxiv.org/pdf/2306.10857v1"
  },
  {
    "id": "2306.10200v1",
    "title": "Privacy-Enhancing Technologies for Financial Data Sharing",
    "authors": [
      "Panagiotis Chatzigiannis",
      "Wanyun Catherine Gu",
      "Srinivasan Raghuraman",
      "Peter Rindal",
      "Mahdi Zamani"
    ],
    "abstract": "Today, financial institutions (FIs) store and share consumers' financial data\nfor various reasons such as offering loans, processing payments, and protecting\nagainst fraud and financial crime. Such sharing of sensitive data have been\nsubject to data breaches in the past decade.\n  While some regulations (e.g., GDPR, FCRA, and CCPA) help to prevent\ninstitutions from freely sharing clients' sensitive information, some\nregulations (e.g., BSA 1970) require FIs to share certain financial data with\ngovernment agencies to combat financial crime. This creates an inherent tension\nbetween the privacy and the integrity of financial transactions. In the past\ndecade, significant progress has been made in building efficient\nprivacy-enhancing technologies that allow computer systems and networks to\nvalidate encrypted data automatically.\n  In this paper, we investigate some of these technologies to identify the\nbenefits and limitations of each, in particular, for use in data sharing among\nFIs. As a case study, we look into the emerging area of Central Bank Digital\nCurrencies (CBDCs) and how privacy-enhancing technologies can be integrated\ninto the CBDC architecture. Our study, however, is not limited to CBDCs and can\nbe applied to other financial scenarios with tokenized bank deposits such as\ncross-border payments, real-time settlements, and card payments.",
    "categories": [
      "cs.CR"
    ],
    "published": "2023-06-16T22:35:08+00:00",
    "updated": "2023-06-16T22:35:08+00:00",
    "url": "http://arxiv.org/pdf/2306.10200v1"
  },
  {
    "id": "2306.09633v10",
    "title": "The False Dawn: Reevaluating Google's Reinforcement Learning for Chip Macro Placement",
    "authors": [
      "Igor L. Markov"
    ],
    "abstract": "Reinforcement learning (RL) for physical design of silicon chips in a Google\n2021 Nature paper stirred controversy due to poorly documented claims that\nraised eyebrows and drew critical media coverage. The paper withheld critical\nmethodology steps and most inputs needed to reproduce results. Our\nmeta-analysis shows how two separate evaluations filled in the gaps and\ndemonstrated that Google RL lags behind (i) human designers, (ii) a well-known\nalgorithm (Simulated Annealing), and (iii) generally-available commercial\nsoftware, while being slower; and in a 2023 open research contest, RL methods\nweren't in top 5. Crosschecked data indicate that the integrity of the Nature\npaper is substantially undermined owing to errors in conduct, analysis and\nreporting. Before publishing, Google rebuffed internal allegations of fraud,\nwhich still stand. We note policy implications and conclusions for chip design.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.CY"
    ],
    "published": "2023-06-16T05:32:24+00:00",
    "updated": "2024-09-28T08:20:55+00:00",
    "url": "http://arxiv.org/pdf/2306.09633v10"
  },
  {
    "id": "2307.01155v1",
    "title": "From Portfolio Optimization to Quantum Blockchain and Security: A Systematic Review of Quantum Computing in Finance",
    "authors": [
      "Abha Naik",
      "Esra Yeniaras",
      "Gerhard Hellstern",
      "Grishma Prasad",
      "Sanjay Kumar Lalta Prasad Vishwakarma"
    ],
    "abstract": "In this paper, we provide an overview of the recent work in the quantum\nfinance realm from various perspectives. The applications in consideration are\nPortfolio Optimization, Fraud Detection, and Monte Carlo methods for derivative\npricing and risk calculation. Furthermore, we give a comprehensive overview of\nthe applications of quantum computing in the field of blockchain technology\nwhich is a main concept in fintech. In that sense, we first introduce the\ngeneral overview of blockchain with its main cryptographic primitives such as\ndigital signature algorithms, hash functions, and random number generators as\nwell as the security vulnerabilities of blockchain technologies after the merge\nof quantum computers considering Shor's quantum factoring and Grover's quantum\nsearch algorithms. We then discuss the privacy preserving quantum-resistant\nblockchain systems via threshold signatures, ring signatures, and\nzero-knowledge proof systems i.e. ZK-SNARKs in quantum resistant blockchains.\nAfter emphasizing the difference between the quantum-resistant blockchain and\nquantum-safe blockchain we mention the security countermeasures to take against\nthe possible quantumized attacks aiming these systems. We finalize our\ndiscussion with quantum blockchain, efficient quantum mining and necessary\ninfrastructures for constructing such systems based on quantum computing. This\nreview has the intention to be a bridge to fill the gap between quantum\ncomputing and one of its most prominent application realms: Finance. We provide\nthe state-of-the-art results in the intersection of finance and quantum\ntechnology for both industrial practitioners and academicians.",
    "categories": [
      "cs.CR",
      "q-fin.CP",
      "quant-ph"
    ],
    "published": "2023-06-12T19:53:23+00:00",
    "updated": "2023-06-12T19:53:23+00:00",
    "url": "http://arxiv.org/pdf/2307.01155v1"
  },
  {
    "id": "2306.07011v1",
    "title": "Deepfake in the Metaverse: An Outlook Survey",
    "authors": [
      "Haojie Wu",
      "Pan Hui",
      "Pengyuan Zhou"
    ],
    "abstract": "We envision deepfake technologies, which synthesize realistic fake images and\nvideos, will play an important role in the future metaverse. While enhancing\nusers' immersion and experience with synthesized virtual characters and scenes,\ndeepfake can cause serious consequences if used for fraud, impersonation, and\ndissemination of fake information. In this paper, we introduce the principles,\napplications, and risks of deepfake technology, and propose some\ncountermeasures to help users and developers in the metaverse deal with the\nchallenges brought by deepfake technologies. Further, we provide an outlook on\nthe future development of deepfake in the metaverse.",
    "categories": [
      "cs.HC"
    ],
    "published": "2023-06-12T10:31:00+00:00",
    "updated": "2023-06-12T10:31:00+00:00",
    "url": "http://arxiv.org/pdf/2306.07011v1"
  },
  {
    "id": "2306.06198v2",
    "title": "Spoofing Against Spoofing: Towards Caller ID Verification In Heterogeneous Telecommunication Systems",
    "authors": [
      "Shen Wang",
      "Mahshid Delavar",
      "Muhammad Ajmal Azad",
      "Farshad Nabizadeh",
      "Steve Smith",
      "Feng Hao"
    ],
    "abstract": "Caller ID spoofing is a global industry problem and often acts as a critical\nenabler for telephone fraud. To address this problem, the Federal\nCommunications Commission (FCC) has mandated telecom providers in the US to\nimplement STIR/SHAKEN, an industry-driven solution based on digital signatures.\nSTIR/SHAKEN relies on a public key infrastructure (PKI) to manage digital\ncertificates, but scaling up this PKI for the global telecom industry is\nextremely difficult, if not impossible. Furthermore, it only works with\nIP-based systems (e.g., SIP), leaving the traditional non-IP systems (e.g.,\nSS7) unprotected. So far the alternatives to the STIR/SHAKEN have not been\nsufficiently studied. In this paper, we propose a PKI-free solution, called\nCaller ID Verification (CIV). CIV authenticates the caller ID based on a\nchallenge-response process instead of digital signatures, hence requiring no\nPKI. It supports both IP and non-IP systems. Perhaps counter-intuitively, we\nshow that number spoofing can be leveraged, in conjunction with Dual-Tone\nMulti-Frequency (DTMF), to efficiently implement the challenge-response\nprocess, i.e., using spoofing to fight against spoofing. We implement CIV for\nVoIP, cellular, and landline phones across heterogeneous networks (SS7/SIP) by\nonly updating the software on the user's phone. This is the first caller ID\nauthentication solution with working prototypes for all three types of\ntelephone systems in the current telecom architecture. Finally, we show how the\nimplementation of CIV can be optimized by integrating it into telecom clouds as\na service, which users may subscribe to.",
    "categories": [
      "cs.CR"
    ],
    "published": "2023-06-09T19:03:29+00:00",
    "updated": "2023-09-24T14:38:54+00:00",
    "url": "http://arxiv.org/pdf/2306.06198v2"
  },
  {
    "id": "2306.06139v1",
    "title": "WePaMaDM-Outlier Detection: Weighted Outlier Detection using Pattern Approaches for Mass Data Mining",
    "authors": [
      "Ravindrakumar Purohit",
      "Jai Prakash Verma",
      "Rachna Jain",
      "Madhuri Bhavsar"
    ],
    "abstract": "Weighted Outlier Detection is a method for identifying unusual or anomalous\ndata points in a dataset, which can be caused by various factors like human\nerror, fraud, or equipment malfunctions. Detecting outliers can reveal vital\ninformation about system faults, fraudulent activities, and patterns in the\ndata, assisting experts in addressing the root causes of these anomalies.\nHowever,creating a model of normal data patterns to identify outliers can be\nchallenging due to the nature of input data, labeled data availability, and\nspecific requirements of the problem. This article proposed the\nWePaMaDM-Outlier Detection with distinct mass data mining domain, demonstrating\nthat such techniques are domain-dependent and usually developed for specific\nproblem formulations. Nevertheless, similar domains can adapt solutions with\nmodifications. This work also investigates the significance of data modeling in\noutlier detection techniques in surveillance, fault detection, and trend\nanalysis, also referred to as novelty detection, a semisupervised task where\nthe algorithm learns to recognize abnormality while being taught the normal\nclass.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2023-06-09T07:00:00+00:00",
    "updated": "2023-06-09T07:00:00+00:00",
    "url": "http://arxiv.org/pdf/2306.06139v1"
  },
  {
    "id": "2306.04064v2",
    "title": "Transferable Adversarial Robustness for Categorical Data via Universal Robust Embeddings",
    "authors": [
      "Klim Kireev",
      "Maksym Andriushchenko",
      "Carmela Troncoso",
      "Nicolas Flammarion"
    ],
    "abstract": "Research on adversarial robustness is primarily focused on image and text\ndata. Yet, many scenarios in which lack of robustness can result in serious\nrisks, such as fraud detection, medical diagnosis, or recommender systems often\ndo not rely on images or text but instead on tabular data. Adversarial\nrobustness in tabular data poses two serious challenges. First, tabular\ndatasets often contain categorical features, and therefore cannot be tackled\ndirectly with existing optimization procedures. Second, in the tabular domain,\nalgorithms that are not based on deep networks are widely used and offer great\nperformance, but algorithms to enhance robustness are tailored to neural\nnetworks (e.g. adversarial training).\n  In this paper, we tackle both challenges. We present a method that allows us\nto train adversarially robust deep networks for tabular data and to transfer\nthis robustness to other classifiers via universal robust embeddings tailored\nto categorical data. These embeddings, created using a bilevel alternating\nminimization framework, can be transferred to boosted trees or random forests\nmaking them robust without the need for adversarial training while preserving\ntheir high accuracy on tabular data. We show that our methods outperform\nexisting techniques within a practical threat model suitable for tabular data.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-06-06T23:24:02+00:00",
    "updated": "2023-12-13T12:10:46+00:00",
    "url": "http://arxiv.org/pdf/2306.04064v2"
  },
  {
    "id": "2306.03502v2",
    "title": "Russo-Ukrainian War: Prediction and explanation of Twitter suspension",
    "authors": [
      "Alexander Shevtsov",
      "Despoina Antonakaki",
      "Ioannis Lamprou",
      "Ioannis Kontogiorgakis",
      "Polyvios Pratikakis",
      "Sotiris Ioannidis"
    ],
    "abstract": "On 24 February 2022, Russia invaded Ukraine, starting what is now known as\nthe Russo-Ukrainian War, initiating an online discourse on social media.\nTwitter as one of the most popular SNs, with an open and democratic character,\nenables a transparent discussion among its large user base. Unfortunately, this\noften leads to Twitter's policy violations, propaganda, abusive actions, civil\nintegrity violation, and consequently to user accounts' suspension and\ndeletion. This study focuses on the Twitter suspension mechanism and the\nanalysis of shared content and features of the user accounts that may lead to\nthis. Toward this goal, we have obtained a dataset containing 107.7M tweets,\noriginating from 9.8 million users, using Twitter API. We extract the\ncategories of shared content of the suspended accounts and explain their\ncharacteristics, through the extraction of text embeddings in junction with\ncosine similarity clustering. Our results reveal scam campaigns taking\nadvantage of trending topics regarding the Russia-Ukrainian conflict for\nBitcoin and Ethereum fraud, spam, and advertisement campaigns. Additionally, we\napply a machine learning methodology including a SHapley Additive\nexplainability model to understand and explain how user accounts get suspended.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2023-06-06T08:41:02+00:00",
    "updated": "2023-12-27T11:51:15+00:00",
    "url": "http://arxiv.org/pdf/2306.03502v2"
  },
  {
    "id": "2306.03356v1",
    "title": "Query Complexity of Active Learning for Function Family With Nearly Orthogonal Basis",
    "authors": [
      "Xiang Chen",
      "Zhao Song",
      "Baocheng Sun",
      "Junze Yin",
      "Danyang Zhuo"
    ],
    "abstract": "Many machine learning algorithms require large numbers of labeled data to\ndeliver state-of-the-art results. In applications such as medical diagnosis and\nfraud detection, though there is an abundance of unlabeled data, it is costly\nto label the data by experts, experiments, or simulations. Active learning\nalgorithms aim to reduce the number of required labeled data points while\npreserving performance. For many convex optimization problems such as linear\nregression and $p$-norm regression, there are theoretical bounds on the number\nof required labels to achieve a certain accuracy. We call this the query\ncomplexity of active learning. However, today's active learning algorithms\nrequire the underlying learned function to have an orthogonal basis. For\nexample, when applying active learning to linear regression, the requirement is\nthe target function is a linear composition of a set of orthogonal linear\nfunctions, and active learning can find the coefficients of these linear\nfunctions. We present a theoretical result to show that active learning does\nnot need an orthogonal basis but rather only requires a nearly orthogonal\nbasis. We provide the corresponding theoretical proofs for the function family\nof nearly orthogonal basis, and its applications associated with the\nalgorithmically efficient active learning framework.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-06-06T02:14:20+00:00",
    "updated": "2023-06-06T02:14:20+00:00",
    "url": "http://arxiv.org/pdf/2306.03356v1"
  },
  {
    "id": "2306.02543v1",
    "title": "Addressing Budget Allocation and Revenue Allocation in Data Market Environments Using an Adaptive Sampling Algorithm",
    "authors": [
      "Boxin Zhao",
      "Boxiang Lyu",
      "Raul Castro Fernandez",
      "Mladen Kolar"
    ],
    "abstract": "High-quality machine learning models are dependent on access to high-quality\ntraining data. When the data are not already available, it is tedious and\ncostly to obtain them. Data markets help with identifying valuable training\ndata: model consumers pay to train a model, the market uses that budget to\nidentify data and train the model (the budget allocation problem), and finally\nthe market compensates data providers according to their data contribution\n(revenue allocation problem). For example, a bank could pay the data market to\naccess data from other financial institutions to train a fraud detection model.\nCompensating data contributors requires understanding data's contribution to\nthe model; recent efforts to solve this revenue allocation problem based on the\nShapley value are inefficient to lead to practical data markets.\n  In this paper, we introduce a new algorithm to solve budget allocation and\nrevenue allocation problems simultaneously in linear time. The new algorithm\nemploys an adaptive sampling process that selects data from those providers who\nare contributing the most to the model. Better data means that the algorithm\naccesses those providers more often, and more frequent accesses corresponds to\nhigher compensation. Furthermore, the algorithm can be deployed in both\ncentralized and federated scenarios, boosting its applicability. We provide\ntheoretical guarantees for the algorithm that show the budget is used\nefficiently and the properties of revenue allocation are similar to Shapley's.\nFinally, we conduct an empirical evaluation to show the performance of the\nalgorithm in practical scenarios and when compared to other baselines. Overall,\nwe believe that the new algorithm paves the way for the implementation of\npractical data markets.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-06-05T02:28:19+00:00",
    "updated": "2023-06-05T02:28:19+00:00",
    "url": "http://arxiv.org/pdf/2306.02543v1"
  },
  {
    "id": "2306.02487v1",
    "title": "Discussion Paper: The Threat of Real Time Deepfakes",
    "authors": [
      "Guy Frankovits",
      "Yisroel Mirsky"
    ],
    "abstract": "Generative deep learning models are able to create realistic audio and video.\nThis technology has been used to impersonate the faces and voices of\nindividuals. These ``deepfakes'' are being used to spread misinformation,\nenable scams, perform fraud, and blackmail the innocent. The technology\ncontinues to advance and today attackers have the ability to generate deepfakes\nin real-time. This new capability poses a significant threat to society as\nattackers begin to exploit the technology in advances social engineering\nattacks. In this paper, we discuss the implications of this emerging threat,\nidentify the challenges with preventing these attacks and suggest a better\ndirection for researching stronger defences.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "published": "2023-06-04T21:40:11+00:00",
    "updated": "2023-06-04T21:40:11+00:00",
    "url": "http://arxiv.org/pdf/2306.02487v1"
  },
  {
    "id": "2306.02473v1",
    "title": "Anomaly Detection Techniques in Smart Grid Systems: A Review",
    "authors": [
      "Shampa Banik",
      "Sohag Kumar Saha",
      "Trapa Banik",
      "S M Mostaq Hossain"
    ],
    "abstract": "Smart grid data can be evaluated for anomaly detection in numerous fields,\nincluding cyber-security, fault detection, electricity theft, etc. The strange\nanomalous behaviors may have been caused by various reasons, including peculiar\nconsumption patterns of the consumers, malfunctioning grid infrastructures,\noutages, external cyber-attacks, or energy fraud. Recently, anomaly detection\nof the smart grid has attracted a large amount of interest from researchers,\nand it is widely applied in a number of high-impact fields. One of the most\nsignificant challenges within the smart grid is the implementation of efficient\nanomaly detection for multiple forms of aberrant behaviors. In this paper, we\nprovide a scoping review of research from the recent advancements in anomaly\ndetection in the context of smart grids. We categorize our study from numerous\naspects for deep understanding and inspection of the research challenges so\nfar. Finally, after analyzing the gap in the reviewed paper, the direction for\nfuture research on anomaly detection in smart-grid systems has been provided\nbriefly.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2023-06-04T20:45:14+00:00",
    "updated": "2023-06-04T20:45:14+00:00",
    "url": "http://arxiv.org/pdf/2306.02473v1"
  },
  {
    "id": "2306.02025v1",
    "title": "Exploring Global and Local Information for Anomaly Detection with Normal Samples",
    "authors": [
      "Fan Xu",
      "Nan Wang",
      "Xibin Zhao"
    ],
    "abstract": "Anomaly detection aims to detect data that do not conform to regular\npatterns, and such data is also called outliers. The anomalies to be detected\nare often tiny in proportion, containing crucial information, and are suitable\nfor application scenes like intrusion detection, fraud detection, fault\ndiagnosis, e-commerce platforms, et al. However, in many realistic scenarios,\nonly the samples following normal behavior are observed, while we can hardly\nobtain any anomaly information. To address such problem, we propose an anomaly\ndetection method GALDetector which is combined of global and local information\nbased on observed normal samples. The proposed method can be divided into a\nthree-stage method. Firstly, the global similar normal scores and the local\nsparsity scores of unlabeled samples are computed separately. Secondly,\npotential anomaly samples are separated from the unlabeled samples\ncorresponding to these two scores and corresponding weights are assigned to the\nselected samples. Finally, a weighted anomaly detector is trained by loads of\nsamples, then the detector is utilized to identify else anomalies. To evaluate\nthe effectiveness of the proposed method, we conducted experiments on three\ncategories of real-world datasets from diverse domains, and experimental\nresults show that our method achieves better performance when compared with\nother state-of-the-art methods.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-06-03T06:51:22+00:00",
    "updated": "2023-06-03T06:51:22+00:00",
    "url": "http://arxiv.org/pdf/2306.02025v1"
  },
  {
    "id": "2306.01951v8",
    "title": "GAD-NR: Graph Anomaly Detection via Neighborhood Reconstruction",
    "authors": [
      "Amit Roy",
      "Juan Shu",
      "Jia Li",
      "Carl Yang",
      "Olivier Elshocht",
      "Jeroen Smeets",
      "Pan Li"
    ],
    "abstract": "Graph Anomaly Detection (GAD) is a technique used to identify abnormal nodes\nwithin graphs, finding applications in network security, fraud detection,\nsocial media spam detection, and various other domains. A common method for GAD\nis Graph Auto-Encoders (GAEs), which encode graph data into node\nrepresentations and identify anomalies by assessing the reconstruction quality\nof the graphs based on these representations. However, existing GAE models are\nprimarily optimized for direct link reconstruction, resulting in nodes\nconnected in the graph being clustered in the latent space. As a result, they\nexcel at detecting cluster-type structural anomalies but struggle with more\ncomplex structural anomalies that do not conform to clusters. To address this\nlimitation, we propose a novel solution called GAD-NR, a new variant of GAE\nthat incorporates neighborhood reconstruction for graph anomaly detection.\nGAD-NR aims to reconstruct the entire neighborhood of a node, encompassing the\nlocal structure, self-attributes, and neighbor attributes, based on the\ncorresponding node representation. By comparing the neighborhood reconstruction\nloss between anomalous nodes and normal nodes, GAD-NR can effectively detect\nany anomalies. Extensive experimentation conducted on six real-world datasets\nvalidates the effectiveness of GAD-NR, showcasing significant improvements (by\nup to 30% in AUC) over state-of-the-art competitors. The source code for GAD-NR\nis openly available. Importantly, the comparative analysis reveals that the\nexisting methods perform well only in detecting one or two types of anomalies\nout of the three types studied. In contrast, GAD-NR excels at detecting all\nthree types of anomalies across the datasets, demonstrating its comprehensive\nanomaly detection capabilities.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-06-02T23:23:34+00:00",
    "updated": "2025-01-25T13:23:49+00:00",
    "url": "http://arxiv.org/pdf/2306.01951v8"
  },
  {
    "id": "2306.00893v3",
    "title": "Efficient Temporal Butterfly Counting and Enumeration on Temporal Bipartite Graphs",
    "authors": [
      "Xinwei Cai",
      "Xiangyu Ke",
      "Kai Wang",
      "Lu Chen",
      "Tianming Zhang",
      "Qing Liu",
      "Yunjun Gao"
    ],
    "abstract": "Bipartite graphs characterize relationships between two different sets of\nentities, like actor-movie, user-item, and author-paper. The butterfly, a\n4-vertices 4-edges (2,2)-biclique, is the simplest cohesive motif in a\nbipartite graph and is the fundamental component of higher-order substructures.\nCounting and enumerating the butterflies offer significant benefits across\nvarious applications, including fraud detection, graph embedding, and community\nsearch. While the corresponding motif, the triangle, in the unipartite graphs\nhas been widely studied in both static and temporal settings, the extension of\nbutterfly to temporal bipartite graphs remains unexplored. In this paper, we\ninvestigate the temporal butterfly counting and enumeration problem: count and\nenumerate the butterflies whose edges establish following a certain order\nwithin a given duration. Towards efficient computation, we devise a non-trivial\nbaseline rooted in the state-of-the-art butterfly counting algorithm on static\ngraphs, further, explore the intrinsic property of the temporal butterfly, and\ndevelop a new optimization framework with a compact data structure and\neffective priority strategy. The time complexity is proved to be significantly\nreduced without compromising on space efficiency. In addition, we generalize\nour algorithms to practical streaming settings and multi-core computing\narchitectures. Our extensive experiments on 11 large-scale real-world datasets\ndemonstrate the efficiency and scalability of our solutions.",
    "categories": [
      "cs.DS"
    ],
    "published": "2023-06-01T16:50:48+00:00",
    "updated": "2024-01-08T13:22:57+00:00",
    "url": "http://arxiv.org/pdf/2306.00893v3"
  },
  {
    "id": "2306.00869v2",
    "title": "Blockchain-based Decentralized Co-governance: Innovations and Solutions for Sustainable Crowdfunding",
    "authors": [
      "Bingyou Chen",
      "Yu Luo",
      "Jieni Li",
      "Yujian Li",
      "Ying Liu",
      "Fan Yang",
      "Junge Bo",
      "Yanan Qiao"
    ],
    "abstract": "This thesis provides an in-depth exploration of the Decentralized\nCo-governance Crowdfunding (DCC) Ecosystem, a novel solution addressing\nprevailing challenges in conventional crowdfunding methods faced by MSMEs and\ninnovative projects. Among the problems it seeks to mitigate are high\ntransaction costs, lack of transparency, fraud, and inefficient resource\nallocation. Leveraging a comprehensive review of the existing literature on\ncrowdfunding economic activities and blockchain's impact on organizational\ngovernance, we propose a transformative socio-economic model based on digital\ntokens and decentralized co-governance. This ecosystem is marked by a\ntripartite community structure - the Labor, Capital, and Governance communities\n- each contributing uniquely to the ecosystem's operation. Our research unfolds\nthe evolution of the DCC ecosystem through distinct phases, offering a novel\nunderstanding of socioeconomic dynamics in a decentralized digital world. It\nalso delves into the intricate governance mechanism of the ecosystem, ensuring\nintegrity, fairness, and a balanced distribution of value and wealth.",
    "categories": [
      "cs.CY",
      "econ.GN",
      "q-fin.EC"
    ],
    "published": "2023-06-01T16:26:35+00:00",
    "updated": "2023-06-02T12:03:38+00:00",
    "url": "http://arxiv.org/pdf/2306.00869v2"
  },
  {
    "id": "2306.01008v1",
    "title": "Credit Card Fraud Detection Using Asexual Reproduction Optimization",
    "authors": [
      "Anahita Farhang Ghahfarokhi",
      "Taha Mansouri",
      "Mohammad Reza Sadeghi Moghadam",
      "Nila Bahrambeik",
      "Ramin Yavari",
      "Mohammadreza Fani Sani"
    ],
    "abstract": "As the number of credit card users has increased, detecting fraud in this\ndomain has become a vital issue. Previous literature has applied various\nsupervised and unsupervised machine learning methods to find an effective fraud\ndetection system. However, some of these methods require an enormous amount of\ntime to achieve reasonable accuracy. In this paper, an Asexual Reproduction\nOptimization (ARO) approach was employed, which is a supervised method to\ndetect credit card fraud. ARO refers to a kind of production in which one\nparent produces some offspring. By applying this method and sampling just from\nthe majority class, the effectiveness of the classification is increased. A\ncomparison to Artificial Immune Systems (AIS), which is one of the best methods\nimplemented on current datasets, has shown that the proposed method is able to\nremarkably reduce the required training time and at the same time increase the\nrecall that is important in fraud detection problems. The obtained results show\nthat ARO achieves the best cost in a short time, and consequently, it can be\nconsidered a real-time fraud detection system.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "published": "2023-05-31T19:32:38+00:00",
    "updated": "2023-05-31T19:32:38+00:00",
    "url": "http://arxiv.org/pdf/2306.01008v1"
  },
  {
    "id": "2305.19168v2",
    "title": "Forensic analysis of the Turkey 2023 presidential election reveals extreme vote swings in remote areas",
    "authors": [
      "Peter Klimek",
      "Ahmet Aykac",
      "Stefan Thurner"
    ],
    "abstract": "Concerns about the integrity of Turkey's elections have increased with the\nrecent transition from a parliamentary democracy to an executive presidency\nunder Recep Tayyip Erdogan. Election forensics tools are used to identify\nstatistical traces of certain types of electoral fraud, providing important\ninformation about the integrity and validity of democratic elections. Such\nanalyses of the 2017 and 2018 Turkish elections revealed that malpractices such\nas ballot stuffing or voter manipulation may indeed have played a significant\nrole in determining the election results. Here, we apply election forensic\nstatistical tests for ballot stuffing and voter manipulation to the results of\nthe 2023 presidential election in Turkey. We find that both rounds of the 2023\npresidential election exhibit similar statistical irregularities to those\nobserved in the 2018 presidential election, however the magnitude of these\ndistortions has decreased. We estimate that 2.4% (SD 1.9%) and 1.9% (SD 1.7%)\nof electoral units may have been affected by ballot stuffing practices in\nfavour of Erdogan in the first and second rounds, respectively, compared to\n8.5% (SD 3.9%) in 2018. Areas with smaller polling stations and fewer ballot\nboxes had significantly inflated votes and turnout, again, in favor of Erdogan.\nFurthermore, electoral districts with two or fewer ballot boxes were more\nlikely to show large swings in vote shares in favour of Erdogan from the first\nto the second round. Based on a statistical model, we estimate that these\nswings translate into 342,000 excess votes (SD 4,900) or 0.64% for Erdogan. Our\nresults suggest that Turkish elections continue to be riddled with statistical\nirregularities, that may be indicative of electoral fraud.",
    "categories": [
      "stat.AP"
    ],
    "published": "2023-05-30T16:14:56+00:00",
    "updated": "2023-06-25T09:19:08+00:00",
    "url": "http://arxiv.org/pdf/2305.19168v2"
  },
  {
    "id": "2305.17339v1",
    "title": "Counterfactual Evaluation of Peer-Review Assignment Policies",
    "authors": [
      "Martin Saveski",
      "Steven Jecmen",
      "Nihar B. Shah",
      "Johan Ugander"
    ],
    "abstract": "Peer review assignment algorithms aim to match research papers to suitable\nexpert reviewers, working to maximize the quality of the resulting reviews. A\nkey challenge in designing effective assignment policies is evaluating how\nchanges to the assignment algorithm map to changes in review quality. In this\nwork, we leverage recently proposed policies that introduce randomness in\npeer-review assignment--in order to mitigate fraud--as a valuable opportunity\nto evaluate counterfactual assignment policies. Specifically, we exploit how\nsuch randomized assignments provide a positive probability of observing the\nreviews of many assignment policies of interest. To address challenges in\napplying standard off-policy evaluation methods, such as violations of\npositivity, we introduce novel methods for partial identification based on\nmonotonicity and Lipschitz smoothness assumptions for the mapping between\nreviewer-paper covariates and outcomes. We apply our methods to peer-review\ndata from two computer science venues: the TPDP'21 workshop (95 papers and 35\nreviewers) and the AAAI'22 conference (8,450 papers and 3,145 reviewers). We\nconsider estimates of (i) the effect on review quality when changing weights in\nthe assignment algorithm, e.g., weighting reviewers' bids vs. textual\nsimilarity (between the review's past papers and the submission), and (ii) the\n\"cost of randomization\", capturing the difference in expected quality between\nthe perturbed and unperturbed optimal match. We find that placing higher weight\non text similarity results in higher review quality and that introducing\nrandomization in the reviewer-paper assignment only marginally reduces the\nreview quality. Our methods for partial identification may be of independent\ninterest, while our off-policy approach can likely find use evaluating a broad\nclass of algorithmic matching systems.",
    "categories": [
      "cs.IR",
      "cs.DL",
      "stat.AP"
    ],
    "published": "2023-05-27T02:40:45+00:00",
    "updated": "2023-05-27T02:40:45+00:00",
    "url": "http://arxiv.org/pdf/2305.17339v1"
  },
  {
    "id": "2308.02424v1",
    "title": "Implementing Smart Contracts: The case of NFT-rental with pay-per-like",
    "authors": [
      "Alfred Sopi",
      "Johannes Schneider",
      "Jan vom Brocke"
    ],
    "abstract": "Non-fungible tokens(NFTs) are on the rise. They can represent artworks\nexhibited for marketing purposes on webpages of companies or online stores --\nanalogously to physical artworks. Lending of NFTs is an attractive form of\npassive income for owners but comes with risks (e.g., items are not returned)\nand costs for escrow agents. Similarly, renters have difficulties in\nanticipating the impact of artworks, e.g., how spectators of NFTs perceive\nthem. To address these challenges, we introduce an NFT rental solution based on\na pay-per-like pricing model using blockchain technology, i.e., smart contracts\nbased on the Ethereum chain. We find that blockchain solutions enjoy many\nadvantages also reported for other applications, but interestingly, we also\nobserve dark sides of (large) blockchain fees. Blockchain solutions appear\nunfair to niche artists and potentially hamper cultural diversity. Furthermore,\na trust-cost tradeoff arises to handle fraud caused by manipulation from\nparties outside the blockchain. All code for the solution is publicly available\nat: https://github.com/asopi/rental-project",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.DC"
    ],
    "published": "2023-07-23T18:31:31+00:00",
    "updated": "2023-07-23T18:31:31+00:00",
    "url": "http://arxiv.org/pdf/2308.02424v1"
  },
  {
    "id": "2308.00065v1",
    "title": "FinPT: Financial Risk Prediction with Profile Tuning on Pretrained Foundation Models",
    "authors": [
      "Yuwei Yin",
      "Yazheng Yang",
      "Jian Yang",
      "Qi Liu"
    ],
    "abstract": "Financial risk prediction plays a crucial role in the financial sector.\nMachine learning methods have been widely applied for automatically detecting\npotential risks and thus saving the cost of labor. However, the development in\nthis field is lagging behind in recent years by the following two facts: 1) the\nalgorithms used are somewhat outdated, especially in the context of the fast\nadvance of generative AI and large language models (LLMs); 2) the lack of a\nunified and open-sourced financial benchmark has impeded the related research\nfor years. To tackle these issues, we propose FinPT and FinBench: the former is\na novel approach for financial risk prediction that conduct Profile Tuning on\nlarge pretrained foundation models, and the latter is a set of high-quality\ndatasets on financial risks such as default, fraud, and churn. In FinPT, we\nfill the financial tabular data into the pre-defined instruction template,\nobtain natural-language customer profiles by prompting LLMs, and fine-tune\nlarge foundation models with the profile text to make predictions. We\ndemonstrate the effectiveness of the proposed FinPT by experimenting with a\nrange of representative strong baselines on FinBench. The analytical studies\nfurther deepen the understanding of LLMs for financial risk prediction.",
    "categories": [
      "q-fin.RM",
      "cs.CE",
      "cs.CL",
      "cs.LG",
      "q-fin.ST"
    ],
    "published": "2023-07-22T09:27:05+00:00",
    "updated": "2023-07-22T09:27:05+00:00",
    "url": "http://arxiv.org/pdf/2308.00065v1"
  },
  {
    "id": "2307.10726v1",
    "title": "A Blockchain-based Electronic Voting System: EtherVote",
    "authors": [
      "Achilleas Spanos",
      "Ioanna Kantzavelou"
    ],
    "abstract": "The development of an electronic voting system that would replace traditional\nelection procedures is a research topic of great interest for many years.\nBlockchain technology could provide some guarantees and fulfill strong\nrequirements for electronic voting platforms, such as transparency,\nimmutability, and confidentiality. From time to time research is conducted to\naddress problems in voting systems. Many research works attempt to implement\nsecure and reliable voting systems, which address known security, anonymity,\nand fraud issues that might threaten such systems.\n  This paper presents a proposal of a secure electronic voting system, the\nEtherVote, using the Ethereum Blockchain network that focuses deeply on the\nfield of identification of eligible citizens. The proposed system will be\nentirely based on Blockchain without any central authority servers or\ndatabases, thus improving security, privacy, and election cost. Limitations,\nproblems, and solutions are discussed, in order to make the proposed electronic\nvoting system ideal and ready to use for national elections.",
    "categories": [
      "cs.CR",
      "C.2.0"
    ],
    "published": "2023-07-20T09:39:29+00:00",
    "updated": "2023-07-20T09:39:29+00:00",
    "url": "http://arxiv.org/pdf/2307.10726v1"
  },
  {
    "id": "2307.09858v1",
    "title": "Towards Reliable Rare Category Analysis on Graphs via Individual Calibration",
    "authors": [
      "Longfeng Wu",
      "Bowen Lei",
      "Dongkuan Xu",
      "Dawei Zhou"
    ],
    "abstract": "Rare categories abound in a number of real-world networks and play a pivotal\nrole in a variety of high-stakes applications, including financial fraud\ndetection, network intrusion detection, and rare disease diagnosis. Rare\ncategory analysis (RCA) refers to the task of detecting, characterizing, and\ncomprehending the behaviors of minority classes in a highly-imbalanced data\ndistribution. While the vast majority of existing work on RCA has focused on\nimproving the prediction performance, a few fundamental research questions\nheretofore have received little attention and are less explored: How confident\nor uncertain is a prediction model in rare category analysis? How can we\nquantify the uncertainty in the learning process and enable reliable rare\ncategory analysis?\n  To answer these questions, we start by investigating miscalibration in\nexisting RCA methods. Empirical results reveal that state-of-the-art RCA\nmethods are mainly over-confident in predicting minority classes and\nunder-confident in predicting majority classes. Motivated by the observation,\nwe propose a novel individual calibration framework, named CALIRARE, for\nalleviating the unique challenges of RCA, thus enabling reliable rare category\nanalysis. In particular, to quantify the uncertainties in RCA, we develop a\nnode-level uncertainty quantification algorithm to model the overlapping\nsupport regions with high uncertainty; to handle the rarity of minority classes\nin miscalibration calculation, we generalize the distribution-based calibration\nmetric to the instance level and propose the first individual calibration\nmeasurement on graphs named Expected Individual Calibration Error (EICE). We\nperform extensive experimental evaluations on real-world datasets, including\nrare category characterization and model calibration tasks, which demonstrate\nthe significance of our proposed framework.",
    "categories": [
      "cs.AI"
    ],
    "published": "2023-07-19T09:38:52+00:00",
    "updated": "2023-07-19T09:38:52+00:00",
    "url": "http://arxiv.org/pdf/2307.09858v1"
  },
  {
    "id": "2307.11100v1",
    "title": "CSSL-RHA: Contrastive Self-Supervised Learning for Robust Handwriting Authentication",
    "authors": [
      "Jingyao Wang",
      "Luntian Mou",
      "Changwen Zheng",
      "Wen Gao"
    ],
    "abstract": "Handwriting authentication is a valuable tool used in various fields, such as\nfraud prevention and cultural heritage protection. However, it remains a\nchallenging task due to the complex features, severe damage, and lack of\nsupervision. In this paper, we propose a novel Contrastive Self-Supervised\nLearning framework for Robust Handwriting Authentication (CSSL-RHA) to address\nthese issues. It can dynamically learn complex yet important features and\naccurately predict writer identities. Specifically, to remove the negative\neffects of imperfections and redundancy, we design an information-theoretic\nfilter for pre-processing and propose a novel adaptive matching scheme to\nrepresent images as patches of local regions dominated by more important\nfeatures. Through online optimization at inference time, the most informative\npatch embeddings are identified as the \"most important\" elements. Furthermore,\nwe employ contrastive self-supervised training with a momentum-based paradigm\nto learn more general statistical structures of handwritten data without\nsupervision. We conduct extensive experiments on five benchmark datasets and\nour manually annotated dataset EN-HA, which demonstrate the superiority of our\nCSSL-RHA compared to baselines. Additionally, we show that our proposed model\ncan still effectively achieve authentication even under abnormal circumstances,\nsuch as data falsification and corruption.",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "published": "2023-07-18T02:20:46+00:00",
    "updated": "2023-07-18T02:20:46+00:00",
    "url": "http://arxiv.org/pdf/2307.11100v1"
  },
  {
    "id": "2307.07683v2",
    "title": "Single and Multi-Speaker Cloned Voice Detection: From Perceptual to Learned Features",
    "authors": [
      "Sarah Barrington",
      "Romit Barua",
      "Gautham Koorma",
      "Hany Farid"
    ],
    "abstract": "Synthetic-voice cloning technologies have seen significant advances in recent\nyears, giving rise to a range of potential harms. From small- and large-scale\nfinancial fraud to disinformation campaigns, the need for reliable methods to\ndifferentiate real and synthesized voices is imperative. We describe three\ntechniques for differentiating a real from a cloned voice designed to\nimpersonate a specific person. These three approaches differ in their feature\nextraction stage with low-dimensional perceptual features offering high\ninterpretability but lower accuracy, to generic spectral features, and\nend-to-end learned features offering less interpretability but higher accuracy.\nWe show the efficacy of these approaches when trained on a single speaker's\nvoice and when trained on multiple voices. The learned features consistently\nyield an equal error rate between 0% and 4%, and are reasonably robust to\nadversarial laundering.",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "published": "2023-07-15T02:20:26+00:00",
    "updated": "2023-09-27T16:50:15+00:00",
    "url": "http://arxiv.org/pdf/2307.07683v2"
  },
  {
    "id": "2307.10028v1",
    "title": "Organized crime behavior of shell-company networks in procurement: prevention insights for policy and reform",
    "authors": [
      "J. R. Nicolás-Carlock",
      "I. Luna-Pla"
    ],
    "abstract": "In recent years, the analysis of economic crime and corruption in procurement\nhas benefited from integrative studies that acknowledge the interconnected\nnature of the procurement ecosystem. Following this line of research, we\npresent a networks approach for the analysis of shell-companies operations in\nprocurement that makes use of contracting and ownership data under one\nframework to gain knowledge about the organized crime behavior that emerges in\nthis setting. In this approach, ownership and management data are used to\nidentify connected components in shell-company networks that, together with the\ncontracting data, allows to develop an alternative representation of the\ntraditional buyer-supplier network: the module-component bipartite network,\nwhere the modules are groups of buyers and the connected components are groups\nof suppliers. This is applied to two documented cases of procurement corruption\nin Mexico characterized by the involvement of large groups of shell-companies\nin the misappropriation of millions of dollars across many sectors. We quantify\nthe economic impact of single versus connected shell-companies operations. In\naddition, we incorporate metrics for the diversity of operations and favoritism\nlevels. This paper builds into the quantitative organized crime in the private\nsector studies and contributes by proposing a networks approach for preventing\nfraud and understanding the need for legal reforms.",
    "categories": [
      "physics.soc-ph"
    ],
    "published": "2023-07-13T22:38:00+00:00",
    "updated": "2023-07-13T22:38:00+00:00",
    "url": "http://arxiv.org/pdf/2307.10028v1"
  },
  {
    "id": "2307.06669v1",
    "title": "Uncovering the Deceptions: An Analysis on Audio Spoofing Detection and Future Prospects",
    "authors": [
      "Rishabh Ranjan",
      "Mayank Vatsa",
      "Richa Singh"
    ],
    "abstract": "Audio has become an increasingly crucial biometric modality due to its\nability to provide an intuitive way for humans to interact with machines. It is\ncurrently being used for a range of applications, including person\nauthentication to banking to virtual assistants. Research has shown that these\nsystems are also susceptible to spoofing and attacks. Therefore, protecting\naudio processing systems against fraudulent activities, such as identity theft,\nfinancial fraud, and spreading misinformation, is of paramount importance. This\npaper reviews the current state-of-the-art techniques for detecting audio\nspoofing and discusses the current challenges along with open research\nproblems. The paper further highlights the importance of considering the\nethical and privacy implications of audio spoofing detection systems. Lastly,\nthe work aims to accentuate the need for building more robust and generalizable\nmethods, the integration of automatic speaker verification and countermeasure\nsystems, and better evaluation protocols.",
    "categories": [
      "cs.SD",
      "cs.CR",
      "eess.AS"
    ],
    "published": "2023-07-13T10:25:30+00:00",
    "updated": "2023-07-13T10:25:30+00:00",
    "url": "http://arxiv.org/pdf/2307.06669v1"
  },
  {
    "id": "2307.05797v1",
    "title": "Verifi-Chain: A Credentials Verifier using Blockchain and IPFS",
    "authors": [
      "Tasfia Rahman",
      "Sumaiya Islam Mouno",
      "Arunangshu Mojumder Raatul",
      "Abul Kalam Al Azad",
      "Nafees Mansoor"
    ],
    "abstract": "Submitting fake certificates is a common problem in Southeast Asia, which\nprevents qualified candidates from getting the jobs they deserve. When applying\nfor a job, students must provide academic credentials as proof of their\nqualifications, acquired both inside and outside the classroom. Verifying\nacademic documents before hiring is crucial to prevent fraud. Employing\nblockchain technology has the potential to address this issue. Blockchain\nprovides an electronic certificate that is tamper-proof and non-repudiable,\nmaking it difficult for students to manipulate their academic credentials. This\npaper presents a prototype for an academic credential verification model that\nleverages the security features of blockchain and IPFS (Interplanetary File\nSystem). Certificates are temporarily stored in a database before being\ntransferred to IPFS, where a unique hash code is generated using a hashing\nalgorithm. This hash code serves as the certificate's unique identity and is\nstored in the blockchain nodes. Companies can verify an applicant's credentials\nby searching for the applicant and accessing their already verified\ncertificates. Utilizing IPFS as a middleman storage platform lowers the\nexpenses of directly storing massive data on the blockchain. To sum it up, the\nproposed solution would make the process of certificate verification more\nefficient, secure, and cost-effective. It would save time and resources that\nwould otherwise be used to manually verify certificates.",
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "published": "2023-07-11T20:42:28+00:00",
    "updated": "2023-07-11T20:42:28+00:00",
    "url": "http://arxiv.org/pdf/2307.05797v1"
  },
  {
    "id": "2307.05121v1",
    "title": "Transaction Fraud Detection via Spatial-Temporal-Aware Graph Transformer",
    "authors": [
      "Yue Tian",
      "Guanjun Liu"
    ],
    "abstract": "How to obtain informative representations of transactions and then perform\nthe identification of fraudulent transactions is a crucial part of ensuring\nfinancial security. Recent studies apply Graph Neural Networks (GNNs) to the\ntransaction fraud detection problem. Nevertheless, they encounter challenges in\neffectively learning spatial-temporal information due to structural\nlimitations. Moreover, few prior GNN-based detectors have recognized the\nsignificance of incorporating global information, which encompasses similar\nbehavioral patterns and offers valuable insights for discriminative\nrepresentation learning. Therefore, we propose a novel heterogeneous graph\nneural network called Spatial-Temporal-Aware Graph Transformer (STA-GT) for\ntransaction fraud detection problems. Specifically, we design a temporal\nencoding strategy to capture temporal dependencies and incorporate it into the\ngraph neural network framework, enhancing spatial-temporal information modeling\nand improving expressive ability. Furthermore, we introduce a transformer\nmodule to learn local and global information. Pairwise node-node interactions\novercome the limitation of the GNN structure and build up the interactions with\nthe target node and long-distance ones. Experimental results on two financial\ndatasets compared to general GNN models and GNN-based fraud detectors\ndemonstrate that our proposed method STA-GT is effective on the transaction\nfraud detection task.",
    "categories": [
      "cs.LG",
      "q-fin.GN"
    ],
    "published": "2023-07-11T08:56:53+00:00",
    "updated": "2023-07-11T08:56:53+00:00",
    "url": "http://arxiv.org/pdf/2307.05121v1"
  },
  {
    "id": "2307.05633v1",
    "title": "Transaction Fraud Detection via an Adaptive Graph Neural Network",
    "authors": [
      "Yue Tian",
      "Guanjun Liu",
      "Jiacun Wang",
      "Mengchu Zhou"
    ],
    "abstract": "Many machine learning methods have been proposed to achieve accurate\ntransaction fraud detection, which is essential to the financial security of\nindividuals and banks. However, most existing methods leverage original\nfeatures only or require manual feature engineering. They lack the ability to\nlearn discriminative representations from transaction data. Moreover, criminals\noften commit fraud by imitating cardholders' behaviors, which causes the poor\nperformance of existing detection models. In this paper, we propose an Adaptive\nSampling and Aggregation-based Graph Neural Network (ASA-GNN) that learns\ndiscriminative representations to improve the performance of transaction fraud\ndetection. A neighbor sampling strategy is performed to filter noisy nodes and\nsupplement information for fraudulent nodes. Specifically, we leverage cosine\nsimilarity and edge weights to adaptively select neighbors with similar\nbehavior patterns for target nodes and then find multi-hop neighbors for\nfraudulent nodes. A neighbor diversity metric is designed by calculating the\nentropy among neighbors to tackle the camouflage issue of fraudsters and\nexplicitly alleviate the over-smoothing phenomena. Extensive experiments on\nthree real financial datasets demonstrate that the proposed method ASA-GNN\noutperforms state-of-the-art ones.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-07-11T07:48:39+00:00",
    "updated": "2023-07-11T07:48:39+00:00",
    "url": "http://arxiv.org/pdf/2307.05633v1"
  },
  {
    "id": "2307.04350v3",
    "title": "The Linked Data Benchmark Council (LDBC): Driving competition and collaboration in the graph data management space",
    "authors": [
      "Gábor Szárnyas",
      "Brad Bebee",
      "Altan Birler",
      "Alin Deutsch",
      "George Fletcher",
      "Henry A. Gabb",
      "Denise Gosnell",
      "Alastair Green",
      "Zhihui Guo",
      "Keith W. Hare",
      "Jan Hidders",
      "Alexandru Iosup",
      "Atanas Kiryakov",
      "Tomas Kovatchev",
      "Xinsheng Li",
      "Leonid Libkin",
      "Heng Lin",
      "Xiaojian Luo",
      "Arnau Prat-Pérez",
      "David Püroja",
      "Shipeng Qi",
      "Oskar van Rest",
      "Benjamin A. Steer",
      "Dávid Szakállas",
      "Bing Tong",
      "Jack Waudby",
      "Mingxi Wu",
      "Bin Yang",
      "Wenyuan Yu",
      "Chen Zhang",
      "Jason Zhang",
      "Yan Zhou",
      "Peter Boncz"
    ],
    "abstract": "Graph data management is instrumental for several use cases such as\nrecommendation, root cause analysis, financial fraud detection, and enterprise\nknowledge representation. Efficiently supporting these use cases yields a\nnumber of unique requirements, including the need for a concise query language\nand graph-aware query optimization techniques. The goal of the Linked Data\nBenchmark Council (LDBC) is to design a set of standard benchmarks that capture\nrepresentative categories of graph data management problems, making the\nperformance of systems comparable and facilitating competition among vendors.\nLDBC also conducts research on graph schemas and graph query languages. This\npaper introduces the LDBC organization and its work over the last decade.",
    "categories": [
      "cs.DB",
      "H.2.4"
    ],
    "published": "2023-07-10T05:20:36+00:00",
    "updated": "2024-08-30T11:30:26+00:00",
    "url": "http://arxiv.org/pdf/2307.04350v3"
  },
  {
    "id": "2307.05565v1",
    "title": "Dubious Identities: A Visit to the Borwein Zoo",
    "authors": [
      "Zachary P. Bradshaw",
      "Christophe Vignat"
    ],
    "abstract": "We contribute to the zoo of dubious identities established by J.M. and P.B.\nBorwein in their 1992 paper, \"Strange Series and High Precision Fraud\" with\nfive new entries, each of a different variety than the last. Some of these\nidentities are again a high precision fraud and picking out the true from the\nbogus can be a challenging task with many unexpected twists along the way.",
    "categories": [
      "math.HO",
      "00A08 05A19 41A99"
    ],
    "published": "2023-07-09T23:26:05+00:00",
    "updated": "2023-07-09T23:26:05+00:00",
    "url": "http://arxiv.org/pdf/2307.05565v1"
  },
  {
    "id": "2307.05527v1",
    "title": "The Ethical Implications of Generative Audio Models: A Systematic Literature Review",
    "authors": [
      "Julia Barnett"
    ],
    "abstract": "Generative audio models typically focus their applications in music and\nspeech generation, with recent models having human-like quality in their audio\noutput. This paper conducts a systematic literature review of 884 papers in the\narea of generative audio models in order to both quantify the degree to which\nresearchers in the field are considering potential negative impacts and\nidentify the types of ethical implications researchers in this area need to\nconsider. Though 65% of generative audio research papers note positive\npotential impacts of their work, less than 10% discuss any negative impacts.\nThis jarringly small percentage of papers considering negative impact is\nparticularly worrying because the issues brought to light by the few papers\ndoing so are raising serious ethical implications and concerns relevant to the\nbroader field such as the potential for fraud, deep-fakes, and copyright\ninfringement. By quantifying this lack of ethical consideration in generative\naudio research and identifying key areas of potential harm, this paper lays the\ngroundwork for future work in the field at a critical point in time in order to\nguide more conscientious research as this field progresses.",
    "categories": [
      "cs.CY",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "published": "2023-07-07T22:00:32+00:00",
    "updated": "2023-07-07T22:00:32+00:00",
    "url": "http://arxiv.org/pdf/2307.05527v1"
  },
  {
    "id": "2307.05680v1",
    "title": "LogitMat : Zeroshot Learning Algorithm for Recommender Systems without Transfer Learning or Pretrained Models",
    "authors": [
      "Hao Wang"
    ],
    "abstract": "Recommender system is adored in the internet industry as one of the most\nprofitable technologies. Unlike other sectors such as fraud detection in the\nFintech industry, recommender system is both deep and broad. In recent years,\nmany researchers start to focus on the cold-start problem of recommender\nsystems. In spite of the large volume of research literature, the majority of\nthe research utilizes transfer learning / meta learning and pretrained model to\nsolve the problem. Although the researchers claim the effectiveness of the\napproaches, everyone of them does rely on extra input data from other sources.\nIn 2021 and 2022, several zeroshot learning algorithm for recommender system\nsuch as ZeroMat, DotMat, PoissonMat and PowerMat were invented. They are the\nfirst batch of the algorithms that rely on no transfer learning or pretrained\nmodels to tackle the problem. In this paper, we follow this line and invent a\nnew zeroshot learning algorithm named LogitMat. We take advantage of the Zipf\nLaw property of the user item rating values and logistic regression model to\ntackle the cold-start problem and generate competitive results with other\ncompeting techniques. We prove in experiments that our algorithm is fast,\nrobust and effective.",
    "categories": [
      "cs.IR"
    ],
    "published": "2023-07-06T02:59:54+00:00",
    "updated": "2023-07-06T02:59:54+00:00",
    "url": "http://arxiv.org/pdf/2307.05680v1"
  },
  {
    "id": "2307.02319v1",
    "title": "Algorithms, Incentives, and Democracy",
    "authors": [
      "Elizabeth Maggie Penn",
      "John W. Patty"
    ],
    "abstract": "Classification algorithms are increasingly used in areas such as housing,\ncredit, and law enforcement in order to make decisions affecting peoples'\nlives. These algorithms can change individual behavior deliberately (a fraud\nprediction algorithm deterring fraud) or inadvertently (content sorting\nalgorithms spreading misinformation), and they are increasingly facing public\nscrutiny and regulation. Some of these regulations, like the elimination of\ncash bail in some states, have focused on \\textit{lowering the stakes of\ncertain classifications}. In this paper we characterize how optimal\nclassification by an algorithm designer can affect the distribution of behavior\nin a population -- sometimes in surprising ways. We then look at the effect of\ndemocratizing the rewards and punishments, or stakes, to algorithmic\nclassification to consider how a society can potentially stem (or facilitate!)\npredatory classification. Our results speak to questions of algorithmic\nfairness in settings where behavior and algorithms are interdependent, and\nwhere typical measures of fairness focusing on statistical accuracy across\ngroups may not be appropriate.",
    "categories": [
      "econ.TH",
      "stat.AP",
      "stat.ML"
    ],
    "published": "2023-07-05T14:22:01+00:00",
    "updated": "2023-07-05T14:22:01+00:00",
    "url": "http://arxiv.org/pdf/2307.02319v1"
  },
  {
    "id": "2307.01390v1",
    "title": "Adversarial Learning in Real-World Fraud Detection: Challenges and Perspectives",
    "authors": [
      "Danele Lunghi",
      "Alkis Simitsis",
      "Olivier Caelen",
      "Gianluca Bontempi"
    ],
    "abstract": "Data economy relies on data-driven systems and complex machine learning\napplications are fueled by them. Unfortunately, however, machine learning\nmodels are exposed to fraudulent activities and adversarial attacks, which\nthreaten their security and trustworthiness. In the last decade or so, the\nresearch interest on adversarial machine learning has grown significantly,\nrevealing how learning applications could be severely impacted by effective\nattacks. Although early results of adversarial machine learning indicate the\nhuge potential of the approach to specific domains such as image processing,\nstill there is a gap in both the research literature and practice regarding how\nto generalize adversarial techniques in other domains and applications. Fraud\ndetection is a critical defense mechanism for data economy, as it is for other\napplications as well, which poses several challenges for machine learning. In\nthis work, we describe how attacks against fraud detection systems differ from\nother applications of adversarial machine learning, and propose a number of\ninteresting directions to bridge this gap.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2023-07-03T23:04:49+00:00",
    "updated": "2023-07-03T23:04:49+00:00",
    "url": "http://arxiv.org/pdf/2307.01390v1"
  },
  {
    "id": "2307.00169v1",
    "title": "VoxWatch: An open-set speaker recognition benchmark on VoxCeleb",
    "authors": [
      "Raghuveer Peri",
      "Seyed Omid Sadjadi",
      "Daniel Garcia-Romero"
    ],
    "abstract": "Despite its broad practical applications such as in fraud prevention,\nopen-set speaker identification (OSI) has received less attention in the\nspeaker recognition community compared to speaker verification (SV). OSI deals\nwith determining if a test speech sample belongs to a speaker from a set of\npre-enrolled individuals (in-set) or if it is from an out-of-set speaker. In\naddition to the typical challenges associated with speech variability, OSI is\nprone to the \"false-alarm problem\"; as the size of the in-set speaker\npopulation (a.k.a watchlist) grows, the out-of-set scores become larger,\nleading to increased false alarm rates. This is in particular challenging for\napplications in financial institutions and border security where the watchlist\nsize is typically of the order of several thousand speakers. Therefore, it is\nimportant to systematically quantify the false-alarm problem, and develop\ntechniques that alleviate the impact of watchlist size on detection\nperformance. Prior studies on this problem are sparse, and lack a common\nbenchmark for systematic evaluations. In this paper, we present the first\npublic benchmark for OSI, developed using the VoxCeleb dataset. We quantify the\neffect of the watchlist size and speech duration on the watchlist-based speaker\ndetection task using three strong neural network based systems. In contrast to\nthe findings from prior research, we show that the commonly adopted adaptive\nscore normalization is not guaranteed to improve the performance for this task.\nOn the other hand, we show that score calibration and score fusion, two other\ncommonly used techniques in SV, result in significant improvements in OSI\nperformance.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2023-06-30T23:11:38+00:00",
    "updated": "2023-06-30T23:11:38+00:00",
    "url": "http://arxiv.org/pdf/2307.00169v1"
  },
  {
    "id": "2306.17109v1",
    "title": "Synthetic Demographic Data Generation for Card Fraud Detection Using GANs",
    "authors": [
      "Shuo Wang",
      "Terrence Tricco",
      "Xianta Jiang",
      "Charles Robertson",
      "John Hawkin"
    ],
    "abstract": "Using machine learning models to generate synthetic data has become common in\nmany fields. Technology to generate synthetic transactions that can be used to\ndetect fraud is also growing fast. Generally, this synthetic data contains only\ninformation about the transaction, such as the time, place, and amount of\nmoney. It does not usually contain the individual user's characteristics (age\nand gender are occasionally included). Using relatively complex synthetic\ndemographic data may improve the complexity of transaction data features, thus\nimproving the fraud detection performance. Benefiting from developments of\nmachine learning, some deep learning models have potential to perform better\nthan other well-established synthetic data generation methods, such as\nmicrosimulation. In this study, we built a deep-learning Generative Adversarial\nNetwork (GAN), called DGGAN, which will be used for demographic data\ngeneration. Our model generates samples during model training, which we found\nimportant to overcame class imbalance issues. This study can help improve the\ncognition of synthetic data and further explore the application of synthetic\ndata generation in card fraud detection.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2023-06-29T17:08:57+00:00",
    "updated": "2023-06-29T17:08:57+00:00",
    "url": "http://arxiv.org/pdf/2306.17109v1"
  },
  {
    "id": "2306.16236v1",
    "title": "Estimating the correlation between operational risk loss categories over different time horizons",
    "authors": [
      "Maurice L. Brown",
      "Cheng Ly"
    ],
    "abstract": "Operational risk is challenging to quantify because of the broad range of\ncategories (fraud, technological issues, natural disasters) and the\nheavy-tailed nature of realized losses. Operational risk modeling requires\nquantifying how these broad loss categories are related. We focus on the issue\nof loss frequencies having different time scales (e.g., daily, yearly, monthly\nbasis), specifically on estimating the statistics of losses on arbitrary time\nhorizons. We present a frequency model where mathematical techniques can be\nfeasibly applied to analytically calculate the mean, variance, and co-variances\nthat are accurate compared to more time-consuming Monte Carlo simulations. We\nshow that the analytic calculations of cumulative loss statistics in an\narbitrary time window are feasible here and would otherwise be intractable due\nto temporal correlations. Our work has potential value because these statistics\nare crucial for approximating correlations of losses via copulas. We\nsystematically vary all model parameters to demonstrate the accuracy of our\nmethods for calculating all first and second order statistics of aggregate loss\ndistributions. Finally, using combined data from a consortium of institutions,\nwe show that different time horizons can lead to a large range of loss\nstatistics that can significantly affect calculations of capital requirements.",
    "categories": [
      "stat.AP"
    ],
    "published": "2023-06-28T14:00:06+00:00",
    "updated": "2023-06-28T14:00:06+00:00",
    "url": "http://arxiv.org/pdf/2306.16236v1"
  },
  {
    "id": "2306.15975v2",
    "title": "The LDBC Financial Benchmark",
    "authors": [
      "Shipeng Qi",
      "Heng Lin",
      "Zhihui Guo",
      "Gábor Szárnyas",
      "Bing Tong",
      "Yan Zhou",
      "Bin Yang",
      "Jiansong Zhang",
      "Zheng Wang",
      "Youren Shen",
      "Changyuan Wang",
      "Parviz Peiravi",
      "Henry Gabb",
      "Ben Steer"
    ],
    "abstract": "The Linked Data Benchmark Council's Financial Benchmark (LDBC FinBench) is a\nnew effort that defines a graph database benchmark targeting financial\nscenarios such as anti-fraud and risk control. The benchmark has one workload,\nthe Transaction Workload, currently. It captures OLTP scenario with complex,\nsimple read queries and write queries that continuously insert or delete data\nin the graph. Compared to the LDBC SNB, the LDBC FinBench differs in\napplication scenarios, data patterns, and query patterns. This document\ncontains a detailed explanation of the data used in the LDBC FinBench, the\ndefinition of transaction workload, a detailed description for all queries, and\ninstructions on how to use the benchmark suite.",
    "categories": [
      "cs.DB",
      "cs.PF",
      "H.2.4"
    ],
    "published": "2023-06-28T07:24:46+00:00",
    "updated": "2023-06-30T10:54:35+00:00",
    "url": "http://arxiv.org/pdf/2306.15975v2"
  },
  {
    "id": "2308.12833v1",
    "title": "Use of LLMs for Illicit Purposes: Threats, Prevention Measures, and Vulnerabilities",
    "authors": [
      "Maximilian Mozes",
      "Xuanli He",
      "Bennett Kleinberg",
      "Lewis D. Griffin"
    ],
    "abstract": "Spurred by the recent rapid increase in the development and distribution of\nlarge language models (LLMs) across industry and academia, much recent work has\ndrawn attention to safety- and security-related threats and vulnerabilities of\nLLMs, including in the context of potentially criminal activities.\nSpecifically, it has been shown that LLMs can be misused for fraud,\nimpersonation, and the generation of malware; while other authors have\nconsidered the more general problem of AI alignment. It is important that\ndevelopers and practitioners alike are aware of security-related problems with\nsuch models. In this paper, we provide an overview of existing - predominantly\nscientific - efforts on identifying and mitigating threats and vulnerabilities\narising from LLMs. We present a taxonomy describing the relationship between\nthreats caused by the generative capabilities of LLMs, prevention measures\nintended to address such threats, and vulnerabilities arising from imperfect\nprevention measures. With our work, we hope to raise awareness of the\nlimitations of LLMs in light of such security concerns, among both experienced\ndevelopers and novel users of such technologies.",
    "categories": [
      "cs.CL",
      "cs.CR"
    ],
    "published": "2023-08-24T14:45:50+00:00",
    "updated": "2023-08-24T14:45:50+00:00",
    "url": "http://arxiv.org/pdf/2308.12833v1"
  },
  {
    "id": "2308.12770v3",
    "title": "WavMark: Watermarking for Audio Generation",
    "authors": [
      "Guangyu Chen",
      "Yu Wu",
      "Shujie Liu",
      "Tao Liu",
      "Xiaoyong Du",
      "Furu Wei"
    ],
    "abstract": "Recent breakthroughs in zero-shot voice synthesis have enabled imitating a\nspeaker's voice using just a few seconds of recording while maintaining a high\nlevel of realism. Alongside its potential benefits, this powerful technology\nintroduces notable risks, including voice fraud and speaker impersonation.\nUnlike the conventional approach of solely relying on passive methods for\ndetecting synthetic data, watermarking presents a proactive and robust defence\nmechanism against these looming risks. This paper introduces an innovative\naudio watermarking framework that encodes up to 32 bits of watermark within a\nmere 1-second audio snippet. The watermark is imperceptible to human senses and\nexhibits strong resilience against various attacks. It can serve as an\neffective identifier for synthesized voices and holds potential for broader\napplications in audio copyright protection. Moreover, this framework boasts\nhigh flexibility, allowing for the combination of multiple watermark segments\nto achieve heightened robustness and expanded capacity. Utilizing 10 to\n20-second audio as the host, our approach demonstrates an average Bit Error\nRate (BER) of 0.48\\% across ten common attacks, a remarkable reduction of over\n2800\\% in BER compared to the state-of-the-art watermarking tool. See\nhttps://aka.ms/wavmark for demos of our work.",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "published": "2023-08-24T13:17:35+00:00",
    "updated": "2024-01-07T07:05:37+00:00",
    "url": "http://arxiv.org/pdf/2308.12770v3"
  },
  {
    "id": "2308.12448v1",
    "title": "Trend and Emerging Types of 419 Scams",
    "authors": [
      "Polra Victor Falade"
    ],
    "abstract": "Technological advancements have revolutionized various aspects of human life,\nfacilitating communication, business operations, healthcare, education, and\nenvironmental monitoring. However, this increased reliance on technology has\nalso led to a surge in cybercrime, including cyber scams. The \"419 scam\" or\nNigerian scam has been a persistent problem for decades, encompassing frauds\nlike advance fee scams, fake lotteries, and black money scams. Initially\nprevalent through postal mail and later via fax, the scam has now transitioned\nto email. This study aims to identify recent types of 419 scam emails,\nparticularly after the covid 19 pandemic, and explore commonly used email\nsubjects. Analysis of the sample 419 scam emails revealed trending scams like\nlucky winner, threat of exposure, business/partnership proposals, investment,\ncancer/long-term illness, fund, and compensation scams. Emerging scams included\nCOVID-related, cryptocurrency, marketing contact, and software development\nscams. Irrespective of the scam type, scammers commonly employed email subjects\nsuch as 'Re', 'Good day', 'Greetings', 'Dear friend', 'Confirm', 'Attention',\nand 'Hello dear'. The severity of cybercrime, especially the 419 scams, cannot\nbe overstated, as it erodes trust, causes financial losses, and hampers\nNigeria's reputation and economic progress. Combatting cyber scams and\nenhancing cybersecurity measures are crucial to protect individuals and\norganizations from falling victim to these fraudulent schemes.",
    "categories": [
      "cs.CR"
    ],
    "published": "2023-08-23T22:10:37+00:00",
    "updated": "2023-08-23T22:10:37+00:00",
    "url": "http://arxiv.org/pdf/2308.12448v1"
  },
  {
    "id": "2308.11659v2",
    "title": "An engine to simulate insurance fraud network data",
    "authors": [
      "Bavo D. C. Campo",
      "Katrien Antonio"
    ],
    "abstract": "Traditionally, the detection of fraudulent insurance claims relies on\nbusiness rules and expert judgement which makes it a time-consuming and\nexpensive process (\\'Oskarsd\\'ottir et al., 2022). Consequently, researchers\nhave been examining ways to develop efficient and accurate analytic strategies\nto flag suspicious claims. Feeding learning methods with features engineered\nfrom the social network of parties involved in a claim is a particularly\npromising strategy (see for example Van Vlasselaer et al. (2016); Tumminello et\nal. (2023)). When developing a fraud detection model, however, we are\nconfronted with several challenges. The uncommon nature of fraud, for example,\ncreates a high class imbalance which complicates the development of well\nperforming analytic classification models. In addition, only a small number of\nclaims are investigated and get a label, which results in a large corpus of\nunlabeled data. Yet another challenge is the lack of publicly available data.\nThis hinders not only the development of new methods, but also the validation\nof existing techniques. We therefore design a simulation machine that is\nengineered to create synthetic data with a network structure and available\ncovariates similar to the real life insurance fraud data set analyzed in\n\\'Oskarsd\\'ottir et al. (2022). Further, the user has control over several\ndata-generating mechanisms. We can specify the total number of policyholders\nand parties, the desired level of imbalance and the (effect size of the)\nfeatures in the fraud generating model. As such, the simulation engine enables\nresearchers and practitioners to examine several methodological challenges as\nwell as to test their (development strategy of) insurance fraud detection\nmodels in a range of different settings. Moreover, large synthetic data sets\ncan be generated to evaluate the predictive performance of (advanced) machine\nlearning techniques.",
    "categories": [
      "cs.LG",
      "stat.AP",
      "stat.CO"
    ],
    "published": "2023-08-21T13:14:00+00:00",
    "updated": "2024-10-06T12:56:01+00:00",
    "url": "http://arxiv.org/pdf/2308.11659v2"
  },
  {
    "id": "2308.10055v1",
    "title": "Robust Fraud Detection via Supervised Contrastive Learning",
    "authors": [
      "Vinay M. S.",
      "Shuhan Yuan",
      "Xintao Wu"
    ],
    "abstract": "Deep learning models have recently become popular for detecting malicious\nuser activity sessions in computing platforms. In many real-world scenarios,\nonly a few labeled malicious and a large amount of normal sessions are\navailable. These few labeled malicious sessions usually do not cover the entire\ndiversity of all possible malicious sessions. In many scenarios, possible\nmalicious sessions can be highly diverse. As a consequence, learned session\nrepresentations of deep learning models can become ineffective in achieving a\ngood generalization performance for unseen malicious sessions. To tackle this\nopen-set fraud detection challenge, we propose a robust supervised contrastive\nlearning based framework called ConRo, which specifically operates in the\nscenario where only a few malicious sessions having limited diversity is\navailable. ConRo applies an effective data augmentation strategy to generate\ndiverse potential malicious sessions. By employing these generated and\navailable training set sessions, ConRo derives separable representations w.r.t\nopen-set fraud detection task by leveraging supervised contrastive learning. We\nempirically evaluate our ConRo framework and other state-of-the-art baselines\non benchmark datasets. Our ConRo framework demonstrates noticeable performance\nimprovement over state-of-the-art baselines.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2023-08-19T15:33:53+00:00",
    "updated": "2023-08-19T15:33:53+00:00",
    "url": "http://arxiv.org/pdf/2308.10055v1"
  },
  {
    "id": "2308.10037v1",
    "title": "High Performance Computing Applied to Logistic Regression: A CPU and GPU Implementation Comparison",
    "authors": [
      "Nechba Mohammed",
      "Mouhajir Mohamed",
      "Sedjari Yassine"
    ],
    "abstract": "We present a versatile GPU-based parallel version of Logistic Regression\n(LR), aiming to address the increasing demand for faster algorithms in binary\nclassification due to large data sets. Our implementation is a direct\ntranslation of the parallel Gradient Descent Logistic Regression algorithm\nproposed by X. Zou et al. [12]. Our experiments demonstrate that our GPU-based\nLR outperforms existing CPU-based implementations in terms of execution time\nwhile maintaining comparable f1 score. The significant acceleration of\nprocessing large datasets makes our method particularly advantageous for\nreal-time prediction applications like image recognition, spam detection, and\nfraud detection. Our algorithm is implemented in a ready-to-use Python library\navailable at : https://github.com/NechbaMohammed/SwiftLogisticReg",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-08-19T14:49:37+00:00",
    "updated": "2023-08-19T14:49:37+00:00",
    "url": "http://arxiv.org/pdf/2308.10037v1"
  },
  {
    "id": "2308.09724v1",
    "title": "Knowledge-inspired Subdomain Adaptation for Cross-Domain Knowledge Transfer",
    "authors": [
      "Liyue Chen",
      "Linian Wang",
      "Jinyu Xu",
      "Shuai Chen",
      "Weiqiang Wang",
      "Wenbiao Zhao",
      "Qiyu Li",
      "Leye Wang"
    ],
    "abstract": "Most state-of-the-art deep domain adaptation techniques align source and\ntarget samples in a global fashion. That is, after alignment, each source\nsample is expected to become similar to any target sample. However, global\nalignment may not always be optimal or necessary in practice. For example,\nconsider cross-domain fraud detection, where there are two types of\ntransactions: credit and non-credit. Aligning credit and non-credit\ntransactions separately may yield better performance than global alignment, as\ncredit transactions are unlikely to exhibit patterns similar to non-credit\ntransactions. To enable such fine-grained domain adaption, we propose a novel\nKnowledge-Inspired Subdomain Adaptation (KISA) framework. In particular, (1) We\nprovide the theoretical insight that KISA minimizes the shared expected loss\nwhich is the premise for the success of domain adaptation methods. (2) We\npropose the knowledge-inspired subdomain division problem that plays a crucial\nrole in fine-grained domain adaption. (3) We design a knowledge fusion network\nto exploit diverse domain knowledge. Extensive experiments demonstrate that\nKISA achieves remarkable results on fraud detection and traffic demand\nprediction tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2023-08-17T04:46:38+00:00",
    "updated": "2023-08-17T04:46:38+00:00",
    "url": "http://arxiv.org/pdf/2308.09724v1"
  },
  {
    "id": "2308.08504v1",
    "title": "ResBuilder: Automated Learning of Depth with Residual Structures",
    "authors": [
      "Julian Burghoff",
      "Matthias Rottmann",
      "Jill von Conta",
      "Sebastian Schoenen",
      "Andreas Witte",
      "Hanno Gottschalk"
    ],
    "abstract": "In this work, we develop a neural architecture search algorithm, termed\nResbuilder, that develops ResNet architectures from scratch that achieve high\naccuracy at moderate computational cost. It can also be used to modify existing\narchitectures and has the capability to remove and insert ResNet blocks, in\nthis way searching for suitable architectures in the space of ResNet\narchitectures. In our experiments on different image classification datasets,\nResbuilder achieves close to state-of-the-art performance while saving\ncomputational cost compared to off-the-shelf ResNets. Noteworthy, we once tune\nthe parameters on CIFAR10 which yields a suitable default choice for all other\ndatasets. We demonstrate that this property generalizes even to industrial\napplications by applying our method with default parameters on a proprietary\nfraud detection dataset.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2023-08-16T16:58:25+00:00",
    "updated": "2023-08-16T16:58:25+00:00",
    "url": "http://arxiv.org/pdf/2308.08504v1"
  },
  {
    "id": "2311.16105v1",
    "title": "A Privacy-preserving Central Bank Ledger for Central Bank Digital Currency",
    "authors": [
      "Wang Mong Tikvah Chan"
    ],
    "abstract": "Retail central bank digital currency (rCBDC) is seen as a key upgrade of the\nmonetary system in the 21st century. However, privacy concerns are the main\nimpediment to rCBDC's development and roll-out. On the one hand, the rights of\npeople to keep their transactions private should be protected, including\nagainst central bank surveillance. On the other hand, the central bank needs to\nensure that no over-issuance of money or other frauds occur, demanding a\ncertain form of knowledge of rCBDC transactions to safeguard against malicious\nusers. This work focuses on rCBDC architectures based on the unspent\ntransaction output (UTXO) data model and tackles the research problem of\npreserving a sufficient degree of privacy for UTXO transaction records while\nallowing the central bank to verify their correctness. User privacy is not\nadequately addressed in the UTXO-based rCBDC architectures. Using evolving\npublic keys as pseudonyms to hide the real identities of users only solves the\nprivacy issue partially. Some information could still be leaked out. This work\ninvestigates techniques to address the shortcomings of the pseudonym approach.\nFirst, a Pedersen commitment scheme is applied to hide the transaction values\nof a UTXO transaction while allowing the central bank to verify that no\nover-issuance of rCBDC has occurred in the transaction.This work uses a Schnorr\nsignature to prove no over-issuance of money, which reduces overheads and\nenables a non-interactive proof. Then, Coinjoin is applied to aggregate UTXO\ntransactions from different users into one larger UTXO transaction to obfuscate\nthe payer-payee relationship while preserving the correctness of the amount of\nmoney flow. This work applies k-anonymity to analyse the privacy guarantee of\nCoinjoin. By modelling the transaction traffic by a Poisson process, the\ntrade-off between anonymity and transaction confirmation time of Coinjoin is\nanalysed.",
    "categories": [
      "cs.CR",
      "E.3; G.3; K.4.1; K.4.4"
    ],
    "published": "2023-08-16T12:33:08+00:00",
    "updated": "2023-08-16T12:33:08+00:00",
    "url": "http://arxiv.org/pdf/2311.16105v1"
  },
  {
    "id": "2308.07705v1",
    "title": "Parametric entropy based Cluster Centriod Initialization for k-means clustering of various Image datasets",
    "authors": [
      "Faheem Hussayn",
      "Shahid M Shah"
    ],
    "abstract": "One of the most employed yet simple algorithm for cluster analysis is the\nk-means algorithm. k-means has successfully witnessed its use in artificial\nintelligence, market segmentation, fraud detection, data mining, psychology,\netc., only to name a few. The k-means algorithm, however, does not always yield\nthe best quality results. Its performance heavily depends upon the number of\nclusters supplied and the proper initialization of the cluster centroids or\nseeds. In this paper, we conduct an analysis of the performance of k-means on\nimage data by employing parametric entropies in an entropy based centroid\ninitialization method and propose the best fitting entropy measures for general\nimage datasets. We use several entropies like Taneja entropy, Kapur entropy,\nAczel Daroczy entropy, Sharma Mittal entropy. We observe that for different\ndatasets, different entropies provide better results than the conventional\nmethods. We have applied our proposed algorithm on these datasets: Satellite,\nToys, Fruits, Cars, Brain MRI, Covid X-Ray.",
    "categories": [
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "published": "2023-08-15T11:28:02+00:00",
    "updated": "2023-08-15T11:28:02+00:00",
    "url": "http://arxiv.org/pdf/2308.07705v1"
  },
  {
    "id": "2308.07404v1",
    "title": "Benford Behavior of a Higher-Dimensional Fragmentation Process",
    "authors": [
      "Irfan Durmić",
      "Steven J. Miller"
    ],
    "abstract": "Nature and our world have a bias! Roughly $30\\%$ of the time the number $1$\noccurs as the leading digit in many datasets base $10$. This phenomenon is\nknown as Benford's law and it arrises in diverse fields such as the stock\nmarket, optimizing computers, street addresses, Fibonacci numbers, and is often\nused to detect possible fraud. Based on previous work, we know that different\nforms of a one-dimensional stick fragmentation result in pieces whose lengths\nfollow Benford's Law. We generalize this result and show that this can be\nextended to any finite-dimensional ``volume''. We further conjecture that even\nlower-dimensional volumes, under the unrestricted fragmentation process, follow\nBenford's Law.",
    "categories": [
      "math.PR"
    ],
    "published": "2023-08-14T18:47:01+00:00",
    "updated": "2023-08-14T18:47:01+00:00",
    "url": "http://arxiv.org/pdf/2308.07404v1"
  },
  {
    "id": "2308.05237v1",
    "title": "Financial Fraud Detection: A Comparative Study of Quantum Machine Learning Models",
    "authors": [
      "Nouhaila Innan",
      "Muhammad Al-Zafar Khan",
      "Mohamed Bennai"
    ],
    "abstract": "In this research, a comparative study of four Quantum Machine Learning (QML)\nmodels was conducted for fraud detection in finance. We proved that the Quantum\nSupport Vector Classifier model achieved the highest performance, with F1\nscores of 0.98 for fraud and non-fraud classes. Other models like the\nVariational Quantum Classifier, Estimator Quantum Neural Network (QNN), and\nSampler QNN demonstrate promising results, propelling the potential of QML\nclassification for financial applications. While they exhibit certain\nlimitations, the insights attained pave the way for future enhancements and\noptimisation strategies. However, challenges exist, including the need for more\nefficient Quantum algorithms and larger and more complex datasets. The article\nprovides solutions to overcome current limitations and contributes new insights\nto the field of Quantum Machine Learning in fraud detection, with important\nimplications for its future development.",
    "categories": [
      "quant-ph",
      "cs.LG",
      "q-fin.GN"
    ],
    "published": "2023-08-09T21:47:50+00:00",
    "updated": "2023-08-09T21:47:50+00:00",
    "url": "http://arxiv.org/pdf/2308.05237v1"
  },
  {
    "id": "2308.07932v1",
    "title": "Balanced Butterfly Counting in Bipartite-Network",
    "authors": [
      "Apurba Das",
      "Aman Abidi",
      "Ajinkya Shingane",
      "Mekala Kiran"
    ],
    "abstract": "Bipartite graphs offer a powerful framework for modeling complex\nrelationships between two distinct types of vertices, incorporating\nprobabilistic, temporal, and rating-based information. While the research\ncommunity has extensively explored various types of bipartite relationships,\nthere has been a notable gap in studying Signed Bipartite Graphs, which capture\nliking / disliking interactions in real-world networks such as\ncustomer-rating-product and senator-vote-bill. Balance butterflies,\nrepresenting 2 x 2 bicliques, provide crucial insights into antagonistic\ngroups, balance theory, and fraud detection by leveraging the signed\ninformation. However, such applications require counting balance butterflies\nwhich remains unexplored. In this paper, we propose a new problem: counting\nbalance butterflies in a signed bipartite graph. To address this problem, we\nadopt state-of-the-art algorithms for butterfly counting, establishing a smart\nbaseline that reduces the time complexity for solving our specific problem. We\nfurther introduce a novel bucket approach specifically designed to count\nbalanced butterflies efficiently. We propose a parallelized version of the\nbucketing approach to enhance performance. Extensive experimental studies on\nnine real-world datasets demonstrate that our proposed bucket-based algorithm\nis up to 120x faster over the baseline, and the parallel implementation of the\nbucket-based algorithm is up to 45x faster over the single core execution.\nMoreover, a real-world case study showcases the practical application and\nrelevance of counting balanced butterflies.",
    "categories": [
      "cs.SI"
    ],
    "published": "2023-08-09T04:57:32+00:00",
    "updated": "2023-08-09T04:57:32+00:00",
    "url": "http://arxiv.org/pdf/2308.07932v1"
  },
  {
    "id": "2308.04177v2",
    "title": "How Generalizable are Deepfake Image Detectors? An Empirical Study",
    "authors": [
      "Boquan Li",
      "Jun Sun",
      "Christopher M. Poskitt",
      "Xingmei Wang"
    ],
    "abstract": "Deepfakes are becoming increasingly credible, posing a significant threat\ngiven their potential to facilitate fraud or bypass access control systems.\nThis has motivated the development of deepfake detection methods, in which deep\nlearning models are trained to distinguish between real and synthesized\nfootage. Unfortunately, existing detectors struggle to generalize to deepfakes\nfrom datasets they were not trained on, but little work has been done to\nexamine why or how this limitation can be addressed. Especially, those\nsingle-modality deepfake images reveal little available forgery evidence,\nposing greater challenges than detecting deepfake videos. In this work, we\npresent the first empirical study on the generalizability of deepfake\ndetectors, an essential goal for detectors to stay one step ahead of attackers.\nOur study utilizes six deepfake datasets, five deepfake image detection\nmethods, and two model augmentation approaches, confirming that detectors do\nnot generalize in zero-shot settings. Additionally, we find that detectors are\nlearning unwanted properties specific to synthesis methods and struggling to\nextract discriminative features, limiting their ability to generalize. Finally,\nwe find that there are neurons universally contributing to detection across\nseen and unseen datasets, suggesting a possible path towards zero-shot\ngeneralizability.",
    "categories": [
      "cs.CV",
      "cs.CR"
    ],
    "published": "2023-08-08T10:30:34+00:00",
    "updated": "2024-08-03T06:05:56+00:00",
    "url": "http://arxiv.org/pdf/2308.04177v2"
  },
  {
    "id": "2308.04469v1",
    "title": "Correlating Medi-Claim Service by Deep Learning Neural Networks",
    "authors": [
      "Jayanthi Vajiram",
      "Negha Senthil",
      "Nean Adhith. P"
    ],
    "abstract": "Medical insurance claims are of organized crimes related to patients,\nphysicians, diagnostic centers, and insurance providers, forming a chain\nreaction that must be monitored constantly. These kinds of frauds affect the\nfinancial growth of both insured people and health insurance companies. The\nConvolution Neural Network architecture is used to detect fraudulent claims\nthrough a correlation study of regression models, which helps to detect money\nlaundering on different claims given by different providers. Supervised and\nunsupervised classifiers are used to detect fraud and non-fraud claims.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2023-08-08T07:40:21+00:00",
    "updated": "2023-08-08T07:40:21+00:00",
    "url": "http://arxiv.org/pdf/2308.04469v1"
  },
  {
    "id": "2308.03800v1",
    "title": "Textual Data Mining for Financial Fraud Detection: A Deep Learning Approach",
    "authors": [
      "Qiuru Li"
    ],
    "abstract": "In this report, I present a deep learning approach to conduct a natural\nlanguage processing (hereafter NLP) binary classification task for analyzing\nfinancial-fraud texts. First, I searched for regulatory announcements and\nenforcement bulletins from HKEX news to define fraudulent companies and to\nextract their MD&A reports before I organized the sentences from the reports\nwith labels and reporting time. My methodology involved different kinds of\nneural network models, including Multilayer Perceptrons with Embedding layers,\nvanilla Recurrent Neural Network (RNN), Long-Short Term Memory (LSTM), and\nGated Recurrent Unit (GRU) for the text classification task. By utilizing this\ndiverse set of models, I aim to perform a comprehensive comparison of their\naccuracy in detecting financial fraud. My results bring significant\nimplications for financial fraud detection as this work contributes to the\ngrowing body of research at the intersection of deep learning, NLP, and\nfinance, providing valuable insights for industry practitioners, regulators,\nand researchers in the pursuit of more robust and effective fraud detection\nmethodologies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2023-08-05T15:33:10+00:00",
    "updated": "2023-08-05T15:33:10+00:00",
    "url": "http://arxiv.org/pdf/2308.03800v1"
  },
  {
    "id": "2308.02793v2",
    "title": "Crowdsourcing Fraud Detection over Heterogeneous Temporal MMMA Graph",
    "authors": [
      "Zequan Xu",
      "Qihang Sun",
      "Shaofeng Hu",
      "Jieming Shi",
      "Hui Li"
    ],
    "abstract": "The rise of the click farm business using Multi-purpose Messaging Mobile Apps\n(MMMAs) tempts cybercriminals to perpetrate crowdsourcing frauds that cause\nfinancial losses to click farm workers. In this paper, we propose a novel\ncontrastive multi-view learning method named CMT for crowdsourcing fraud\ndetection over the heterogeneous temporal graph (HTG) of MMMA. CMT captures\nboth heterogeneity and dynamics of HTG and generates high-quality\nrepresentations for crowdsourcing fraud detection in a self-supervised manner.\nWe deploy CMT to detect crowdsourcing frauds on an industry-size HTG of a\nrepresentative MMMA WeChat and it significantly outperforms other methods. CMT\nalso shows promising results for fraud detection on a large-scale public\nfinancial HTG, indicating that it can be applied in other graph anomaly\ndetection tasks. We provide our implementation at\nhttps://github.com/KDEGroup/CMT.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "published": "2023-08-05T05:35:40+00:00",
    "updated": "2024-04-04T05:10:06+00:00",
    "url": "http://arxiv.org/pdf/2308.02793v2"
  },
  {
    "id": "2308.02695v1",
    "title": "FPR Estimation for Fraud Detection in the Presence of Class-Conditional Label Noise",
    "authors": [
      "Justin Tittelfitz"
    ],
    "abstract": "We consider the problem of estimating the false-/ true-positive-rate\n(FPR/TPR) for a binary classification model when there are incorrect labels\n(label noise) in the validation set. Our motivating application is fraud\nprevention where accurate estimates of FPR are critical to preserving the\nexperience for good customers, and where label noise is highly asymmetric.\nExisting methods seek to minimize the total error in the cleaning process - to\navoid cleaning examples that are not noise, and to ensure cleaning of examples\nthat are. This is an important measure of accuracy but insufficient to\nguarantee good estimates of the true FPR or TPR for a model, and we show that\nusing the model to directly clean its own validation data leads to\nunderestimates even if total error is low. This indicates a need for\nresearchers to pursue methods that not only reduce total error but also seek to\nde-correlate cleaning error with model scores.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2023-08-04T20:14:34+00:00",
    "updated": "2023-08-04T20:14:34+00:00",
    "url": "http://arxiv.org/pdf/2308.02695v1"
  },
  {
    "id": "2308.01586v1",
    "title": "Analyzing Bank Account Information of Nominees and Scammers",
    "authors": [
      "Patsita Sirawongphatsara",
      "Phisit Pornpongtechavanich",
      "Pakkasit Sriamorntrakul",
      "Therdpong Daengsi"
    ],
    "abstract": "Nowadays, people heavily rely on the Internet for various activities, such as\ne-commerce (e.g., online shopping) and online banking. While online\ntransactions are practical, they also provide scammers with a new way to\nexploit unsuspecting individuals. This study and investigation utilized data\nfrom ChaladOhn, a website designed and developed by academics and policemen.\nThe data covered the period from February 2022 to January 2023. After analyzing\nand investigating, the results reveal that the total losses amounted to over\n3,100 million Thai Baht, with each case incurring losses of less than 10\nmillion. Furthermore, the investigation discovered the involvement of the top\ntwo banks in the market, KB*** and BB*, in the fraud. These banks accounted\nfor: 1) 28.2% and 16.0% of the total number of scam accounts, 2) 25.6% and\n20.5% of the total transactions, and 3) 35.7% and 14.9% of the total losses\nfrom the victims as recorded in the database, respectively. Considering the\nanticipated deterioration of this issue, it is crucial to inform regulators and\nrelevant organizations about the investigation's findings. This will enable the\ndevelopment, suggestion, and implementation of an efficient solution to address\nthe rapidly increasing number of online scam cases.",
    "categories": [
      "cs.CY"
    ],
    "published": "2023-08-03T07:45:15+00:00",
    "updated": "2023-08-03T07:45:15+00:00",
    "url": "http://arxiv.org/pdf/2308.01586v1"
  },
  {
    "id": "2308.01469v1",
    "title": "VertexSerum: Poisoning Graph Neural Networks for Link Inference",
    "authors": [
      "Ruyi Ding",
      "Shijin Duan",
      "Xiaolin Xu",
      "Yunsi Fei"
    ],
    "abstract": "Graph neural networks (GNNs) have brought superb performance to various\napplications utilizing graph structural data, such as social analysis and fraud\ndetection. The graph links, e.g., social relationships and transaction history,\nare sensitive and valuable information, which raises privacy concerns when\nusing GNNs. To exploit these vulnerabilities, we propose VertexSerum, a novel\ngraph poisoning attack that increases the effectiveness of graph link stealing\nby amplifying the link connectivity leakage. To infer node adjacency more\naccurately, we propose an attention mechanism that can be embedded into the\nlink detection network. Our experiments demonstrate that VertexSerum\nsignificantly outperforms the SOTA link inference attack, improving the AUC\nscores by an average of $9.8\\%$ across four real-world datasets and three\ndifferent GNN structures. Furthermore, our experiments reveal the effectiveness\nof VertexSerum in both black-box and online learning settings, further\nvalidating its applicability in real-world scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2023-08-02T23:13:49+00:00",
    "updated": "2023-08-02T23:13:49+00:00",
    "url": "http://arxiv.org/pdf/2308.01469v1"
  },
  {
    "id": "2308.01063v1",
    "title": "Graph Anomaly Detection at Group Level: A Topology Pattern Enhanced Unsupervised Approach",
    "authors": [
      "Xing Ai",
      "Jialong Zhou",
      "Yulin Zhu",
      "Gaolei Li",
      "Tomasz P. Michalak",
      "Xiapu Luo",
      "Kai Zhou"
    ],
    "abstract": "Graph anomaly detection (GAD) has achieved success and has been widely\napplied in various domains, such as fraud detection, cybersecurity, finance\nsecurity, and biochemistry. However, existing graph anomaly detection\nalgorithms focus on distinguishing individual entities (nodes or graphs) and\noverlook the possibility of anomalous groups within the graph. To address this\nlimitation, this paper introduces a novel unsupervised framework for a new task\ncalled Group-level Graph Anomaly Detection (Gr-GAD). The proposed framework\nfirst employs a variant of Graph AutoEncoder (GAE) to locate anchor nodes that\nbelong to potential anomaly groups by capturing long-range inconsistencies.\nSubsequently, group sampling is employed to sample candidate groups, which are\nthen fed into the proposed Topology Pattern-based Graph Contrastive Learning\n(TPGCL) method. TPGCL utilizes the topology patterns of groups as clues to\ngenerate embeddings for each candidate group and thus distinct anomaly groups.\nThe experimental results on both real-world and synthetic datasets demonstrate\nthat the proposed framework shows superior performance in identifying and\nlocalizing anomaly groups, highlighting it as a promising solution for Gr-GAD.\nDatasets and codes of the proposed framework are at the github repository\nhttps://anonymous.4open.science/r/Topology-Pattern-Enhanced-Unsupervised-Group-level-Graph-Anomaly-Detection.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2023-08-02T10:22:04+00:00",
    "updated": "2023-08-02T10:22:04+00:00",
    "url": "http://arxiv.org/pdf/2308.01063v1"
  },
  {
    "id": "2308.00074v1",
    "title": "Using Kernel SHAP XAI Method to optimize the Network Anomaly Detection Model",
    "authors": [
      "Khushnaseeb Roshan",
      "Aasim Zafar"
    ],
    "abstract": "Anomaly detection and its explanation is important in many research areas\nsuch as intrusion detection, fraud detection, unknown attack detection in\nnetwork traffic and logs. It is challenging to identify the cause or\nexplanation of why one instance is an anomaly? and the other is not due to its\nunbounded and lack of supervisory nature. The answer to this question is\npossible with the emerging technique of explainable artificial intelligence\n(XAI). XAI provides tools and techniques to interpret and explain the output\nand working of complex models such as Deep Learning (DL). This paper aims to\ndetect and explain network anomalies with XAI, kernelSHAP method. The same\napproach is used to improve the network anomaly detection model in terms of\naccuracy, recall, precision and f score. The experiment is conduced with the\nlatest CICIDS2017 dataset. Two models are created (Model_1 and OPT_Model) and\ncompared. The overall accuracy and F score of OPT_Model (when trained in\nunsupervised way) are 0.90 and 0.76, respectively.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2023-07-31T18:47:45+00:00",
    "updated": "2023-07-31T18:47:45+00:00",
    "url": "http://arxiv.org/pdf/2308.00074v1"
  },
  {
    "id": "2307.15969v4",
    "title": "Fast Searching The Densest Subgraph And Decomposition With Local Optimality",
    "authors": [
      "Yugao Zhu",
      "Shenghua Liu",
      "Wenjie Feng",
      "Xueqi Cheng"
    ],
    "abstract": "Densest Subgraph Problem (DSP) is an important primitive problem with a wide\nrange of applications, including fraud detection, community detection and DNA\nmotif discovery. Edge-based density is one of the most common metrics in DSP.\nAlthough a maximum flow algorithm can exactly solve it in polynomial time, the\nincreasing amount of data and the high complexity of algorithms motivate\nscientists to find approximation algorithms. Among these, its duality of linear\nprogramming derives several iterative algorithms including Greedy++,\nFrank-Wolfe and FISTA which redistribute edge weights to find the densest\nsubgraph, however, these iterative algorithms vibrate around the optimal\nsolution, which are not satisfactory for fast convergence. We propose our main\nalgorithm Locally Optimal Weight Distribution (LOWD) to distribute the\nremaining edge weights in a locally optimal operation to converge to the\noptimal solution monotonically. Theoretically, we show that it will reach the\noptimal state of a specific linear programming which is called locally-dense\ndecomposition. Besides, we show that it is not necessary to consider most of\nthe edges in the original graph. Therefore, we develop a pruning algorithm\nusing a modified Counting Sort to prune graphs by removing unnecessary edges\nand nodes, and then we can search the densest subgraph in a much smaller graph.",
    "categories": [
      "cs.DB"
    ],
    "published": "2023-07-29T12:20:49+00:00",
    "updated": "2023-10-29T15:38:02+00:00",
    "url": "http://arxiv.org/pdf/2307.15969v4"
  },
  {
    "id": "2307.15677v1",
    "title": "Adversarial training for tabular data with attack propagation",
    "authors": [
      "Tiago Leon Melo",
      "João Bravo",
      "Marco O. P. Sampaio",
      "Paolo Romano",
      "Hugo Ferreira",
      "João Tiago Ascensão",
      "Pedro Bizarro"
    ],
    "abstract": "Adversarial attacks are a major concern in security-centered applications,\nwhere malicious actors continuously try to mislead Machine Learning (ML) models\ninto wrongly classifying fraudulent activity as legitimate, whereas system\nmaintainers try to stop them. Adversarially training ML models that are robust\nagainst such attacks can prevent business losses and reduce the work load of\nsystem maintainers. In such applications data is often tabular and the space\navailable for attackers to manipulate undergoes complex feature engineering\ntransformations, to provide useful signals for model training, to a space\nattackers cannot access. Thus, we propose a new form of adversarial training\nwhere attacks are propagated between the two spaces in the training loop. We\nthen test this method empirically on a real world dataset in the domain of\ncredit card fraud detection. We show that our method can prevent about 30%\nperformance drops under moderate attacks and is essential under very aggressive\nattacks, with a trade-off loss in performance under no attacks smaller than 7%.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2023-07-28T17:12:46+00:00",
    "updated": "2023-07-28T17:12:46+00:00",
    "url": "http://arxiv.org/pdf/2307.15677v1"
  },
  {
    "id": "2307.15555v1",
    "title": "All-for-One and One-For-All: Deep learning-based feature fusion for Synthetic Speech Detection",
    "authors": [
      "Daniele Mari",
      "Davide Salvi",
      "Paolo Bestagini",
      "Simone Milani"
    ],
    "abstract": "Recent advances in deep learning and computer vision have made the synthesis\nand counterfeiting of multimedia content more accessible than ever, leading to\npossible threats and dangers from malicious users. In the audio field, we are\nwitnessing the growth of speech deepfake generation techniques, which solicit\nthe development of synthetic speech detection algorithms to counter possible\nmischievous uses such as frauds or identity thefts. In this paper, we consider\nthree different feature sets proposed in the literature for the synthetic\nspeech detection task and present a model that fuses them, achieving overall\nbetter performances with respect to the state-of-the-art solutions. The system\nwas tested on different scenarios and datasets to prove its robustness to\nanti-forensic attacks and its generalization capabilities.",
    "categories": [
      "cs.SD",
      "cs.CL",
      "cs.CR",
      "eess.AS"
    ],
    "published": "2023-07-28T13:50:25+00:00",
    "updated": "2023-07-28T13:50:25+00:00",
    "url": "http://arxiv.org/pdf/2307.15555v1"
  },
  {
    "id": "2309.13183v2",
    "title": "Statistical Hypothesis Testing for Information Value (IV)",
    "authors": [
      "Helder Rojas",
      "Cirilo Alvarez",
      "Nilton Rojas"
    ],
    "abstract": "Information value (IV) is a quite popular technique for features selection\nbefore the modeling phase. There are practical criteria, based on fixed\nthresholds for IV, but at the same time mysterious and lacking theoretical\narguments, to decide if a predictor has sufficient predictive power to be\nconsidered in the modeling phase. However, the mathematical development and\nstatistical inference methods for this technique are almost nonexistent in the\nliterature. In this paper we present a theoretical framework for IV, and at the\nsame time, we propose a non-parametric hypothesis test to evaluate the\npredictive power of features contemplated in a data set. Due to its\nrelationship with divergence measures developed in the Information Theory, we\ncall our proposal the J - Divergence test. We show how to efficiently compute\nour test statistic and we study its performance on simulated data. In various\nscenarios, particularly in unbalanced data sets, we show its superiority over\nconventional criteria based on fixed thresholds. Furthermore, we apply our test\non fraud identification data and provide an open-source Python library, called\n\"statistical-iv\"(https://pypi.org/project/statistical-iv/), where we implement\nour main results.",
    "categories": [
      "math.ST",
      "stat.ME",
      "stat.ML",
      "stat.TH"
    ],
    "published": "2023-09-22T21:16:18+00:00",
    "updated": "2023-09-30T00:27:31+00:00",
    "url": "http://arxiv.org/pdf/2309.13183v2"
  },
  {
    "id": "2309.09486v1",
    "title": "Online Efficient Secure Logistic Regression based on Function Secret Sharing",
    "authors": [
      "Jing Liu",
      "Jamie Cui",
      "Cen Chen"
    ],
    "abstract": "Logistic regression is an algorithm widely used for binary classification in\nvarious real-world applications such as fraud detection, medical diagnosis, and\nrecommendation systems. However, training a logistic regression model with data\nfrom different parties raises privacy concerns. Secure Multi-Party Computation\n(MPC) is a cryptographic tool that allows multiple parties to train a logistic\nregression model jointly without compromising privacy. The efficiency of the\nonline training phase becomes crucial when dealing with large-scale data in\npractice. In this paper, we propose an online efficient protocol for\nprivacy-preserving logistic regression based on Function Secret Sharing (FSS).\nOur protocols are designed in the two non-colluding servers setting and assume\nthe existence of a third-party dealer who only poses correlated randomness to\nthe computing parties. During the online phase, two servers jointly train a\nlogistic regression model on their private data by utilizing pre-generated\ncorrelated randomness. Furthermore, we propose accurate and MPC-friendly\nalternatives to the sigmoid function and encapsulate the logistic regression\ntraining process into a function secret sharing gate. The online communication\noverhead significantly decreases compared with the traditional secure logistic\nregression training based on secret sharing. We provide both theoretical and\nexperimental analyses to demonstrate the efficiency and effectiveness of our\nmethod.",
    "categories": [
      "cs.CR"
    ],
    "published": "2023-09-18T04:50:54+00:00",
    "updated": "2023-09-18T04:50:54+00:00",
    "url": "http://arxiv.org/pdf/2309.09486v1"
  },
  {
    "id": "2309.04350v1",
    "title": "Exploring Cohesive Subgraphs in Hypergraphs: The (k,g)-core Approach",
    "authors": [
      "Dahee Kim",
      "Junghoon Kim",
      "Sungsu Lim",
      "Hyun Ji Jeong"
    ],
    "abstract": "Identifying cohesive subgraphs in hypergraphs is a fundamental problem that\nhas received recent attention in data mining and engineering fields. Existing\napproaches mainly focus on a strongly induced subhypergraph or edge\ncardinality, overlooking the importance of the frequency of co-occurrence. In\nthis paper, we propose a new cohesive subgraph named (k,g)-core, which\nconsiders both neighbour and co-occurrence simultaneously. The $(k,g)$-core has\nvarious applications including recommendation system, network analysis, and\nfraud detection. To the best of our knowledge, this is the first work to\ncombine these factors. We extend an existing efficient algorithm to find\nsolutions for $(k,g)$-core. Finally, we conduct extensive experimental studies\nthat demonstrate the efficiency and effectiveness of our proposed algorithm.",
    "categories": [
      "cs.SI"
    ],
    "published": "2023-09-08T14:21:46+00:00",
    "updated": "2023-09-08T14:21:46+00:00",
    "url": "http://arxiv.org/pdf/2309.04350v1"
  },
  {
    "id": "2309.03470v1",
    "title": "Machine Learning for Tangible Effects: Natural Language Processing for Uncovering the Illicit Massage Industry & Computer Vision for Tactile Sensing",
    "authors": [
      "Rui Ouyang"
    ],
    "abstract": "I explore two questions in this thesis: how can computer science be used to\nfight human trafficking? And how can computer vision create a sense of touch?\n  I use natural language processing (NLP) to monitor the United States illicit\nmassage industry (IMI), a multi-billion dollar industry that offers not just\ntherapeutic massages but also commercial sexual services. Employees of this\nindustry are often immigrant women with few job opportunities, leaving them\nvulnerable to fraud, coercion, and other facets of human trafficking.\nMonitoring spatiotemporal trends helps prevent trafficking in the IMI. By\ncreating datasets with three publicly-accessible websites: Google Places,\nRubmaps, and AMPReviews, combined with NLP techniques such as bag-of-words and\nWord2Vec, I show how to derive insights into the labor pressures and language\nbarriers that employees face, as well as the income, demographics, and societal\npressures affecting sex buyers. I include a call-to-action to other researchers\ngiven these datasets. I also consider how to creating synthetic financial data,\nwhich can aid with counter-trafficking in the banking sector. I use an\nagent-based model to create both tabular and payee-recipient graph data.\n  I then consider the role of computer vision in making tactile sensors. I\nreport on a novel sensor, the Digger Finger, that adapts the Gelsight sensor to\nfinding objects in granular media. Changes include using a wedge shape to\nfacilitate digging, replacing the internal lighting LEDs with fluorescent\npaint, and adding a vibrator motor to counteract jamming. Finally, I also show\nhow to use a webcam and a printed reference marker, or fiducial, to create a\nlow-cost six-axis force-torque sensor. This sensor is up to a hundred times\nless expensive than commercial sensors, allowing for a wider range of\napplications. For this and earlier chapters I release design files and code as\nopen source.",
    "categories": [
      "cs.CL",
      "cs.CY",
      "cs.SI"
    ],
    "published": "2023-09-07T04:04:01+00:00",
    "updated": "2023-09-07T04:04:01+00:00",
    "url": "http://arxiv.org/pdf/2309.03470v1"
  },
  {
    "id": "2309.03303v1",
    "title": "A Novel Approach for Invoice Management using Blockchain",
    "authors": [
      "Nikhil Sontakke",
      "Shivansh Rastogi",
      "Sejal Utekar",
      "Shriraj Sonawane"
    ],
    "abstract": "Electronic invoicing is another area where blockchain technology is being\nused. Additionally, it has the power to alter how payments are made, invoices\nare issued, and transactions are validated. Using a blockchain-based invoicing\nsystem will enable smooth payments from a customer's digital wallet to a\nbusiness's digital wallet. Transactions are simple to track and monitor, and\nthe blockchain may be used to retrieve an exchange's full history. Sometimes\nshopkeepers create fake bills and submit them to the higher tax-paying\nauthorities. To bring transparency to this billing system between customers,\nshopkeepers, and tax-paying authorities billing system using blockchain is to\nbe implemented using the concept of Blockchain and make the billing system in\nour country work smoothly. Blockchain technology can revolutionize the\ninvoicing and payment process by providing a secure, transparent and\ntamper-proof system. A blockchain-based billing system can facilitate smooth\npayments, allow for easy tracking and monitoring of transactions, and provide a\ntamper-proof history of all exchanges. The use of blockchain can prevent fraud\nand increase transparency among customers, shopkeepers, and tax-paying\nauthorities. Furthermore, it can streamline the process by using digital\nwallets for both customers and businesses, reducing time and resources for\ntraditional invoicing methods. Overall, blockchain technology can bring greater\nefficiency and trust to the billing system, benefiting all parties involved. It\ncan prevent fraud, increase transparency and streamline the invoicing and\npayment process. This technology can create a more secure and efficient billing\nsystem ultimately benefiting all parties involved.",
    "categories": [
      "cs.CR"
    ],
    "published": "2023-09-06T18:26:40+00:00",
    "updated": "2023-09-06T18:26:40+00:00",
    "url": "http://arxiv.org/pdf/2309.03303v1"
  },
  {
    "id": "2309.12364v1",
    "title": "Optimizing Traversing and Retrieval Speed of Large Breached Databases",
    "authors": [
      "Mayank Gite"
    ],
    "abstract": "Breached data refers to the unauthorized access, theft, or exposure of\nconfidential or sensitive information. Breaches typically occur when malicious\nactors or unauthorized users breach secure systems or networks, resulting in\ncompromised personally identifiable information (PII), protected or personal\nhealth information (PHI), payment card industry (PCI) information, or other\nsensitive data. Data breaches are often the result of malicious activities such\nas hacking, phishing, insider threats, malware, or physical theft. The misuse\nof breached data can lead to identity theft, fraud, spamming, or blackmailing.\nOrganizations that experience data breaches may face legal and financial\nconsequences, reputational damage, and harm to their customers or users.\nBreached records are commonly sold on the dark web or made available on various\npublic forums. To counteract these malicious activities, it is possible to\ncollect breached databases and mitigate potential harm. These databases can be\nquite large, reaching sizes of up to 150 GB or more. Typically, breached data\nis stored in the CSV (Comma Separated Value) format due to its simplicity and\nlightweight nature, which reduces storage requirements. Analyzing and\ntraversing large breached databases necessitates substantial computational\npower. However, this research explores techniques to optimize database\ntraversal speed without the need to rent expensive cloud machines or virtual\nprivate servers (VPS). This optimization will enable individual security\nresearchers to analyze and process large databases on their personal computer\nsystems while significantly reducing costs.",
    "categories": [
      "cs.DB",
      "cs.CR"
    ],
    "published": "2023-09-06T13:11:18+00:00",
    "updated": "2023-09-06T13:11:18+00:00",
    "url": "http://arxiv.org/pdf/2309.12364v1"
  },
  {
    "id": "2309.02012v1",
    "title": "iLoRE: Dynamic Graph Representation with Instant Long-term Modeling and Re-occurrence Preservation",
    "authors": [
      "Siwei Zhang",
      "Yun Xiong",
      "Yao Zhang",
      "Xixi Wu",
      "Yiheng Sun",
      "Jiawei Zhang"
    ],
    "abstract": "Continuous-time dynamic graph modeling is a crucial task for many real-world\napplications, such as financial risk management and fraud detection. Though\nexisting dynamic graph modeling methods have achieved satisfactory results,\nthey still suffer from three key limitations, hindering their scalability and\nfurther applicability. i) Indiscriminate updating. For incoming edges, existing\nmethods would indiscriminately deal with them, which may lead to more time\nconsumption and unexpected noisy information. ii) Ineffective node-wise\nlong-term modeling. They heavily rely on recurrent neural networks (RNNs) as a\nbackbone, which has been demonstrated to be incapable of fully capturing\nnode-wise long-term dependencies in event sequences. iii) Neglect of\nre-occurrence patterns. Dynamic graphs involve the repeated occurrence of\nneighbors that indicates their importance, which is disappointedly neglected by\nexisting methods. In this paper, we present iLoRE, a novel dynamic graph\nmodeling method with instant node-wise Long-term modeling and Re-occurrence\npreservation. To overcome the indiscriminate updating issue, we introduce the\nAdaptive Short-term Updater module that will automatically discard the useless\nor noisy edges, ensuring iLoRE's effectiveness and instant ability. We further\npropose the Long-term Updater to realize more effective node-wise long-term\nmodeling, where we innovatively propose the Identity Attention mechanism to\nempower a Transformer-based updater, bypassing the limited effectiveness of\ntypical RNN-dominated designs. Finally, the crucial re-occurrence patterns are\nalso encoded into a graph module for informative representation learning, which\nwill further improve the expressiveness of our method. Our experimental results\non real-world datasets demonstrate the effectiveness of our iLoRE for dynamic\ngraph modeling.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "published": "2023-09-05T07:48:52+00:00",
    "updated": "2023-09-05T07:48:52+00:00",
    "url": "http://arxiv.org/pdf/2309.02012v1"
  },
  {
    "id": "2309.01586v1",
    "title": "Automatic Scam-Baiting Using ChatGPT",
    "authors": [
      "Piyush Bajaj",
      "Matthew Edwards"
    ],
    "abstract": "Automatic scam-baiting is an online fraud countermeasure that involves\nautomated systems responding to online fraudsters in order to waste their time\nand deplete their resources, diverting attackers away from real potential\nvictims. Previous work has demonstrated that text generation systems are\ncapable of engaging with attackers as automatic scam-baiters, but the fluency\nand coherence of generated text may be a limit to the effectiveness of such\nsystems.\n  In this paper, we report on the results of a month-long experiment comparing\nthe effectiveness of two ChatGPT-based automatic scam-baiters to a control\nmeasure. Within our results, with engagement from over 250 real email\nfraudsters, we find that ChatGPT-based scam-baiters show a marked increase in\nscammer response rate and conversation length relative to the control measure,\noutperforming previous approaches. We discuss the implications of these results\nand practical considerations for wider deployment of automatic scam-baiting.",
    "categories": [
      "cs.CR"
    ],
    "published": "2023-09-04T13:13:35+00:00",
    "updated": "2023-09-04T13:13:35+00:00",
    "url": "http://arxiv.org/pdf/2309.01586v1"
  },
  {
    "id": "2309.01472v1",
    "title": "FinDiff: Diffusion Models for Financial Tabular Data Generation",
    "authors": [
      "Timur Sattarov",
      "Marco Schreyer",
      "Damian Borth"
    ],
    "abstract": "The sharing of microdata, such as fund holdings and derivative instruments,\nby regulatory institutions presents a unique challenge due to strict data\nconfidentiality and privacy regulations. These challenges often hinder the\nability of both academics and practitioners to conduct collaborative research\neffectively. The emergence of generative models, particularly diffusion models,\ncapable of synthesizing data mimicking the underlying distributions of\nreal-world data presents a compelling solution. This work introduces 'FinDiff',\na diffusion model designed to generate real-world financial tabular data for a\nvariety of regulatory downstream tasks, for example economic scenario modeling,\nstress tests, and fraud detection. The model uses embedding encodings to model\nmixed modality financial data, comprising both categorical and numeric\nattributes. The performance of FinDiff in generating synthetic tabular\nfinancial data is evaluated against state-of-the-art baseline models using\nthree real-world financial datasets (including two publicly available datasets\nand one proprietary dataset). Empirical results demonstrate that FinDiff excels\nin generating synthetic tabular financial data with high fidelity, privacy, and\nutility.",
    "categories": [
      "cs.LG",
      "q-fin.ST"
    ],
    "published": "2023-09-04T09:30:15+00:00",
    "updated": "2023-09-04T09:30:15+00:00",
    "url": "http://arxiv.org/pdf/2309.01472v1"
  },
  {
    "id": "2309.01127v1",
    "title": "Financial Fraud Detection using Quantum Graph Neural Networks",
    "authors": [
      "Nouhaila Innan",
      "Abhishek Sawaika",
      "Ashim Dhor",
      "Siddhant Dutta",
      "Sairupa Thota",
      "Husayn Gokal",
      "Nandan Patel",
      "Muhammad Al-Zafar Khan",
      "Ioannis Theodonis",
      "Mohamed Bennai"
    ],
    "abstract": "Financial fraud detection is essential for preventing significant financial\nlosses and maintaining the reputation of financial institutions. However,\nconventional methods of detecting financial fraud have limited effectiveness,\nnecessitating the need for new approaches to improve detection rates. In this\npaper, we propose a novel approach for detecting financial fraud using Quantum\nGraph Neural Networks (QGNNs). QGNNs are a type of neural network that can\nprocess graph-structured data and leverage the power of Quantum Computing (QC)\nto perform computations more efficiently than classical neural networks. Our\napproach uses Variational Quantum Circuits (VQC) to enhance the performance of\nthe QGNN. In order to evaluate the efficiency of our proposed method, we\ncompared the performance of QGNNs to Classical Graph Neural Networks using a\nreal-world financial fraud detection dataset. The results of our experiments\nshowed that QGNNs achieved an AUC of $0.85$, which outperformed classical GNNs.\nOur research highlights the potential of QGNNs and suggests that QGNNs are a\npromising new approach for improving financial fraud detection.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2023-09-03T09:42:49+00:00",
    "updated": "2023-09-03T09:42:49+00:00",
    "url": "http://arxiv.org/pdf/2309.01127v1"
  },
  {
    "id": "2309.00088v1",
    "title": "Deep Semi-Supervised Anomaly Detection for Finding Fraud in the Futures Market",
    "authors": [
      "Timothy DeLise"
    ],
    "abstract": "Modern financial electronic exchanges are an exciting and fast-paced\nmarketplace where billions of dollars change hands every day. They are also\nrife with manipulation and fraud. Detecting such activity is a major\nundertaking, which has historically been a job reserved exclusively for humans.\nRecently, more research and resources have been focused on automating these\nprocesses via machine learning and artificial intelligence. Fraud detection is\noverwhelmingly associated with the greater field of anomaly detection, which is\nusually performed via unsupervised learning techniques because of the lack of\nlabeled data needed for supervised learning. However, a small quantity of\nlabeled data does often exist. This research article aims to evaluate the\nefficacy of a deep semi-supervised anomaly detection technique, called Deep\nSAD, for detecting fraud in high-frequency financial data. We use exclusive\nproprietary limit order book data from the TMX exchange in Montr\\'eal, with a\nsmall set of true labeled instances of fraud, to evaluate Deep SAD against its\nunsupervised predecessor. We show that incorporating a small amount of labeled\ndata into an unsupervised anomaly detection framework can greatly improve its\naccuracy.",
    "categories": [
      "cs.LG",
      "q-fin.RM",
      "91G99"
    ],
    "published": "2023-08-31T19:07:50+00:00",
    "updated": "2023-08-31T19:07:50+00:00",
    "url": "http://arxiv.org/pdf/2309.00088v1"
  },
  {
    "id": "2308.16538v1",
    "title": "The AI Revolution: Opportunities and Challenges for the Finance Sector",
    "authors": [
      "Carsten Maple",
      "Lukasz Szpruch",
      "Gregory Epiphaniou",
      "Kalina Staykova",
      "Simran Singh",
      "William Penwarden",
      "Yisi Wen",
      "Zijian Wang",
      "Jagdish Hariharan",
      "Pavle Avramovic"
    ],
    "abstract": "This report examines Artificial Intelligence (AI) in the financial sector,\noutlining its potential to revolutionise the industry and identify its\nchallenges. It underscores the criticality of a well-rounded understanding of\nAI, its capabilities, and its implications to effectively leverage its\npotential while mitigating associated risks. The potential of AI potential\nextends from augmenting existing operations to paving the way for novel\napplications in the finance sector. The application of AI in the financial\nsector is transforming the industry. Its use spans areas from customer service\nenhancements, fraud detection, and risk management to credit assessments and\nhigh-frequency trading. However, along with these benefits, AI also presents\nseveral challenges. These include issues related to transparency,\ninterpretability, fairness, accountability, and trustworthiness. The use of AI\nin the financial sector further raises critical questions about data privacy\nand security. A further issue identified in this report is the systemic risk\nthat AI can introduce to the financial sector. Being prone to errors, AI can\nexacerbate existing systemic risks, potentially leading to financial crises.\nRegulation is crucial to harnessing the benefits of AI while mitigating its\npotential risks. Despite the global recognition of this need, there remains a\nlack of clear guidelines or legislation for AI use in finance. This report\ndiscusses key principles that could guide the formation of effective AI\nregulation in the financial sector, including the need for a risk-based\napproach, the inclusion of ethical considerations, and the importance of\nmaintaining a balance between innovation and consumer protection. The report\nprovides recommendations for academia, the finance industry, and regulators.",
    "categories": [
      "cs.AI"
    ],
    "published": "2023-08-31T08:30:09+00:00",
    "updated": "2023-08-31T08:30:09+00:00",
    "url": "http://arxiv.org/pdf/2308.16538v1"
  },
  {
    "id": "2308.16391v2",
    "title": "Improving the Accuracy of Transaction-Based Ponzi Detection on Ethereum",
    "authors": [
      "Phuong Duy Huynh",
      "Son Hoang Dau",
      "Xiaodong Li",
      "Phuc Luong",
      "Emanuele Viterbo"
    ],
    "abstract": "The Ponzi scheme, an old-fashioned fraud, is now popular on the Ethereum\nblockchain, causing considerable financial losses to many crypto investors. A\nfew Ponzi detection methods have been proposed in the literature, most of which\ndetect a Ponzi scheme based on its smart contract source code. This\ncontract-code-based approach, while achieving very high accuracy, is not robust\nbecause a Ponzi developer can fool a detection model by obfuscating the opcode\nor inventing a new profit distribution logic that cannot be detected. On the\ncontrary, a transaction-based approach could improve the robustness of\ndetection because transactions, unlike smart contracts, are harder to be\nmanipulated. However, the current transaction-based detection models achieve\nfairly low accuracy. In this paper, we aim to improve the accuracy of the\ntransaction-based models by employing time-series features, which turn out to\nbe crucial in capturing the life-time behaviour a Ponzi application but were\ncompletely overlooked in previous works. We propose a new set of 85 features\n(22 known account-based and 63 new time-series features), which allows\noff-the-shelf machine learning algorithms to achieve up to 30% higher F1-scores\ncompared to existing works.",
    "categories": [
      "cs.CR",
      "cs.CE",
      "cs.LG",
      "q-fin.ST"
    ],
    "published": "2023-08-31T01:54:31+00:00",
    "updated": "2024-07-18T03:05:50+00:00",
    "url": "http://arxiv.org/pdf/2308.16391v2"
  },
  {
    "id": "2308.15992v3",
    "title": "AI-powered Fraud Detection in Decentralized Finance: A Project Life Cycle Perspective",
    "authors": [
      "Bingqiao Luo",
      "Zhen Zhang",
      "Qian Wang",
      "Anli Ke",
      "Shengliang Lu",
      "Bingsheng He"
    ],
    "abstract": "In recent years, blockchain technology has introduced decentralized finance\n(DeFi) as an alternative to traditional financial systems. DeFi aims to create\na transparent and efficient financial ecosystem using smart contracts and\nemerging decentralized applications. However, the growing popularity of DeFi\nhas made it a target for fraudulent activities, resulting in losses of billions\nof dollars due to various types of frauds. To address these issues, researchers\nhave explored the potential of artificial intelligence (AI) approaches to\ndetect such fraudulent activities. Yet, there is a lack of a systematic survey\nto organize and summarize those existing works and to identify the future\nresearch opportunities. In this survey, we provide a systematic taxonomy of\nvarious frauds in the DeFi ecosystem, categorized by the different stages of a\nDeFi project's life cycle: project development, introduction, growth, maturity,\nand decline. This taxonomy is based on our finding: many frauds have strong\ncorrelations in the stage of the DeFi project. According to the taxonomy, we\nreview existing AI-powered detection methods, including statistical modeling,\nnatural language processing and other machine learning techniques, etc. We find\nthat fraud detection in different stages employs distinct types of methods and\nobserve the commendable performance of tree-based and graph-related models in\ntackling fraud detection tasks. By analyzing the challenges and trends, we\npresent the findings to provide proactive suggestion and guide future research\nin DeFi fraud detection. We believe that this survey is able to support\nresearchers, practitioners, and regulators in establishing a secure and\ntrustworthy DeFi ecosystem.",
    "categories": [
      "cs.CE"
    ],
    "published": "2023-08-30T12:24:55+00:00",
    "updated": "2024-03-13T11:17:46+00:00",
    "url": "http://arxiv.org/pdf/2308.15992v3"
  },
  {
    "id": "2308.14752v1",
    "title": "AI Deception: A Survey of Examples, Risks, and Potential Solutions",
    "authors": [
      "Peter S. Park",
      "Simon Goldstein",
      "Aidan O'Gara",
      "Michael Chen",
      "Dan Hendrycks"
    ],
    "abstract": "This paper argues that a range of current AI systems have learned how to\ndeceive humans. We define deception as the systematic inducement of false\nbeliefs in the pursuit of some outcome other than the truth. We first survey\nempirical examples of AI deception, discussing both special-use AI systems\n(including Meta's CICERO) built for specific competitive situations, and\ngeneral-purpose AI systems (such as large language models). Next, we detail\nseveral risks from AI deception, such as fraud, election tampering, and losing\ncontrol of AI systems. Finally, we outline several potential solutions to the\nproblems posed by AI deception: first, regulatory frameworks should subject AI\nsystems that are capable of deception to robust risk-assessment requirements;\nsecond, policymakers should implement bot-or-not laws; and finally,\npolicymakers should prioritize the funding of relevant research, including\ntools to detect AI deception and to make AI systems less deceptive.\nPolicymakers, researchers, and the broader public should work proactively to\nprevent AI deception from destabilizing the shared foundations of our society.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "published": "2023-08-28T17:59:35+00:00",
    "updated": "2023-08-28T17:59:35+00:00",
    "url": "http://arxiv.org/pdf/2308.14752v1"
  },
  {
    "id": "2308.14215v1",
    "title": "TimeTrail: Unveiling Financial Fraud Patterns through Temporal Correlation Analysis",
    "authors": [
      "Sushrut Ghimire"
    ],
    "abstract": "In the field of financial fraud detection, understanding the underlying\npatterns and dynamics is important to ensure effective and reliable systems.\nThis research introduces a new technique, \"TimeTrail,\" which employs advanced\ntemporal correlation analysis to explain complex financial fraud patterns. The\ntechnique leverages time-related insights to provide transparent and\ninterpretable explanations for fraud detection decisions, enhancing\naccountability and trust.\n  The \"TimeTrail\" methodology consists of three key phases: temporal data\nenrichment, dynamic correlation analysis, and interpretable pattern\nvisualization. Initially, raw financial transaction data is enriched with\ntemporal attributes. Dynamic correlations between these attributes are then\nquantified using innovative statistical measures. Finally, a unified\nvisualization framework presents these correlations in an interpretable manner.\nTo validate the effectiveness of \"TimeTrail,\" a study is conducted on a diverse\nfinancial dataset, surrounding various fraud scenarios. Results demonstrate the\ntechnique's capability to uncover hidden temporal correlations and patterns,\nperforming better than conventional methods in both accuracy and\ninterpretability. Moreover, a case study showcasing the application of\n\"TimeTrail\" in real-world scenarios highlights its utility for fraud detection.",
    "categories": [
      "cs.LG",
      "q-fin.ST"
    ],
    "published": "2023-08-27T22:27:57+00:00",
    "updated": "2023-08-27T22:27:57+00:00",
    "url": "http://arxiv.org/pdf/2308.14215v1"
  },
  {
    "id": "2310.05941v1",
    "title": "The Ripple Effect of Retraction on an Author's Collaboration Network",
    "authors": [
      "Kiran Sharma",
      "Satyam Mukherjee"
    ],
    "abstract": "Scientists involved in scientific misconduct may face social stigmatization,\nleading to isolation and limited opportunities for collaboration. The\nreputation of every individual is reflected on the team, as the fraud attempted\nby any member will be reflected on the team. Earlier studies pointed out the\nimpact of citation penalty on the prior work of coauthors, the effect of\nretraction on a co-author's research career, and stigmatization through mere\nassociation. This paper explores the formation and dynamics of the networks of\nauthors who faced retractions and their \"innocent coauthors\" who never faced\nretractions in their careers. Leveraging a dataset of 5972 retracted papers\ninvolving 24209 authors, we investigate whether scientific misconduct reduces\ncollaborative ties of misconducting authors as opposed to those who never faced\nallegations of academic misconduct. We observe that the network structure of\nauthors involved in retractions does not change significantly over the years\ncompared to that of the \"innocent coauthors\". Our results suggest that\nstigmatization rarely affects the collaboration network of stigmatized authors.\nOur findings have implications for institutions adopting stringent measures and\nfostering ethical practices research.",
    "categories": [
      "cs.DL"
    ],
    "published": "2023-08-27T09:38:54+00:00",
    "updated": "2023-08-27T09:38:54+00:00",
    "url": "http://arxiv.org/pdf/2310.05941v1"
  },
  {
    "id": "2308.12833v1",
    "title": "Use of LLMs for Illicit Purposes: Threats, Prevention Measures, and Vulnerabilities",
    "authors": [
      "Maximilian Mozes",
      "Xuanli He",
      "Bennett Kleinberg",
      "Lewis D. Griffin"
    ],
    "abstract": "Spurred by the recent rapid increase in the development and distribution of\nlarge language models (LLMs) across industry and academia, much recent work has\ndrawn attention to safety- and security-related threats and vulnerabilities of\nLLMs, including in the context of potentially criminal activities.\nSpecifically, it has been shown that LLMs can be misused for fraud,\nimpersonation, and the generation of malware; while other authors have\nconsidered the more general problem of AI alignment. It is important that\ndevelopers and practitioners alike are aware of security-related problems with\nsuch models. In this paper, we provide an overview of existing - predominantly\nscientific - efforts on identifying and mitigating threats and vulnerabilities\narising from LLMs. We present a taxonomy describing the relationship between\nthreats caused by the generative capabilities of LLMs, prevention measures\nintended to address such threats, and vulnerabilities arising from imperfect\nprevention measures. With our work, we hope to raise awareness of the\nlimitations of LLMs in light of such security concerns, among both experienced\ndevelopers and novel users of such technologies.",
    "categories": [
      "cs.CL",
      "cs.CR"
    ],
    "published": "2023-08-24T14:45:50+00:00",
    "updated": "2023-08-24T14:45:50+00:00",
    "url": "http://arxiv.org/pdf/2308.12833v1"
  },
  {
    "id": "2308.12770v3",
    "title": "WavMark: Watermarking for Audio Generation",
    "authors": [
      "Guangyu Chen",
      "Yu Wu",
      "Shujie Liu",
      "Tao Liu",
      "Xiaoyong Du",
      "Furu Wei"
    ],
    "abstract": "Recent breakthroughs in zero-shot voice synthesis have enabled imitating a\nspeaker's voice using just a few seconds of recording while maintaining a high\nlevel of realism. Alongside its potential benefits, this powerful technology\nintroduces notable risks, including voice fraud and speaker impersonation.\nUnlike the conventional approach of solely relying on passive methods for\ndetecting synthetic data, watermarking presents a proactive and robust defence\nmechanism against these looming risks. This paper introduces an innovative\naudio watermarking framework that encodes up to 32 bits of watermark within a\nmere 1-second audio snippet. The watermark is imperceptible to human senses and\nexhibits strong resilience against various attacks. It can serve as an\neffective identifier for synthesized voices and holds potential for broader\napplications in audio copyright protection. Moreover, this framework boasts\nhigh flexibility, allowing for the combination of multiple watermark segments\nto achieve heightened robustness and expanded capacity. Utilizing 10 to\n20-second audio as the host, our approach demonstrates an average Bit Error\nRate (BER) of 0.48\\% across ten common attacks, a remarkable reduction of over\n2800\\% in BER compared to the state-of-the-art watermarking tool. See\nhttps://aka.ms/wavmark for demos of our work.",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "published": "2023-08-24T13:17:35+00:00",
    "updated": "2024-01-07T07:05:37+00:00",
    "url": "http://arxiv.org/pdf/2308.12770v3"
  },
  {
    "id": "2310.14429v1",
    "title": "Text generation for dataset augmentation in security classification tasks",
    "authors": [
      "Alexander P. Welsh",
      "Matthew Edwards"
    ],
    "abstract": "Security classifiers, designed to detect malicious content in computer\nsystems and communications, can underperform when provided with insufficient\ntraining data. In the security domain, it is often easy to find samples of the\nnegative (benign) class, and challenging to find enough samples of the positive\n(malicious) class to train an effective classifier. This study evaluates the\napplication of natural language text generators to fill this data gap in\nmultiple security-related text classification tasks. We describe a variety of\npreviously-unexamined language-model fine-tuning approaches for this purpose\nand consider in particular the impact of disproportionate class-imbalances in\nthe training set. Across our evaluation using three state-of-the-art\nclassifiers designed for offensive language detection, review fraud detection,\nand SMS spam detection, we find that models trained with GPT-3 data\naugmentation strategies outperform both models trained without augmentation and\nmodels trained using basic data augmentation strategies already in common\nusage. In particular, we find substantial benefits for GPT-3 data augmentation\nstrategies in situations with severe limitations on known positive-class\nsamples.",
    "categories": [
      "cs.CR",
      "cs.CL"
    ],
    "published": "2023-10-22T22:25:14+00:00",
    "updated": "2023-10-22T22:25:14+00:00",
    "url": "http://arxiv.org/pdf/2310.14429v1"
  },
  {
    "id": "2310.08800v2",
    "title": "DDMT: Denoising Diffusion Mask Transformer Models for Multivariate Time Series Anomaly Detection",
    "authors": [
      "Chaocheng Yang",
      "Tingyin Wang",
      "Xuanhui Yan"
    ],
    "abstract": "Anomaly detection in multivariate time series has emerged as a crucial\nchallenge in time series research, with significant research implications in\nvarious fields such as fraud detection, fault diagnosis, and system state\nestimation. Reconstruction-based models have shown promising potential in\nrecent years for detecting anomalies in time series data. However, due to the\nrapid increase in data scale and dimensionality, the issues of noise and Weak\nIdentity Mapping (WIM) during time series reconstruction have become\nincreasingly pronounced. To address this, we introduce a novel Adaptive Dynamic\nNeighbor Mask (ADNM) mechanism and integrate it with the Transformer and\nDenoising Diffusion Model, creating a new framework for multivariate time\nseries anomaly detection, named Denoising Diffusion Mask Transformer (DDMT).\nThe ADNM module is introduced to mitigate information leakage between input and\noutput features during data reconstruction, thereby alleviating the problem of\nWIM during reconstruction. The Denoising Diffusion Transformer (DDT) employs\nthe Transformer as an internal neural network structure for Denoising Diffusion\nModel. It learns the stepwise generation process of time series data to model\nthe probability distribution of the data, capturing normal data patterns and\nprogressively restoring time series data by removing noise, resulting in a\nclear recovery of anomalies. To the best of our knowledge, this is the first\nmodel that combines Denoising Diffusion Model and the Transformer for\nmultivariate time series anomaly detection. Experimental evaluations were\nconducted on five publicly available multivariate time series anomaly detection\ndatasets. The results demonstrate that the model effectively identifies\nanomalies in time series data, achieving state-of-the-art performance in\nanomaly detection.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2023-10-13T01:18:41+00:00",
    "updated": "2023-10-30T06:23:59+00:00",
    "url": "http://arxiv.org/pdf/2310.08800v2"
  },
  {
    "id": "2310.08335v1",
    "title": "2SFGL: A Simple And Robust Protocol For Graph-Based Fraud Detection",
    "authors": [
      "Zhirui Pan",
      "Guangzhong Wang",
      "Zhaoning Li",
      "Lifeng Chen",
      "Yang Bian",
      "Zhongyuan Lai"
    ],
    "abstract": "Financial crime detection using graph learning improves financial safety and\nefficiency. However, criminals may commit financial crimes across different\ninstitutions to avoid detection, which increases the difficulty of detection\nfor financial institutions which use local data for graph learning. As most\nfinancial institutions are subject to strict regulations in regards to data\nprivacy protection, the training data is often isolated and conventional\nlearning technology cannot handle the problem. Federated learning (FL) allows\nmultiple institutions to train a model without revealing their datasets to each\nother, hence ensuring data privacy protection. In this paper, we proposes a\nnovel two-stage approach to federated graph learning (2SFGL): The first stage\nof 2SFGL involves the virtual fusion of multiparty graphs, and the second\ninvolves model training and inference on the virtual graph. We evaluate our\nframework on a conventional fraud detection task based on the\nFraudAmazonDataset and FraudYelpDataset. Experimental results show that\nintegrating and applying a GCN (Graph Convolutional Network) with our 2SFGL\nframework to the same task results in a 17.6\\%-30.2\\% increase in performance\non several typical metrics compared to the case only using FedAvg, while\nintegrating GraphSAGE with 2SFGL results in a 6\\%-16.2\\% increase in\nperformance compared to the case only using FedAvg. We conclude that our\nproposed framework is a robust and simple protocol which can be simply\nintegrated to pre-existing graph-based fraud detection methods.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2023-10-12T13:48:26+00:00",
    "updated": "2023-10-12T13:48:26+00:00",
    "url": "http://arxiv.org/pdf/2310.08335v1"
  },
  {
    "id": "2310.04768v2",
    "title": "Online Corrupted User Detection and Regret Minimization",
    "authors": [
      "Zhiyong Wang",
      "Jize Xie",
      "Tong Yu",
      "Shuai Li",
      "John C. S. Lui"
    ],
    "abstract": "In real-world online web systems, multiple users usually arrive sequentially\ninto the system. For applications like click fraud and fake reviews, some users\ncan maliciously perform corrupted (disrupted) behaviors to trick the system.\nTherefore, it is crucial to design efficient online learning algorithms to\nrobustly learn from potentially corrupted user behaviors and accurately\nidentify the corrupted users in an online manner. Existing works propose bandit\nalgorithms robust to adversarial corruption. However, these algorithms are\ndesigned for a single user, and cannot leverage the implicit social relations\namong multiple users for more efficient learning. Moreover, none of them\nconsider how to detect corrupted users online in the multiple-user scenario. In\nthis paper, we present an important online learning problem named LOCUD to\nlearn and utilize unknown user relations from disrupted behaviors to speed up\nlearning, and identify the corrupted users in an online setting. To robustly\nlearn and utilize the unknown relations among potentially corrupted users, we\npropose a novel bandit algorithm RCLUB-WCU. To detect the corrupted users, we\ndevise a novel online detection algorithm OCCUD based on RCLUB-WCU's inferred\nuser relations. We prove a regret upper bound for RCLUB-WCU, which\nasymptotically matches the lower bound with respect to $T$ up to logarithmic\nfactors, and matches the state-of-the-art results in degenerate cases. We also\ngive a theoretical guarantee for the detection accuracy of OCCUD. With\nextensive experiments, our methods achieve superior performance over previous\nbandit algorithms and high corrupted user detection accuracy.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-10-07T10:20:26+00:00",
    "updated": "2023-10-10T01:55:28+00:00",
    "url": "http://arxiv.org/pdf/2310.04768v2"
  },
  {
    "id": "2310.04546v1",
    "title": "Privacy-Preserving Financial Anomaly Detection via Federated Learning & Multi-Party Computation",
    "authors": [
      "Sunpreet Arora",
      "Andrew Beams",
      "Panagiotis Chatzigiannis",
      "Sebastian Meiser",
      "Karan Patel",
      "Srinivasan Raghuraman",
      "Peter Rindal",
      "Harshal Shah",
      "Yizhen Wang",
      "Yuhang Wu",
      "Hao Yang",
      "Mahdi Zamani"
    ],
    "abstract": "One of the main goals of financial institutions (FIs) today is combating\nfraud and financial crime. To this end, FIs use sophisticated machine-learning\nmodels trained using data collected from their customers. The output of machine\nlearning models may be manually reviewed for critical use cases, e.g.,\ndetermining the likelihood of a transaction being anomalous and the subsequent\ncourse of action. While advanced machine learning models greatly aid an FI in\nanomaly detection, model performance could be significantly improved using\nadditional customer data from other FIs. In practice, however, an FI may not\nhave appropriate consent from customers to share their data with other FIs.\nAdditionally, data privacy regulations may prohibit FIs from sharing clients'\nsensitive data in certain geographies. Combining customer data to jointly train\nhighly accurate anomaly detection models is therefore challenging for FIs in\noperational settings.\n  In this paper, we describe a privacy-preserving framework that allows FIs to\njointly train highly accurate anomaly detection models. The framework combines\nthe concept of federated learning with efficient multi-party computation and\nnoisy aggregates inspired by differential privacy. The presented framework was\nsubmitted as a winning entry to the financial crime detection track of the\nUS/UK PETs Challenge. The challenge considered an architecture where banks hold\ncustomer data and execute transactions through a central network. We show that\nour solution enables the network to train a highly accurate anomaly detection\nmodel while preserving privacy of customer data. Experimental results\ndemonstrate that use of additional customer data using the proposed approach\nresults in improvement of our anomaly detection model's AUPRC from 0.6 to 0.7.\nWe discuss how our framework, can be generalized to other similar scenarios.",
    "categories": [
      "cs.CR"
    ],
    "published": "2023-10-06T19:16:41+00:00",
    "updated": "2023-10-06T19:16:41+00:00",
    "url": "http://arxiv.org/pdf/2310.04546v1"
  },
  {
    "id": "2310.04171v3",
    "title": "Dynamic Relation-Attentive Graph Neural Networks for Fraud Detection",
    "authors": [
      "Heehyeon Kim",
      "Jinhyeok Choi",
      "Joyce Jiyoung Whang"
    ],
    "abstract": "Fraud detection aims to discover fraudsters deceiving other users by, for\nexample, leaving fake reviews or making abnormal transactions. Graph-based\nfraud detection methods consider this task as a classification problem with two\nclasses: frauds or normal. We address this problem using Graph Neural Networks\n(GNNs) by proposing a dynamic relation-attentive aggregation mechanism. Based\non the observation that many real-world graphs include different types of\nrelations, we propose to learn a node representation per relation and aggregate\nthe node representations using a learnable attention function that assigns a\ndifferent attention coefficient to each relation. Furthermore, we combine the\nnode representations from different layers to consider both the local and\nglobal structures of a target node, which is beneficial to improving the\nperformance of fraud detection on graphs with heterophily. By employing dynamic\ngraph attention in all the aggregation processes, our method adaptively\ncomputes the attention coefficients for each node. Experimental results show\nthat our method, DRAG, outperforms state-of-the-art fraud detection methods on\nreal-world benchmark datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "I.2"
    ],
    "published": "2023-10-06T11:41:38+00:00",
    "updated": "2024-01-03T07:32:11+00:00",
    "url": "http://arxiv.org/pdf/2310.04171v3"
  },
  {
    "id": "2310.02800v3",
    "title": "Everest: GPU-Accelerated System For Mining Temporal Motifs",
    "authors": [
      "Yichao Yuan",
      "Haojie Ye",
      "Sanketh Vedula",
      "Wynn Kaza",
      "Nishil Talati"
    ],
    "abstract": "Temporal motif mining is the task of finding the occurrences of subgraph\npatterns within a large input temporal graph that obey the specified structural\nand temporal constraints. Despite its utility in several critical application\ndomains that demand high performance (e.g., detecting fraud in financial\ntransaction graphs), the performance of existing software is limited on\ncommercial hardware platforms, in that it runs for tens of hours. This paper\npresents Everest - a system that efficiently maps the workload of mining\n(supports both enumeration and counting) temporal motifs to the highly parallel\nGPU architecture. In particular, using an input temporal graph and a more\nexpressive user-defined temporal motif query definition compared to prior\nworks, Everest generates an execution plan and runtime primitives that optimize\nthe workload execution by exploiting the high compute throughput of a GPU.\nEverest generates motif-specific mining code to reduce long-latency memory\naccesses and frequent thread divergence operations. Everest incorporates novel\nlow-cost runtime mechanisms to enable load balancing to improve GPU hardware\nutilization. To support large graphs that do not fit on GPU memory, Everest\nalso supports multi-GPU execution by intelligently partitioning the edge list\nthat prevents inter-GPU communication. Everest hides the implementation\ncomplexity of presented optimizations away from the targeted system user for\nbetter usability. Our evaluation shows that, using proposed optimizations,\nEverest improves the performance of a baseline GPU implementation by 19x, on\naverage.",
    "categories": [
      "cs.SE",
      "cs.DC"
    ],
    "published": "2023-10-04T13:21:04+00:00",
    "updated": "2023-10-11T15:24:40+00:00",
    "url": "http://arxiv.org/pdf/2310.02800v3"
  },
  {
    "id": "2310.00856v1",
    "title": "Multi-triplet Feature Augmentation for Ponzi Scheme Detection in Ethereum",
    "authors": [
      "Chengxiang Jin",
      "Jiajun Zhou",
      "Shengbo Gong",
      "Chenxuan Xie",
      "Qi Xuan"
    ],
    "abstract": "Blockchain technology revolutionizes the Internet, but also poses increasing\nrisks, particularly in cryptocurrency finance. On the Ethereum platform, Ponzi\nschemes, phishing scams, and a variety of other frauds emerge. Existing Ponzi\nscheme detection approaches based on heterogeneous transaction graph modeling\nleverages semantic information between node (account) pairs to establish\nconnections, overlooking the semantic attributes inherent to the edges\n(interactions). To overcome this, we construct heterogeneous Ethereum\ninteraction graphs with multiple triplet interaction patterns to better depict\nthe real Ethereum environment. Based on this, we design a new framework named\nmulti-triplet augmented heterogeneous graph neural network (MAHGNN) for Ponzi\nscheme detection. We introduce the Conditional Variational Auto Encoder (CVAE)\nto capture the semantic information of different triplet interaction patterns,\nwhich facilitates the characterization on account features. Extensive\nexperiments demonstrate that MAHGNN is capable of addressing the problem of\nmulti-edge interactions in heterogeneous Ethereum interaction graphs and\nachieving state-of-the-art performance in Ponzi scheme detection.",
    "categories": [
      "cs.SI"
    ],
    "published": "2023-10-02T02:36:44+00:00",
    "updated": "2023-10-02T02:36:44+00:00",
    "url": "http://arxiv.org/pdf/2310.00856v1"
  },
  {
    "id": "2310.00335v1",
    "title": "Anomaly Detection in Power Generation Plants with Generative Adversarial Networks",
    "authors": [
      "Marcellin Atemkeng",
      "Toheeb Aduramomi Jimoh"
    ],
    "abstract": "Anomaly detection is a critical task that involves the identification of data\npoints that deviate from a predefined pattern, useful for fraud detection and\nrelated activities. Various techniques are employed for anomaly detection, but\nrecent research indicates that deep learning methods, with their ability to\ndiscern intricate data patterns, are well-suited for this task. This study\nexplores the use of Generative Adversarial Networks (GANs) for anomaly\ndetection in power generation plants. The dataset used in this investigation\ncomprises fuel consumption records obtained from power generation plants\noperated by a telecommunications company. The data was initially collected in\nresponse to observed irregularities in the fuel consumption patterns of the\ngenerating sets situated at the company's base stations. The dataset was\ndivided into anomalous and normal data points based on specific variables, with\n64.88% classified as normal and 35.12% as anomalous. An analysis of feature\nimportance, employing the random forest classifier, revealed that Running Time\nPer Day exhibited the highest relative importance. A GANs model was trained and\nfine-tuned both with and without data augmentation, with the goal of increasing\nthe dataset size to enhance performance. The generator model consisted of five\ndense layers using the tanh activation function, while the discriminator\ncomprised six dense layers, each integrated with a dropout layer to prevent\noverfitting. Following data augmentation, the model achieved an accuracy rate\nof 98.99%, compared to 66.45% before augmentation. This demonstrates that the\nmodel nearly perfectly classified data points into normal and anomalous\ncategories, with the augmented data significantly enhancing the GANs'\nperformance in anomaly detection. Consequently, this study recommends the use\nof GANs, particularly when using large datasets, for effective anomaly\ndetection.",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "published": "2023-09-30T10:44:05+00:00",
    "updated": "2023-09-30T10:44:05+00:00",
    "url": "http://arxiv.org/pdf/2310.00335v1"
  },
  {
    "id": "2309.14880v1",
    "title": "Credit Card Fraud Detection with Subspace Learning-based One-Class Classification",
    "authors": [
      "Zaffar Zaffar",
      "Fahad Sohrab",
      "Juho Kanniainen",
      "Moncef Gabbouj"
    ],
    "abstract": "In an increasingly digitalized commerce landscape, the proliferation of\ncredit card fraud and the evolution of sophisticated fraudulent techniques have\nled to substantial financial losses. Automating credit card fraud detection is\na viable way to accelerate detection, reducing response times and minimizing\npotential financial losses. However, addressing this challenge is complicated\nby the highly imbalanced nature of the datasets, where genuine transactions\nvastly outnumber fraudulent ones. Furthermore, the high number of dimensions\nwithin the feature set gives rise to the ``curse of dimensionality\". In this\npaper, we investigate subspace learning-based approaches centered on One-Class\nClassification (OCC) algorithms, which excel in handling imbalanced data\ndistributions and possess the capability to anticipate and counter the\ntransactions carried out by yet-to-be-invented fraud techniques. The study\nhighlights the potential of subspace learning-based OCC algorithms by\ninvestigating the limitations of current fraud detection strategies and the\nspecific challenges of credit card fraud detection. These algorithms integrate\nsubspace learning into the data description; hence, the models transform the\ndata into a lower-dimensional subspace optimized for OCC. Through rigorous\nexperimentation and analysis, the study validated that the proposed approach\nhelps tackle the curse of dimensionality and the imbalanced nature of credit\ncard data for automatic fraud detection to mitigate financial losses caused by\nfraudulent activities.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-09-26T12:26:28+00:00",
    "updated": "2023-09-26T12:26:28+00:00",
    "url": "http://arxiv.org/pdf/2309.14880v1"
  },
  {
    "id": "2309.13531v1",
    "title": "Robust Principal Component Analysis using Density Power Divergence",
    "authors": [
      "Subhrajyoty Roy",
      "Ayanendranath Basu",
      "Abhik Ghosh"
    ],
    "abstract": "Principal component analysis (PCA) is a widely employed statistical tool used\nprimarily for dimensionality reduction. However, it is known to be adversely\naffected by the presence of outlying observations in the sample, which is quite\ncommon. Robust PCA methods using M-estimators have theoretical benefits, but\ntheir robustness drop substantially for high dimensional data. On the other end\nof the spectrum, robust PCA algorithms solving principal component pursuit or\nsimilar optimization problems have high breakdown, but lack theoretical\nrichness and demand high computational power compared to the M-estimators. We\nintroduce a novel robust PCA estimator based on the minimum density power\ndivergence estimator. This combines the theoretical strength of the\nM-estimators and the minimum divergence estimators with a high breakdown\nguarantee regardless of data dimension. We present a computationally efficient\nalgorithm for this estimate. Our theoretical findings are supported by\nextensive simulations and comparisons with existing robust PCA methods. We also\nshowcase the proposed algorithm's applicability on two benchmark datasets and a\ncredit card transactions dataset for fraud detection.",
    "categories": [
      "stat.ME",
      "stat.ML"
    ],
    "published": "2023-09-24T02:59:39+00:00",
    "updated": "2023-09-24T02:59:39+00:00",
    "url": "http://arxiv.org/pdf/2309.13531v1"
  },
  {
    "id": "2311.12663v1",
    "title": "Similar Document Template Matching Algorithm",
    "authors": [
      "Harshitha Yenigalla",
      "Bommareddy Revanth Srinivasa Reddy",
      "Batta Venkata Rahul",
      "Nannapuraju Hemanth Raju"
    ],
    "abstract": "This study outlines a comprehensive methodology for verifying medical\ndocuments, integrating advanced techniques in template extraction, comparison,\nand fraud detection. It begins with template extraction using sophisticated\nregion-of-interest (ROI) methods, incorporating contour analysis and edge\nidentification. Pre-processing steps ensure template clarity through\nmorphological operations and adaptive thresholding. The template comparison\nalgorithm utilizes advanced feature matching with key points and descriptors,\nenhancing robustness through histogram-based analysis for accounting\nvariations. Fraud detection involves the SSIM computation and OCR for textual\ninformation extraction. The SSIM quantifies structural similarity, aiding in\npotential match identification. OCR focuses on critical areas like patient\ndetails, provider information, and billing amounts. Extracted information is\ncompared with a reference dataset, and confidence thresholding ensures reliable\nfraud detection. Adaptive parameters enhance system flexibility for dynamic\nadjustments to varying document layouts. This methodology provides a robust\napproach to medical document verification, addressing complexities in template\nextraction, comparison, fraud detection, and adaptability to diverse document\nstructures.",
    "categories": [
      "cs.CV"
    ],
    "published": "2023-11-21T15:13:18+00:00",
    "updated": "2023-11-21T15:13:18+00:00",
    "url": "http://arxiv.org/pdf/2311.12663v1"
  },
  {
    "id": "2311.12336v1",
    "title": "Classification of Instagram fake users using supervised machine learning algorithms",
    "authors": [
      "Vertika Singh",
      "Naman Tolasaria",
      "Patel Meet Alpeshkumar",
      "Shreyash Bartwal"
    ],
    "abstract": "In the contemporary era, online social networks have become integral to\nsocial life, revolutionizing the way individuals manage their social\nconnections. While enhancing accessibility and immediacy, these networks have\nconcurrently given rise to challenges, notably the proliferation of fraudulent\nprofiles and online impersonation. This paper proposes an application designed\nto detect and neutralize such dishonest entities, with a focus on safeguarding\ncompanies from potential fraud. The user-centric design of the application\nensures accessibility for investigative agencies, particularly the criminal\nbranch, facilitating navigation of complex social media landscapes and\nintegration with existing investigative procedures",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "published": "2023-11-21T03:59:14+00:00",
    "updated": "2023-11-21T03:59:14+00:00",
    "url": "http://arxiv.org/pdf/2311.12336v1"
  },
  {
    "id": "2311.11961v2",
    "title": "NNG-Mix: Improving Semi-supervised Anomaly Detection with Pseudo-anomaly Generation",
    "authors": [
      "Hao Dong",
      "Gaëtan Frusque",
      "Yue Zhao",
      "Eleni Chatzi",
      "Olga Fink"
    ],
    "abstract": "Anomaly detection (AD) is essential in identifying rare and often critical\nevents in complex systems, finding applications in fields such as network\nintrusion detection, financial fraud detection, and fault detection in\ninfrastructure and industrial systems. While AD is typically treated as an\nunsupervised learning task due to the high cost of label annotation, it is more\npractical to assume access to a small set of labeled anomaly samples from\ndomain experts, as is the case for semi-supervised anomaly detection.\nSemi-supervised and supervised approaches can leverage such labeled data,\nresulting in improved performance. In this paper, rather than proposing a new\nsemi-supervised or supervised approach for AD, we introduce a novel algorithm\nfor generating additional pseudo-anomalies on the basis of the limited labeled\nanomalies and a large volume of unlabeled data. This serves as an augmentation\nto facilitate the detection of new anomalies. Our proposed algorithm, named\nNearest Neighbor Gaussian Mixup (NNG-Mix), efficiently integrates information\nfrom both labeled and unlabeled data to generate pseudo-anomalies. We compare\nthe performance of this novel algorithm with commonly applied augmentation\ntechniques, such as Mixup and Cutout. We evaluate NNG-Mix by training various\nexisting semi-supervised and supervised anomaly detection algorithms on the\noriginal training data along with the generated pseudo-anomalies. Through\nextensive experiments on 57 benchmark datasets in ADBench, reflecting different\ndata types, we demonstrate that NNG-Mix outperforms other data augmentation\nmethods. It yields significant performance improvements compared to the\nbaselines trained exclusively on the original training data. Notably, NNG-Mix\nyields up to 16.4%, 8.8%, and 8.0% improvements on Classical, CV, and NLP\ndatasets in ADBench. Our source code is available at\nhttps://github.com/donghao51/NNG-Mix.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2023-11-20T17:38:35+00:00",
    "updated": "2024-06-11T15:39:52+00:00",
    "url": "http://arxiv.org/pdf/2311.11961v2"
  },
  {
    "id": "2312.09442v2",
    "title": "A Compact LSTM-SVM Fusion Model for Long-Duration Cardiovascular Diseases Detection",
    "authors": [
      "Siyang Wu"
    ],
    "abstract": "Globally, cardiovascular diseases (CVDs) are the leading cause of mortality,\naccounting for an estimated 17.9 million deaths annually. One critical clinical\nobjective is the early detection of CVDs using electrocardiogram (ECG) data, an\narea that has received significant attention from the research community.\nRecent advancements based on machine learning and deep learning have achieved\ngreat progress in this domain. However, existing methodologies exhibit inherent\nlimitations, including inappropriate model evaluations and instances of data\nleakage. In this study, we present a streamlined workflow paradigm for\npreprocessing ECG signals into consistent 10-second durations, eliminating the\nneed for manual feature extraction/beat detection. We also propose a hybrid\nmodel of Long Short-Term Memory (LSTM) with Support Vector Machine (SVM) for\nfraud detection. This architecture consists of two LSTM layers and an SVM\nclassifier, which achieves a SOTA results with an Average precision score of\n0.9402 on the MIT-BIH arrhythmia dataset and 0.9563 on the MIT-BIH atrial\nfibrillation dataset. Based on the results, we believe our method can\nsignificantly benefit the early detection and management of CVDs.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2023-11-20T10:57:11+00:00",
    "updated": "2024-01-23T21:56:34+00:00",
    "url": "http://arxiv.org/pdf/2312.09442v2"
  },
  {
    "id": "2311.11021v1",
    "title": "Secure Software Development: Issues and Challenges",
    "authors": [
      "Sam Wen Ping",
      "Jeffrey Cheok Jun Wah",
      "Lee Wen Jie",
      "Jeremy Bong Yong Han",
      "Saira Muzafar"
    ],
    "abstract": "In recent years, technology has advanced considerably with the introduction\nof many systems including advanced robotics, big data analytics, cloud\ncomputing, machine learning and many more. The opportunities to exploit the yet\nto come security that comes with these systems are going toe to toe with new\nreleases of security protocols to combat this exploitation to provide a secure\nsystem. The digitization of our lives proves to solve our human problems as\nwell as improve quality of life but because it is digitalized, information and\ntechnology could be misused for other malicious gains. Hackers aim to steal the\ndata of innocent people to use it for other causes such as identity fraud,\nscams and many more. This issue can be corrected during the software\ndevelopment life cycle, integrating security across the development phases, and\ntesting of the software is done early to reduce the number of vulnerabilities\nthat might or might not heavily impact an organisation depending on the range\nof the attack. The goal of a secured system software is to prevent such\nexploitations from ever happening by conducting a system life cycle where\nthrough planning and testing is done to maximise security while maintaining\nfunctionality of the system. In this paper, we are going to discuss the recent\ntrends in security for system development as well as our predictions and\nsuggestions to improve the current security practices in this industry.",
    "categories": [
      "cs.CR",
      "cs.SE"
    ],
    "published": "2023-11-18T09:44:48+00:00",
    "updated": "2023-11-18T09:44:48+00:00",
    "url": "http://arxiv.org/pdf/2311.11021v1"
  },
  {
    "id": "2311.10370v1",
    "title": "Few-shot Message-Enhanced Contrastive Learning for Graph Anomaly Detection",
    "authors": [
      "Fan Xu",
      "Nan Wang",
      "Xuezhi Wen",
      "Meiqi Gao",
      "Chaoqun Guo",
      "Xibin Zhao"
    ],
    "abstract": "Graph anomaly detection plays a crucial role in identifying exceptional\ninstances in graph data that deviate significantly from the majority. It has\ngained substantial attention in various domains of information security,\nincluding network intrusion, financial fraud, and malicious comments, et al.\nExisting methods are primarily developed in an unsupervised manner due to the\nchallenge in obtaining labeled data. For lack of guidance from prior knowledge\nin unsupervised manner, the identified anomalies may prove to be data noise or\nindividual data instances. In real-world scenarios, a limited batch of labeled\nanomalies can be captured, making it crucial to investigate the few-shot\nproblem in graph anomaly detection. Taking advantage of this potential, we\npropose a novel few-shot Graph Anomaly Detection model called FMGAD (Few-shot\nMessage-Enhanced Contrastive-based Graph Anomaly Detector). FMGAD leverages a\nself-supervised contrastive learning strategy within and across views to\ncapture intrinsic and transferable structural representations. Furthermore, we\npropose the Deep-GNN message-enhanced reconstruction module, which extensively\nexploits the few-shot label information and enables long-range propagation to\ndisseminate supervision signals to deeper unlabeled nodes. This module in turn\nassists in the training of self-supervised contrastive learning. Comprehensive\nexperimental results on six real-world datasets demonstrate that FMGAD can\nachieve better performance than other state-of-the-art methods, regardless of\nartificially injected anomalies or domain-organic anomalies.",
    "categories": [
      "cs.LG"
    ],
    "published": "2023-11-17T07:49:20+00:00",
    "updated": "2023-11-17T07:49:20+00:00",
    "url": "http://arxiv.org/pdf/2311.10370v1"
  },
  {
    "id": "2311.08577v3",
    "title": "Finding AI-Generated Faces in the Wild",
    "authors": [
      "Gonzalo J. Aniano Porcile",
      "Jack Gindi",
      "Shivansh Mundra",
      "James R. Verbus",
      "Hany Farid"
    ],
    "abstract": "AI-based image generation has continued to rapidly improve, producing\nincreasingly more realistic images with fewer obvious visual flaws.\nAI-generated images are being used to create fake online profiles which in turn\nare being used for spam, fraud, and disinformation campaigns. As the general\nproblem of detecting any type of manipulated or synthesized content is\nreceiving increasing attention, here we focus on a more narrow task of\ndistinguishing a real face from an AI-generated face. This is particularly\napplicable when tackling inauthentic online accounts with a fake user profile\nphoto. We show that by focusing on only faces, a more resilient and\ngeneral-purpose artifact can be detected that allows for the detection of\nAI-generated faces from a variety of GAN- and diffusion-based synthesis\nengines, and across image resolutions (as low as 128 x 128 pixels) and\nqualities.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2023-11-14T22:46:01+00:00",
    "updated": "2024-04-05T17:37:36+00:00",
    "url": "http://arxiv.org/pdf/2311.08577v3"
  },
  {
    "id": "2311.08372v1",
    "title": "Aid Nexus : A Blockchain Based Financial Distribution System",
    "authors": [
      "Md. Raisul Hasan Shahrukh",
      "Md. Tabassinur Rahman",
      "Nafees Mansoor"
    ],
    "abstract": "Blockchain technology has emerged as a disruptive force with transformative\npotential across numerous industries, promising efficient and automated\nsolutions that can revolutionize traditional systems. By leveraging\ndecentralized ledger systems, blockchain offers enhanced security,\ntransparency, and transaction verification without the need for intermediaries.\nThe finance sector is exploring blockchain-based solutions for payments,\nremittances, lending, and investments, while healthcare adopts the technology\nfor medical record keeping, supply chain tracking, and data management.\nSimilarly, supply chain management benefits from blockchain's ability to\nenhance transparency, traceability, and accountability from raw materials to\nfinished products. Other sectors, including real estate, energy, and\ngovernment, are also investigating blockchain-based solutions to improve\nefficiency, security, and transparency. Furthermore, smart contracts within the\nblockchain enable process automation, reducing manual intervention in\ndistribution workflows. AidNeux, a consortium-based blockchain DApp, reimagines\nthe distribution of financial assistance by addressing inefficiencies and\nopaqueness. Using smart contracts ensures the security and directness of money\ntransfers. Its robust digital identity verification and real-time auditability\nreduce fraud risks and strengthen accountability, thereby presenting a\nscalable, transparent solution to problems inherent to conventional financial\naid systems.",
    "categories": [
      "cs.SE",
      "cs.CE",
      "cs.CR"
    ],
    "published": "2023-11-14T18:35:02+00:00",
    "updated": "2023-11-14T18:35:02+00:00",
    "url": "http://arxiv.org/pdf/2311.08372v1"
  },
  {
    "id": "2311.08370v2",
    "title": "SimpleSafetyTests: a Test Suite for Identifying Critical Safety Risks in Large Language Models",
    "authors": [
      "Bertie Vidgen",
      "Nino Scherrer",
      "Hannah Rose Kirk",
      "Rebecca Qian",
      "Anand Kannappan",
      "Scott A. Hale",
      "Paul Röttger"
    ],
    "abstract": "The past year has seen rapid acceleration in the development of large\nlanguage models (LLMs). However, without proper steering and safeguards, LLMs\nwill readily follow malicious instructions, provide unsafe advice, and generate\ntoxic content. We introduce SimpleSafetyTests (SST) as a new test suite for\nrapidly and systematically identifying such critical safety risks. The test\nsuite comprises 100 test prompts across five harm areas that LLMs, for the vast\nmajority of applications, should refuse to comply with. We test 11 open-access\nand open-source LLMs and four closed-source LLMs, and find critical safety\nweaknesses. While some of the models do not give a single unsafe response, most\ngive unsafe responses to more than 20% of the prompts, with over 50% unsafe\nresponses in the extreme. Prepending a safety-emphasising system prompt\nsubstantially reduces the occurrence of unsafe responses, but does not\ncompletely stop them from happening. Trained annotators labelled every model\nresponse to SST (n = 3,000). We use these annotations to evaluate five AI\nsafety filters (which assess whether a models' response is unsafe given a\nprompt) as a way of automatically evaluating models' performance on SST. The\nfilters' performance varies considerably. There are also differences across the\nfive harm areas, and on the unsafe versus safe responses. The widely-used\nPerspective API has 72% accuracy and a newly-created zero-shot prompt to\nOpenAI's GPT-4 performs best with 89% accuracy. Content Warning: This paper\ncontains prompts and responses that relate to child abuse, suicide, self-harm\nand eating disorders, scams and fraud, illegal items, and physical harm.",
    "categories": [
      "cs.CL"
    ],
    "published": "2023-11-14T18:33:43+00:00",
    "updated": "2024-02-16T09:42:19+00:00",
    "url": "http://arxiv.org/pdf/2311.08370v2"
  },
  {
    "id": "2311.07700v1",
    "title": "AuthentiGPT: Detecting Machine-Generated Text via Black-Box Language Models Denoising",
    "authors": [
      "Zhen Guo",
      "Shangdi Yu"
    ],
    "abstract": "Large language models (LLMs) have opened up enormous opportunities while\nsimultaneously posing ethical dilemmas. One of the major concerns is their\nability to create text that closely mimics human writing, which can lead to\npotential misuse, such as academic misconduct, disinformation, and fraud. To\naddress this problem, we present AuthentiGPT, an efficient classifier that\ndistinguishes between machine-generated and human-written texts. Under the\nassumption that human-written text resides outside the distribution of\nmachine-generated text, AuthentiGPT leverages a black-box LLM to denoise input\ntext with artificially added noise, and then semantically compares the denoised\ntext with the original to determine if the content is machine-generated. With\nonly one trainable parameter, AuthentiGPT eliminates the need for a large\ntraining dataset, watermarking the LLM's output, or computing the\nlog-likelihood. Importantly, the detection capability of AuthentiGPT can be\neasily adapted to any generative language model. With a 0.918 AUROC score on a\ndomain-specific dataset, AuthentiGPT demonstrates its effectiveness over other\ncommercial algorithms, highlighting its potential for detecting\nmachine-generated text in academic settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2023-11-13T19:36:54+00:00",
    "updated": "2023-11-13T19:36:54+00:00",
    "url": "http://arxiv.org/pdf/2311.07700v1"
  },
  {
    "id": "2311.04861v1",
    "title": "Sandi: A System for Accountability and Applications in Direct Communication (Extended Abstract)",
    "authors": [
      "F. Betül Durak",
      "Kim Laine",
      "Simon Langowski",
      "Radames Cruz Moreno",
      "Robert Sim",
      "Shrey Jain"
    ],
    "abstract": "Reputation systems guide our decision making both in life and work: which\nrestaurant to eat at, which vendor to buy from, which software dependencies to\nuse, and who or what to trust. These systems are often based on old ideas and\nare failing in the face of modern threats. Fraudsters have found ways to\nmanipulate them, undermining their integrity and utility. Generative AI adds to\nthe problem by enabling the creation of real-looking fake narratives at scale,\ncreating a false sense of consensus. Meanwhile, the need for reliable\nreputation concepts is more important than ever, as wrong decisions lead to\nincreasingly severe outcomes: wasted time, poor service, and a feeling of\ninjustice at best, fraud, identity theft, and ransomware at worst.\n  In this extended abstract we introduce Sandi, a new kind of reputation system\nwith a single well-defined purpose: to create trust through accountability in\none-to-one transactions. Examples of such transactions include sending an email\nor making a purchase online. Sandi has strong security and privacy properties\nthat make it suitable for use also in sensitive contexts. Furthermore, Sandi\ncan guarantee reputation integrity and transparency for its registered users.\n  As a primary application, we envision how Sandi could counter fraud and abuse\nin direct communication. Concretely, message senders request a cryptographic\ntag from Sandi that they send along with their message. If the receiver finds\nthe message inappropriate, they can report the sender using this tag. Notably,\nonly senders need registered accounts and do not need to manage long-term keys.\nThe design of Sandi ensures compatibility with any communication system that\nallows for small binary data transmission.",
    "categories": [
      "cs.CR"
    ],
    "published": "2023-11-08T17:56:56+00:00",
    "updated": "2023-11-08T17:56:56+00:00",
    "url": "http://arxiv.org/pdf/2311.04861v1"
  },
  {
    "id": "2311.03573v3",
    "title": "Smart Blockchain Networks: Revolutionizing Donation Tracking in the Web 3.0",
    "authors": [
      "Chaimaa Nairi",
      "Murtaza Cicioglu",
      "Ali Calhan"
    ],
    "abstract": "A donation-tracking system leveraging smart contracts and blockchain\ntechnology holds transformative potential for reshaping the landscape of\ncharitable giving, especially within the context of Web 3.0. This paper\nexplores how smart contracts and blockchain can be used to create a transparent\nand secure ledger for tracking charitable donations. We highlight the\nlimitations of traditional donation systems and how a blockchain-based system\ncan help overcome these challenges. The functionality of smart contracts in\ndonation tracking, offering advantages such as automation, reduced transaction\nfees, and enhanced accountability, is elucidated. The decentralized and\ntamper-proof nature of blockchain technology is emphasized for increased\ntransparency and fraud prevention. While elucidating the benefits, we also\naddress challenges in implementing such a system, including the need for\ntechnical expertise and security considerations. By fostering trust and\naccountability, a donation-tracking system in Web 3.0, empowered by smart\nblockchain networks, aims to catalyze a profound positive impact in the realm\nof philanthropy.",
    "categories": [
      "cs.CR"
    ],
    "published": "2023-11-06T22:18:32+00:00",
    "updated": "2024-03-28T07:19:02+00:00",
    "url": "http://arxiv.org/pdf/2311.03573v3"
  },
  {
    "id": "2311.16139v2",
    "title": "GNNBleed: Inference Attacks to Unveil Private Edges in Graphs with Realistic Access to GNN Models",
    "authors": [
      "Zeyu Song",
      "Ehsanul Kabir",
      "Shagufta Mehnaz"
    ],
    "abstract": "Graph Neural Networks (GNNs) have become indispensable tools for learning\nfrom graph structured data, catering to various applications such as social\nnetwork analysis and fraud detection for financial services. At the heart of\nthese networks are the edges, which are crucial in guiding GNN models'\npredictions. In many scenarios, these edges represent sensitive information,\nsuch as personal associations or financial dealings, which require privacy\nassurance. However, their contributions to GNN model predictions may, in turn,\nbe exploited by the adversary to compromise their privacy. Motivated by these\nconflicting requirements, this paper investigates edge privacy in contexts\nwhere adversaries possess only black-box access to the target GNN model,\nrestricted further by access controls, preventing direct insights into\narbitrary node outputs. Moreover, we are the first to extensively examine\nsituations where the target graph continuously evolves, a common trait of many\nreal-world graphs. In this setting, we present a range of attacks that leverage\nthe message-passing mechanism of GNNs. We evaluated the effectiveness of our\nattacks using nine real-world datasets, encompassing both static and dynamic\ngraphs, across four different GNN architectures. The results demonstrate that\nour attack outperforms existing methods across various GNN architectures,\nconsistently achieving an F1 score of at least 0.8 in static scenarios.\nFurthermore, our attack retains robustness in dynamic graph scenarios,\nmaintaining F1 scores up to 0.8, unlike previous methods that only achieve F1\nscores around 0.2.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2023-11-03T20:26:03+00:00",
    "updated": "2025-05-30T04:00:25+00:00",
    "url": "http://arxiv.org/pdf/2311.16139v2"
  },
  {
    "id": "2311.00964v3",
    "title": "On Finding Bi-objective Pareto-optimal Fraud Prevention Rule Sets for Fintech Applications",
    "authors": [
      "Chengyao Wen",
      "Yin Lou"
    ],
    "abstract": "Rules are widely used in Fintech institutions to make fraud prevention\ndecisions, since rules are highly interpretable thanks to their intuitive\nif-then structure. In practice, a two-stage framework of fraud prevention\ndecision rule set mining is usually employed in large Fintech institutions;\nStage 1 generates a potentially large pool of rules and Stage 2 aims to produce\na refined rule subset according to some criteria (typically based on precision\nand recall). This paper focuses on improving the flexibility and efficacy of\nthis two-stage framework, and is concerned with finding high-quality rule\nsubsets in a bi-objective space (such as precision and recall). To this end, we\nfirst introduce a novel algorithm called SpectralRules that directly generates\na compact pool of rules in Stage 1 with high diversity. We empirically find\nsuch diversity improves the quality of the final rule subset. In addition, we\nintroduce an intermediate stage between Stage 1 and 2 that adopts the concept\nof Pareto optimality and aims to find a set of non-dominated rule subsets,\nwhich constitutes a Pareto front. This intermediate stage greatly simplifies\nthe selection criteria and increases the flexibility of Stage 2. For this\nintermediate stage, we propose a heuristic-based framework called PORS and we\nidentify that the core of PORS is the problem of solution selection on the\nfront (SSF). We provide a systematic categorization of the SSF problem and a\nthorough empirical evaluation of various SSF methods on both public and\nproprietary datasets. On two real application scenarios within Alipay, we\ndemonstrate the advantages of our proposed methodology over existing work.",
    "categories": [
      "cs.LG",
      "q-fin.ST"
    ],
    "published": "2023-11-02T03:18:40+00:00",
    "updated": "2024-06-27T19:07:30+00:00",
    "url": "http://arxiv.org/pdf/2311.00964v3"
  },
  {
    "id": "2311.00724v1",
    "title": "Fraud Analytics Using Machine-learning & Engineering on Big Data (FAME) for Telecom",
    "authors": [
      "Sudarson Roy Pratihar",
      "Subhadip Paul",
      "Pranab Kumar Dash",
      "Amartya Kumar Das"
    ],
    "abstract": "Telecom industries lose globally 46.3 Billion USD due to fraud. Data mining\nand machine learning techniques (apart from rules oriented approach) have been\nused in past, but efficiency has been low as fraud pattern changes very\nrapidly. This paper presents an industrialized solution approach with self\nadaptive data mining technique and application of big data technologies to\ndetect fraud and discover novel fraud patterns in accurate, efficient and cost\neffective manner. Solution has been successfully demonstrated to detect\nInternational Revenue Share Fraud with <5% false positive. More than 1 Terra\nBytes of Call Detail Record from a reputed wholesale carrier and overseas\ntelecom transit carrier has been used to conduct this study.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "published": "2023-10-31T05:47:35+00:00",
    "updated": "2023-10-31T05:47:35+00:00",
    "url": "http://arxiv.org/pdf/2311.00724v1"
  },
  {
    "id": "2310.20028v1",
    "title": "From the Top Down: Does Corruption Affect Performance?",
    "authors": [
      "Maurizio La Rocca",
      "Tiziana La Rocca",
      "Francesco Fasano",
      "Javier Sanchez-Vidal"
    ],
    "abstract": "Corruption, fraud, and unethical activities have emerged as significant\nobstacles to global economic, political, and social progress. Although many\nempirical studies have focused on country-level corruption metrics, this study\nis the first to utilize a substantial international dataset to assess the\neffects of illicit and unethical managerial practices on firm performance.\nEmploying cross-sectional data, this research examines the influence of\ncorruption on corporate outcomes. Our definition of corruption evaluates the\ndegree to which managers engage in mismanagement, misconduct, or corrupt\nactivities. The repercussions for corporate governance, especially concerning\nthe process of appointing managers, are both crucial and strategic.",
    "categories": [
      "q-fin.GN"
    ],
    "published": "2023-10-30T21:24:48+00:00",
    "updated": "2023-10-30T21:24:48+00:00",
    "url": "http://arxiv.org/pdf/2310.20028v1"
  },
  {
    "id": "2310.19091v3",
    "title": "Bridging the gap: Towards an Expanded Toolkit for AI-driven Decision-Making in the Public Sector",
    "authors": [
      "Unai Fischer-Abaigar",
      "Christoph Kern",
      "Noam Barda",
      "Frauke Kreuter"
    ],
    "abstract": "AI-driven decision-making systems are becoming instrumental in the public\nsector, with applications spanning areas like criminal justice, social welfare,\nfinancial fraud detection, and public health. While these systems offer great\npotential benefits to institutional decision-making processes, such as improved\nefficiency and reliability, these systems face the challenge of aligning\nmachine learning (ML) models with the complex realities of public sector\ndecision-making. In this paper, we examine five key challenges where\nmisalignment can occur, including distribution shifts, label bias, the\ninfluence of past decision-making on the data side, as well as competing\nobjectives and human-in-the-loop on the model output side. Our findings suggest\nthat standard ML methods often rely on assumptions that do not fully account\nfor these complexities, potentially leading to unreliable and harmful\npredictions. To address this, we propose a shift in modeling efforts from\nfocusing solely on predictive accuracy to improving decision-making outcomes.\nWe offer guidance for selecting appropriate modeling frameworks, including\ncounterfactual prediction and policy learning, by considering how the model\nestimand connects to the decision-maker's utility. Additionally, we outline\ntechnical methods that address specific challenges within each modeling\napproach. Finally, we argue for the importance of external input from domain\nexperts and stakeholders to ensure that model assumptions and design choices\nalign with real-world policy objectives, taking a step towards harmonizing AI\nand public sector objectives.",
    "categories": [
      "cs.LG",
      "cs.CY",
      "cs.HC",
      "stat.ME"
    ],
    "published": "2023-10-29T17:44:48+00:00",
    "updated": "2024-10-11T20:16:46+00:00",
    "url": "http://arxiv.org/pdf/2310.19091v3"
  },
  {
    "id": "2310.16540v1",
    "title": "Dual Defense: Adversarial, Traceable, and Invisible Robust Watermarking against Face Swapping",
    "authors": [
      "Yunming Zhang",
      "Dengpan Ye",
      "Caiyun Xie",
      "Long Tang",
      "Chuanxi Chen",
      "Ziyi Liu",
      "Jiacheng Deng"
    ],
    "abstract": "The malicious applications of deep forgery, represented by face swapping,\nhave introduced security threats such as misinformation dissemination and\nidentity fraud. While some research has proposed the use of robust watermarking\nmethods to trace the copyright of facial images for post-event traceability,\nthese methods cannot effectively prevent the generation of forgeries at the\nsource and curb their dissemination. To address this problem, we propose a\nnovel comprehensive active defense mechanism that combines traceability and\nadversariality, called Dual Defense. Dual Defense invisibly embeds a single\nrobust watermark within the target face to actively respond to sudden cases of\nmalicious face swapping. It disrupts the output of the face swapping model\nwhile maintaining the integrity of watermark information throughout the entire\ndissemination process. This allows for watermark extraction at any stage of\nimage tracking for traceability. Specifically, we introduce a watermark\nembedding network based on original-domain feature impersonation attack. This\nnetwork learns robust adversarial features of target facial images and embeds\nwatermarks, seeking a well-balanced trade-off between watermark invisibility,\nadversariality, and traceability through perceptual adversarial encoding\nstrategies. Extensive experiments demonstrate that Dual Defense achieves\noptimal overall defense success rates and exhibits promising universality in\nanti-face swapping tasks and dataset generalization ability. It maintains\nimpressive adversariality and traceability in both original and robust\nsettings, surpassing current forgery defense methods that possess only one of\nthese capabilities, including CMUA-Watermark, Anti-Forgery, FakeTagger, or PGD\nmethods.",
    "categories": [
      "cs.CV"
    ],
    "published": "2023-10-25T10:39:51+00:00",
    "updated": "2023-10-25T10:39:51+00:00",
    "url": "http://arxiv.org/pdf/2310.16540v1"
  },
  {
    "id": "2312.14795v1",
    "title": "On support vector machines under a multiple-cost scenario",
    "authors": [
      "Sandra Benítez-Peña",
      "Rafael Blanquero",
      "Emilio Carrizosa",
      "Pepa Ramírez-Cobo"
    ],
    "abstract": "Support Vector Machine (SVM) is a powerful tool in binary classification,\nknown to attain excellent misclassification rates. On the other hand, many\nrealworld classification problems, such as those found in medical diagnosis,\nchurn or fraud prediction, involve misclassification costs which may be\ndifferent in the different classes. However, it may be hard for the user to\nprovide precise values for such misclassification costs, whereas it may be much\neasier to identify acceptable misclassification rates values. In this paper we\npropose a novel SVM model in which misclassification costs are considered by\nincorporating performance constraints in the problem formulation. Specifically,\nour aim is to seek the hyperplane with maximal margin yielding\nmisclassification rates below given threshold values. Such maximal margin\nhyperplane is obtained by solving a quadratic convex problem with linear\nconstraints and integer variables. The reported numerical experience shows that\nour model gives the user control on the misclassification rates in one class\n(possibly at the expense of an increase in misclassification rates for the\nother class) and is feasible in terms of running times.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2023-12-22T16:12:25+00:00",
    "updated": "2023-12-22T16:12:25+00:00",
    "url": "http://arxiv.org/pdf/2312.14795v1"
  },
  {
    "id": "2312.14535v1",
    "title": "ADA-GAD: Anomaly-Denoised Autoencoders for Graph Anomaly Detection",
    "authors": [
      "Junwei He",
      "Qianqian Xu",
      "Yangbangyan Jiang",
      "Zitai Wang",
      "Qingming Huang"
    ],
    "abstract": "Graph anomaly detection is crucial for identifying nodes that deviate from\nregular behavior within graphs, benefiting various domains such as fraud\ndetection and social network. Although existing reconstruction-based methods\nhave achieved considerable success, they may face the \\textit{Anomaly\nOverfitting} and \\textit{Homophily Trap} problems caused by the abnormal\npatterns in the graph, breaking the assumption that normal nodes are often\nbetter reconstructed than abnormal ones. Our observations indicate that models\ntrained on graphs with fewer anomalies exhibit higher detection performance.\nBased on this insight, we introduce a novel two-stage framework called\nAnomaly-Denoised Autoencoders for Graph Anomaly Detection (ADA-GAD). In the\nfirst stage, we design a learning-free anomaly-denoised augmentation method to\ngenerate graphs with reduced anomaly levels. We pretrain graph autoencoders on\nthese augmented graphs at multiple levels, which enables the graph autoencoders\nto capture normal patterns. In the next stage, the decoders are retrained for\ndetection on the original graph, benefiting from the multi-level\nrepresentations learned in the previous stage. Meanwhile, we propose the node\nanomaly distribution regularization to further alleviate \\textit{Anomaly\nOverfitting}. We validate the effectiveness of our approach through extensive\nexperiments on both synthetic and real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "published": "2023-12-22T09:02:01+00:00",
    "updated": "2023-12-22T09:02:01+00:00",
    "url": "http://arxiv.org/pdf/2312.14535v1"
  },
  {
    "id": "2312.14406v1",
    "title": "Generative Pretraining at Scale: Transformer-Based Encoding of Transactional Behavior for Fraud Detection",
    "authors": [
      "Ze Yu Zhao",
      "Zheng Zhu",
      "Guilin Li",
      "Wenhan Wang",
      "Bo Wang"
    ],
    "abstract": "In this work, we introduce an innovative autoregressive model leveraging\nGenerative Pretrained Transformer (GPT) architectures, tailored for fraud\ndetection in payment systems. Our approach innovatively confronts token\nexplosion and reconstructs behavioral sequences, providing a nuanced\nunderstanding of transactional behavior through temporal and contextual\nanalysis. Utilizing unsupervised pretraining, our model excels in feature\nrepresentation without the need for labeled data. Additionally, we integrate a\ndifferential convolutional approach to enhance anomaly detection, bolstering\nthe security and efficacy of one of the largest online payment merchants in\nChina. The scalability and adaptability of our model promise broad\napplicability in various transactional contexts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2023-12-22T03:15:17+00:00",
    "updated": "2023-12-22T03:15:17+00:00",
    "url": "http://arxiv.org/pdf/2312.14406v1"
  },
  {
    "id": "2312.13993v1",
    "title": "Open-Set: ID Card Presentation Attack Detection using Neural Transfer Style",
    "authors": [
      "Reuben Markham",
      "Juan M. Espin",
      "Mario Nieto-Hidalgo",
      "Juan E. Tapia"
    ],
    "abstract": "The accurate detection of ID card Presentation Attacks (PA) is becoming\nincreasingly important due to the rising number of online/remote services that\nrequire the presentation of digital photographs of ID cards for digital\nonboarding or authentication. Furthermore, cybercriminals are continuously\nsearching for innovative ways to fool authentication systems to gain\nunauthorized access to these services. Although advances in neural network\ndesign and training have pushed image classification to the state of the art,\none of the main challenges faced by the development of fraud detection systems\nis the curation of representative datasets for training and evaluation. The\nhandcrafted creation of representative presentation attack samples often\nrequires expertise and is very time-consuming, thus an automatic process of\nobtaining high-quality data is highly desirable. This work explores ID card\nPresentation Attack Instruments (PAI) in order to improve the generation of\nsamples with four Generative Adversarial Networks (GANs) based image\ntranslation models and analyses the effectiveness of the generated data for\ntraining fraud detection systems. Using open-source data, we show that\nsynthetic attack presentations are an adequate complement for additional real\nattack presentations, where we obtain an EER performance increase of 0.63%\npoints for print attacks and a loss of 0.29% for screen capture attacks.",
    "categories": [
      "cs.CV",
      "cs.CR"
    ],
    "published": "2023-12-21T16:28:08+00:00",
    "updated": "2023-12-21T16:28:08+00:00",
    "url": "http://arxiv.org/pdf/2312.13993v1"
  },
  {
    "id": "2312.13896v1",
    "title": "Comparative Evaluation of Anomaly Detection Methods for Fraud Detection in Online Credit Card Payments",
    "authors": [
      "Hugo Thimonier",
      "Fabrice Popineau",
      "Arpad Rimmel",
      "Bich-Liên Doan",
      "Fabrice Daniel"
    ],
    "abstract": "This study explores the application of anomaly detection (AD) methods in\nimbalanced learning tasks, focusing on fraud detection using real online credit\ncard payment data. We assess the performance of several recent AD methods and\ncompare their effectiveness against standard supervised learning methods.\nOffering evidence of distribution shift within our dataset, we analyze its\nimpact on the tested models' performances. Our findings reveal that LightGBM\nexhibits significantly superior performance across all evaluated metrics but\nsuffers more from distribution shifts than AD methods. Furthermore, our\ninvestigation reveals that LightGBM also captures the majority of frauds\ndetected by AD methods. This observation challenges the potential benefits of\nensemble methods to combine supervised, and AD approaches to enhance\nperformance. In summary, this research provides practical insights into the\nutility of these techniques in real-world scenarios, showing LightGBM's\nsuperiority in fraud detection while highlighting challenges related to\ndistribution shifts.",
    "categories": [
      "cs.LG",
      "q-fin.ST"
    ],
    "published": "2023-12-21T14:42:42+00:00",
    "updated": "2023-12-21T14:42:42+00:00",
    "url": "http://arxiv.org/pdf/2312.13896v1"
  },
  {
    "id": "2312.13334v1",
    "title": "Transparency and Privacy: The Role of Explainable AI and Federated Learning in Financial Fraud Detection",
    "authors": [
      "Tomisin Awosika",
      "Raj Mani Shukla",
      "Bernardi Pranggono"
    ],
    "abstract": "Fraudulent transactions and how to detect them remain a significant problem\nfor financial institutions around the world. The need for advanced fraud\ndetection systems to safeguard assets and maintain customer trust is paramount\nfor financial institutions, but some factors make the development of effective\nand efficient fraud detection systems a challenge. One of such factors is the\nfact that fraudulent transactions are rare and that many transaction datasets\nare imbalanced; that is, there are fewer significant samples of fraudulent\ntransactions than legitimate ones. This data imbalance can affect the\nperformance or reliability of the fraud detection model. Moreover, due to the\ndata privacy laws that all financial institutions are subject to follow,\nsharing customer data to facilitate a higher-performing centralized model is\nimpossible. Furthermore, the fraud detection technique should be transparent so\nthat it does not affect the user experience. Hence, this research introduces a\nnovel approach using Federated Learning (FL) and Explainable AI (XAI) to\naddress these challenges. FL enables financial institutions to collaboratively\ntrain a model to detect fraudulent transactions without directly sharing\ncustomer data, thereby preserving data privacy and confidentiality. Meanwhile,\nthe integration of XAI ensures that the predictions made by the model can be\nunderstood and interpreted by human experts, adding a layer of transparency and\ntrust to the system. Experimental results, based on realistic transaction\ndatasets, reveal that the FL-based fraud detection system consistently\ndemonstrates high performance metrics. This study grounds FL's potential as an\neffective and privacy-preserving tool in the fight against fraud.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2023-12-20T18:26:59+00:00",
    "updated": "2023-12-20T18:26:59+00:00",
    "url": "http://arxiv.org/pdf/2312.13334v1"
  },
  {
    "id": "2312.13218v1",
    "title": "FiFAR: A Fraud Detection Dataset for Learning to Defer",
    "authors": [
      "Jean V. Alves",
      "Diogo Leitão",
      "Sérgio Jesus",
      "Marco O. P. Sampaio",
      "Pedro Saleiro",
      "Mário A. T. Figueiredo",
      "Pedro Bizarro"
    ],
    "abstract": "Public dataset limitations have significantly hindered the development and\nbenchmarking of learning to defer (L2D) algorithms, which aim to optimally\ncombine human and AI capabilities in hybrid decision-making systems. In such\nsystems, human availability and domain-specific concerns introduce\ndifficulties, while obtaining human predictions for training and evaluation is\ncostly. Financial fraud detection is a high-stakes setting where algorithms and\nhuman experts often work in tandem; however, there are no publicly available\ndatasets for L2D concerning this important application of human-AI teaming. To\nfill this gap in L2D research, we introduce the Financial Fraud Alert Review\nDataset (FiFAR), a synthetic bank account fraud detection dataset, containing\nthe predictions of a team of 50 highly complex and varied synthetic fraud\nanalysts, with varied bias and feature dependence. We also provide a realistic\ndefinition of human work capacity constraints, an aspect of L2D systems that is\noften overlooked, allowing for extensive testing of assignment systems under\nreal-world conditions. We use our dataset to develop a capacity-aware L2D\nmethod and rejection learning approach under realistic data availability\nconditions, and benchmark these baselines under an array of 300 distinct\ntesting scenarios. We believe that this dataset will serve as a pivotal\ninstrument in facilitating a systematic, rigorous, reproducible, and\ntransparent evaluation and comparison of L2D methods, thereby fostering the\ndevelopment of more synergistic human-AI collaboration in decision-making\nsystems. The public dataset and detailed synthetic expert information are\navailable at: https://github.com/feedzai/fifar-dataset",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2023-12-20T17:36:36+00:00",
    "updated": "2023-12-20T17:36:36+00:00",
    "url": "http://arxiv.org/pdf/2312.13218v1"
  },
  {
    "id": "2312.12879v1",
    "title": "DynamiQS: Quantum Secure Authentication for Dynamic Charging of Electric Vehicles",
    "authors": [
      "Tommaso Bianchi",
      "Alessandro Brighente",
      "Mauro Conti"
    ],
    "abstract": "Dynamic Wireless Power Transfer (DWPT) is a novel technology that allows\ncharging an electric vehicle while driving thanks to a dedicated road\ninfrastructure. DWPT's capabilities in automatically establishing charging\nsessions and billing without users' intervention make it prone to cybersecurity\nattacks. Hence, security is essential in preventing fraud, impersonation, and\nuser tracking. To this aim, researchers proposed different solutions for\nauthenticating users. However, recent advancements in quantum computing\njeopardize classical public key cryptography, making currently existing\nsolutions in DWPT authentication nonviable. To avoid the resource burden\nimposed by technology upgrades, it is essential to develop\npost-quantum-resistant solutions. In this paper, we propose DynamiQS, the first\npost-quantum secure authentication protocol for dynamic wireless charging.\nDynamiQS is privacy-preserving and secure against attacks on the DWPT. We\nleverage an Identity-Based Encryption with Lattices in the Ring Learning With\nError framework. Furthermore, we show the possibility of using DynamiQS in a\nreal environment, leveraging the results of cryptographic computation on real\nconstrained devices and simulations. DynamiQS reaches a total time cost of\naround 281 ms, which is practicable in dynamic charging settings (car and\ncharging infrastructure).",
    "categories": [
      "cs.CR"
    ],
    "published": "2023-12-20T09:40:45+00:00",
    "updated": "2023-12-20T09:40:45+00:00",
    "url": "http://arxiv.org/pdf/2312.12879v1"
  },
  {
    "id": "2312.11948v1",
    "title": "Leveraging the Urysohn Lemma of Topology for an Enhanced Binary Classifier",
    "authors": [
      "Ernesto Lopez Fune"
    ],
    "abstract": "In this article we offer a comprehensive analysis of the Urysohn's classifier\nin a binary classification context. It utilizes Urysohn's Lemma of Topology to\nconstruct separating functions, providing rigorous and adaptable solutions.\nNumerical experiments demonstrated exceptional performance, with scores ranging\nfrom 95% to 100%. Notably, the Urysohn's classifier outperformed CatBoost and\nKNN in various scenarios. Despite sensitivity to the p-metric parameter, it\nproved robust and adaptable. The Urysohn's classifier's mathematical rigor and\nadaptability make it promising for binary classification, with applications in\nmedical diagnosis, fraud detection and cyber security. Future research includes\nparameter optimization and combining the Urysohn's classifier with other\ntechniques. It offers an elegant and principled approach to classification,\nensuring integrity and valuable data insights.",
    "categories": [
      "physics.data-an",
      "stat.ML"
    ],
    "published": "2023-12-19T08:47:53+00:00",
    "updated": "2023-12-19T08:47:53+00:00",
    "url": "http://arxiv.org/pdf/2312.11948v1"
  },
  {
    "id": "2312.06441v3",
    "title": "Revisiting Graph-Based Fraud Detection in Sight of Heterophily and Spectrum",
    "authors": [
      "Fan Xu",
      "Nan Wang",
      "Hao Wu",
      "Xuezhi Wen",
      "Xibin Zhao",
      "Hai Wan"
    ],
    "abstract": "Graph-based fraud detection (GFD) can be regarded as a challenging\nsemi-supervised node binary classification task. In recent years, Graph Neural\nNetworks (GNN) have been widely applied to GFD, characterizing the anomalous\npossibility of a node by aggregating neighbor information. However, fraud\ngraphs are inherently heterophilic, thus most of GNNs perform poorly due to\ntheir assumption of homophily. In addition, due to the existence of heterophily\nand class imbalance problem, the existing models do not fully utilize the\nprecious node label information. To address the above issues, this paper\nproposes a semi-supervised GNN-based fraud detector SEC-GFD. This detector\nincludes a hybrid filtering module and a local environmental constraint module,\nthe two modules are utilized to solve heterophily and label utilization problem\nrespectively. The first module starts from the perspective of the spectral\ndomain, and solves the heterophily problem to a certain extent. Specifically,\nit divides the spectrum into various mixed-frequency bands based on the\ncorrelation between spectrum energy distribution and heterophily. Then in order\nto make full use of the node label information, a local environmental\nconstraint module is adaptively designed. The comprehensive experimental\nresults on four real-world fraud detection datasets denote that SEC-GFD\noutperforms other competitive graph-based fraud detectors. We release our code\nat https://github.com/Sunxkissed/SEC-GFD.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "published": "2023-12-11T15:18:51+00:00",
    "updated": "2024-07-08T06:54:37+00:00",
    "url": "http://arxiv.org/pdf/2312.06441v3"
  },
  {
    "id": "2312.01200v1",
    "title": "FRAUDability: Estimating Users' Susceptibility to Financial Fraud Using Adversarial Machine Learning",
    "authors": [
      "Chen Doytshman",
      "Satoru Momiyama",
      "Inderjeet Singh",
      "Yuval Elovici",
      "Asaf Shabtai"
    ],
    "abstract": "In recent years, financial fraud detection systems have become very efficient\nat detecting fraud, which is a major threat faced by e-commerce platforms. Such\nsystems often include machine learning-based algorithms aimed at detecting and\nreporting fraudulent activity. In this paper, we examine the application of\nadversarial learning based ranking techniques in the fraud detection domain and\npropose FRAUDability, a method for the estimation of a financial fraud\ndetection system's performance for every user. We are motivated by the\nassumption that \"not all users are created equal\" -- while some users are well\nprotected by fraud detection algorithms, others tend to pose a challenge to\nsuch systems. The proposed method produces scores, namely \"fraudability\nscores,\" which are numerical estimations of a fraud detection system's ability\nto detect financial fraud for a specific user, given his/her unique activity in\nthe financial system. Our fraudability scores enable those tasked with\ndefending users in a financial platform to focus their attention and resources\non users with high fraudability scores to better protect them. We validate our\nmethod using a real e-commerce platform's dataset and demonstrate the\napplication of fraudability scores from the attacker's perspective, on the\nplatform, and more specifically, on the fraud detection systems used by the\ne-commerce enterprise. We show that the scores can also help attackers increase\ntheir financial profit by 54%, by engaging solely with users with high\nfraudability scores, avoiding those users whose spending habits enable more\naccurate fraud detection.",
    "categories": [
      "cs.CR"
    ],
    "published": "2023-12-02T18:33:05+00:00",
    "updated": "2023-12-02T18:33:05+00:00",
    "url": "http://arxiv.org/pdf/2312.01200v1"
  },
  {
    "id": "2312.00586v1",
    "title": "Explainable Fraud Detection with Deep Symbolic Classification",
    "authors": [
      "Samantha Visbeek",
      "Erman Acar",
      "Floris den Hengst"
    ],
    "abstract": "There is a growing demand for explainable, transparent, and data-driven\nmodels within the domain of fraud detection. Decisions made by fraud detection\nmodels need to be explainable in the event of a customer dispute. Additionally,\nthe decision-making process in the model must be transparent to win the trust\nof regulators and business stakeholders. At the same time, fraud detection\nsolutions can benefit from data due to the noisy, dynamic nature of fraud and\nthe availability of large historical data sets. Finally, fraud detection is\nnotorious for its class imbalance: there are typically several orders of\nmagnitude more legitimate transactions than fraudulent ones. In this paper, we\npresent Deep Symbolic Classification (DSC), an extension of the Deep Symbolic\nRegression framework to classification problems. DSC casts classification as a\nsearch problem in the space of all analytic functions composed of a vocabulary\nof variables, constants, and operations and optimizes for an arbitrary\nevaluation metric directly. The search is guided by a deep neural network\ntrained with reinforcement learning. Because the functions are mathematical\nexpressions that are in closed-form and concise, the model is inherently\nexplainable both at the level of a single classification decision and the\nmodel's decision process. Furthermore, the class imbalance problem is\nsuccessfully addressed by optimizing for metrics that are robust to class\nimbalance such as the F1 score. This eliminates the need for oversampling and\nundersampling techniques that plague traditional approaches. Finally, the model\nallows to explicitly balance between the prediction accuracy and the\nexplainability. An evaluation on the PaySim data set demonstrates competitive\npredictive performance with state-of-the-art models, while surpassing them in\nterms of explainability. This establishes DSC as a promising model for fraud\ndetection systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2023-12-01T13:50:55+00:00",
    "updated": "2023-12-01T13:50:55+00:00",
    "url": "http://arxiv.org/pdf/2312.00586v1"
  },
  {
    "id": "2312.00260v1",
    "title": "Quantum Multiple Kernel Learning in Financial Classification Tasks",
    "authors": [
      "Shungo Miyabe",
      "Brian Quanz",
      "Noriaki Shimada",
      "Abhijit Mitra",
      "Takahiro Yamamoto",
      "Vladimir Rastunkov",
      "Dimitris Alevras",
      "Mekena Metcalf",
      "Daniel J. M. King",
      "Mohammad Mamouei",
      "Matthew D. Jackson",
      "Martin Brown",
      "Philip Intallura",
      "Jae-Eun Park"
    ],
    "abstract": "Financial services is a prospect industry where unlocked near-term quantum\nutility could yield profitable potential, and, in particular, quantum machine\nlearning algorithms could potentially benefit businesses by improving the\nquality of predictive models. Quantum kernel methods have demonstrated success\nin financial, binary classification tasks, like fraud detection, and avoid\nissues found in variational quantum machine learning approaches. However,\nchoosing a suitable quantum kernel for a classical dataset remains a challenge.\nWe propose a hybrid, quantum multiple kernel learning (QMKL) methodology that\ncan improve classification quality over a single kernel approach. We test the\nrobustness of QMKL on several financially relevant datasets using both fidelity\nand projected quantum kernel approaches. We further demonstrate QMKL on quantum\nhardware using an error mitigation pipeline and show the benefits of QMKL in\nthe large qubit regime.",
    "categories": [
      "quant-ph"
    ],
    "published": "2023-12-01T00:18:43+00:00",
    "updated": "2023-12-01T00:18:43+00:00",
    "url": "http://arxiv.org/pdf/2312.00260v1"
  },
  {
    "id": "2401.10765v2",
    "title": "Starlit: Privacy-Preserving Federated Learning to Enhance Financial Fraud Detection",
    "authors": [
      "Aydin Abadi",
      "Bradley Doyle",
      "Francesco Gini",
      "Kieron Guinamard",
      "Sasi Kumar Murakonda",
      "Jack Liddell",
      "Paul Mellor",
      "Steven J. Murdoch",
      "Mohammad Naseri",
      "Hector Page",
      "George Theodorakopoulos",
      "Suzanne Weller"
    ],
    "abstract": "Federated Learning (FL) is a data-minimization approach enabling\ncollaborative model training across diverse clients with local data, avoiding\ndirect data exchange. However, state-of-the-art FL solutions to identify\nfraudulent financial transactions exhibit a subset of the following\nlimitations. They (1) lack a formal security definition and proof, (2) assume\nprior freezing of suspicious customers' accounts by financial institutions\n(limiting the solutions' adoption), (3) scale poorly, involving either $O(n^2)$\ncomputationally expensive modular exponentiation (where $n$ is the total number\nof financial institutions) or highly inefficient fully homomorphic encryption,\n(4) assume the parties have already completed the identity alignment phase,\nhence excluding it from the implementation, performance evaluation, and\nsecurity analysis, and (5) struggle to resist clients' dropouts. This work\nintroduces Starlit, a novel scalable privacy-preserving FL mechanism that\novercomes these limitations. It has various applications, such as enhancing\nfinancial fraud detection, mitigating terrorism, and enhancing digital health.\nWe implemented Starlit and conducted a thorough performance analysis using\nsynthetic data from a key player in global financial transactions. The\nevaluation indicates Starlit's scalability, efficiency, and accuracy.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2024-01-19T15:37:11+00:00",
    "updated": "2024-01-22T08:17:42+00:00",
    "url": "http://arxiv.org/pdf/2401.10765v2"
  },
  {
    "id": "2401.09960v1",
    "title": "A Comprehensive Scalable Framework for Cloud-Native Pattern Detection with Enhanced Expressiveness",
    "authors": [
      "Ioannis Mavroudopoulos",
      "Anastasios Gounaris"
    ],
    "abstract": "Detecting complex patterns in large volumes of event logs has diverse\napplications in various domains, such as business processes and fraud\ndetection. Existing systems like ELK are commonly used to tackle this\nchallenge, but their performance deteriorates for large patterns, while they\nsuffer from limitations in terms of expressiveness and explanatory capabilities\nfor their responses. In this work, we propose a solution that integrates a\nComplex Event Processing (CEP) engine into a broader query processsor on top of\na decoupled storage infrastructure containing inverted indices of log events.\nThe results demonstrate that our system excels in scalability and robustness,\nparticularly in handling complex queries. Notably, our proposed system delivers\nresponses for large complex patterns within seconds, while ELK experiences\ntimeouts after 10 minutes. It also significantly outperforms solutions relying\non FlinkCEP and executing MATCH_RECOGNIZE SQL queries.",
    "categories": [
      "cs.DB"
    ],
    "published": "2024-01-18T13:12:24+00:00",
    "updated": "2024-01-18T13:12:24+00:00",
    "url": "http://arxiv.org/pdf/2401.09960v1"
  },
  {
    "id": "2401.09824v1",
    "title": "Conning the Crypto Conman: End-to-End Analysis of Cryptocurrency-based Technical Support Scams",
    "authors": [
      "Bhupendra Acharya",
      "Muhammad Saad",
      "Antonio Emanuele Cinà",
      "Lea Schönherr",
      "Hoang Dai Nguyen",
      "Adam Oest",
      "Phani Vadrevu",
      "Thorsten Holz"
    ],
    "abstract": "The mainstream adoption of cryptocurrencies has led to a surge in\nwallet-related issues reported by ordinary users on social media platforms. In\nparallel, there is an increase in an emerging fraud trend called\ncryptocurrency-based technical support scam, in which fraudsters offer fake\nwallet recovery services and target users experiencing wallet-related issues.\n  In this paper, we perform a comprehensive study of cryptocurrency-based\ntechnical support scams. We present an analysis apparatus called HoneyTweet to\nanalyze this kind of scam. Through HoneyTweet, we lure over 9K scammers by\nposting 25K fake wallet support tweets (so-called honey tweets). We then deploy\nautomated systems to interact with scammers to analyze their modus operandi. In\nour experiments, we observe that scammers use Twitter as a starting point for\nthe scam, after which they pivot to other communication channels (eg email,\nInstagram, or Telegram) to complete the fraud activity. We track scammers\nacross those communication channels and bait them into revealing their payment\nmethods. Based on the modes of payment, we uncover two categories of scammers\nthat either request secret key phrase submissions from their victims or direct\npayments to their digital wallets. Furthermore, we obtain scam confirmation by\ndeploying honey wallet addresses and validating private key theft. We also\ncollaborate with the prominent payment service provider by sharing scammer data\ncollections. The payment service provider feedback was consistent with our\nfindings, thereby supporting our methodology and results. By consolidating our\nanalysis across various vantage points, we provide an end-to-end scam lifecycle\nanalysis and propose recommendations for scam mitigation.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-01-18T09:31:45+00:00",
    "updated": "2024-01-18T09:31:45+00:00",
    "url": "http://arxiv.org/pdf/2401.09824v1"
  },
  {
    "id": "2401.09682v1",
    "title": "Comparative Study on the Performance of Categorical Variable Encoders in Classification and Regression Tasks",
    "authors": [
      "Wenbin Zhu",
      "Runwen Qiu",
      "Ying Fu"
    ],
    "abstract": "Categorical variables often appear in datasets for classification and\nregression tasks, and they need to be encoded into numerical values before\ntraining. Since many encoders have been developed and can significantly impact\nperformance, choosing the appropriate encoder for a task becomes a\ntime-consuming yet important practical issue. This study broadly classifies\nmachine learning models into three categories: 1) ATI models that implicitly\nperform affine transformations on inputs, such as multi-layer perceptron neural\nnetwork; 2) Tree-based models that are based on decision trees, such as random\nforest; and 3) the rest, such as kNN. Theoretically, we prove that the one-hot\nencoder is the best choice for ATI models in the sense that it can mimic any\nother encoders by learning suitable weights from the data. We also explain why\nthe target encoder and its variants are the most suitable encoders for\ntree-based models. This study conducted comprehensive computational experiments\nto evaluate 14 encoders, including one-hot and target encoders, along with\neight common machine-learning models on 28 datasets. The computational results\nagree with our theoretical analysis. The findings in this study shed light on\nhow to select the suitable encoder for data scientists in fields such as fraud\ndetection, disease diagnosis, etc.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-01-18T02:21:53+00:00",
    "updated": "2024-01-18T02:21:53+00:00",
    "url": "http://arxiv.org/pdf/2401.09682v1"
  },
  {
    "id": "2401.09199v1",
    "title": "Data Trading and Monetization: Challenges and Open Research Directions",
    "authors": [
      "Qusai Ramadan",
      "Zeyd Boukhers",
      "Muath AlShaikh",
      "Christoph Lange",
      "Jan Jürjens"
    ],
    "abstract": "Traditional data monetization approaches face challenges related to data\nprotection and logistics. In response, digital data marketplaces have emerged\nas intermediaries simplifying data transactions. Despite the growing\nestablishment and acceptance of digital data marketplaces, significant\nchallenges hinder efficient data trading. As a result, few companies can derive\ntangible value from their data, leading to missed opportunities in\nunderstanding customers, pricing decisions, and fraud prevention. In this\npaper, we explore both technical and organizational challenges affecting data\nmonetization. Moreover, we identify areas in need of further research, aiming\nto expand the boundaries of current knowledge by emphasizing where research is\ncurrently limited or lacking.",
    "categories": [
      "cs.DC",
      "cs.DB"
    ],
    "published": "2024-01-17T13:25:27+00:00",
    "updated": "2024-01-17T13:25:27+00:00",
    "url": "http://arxiv.org/pdf/2401.09199v1"
  },
  {
    "id": "2401.07358v2",
    "title": "Harnessing Machine Learning for Discerning AI-Generated Synthetic Images",
    "authors": [
      "Yuyang Wang",
      "Yizhi Hao",
      "Amando Xu Cong"
    ],
    "abstract": "In the realm of digital media, the advent of AI-generated synthetic images\nhas introduced significant challenges in distinguishing between real and\nfabricated visual content. These images, often indistinguishable from authentic\nones, pose a threat to the credibility of digital media, with potential\nimplications for disinformation and fraud. Our research addresses this\nchallenge by employing machine learning techniques to discern between\nAI-generated and genuine images. Central to our approach is the CIFAKE dataset,\na comprehensive collection of images labeled as \"Real\" and \"Fake\". We refine\nand adapt advanced deep learning architectures like ResNet, VGGNet, and\nDenseNet, utilizing transfer learning to enhance their precision in identifying\nsynthetic images. We also compare these with a baseline model comprising a\nvanilla Support Vector Machine (SVM) and a custom Convolutional Neural Network\n(CNN). The experimental results were significant, demonstrating that our\noptimized deep learning models outperform traditional methods, with DenseNet\nachieving an accuracy of 97.74%. Our application study contributes by applying\nand optimizing these advanced models for synthetic image detection, conducting\na comparative analysis using various metrics, and demonstrating their superior\ncapability in identifying AI-generated images over traditional machine learning\ntechniques. This research not only advances the field of digital media\nintegrity but also sets a foundation for future explorations into the ethical\nand technical dimensions of AI-generated content in digital media.",
    "categories": [
      "cs.CV"
    ],
    "published": "2024-01-14T20:00:37+00:00",
    "updated": "2024-05-23T19:48:08+00:00",
    "url": "http://arxiv.org/pdf/2401.07358v2"
  },
  {
    "id": "2401.09476v1",
    "title": "A Framework for Agricultural Food Supply Chain using Blockchain",
    "authors": [
      "Sudarssan N"
    ],
    "abstract": "The main aim of the paper is to create a trust and transparency in the food\nsupply chain system, ensuring food safety for everyone with the help of\nBlockchain Technology. Food supply chain is the process of tracing a crop from\nthe farmer or producer to the buyer. With the advent of blockchain, providing a\nsafe and fraud-free environment for the provision of numerous agricultural\nnecessities has become much easier. Because of the globalization of trade, the\npresent supply chain market today includes various companies involving\nintegration of data, complex transactions and distribution. Information tamper\nresistance, supply-demand relationships, and traceable oversight are all\ndifficulties that arise as a result of this. Blockchain is a distributed ledger\ntechnology that can provide information that is resistant to tampering. This\nstrategy can eliminate the need for a centralized trusted authority,\nintermediaries, and business histories, allowing for increased production and\nsecurity while maintaining the highest levels of integrity, liability, and\nsafety. In order to have an integrity and transparency in food supply chain in\nthe agricultural sector, a framework is proposed here based on block chain and\nIoT.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2024-01-14T04:16:01+00:00",
    "updated": "2024-01-14T04:16:01+00:00",
    "url": "http://arxiv.org/pdf/2401.09476v1"
  },
  {
    "id": "2401.05219v1",
    "title": "Distributed Monitoring for Data Distribution Shifts in Edge-ML Fraud Detection",
    "authors": [
      "Nader Karayanni",
      "Robert J. Shahla",
      "Chieh-Lien Hsiao"
    ],
    "abstract": "The digital era has seen a marked increase in financial fraud. edge ML\nemerged as a promising solution for smartphone payment services fraud\ndetection, enabling the deployment of ML models directly on edge devices. This\napproach enables a more personalized real-time fraud detection. However, a\nsignificant gap in current research is the lack of a robust system for\nmonitoring data distribution shifts in these distributed edge ML applications.\nOur work bridges this gap by introducing a novel open-source framework designed\nfor continuous monitoring of data distribution shifts on a network of edge\ndevices. Our system includes an innovative calculation of the\nKolmogorov-Smirnov (KS) test over a distributed network of edge devices,\nenabling efficient and accurate monitoring of users behavior shifts. We\ncomprehensively evaluate the proposed framework employing both real-world and\nsynthetic financial transaction datasets and demonstrate the framework's\neffectiveness.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "published": "2024-01-10T15:38:00+00:00",
    "updated": "2024-01-10T15:38:00+00:00",
    "url": "http://arxiv.org/pdf/2401.05219v1"
  },
  {
    "id": "2401.04771v1",
    "title": "Network Layout Algorithm with Covariate Smoothing",
    "authors": [
      "Octavious Smiley",
      "Till Hoffmann",
      "Jukka-Pekka Onnela"
    ],
    "abstract": "Network science explores intricate connections among objects, employed in\ndiverse domains like social interactions, fraud detection, and disease spread.\nVisualization of networks facilitates conceptualizing research questions and\nforming scientific hypotheses. Networks, as mathematical high-dimensional\nobjects, require dimensionality reduction for (planar) visualization.\nVisualizing empirical networks present additional challenges. They often\ncontain false positive (spurious) and false negative (missing) edges.\nTraditional visualization methods don't account for errors in observation,\npotentially biasing interpretations. Moreover, contemporary network data\nincludes rich nodal attributes. However, traditional methods neglect these\nattributes when computing node locations. Our visualization approach aims to\nleverage nodal attribute richness to compensate for network data limitations.\nWe employ a statistical model estimating the probability of edge connections\nbetween nodes based on their covariates. We enhance the Fruchterman-Reingold\nalgorithm to incorporate estimated dyad connection probabilities, allowing\npractitioners to balance reliance on observed versus estimated edges. We\nexplore optimal smoothing levels, offering a natural way to include relevant\nnodal information in layouts. Results demonstrate the effectiveness of our\nmethod in achieving robust network visualization, providing insights for\nimproved analysis.",
    "categories": [
      "cs.SI",
      "physics.soc-ph",
      "stat.ME"
    ],
    "published": "2024-01-09T19:01:32+00:00",
    "updated": "2024-01-09T19:01:32+00:00",
    "url": "http://arxiv.org/pdf/2401.04771v1"
  },
  {
    "id": "2401.04139v3",
    "title": "CCNETS: A Modular Causal Learning Framework for Pattern Recognition in Imbalanced Datasets",
    "authors": [
      "Hanbeot Park",
      "Yunjeong Cho",
      "Hoon-Hee Kim"
    ],
    "abstract": "Handling class imbalance remains a central challenge in machine learning,\nparticularly in pattern recognition tasks where rare but critical events-such\nas fraudulent transactions or medical anomalies-must be identified accurately.\nTraditional generative models offer a potential remedy through data\naugmentation but often treat generation and classification as independent\nprocesses, leading to distribution mismatch and limited classifier benefit. To\naddress these shortcomings, we propose Causal Cooperative Networks (CCNETS), a\nmodular learning framework that integrates generation, inference, and\nreconstruction within a unified causal paradigm. CCNETS comprises three\ncooperative modules: an Explainer for latent feature abstraction, a Reasoner\nfor label prediction, and a Producer for context-aware data generation. These\ncomponents interact through a causal feedback loop, where classification\nresults guide targeted sample synthesis. A key innovation, the Zoint mechanism,\nenables adaptive fusion of latent and observable features, enhancing semantic\nrichness and enabling robust decision-making under uncertainty. We evaluate\nCCNETS on a real-world credit card fraud detection dataset with extreme\nimbalance (fraud cases < 0.2%). Across three experimental setups-including\nsynthetic training, amplified generation, and direct classifier\ncomparison-CCNETS outperforms baseline methods, achieving higher F1 scores,\nprecision, and recall. Models trained on CCNETS-generated data also demonstrate\nsuperior generalization under limited data conditions. These results establish\nCCNETS as a scalable, interpretable, and hybrid soft computing framework. By\ncausally aligning synthetic data with classifier objectives, CCNETS advances\nimbalanced pattern recognition and opens new directions for robust, modular\nlearning in real-world applications.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-01-07T14:41:31+00:00",
    "updated": "2025-05-30T04:50:47+00:00",
    "url": "http://arxiv.org/pdf/2401.04139v3"
  },
  {
    "id": "2401.03246v1",
    "title": "SeqNAS: Neural Architecture Search for Event Sequence Classification",
    "authors": [
      "Igor Udovichenko",
      "Egor Shvetsov",
      "Denis Divitsky",
      "Dmitry Osin",
      "Ilya Trofimov",
      "Anatoly Glushenko",
      "Ivan Sukharev",
      "Dmitry Berestenev",
      "Evgeny Burnaev"
    ],
    "abstract": "Neural Architecture Search (NAS) methods are widely used in various\nindustries to obtain high quality taskspecific solutions with minimal human\nintervention. Event Sequences find widespread use in various industrial\napplications including churn prediction customer segmentation fraud detection\nand fault diagnosis among others. Such data consist of categorical and\nreal-valued components with irregular timestamps. Despite the usefulness of NAS\nmethods previous approaches only have been applied to other domains images\ntexts or time series. Our work addresses this limitation by introducing a novel\nNAS algorithm SeqNAS specifically designed for event sequence classification.\nWe develop a simple yet expressive search space that leverages commonly used\nbuilding blocks for event sequence classification including multihead self\nattention convolutions and recurrent cells. To perform the search we adopt\nsequential Bayesian Optimization and utilize previously trained models as an\nensemble of teachers to augment knowledge distillation. As a result of our work\nwe demonstrate that our method surpasses state of the art NAS methods and\npopular architectures suitable for sequence classification and holds great\npotential for various industrial applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2024-01-06T16:00:26+00:00",
    "updated": "2024-01-06T16:00:26+00:00",
    "url": "http://arxiv.org/pdf/2401.03246v1"
  },
  {
    "id": "2401.02450v1",
    "title": "Locally Differentially Private Embedding Models in Distributed Fraud Prevention Systems",
    "authors": [
      "Iker Perez",
      "Jason Wong",
      "Piotr Skalski",
      "Stuart Burrell",
      "Richard Mortier",
      "Derek McAuley",
      "David Sutton"
    ],
    "abstract": "Global financial crime activity is driving demand for machine learning\nsolutions in fraud prevention. However, prevention systems are commonly\nserviced to financial institutions in isolation, and few provisions exist for\ndata sharing due to fears of unintentional leaks and adversarial attacks.\nCollaborative learning advances in finance are rare, and it is hard to find\nreal-world insights derived from privacy-preserving data processing systems. In\nthis paper, we present a collaborative deep learning framework for fraud\nprevention, designed from a privacy standpoint, and awarded at the recent PETs\nPrize Challenges. We leverage latent embedded representations of varied-length\ntransaction sequences, along with local differential privacy, in order to\nconstruct a data release mechanism which can securely inform externally hosted\nfraud and anomaly detection models. We assess our contribution on two\ndistributed data sets donated by large payment networks, and demonstrate\nrobustness to popular inference-time attacks, along with utility-privacy\ntrade-offs analogous to published work in alternative application domains.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2024-01-03T14:04:18+00:00",
    "updated": "2024-01-03T14:04:18+00:00",
    "url": "http://arxiv.org/pdf/2401.02450v1"
  },
  {
    "id": "2401.01641v2",
    "title": "Towards a Foundation Purchasing Model: Pretrained Generative Autoregression on Transaction Sequences",
    "authors": [
      "Piotr Skalski",
      "David Sutton",
      "Stuart Burrell",
      "Iker Perez",
      "Jason Wong"
    ],
    "abstract": "Machine learning models underpin many modern financial systems for use cases\nsuch as fraud detection and churn prediction. Most are based on supervised\nlearning with hand-engineered features, which relies heavily on the\navailability of labelled data. Large self-supervised generative models have\nshown tremendous success in natural language processing and computer vision,\nyet so far they haven't been adapted to multivariate time series of financial\ntransactions. In this paper, we present a generative pretraining method that\ncan be used to obtain contextualised embeddings of financial transactions.\nBenchmarks on public datasets demonstrate that it outperforms state-of-the-art\nself-supervised methods on a range of downstream tasks. We additionally perform\nlarge-scale pretraining of an embedding model using a corpus of data from 180\nissuing banks containing 5.1 billion transactions and apply it to the card\nfraud detection problem on hold-out datasets. The embedding model significantly\nimproves value detection rate at high precision thresholds and transfers well\nto out-of-domain distributions.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-01-03T09:32:48+00:00",
    "updated": "2024-01-04T16:52:11+00:00",
    "url": "http://arxiv.org/pdf/2401.01641v2"
  },
  {
    "id": "2401.00974v1",
    "title": "Downstream Task-Oriented Generative Model Selections on Synthetic Data Training for Fraud Detection Models",
    "authors": [
      "Yinan Cheng",
      "Chi-Hua Wang",
      "Vamsi K. Potluru",
      "Tucker Balch",
      "Guang Cheng"
    ],
    "abstract": "Devising procedures for downstream task-oriented generative model selections\nis an unresolved problem of practical importance. Existing studies focused on\nthe utility of a single family of generative models. They provided limited\ninsights on how synthetic data practitioners select the best family generative\nmodels for synthetic training tasks given a specific combination of machine\nlearning model class and performance metric. In this paper, we approach the\ndownstream task-oriented generative model selections problem in the case of\ntraining fraud detection models and investigate the best practice given\ndifferent combinations of model interpretability and model performance\nconstraints. Our investigation supports that, while both Neural\nNetwork(NN)-based and Bayesian Network(BN)-based generative models are both\ngood to complete synthetic training task under loose model interpretability\nconstrain, the BN-based generative models is better than NN-based when\nsynthetic training fraud detection model under strict model interpretability\nconstrain. Our results provides practical guidance for machine learning\npractitioner who is interested in replacing their training dataset from real to\nsynthetic, and shed lights on more general downstream task-oriented generative\nmodel selection problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2024-01-01T23:33:56+00:00",
    "updated": "2024-01-01T23:33:56+00:00",
    "url": "http://arxiv.org/pdf/2401.00974v1"
  },
  {
    "id": "2401.00965v1",
    "title": "Improve Fidelity and Utility of Synthetic Credit Card Transaction Time Series from Data-centric Perspective",
    "authors": [
      "Din-Yin Hsieh",
      "Chi-Hua Wang",
      "Guang Cheng"
    ],
    "abstract": "Exploring generative model training for synthetic tabular data, specifically\nin sequential contexts such as credit card transaction data, presents\nsignificant challenges. This paper addresses these challenges, focusing on\nattaining both high fidelity to actual data and optimal utility for machine\nlearning tasks. We introduce five pre-processing schemas to enhance the\ntraining of the Conditional Probabilistic Auto-Regressive Model (CPAR),\ndemonstrating incremental improvements in the synthetic data's fidelity and\nutility. Upon achieving satisfactory fidelity levels, our attention shifts to\ntraining fraud detection models tailored for time-series data, evaluating the\nutility of the synthetic data. Our findings offer valuable insights and\npractical guidelines for synthetic data practitioners in the finance sector,\ntransitioning from real to synthetic datasets for training purposes, and\nilluminating broader methodologies for synthesizing credit card transaction\ntime series.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-01-01T22:34:14+00:00",
    "updated": "2024-01-01T22:34:14+00:00",
    "url": "http://arxiv.org/pdf/2401.00965v1"
  },
  {
    "id": "2312.16799v1",
    "title": "Temporal Knowledge Distillation for Time-Sensitive Financial Services Applications",
    "authors": [
      "Hongda Shen",
      "Eren Kurshan"
    ],
    "abstract": "Detecting anomalies has become an increasingly critical function in the\nfinancial service industry. Anomaly detection is frequently used in key\ncompliance and risk functions such as financial crime detection fraud and\ncybersecurity. The dynamic nature of the underlying data patterns especially in\nadversarial environments like fraud detection poses serious challenges to the\nmachine learning models. Keeping up with the rapid changes by retraining the\nmodels with the latest data patterns introduces pressures in balancing the\nhistorical and current patterns while managing the training data size.\nFurthermore the model retraining times raise problems in time-sensitive and\nhigh-volume deployment systems where the retraining period directly impacts the\nmodels ability to respond to ongoing attacks in a timely manner. In this study\nwe propose a temporal knowledge distillation-based label augmentation approach\n(TKD) which utilizes the learning from older models to rapidly boost the latest\nmodel and effectively reduces the model retraining times to achieve improved\nagility. Experimental results show that the proposed approach provides\nadvantages in retraining times while improving the model performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2023-12-28T03:04:30+00:00",
    "updated": "2023-12-28T03:04:30+00:00",
    "url": "http://arxiv.org/pdf/2312.16799v1"
  },
  {
    "id": "2312.16139v2",
    "title": "Abnormal component analysis",
    "authors": [
      "Romain Valla",
      "Pavlo Mozharovskyi",
      "Florence d'Alché-Buc"
    ],
    "abstract": "At the crossway of machine learning and data analysis, anomaly detection aims\nat identifying observations that exhibit abnormal behaviour. Be it measurement\nerrors, disease development, severe weather, production quality default(s)\n(items) or failed equipment, financial frauds or crisis events, their on-time\nidentification and isolation constitute an important task in almost any area of\nindustry and science. While a substantial body of literature is devoted to\ndetection of anomalies, little attention is payed to their explanation. This is\nthe case mostly due to intrinsically non-supervised nature of the task and\nnon-robustness of the exploratory methods like principal component analysis\n(PCA).\n  We introduce a new statistical tool dedicated for exploratory analysis of\nabnormal observations using data depth as a score. Abnormal component analysis\n(shortly ACA) is a method that searches a low-dimensional data representation\nthat best visualises and explains anomalies. This low-dimensional\nrepresentation not only allows to distinguish groups of anomalies better than\nthe methods of the state of the art, but as well provides a -- linear in\nvariables and thus easily interpretable -- explanation for anomalies. In a\ncomparative simulation and real-data study, ACA also proves advantageous for\nanomaly analysis with respect to methods present in the literature.",
    "categories": [
      "stat.ME",
      "cs.LG",
      "stat.ML"
    ],
    "published": "2023-12-26T17:57:46+00:00",
    "updated": "2025-06-05T16:09:29+00:00",
    "url": "http://arxiv.org/pdf/2312.16139v2"
  },
  {
    "id": "2312.14795v1",
    "title": "On support vector machines under a multiple-cost scenario",
    "authors": [
      "Sandra Benítez-Peña",
      "Rafael Blanquero",
      "Emilio Carrizosa",
      "Pepa Ramírez-Cobo"
    ],
    "abstract": "Support Vector Machine (SVM) is a powerful tool in binary classification,\nknown to attain excellent misclassification rates. On the other hand, many\nrealworld classification problems, such as those found in medical diagnosis,\nchurn or fraud prediction, involve misclassification costs which may be\ndifferent in the different classes. However, it may be hard for the user to\nprovide precise values for such misclassification costs, whereas it may be much\neasier to identify acceptable misclassification rates values. In this paper we\npropose a novel SVM model in which misclassification costs are considered by\nincorporating performance constraints in the problem formulation. Specifically,\nour aim is to seek the hyperplane with maximal margin yielding\nmisclassification rates below given threshold values. Such maximal margin\nhyperplane is obtained by solving a quadratic convex problem with linear\nconstraints and integer variables. The reported numerical experience shows that\nour model gives the user control on the misclassification rates in one class\n(possibly at the expense of an increase in misclassification rates for the\nother class) and is feasible in terms of running times.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2023-12-22T16:12:25+00:00",
    "updated": "2023-12-22T16:12:25+00:00",
    "url": "http://arxiv.org/pdf/2312.14795v1"
  },
  {
    "id": "2312.14535v1",
    "title": "ADA-GAD: Anomaly-Denoised Autoencoders for Graph Anomaly Detection",
    "authors": [
      "Junwei He",
      "Qianqian Xu",
      "Yangbangyan Jiang",
      "Zitai Wang",
      "Qingming Huang"
    ],
    "abstract": "Graph anomaly detection is crucial for identifying nodes that deviate from\nregular behavior within graphs, benefiting various domains such as fraud\ndetection and social network. Although existing reconstruction-based methods\nhave achieved considerable success, they may face the \\textit{Anomaly\nOverfitting} and \\textit{Homophily Trap} problems caused by the abnormal\npatterns in the graph, breaking the assumption that normal nodes are often\nbetter reconstructed than abnormal ones. Our observations indicate that models\ntrained on graphs with fewer anomalies exhibit higher detection performance.\nBased on this insight, we introduce a novel two-stage framework called\nAnomaly-Denoised Autoencoders for Graph Anomaly Detection (ADA-GAD). In the\nfirst stage, we design a learning-free anomaly-denoised augmentation method to\ngenerate graphs with reduced anomaly levels. We pretrain graph autoencoders on\nthese augmented graphs at multiple levels, which enables the graph autoencoders\nto capture normal patterns. In the next stage, the decoders are retrained for\ndetection on the original graph, benefiting from the multi-level\nrepresentations learned in the previous stage. Meanwhile, we propose the node\nanomaly distribution regularization to further alleviate \\textit{Anomaly\nOverfitting}. We validate the effectiveness of our approach through extensive\nexperiments on both synthetic and real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "published": "2023-12-22T09:02:01+00:00",
    "updated": "2023-12-22T09:02:01+00:00",
    "url": "http://arxiv.org/pdf/2312.14535v1"
  },
  {
    "id": "2312.14406v1",
    "title": "Generative Pretraining at Scale: Transformer-Based Encoding of Transactional Behavior for Fraud Detection",
    "authors": [
      "Ze Yu Zhao",
      "Zheng Zhu",
      "Guilin Li",
      "Wenhan Wang",
      "Bo Wang"
    ],
    "abstract": "In this work, we introduce an innovative autoregressive model leveraging\nGenerative Pretrained Transformer (GPT) architectures, tailored for fraud\ndetection in payment systems. Our approach innovatively confronts token\nexplosion and reconstructs behavioral sequences, providing a nuanced\nunderstanding of transactional behavior through temporal and contextual\nanalysis. Utilizing unsupervised pretraining, our model excels in feature\nrepresentation without the need for labeled data. Additionally, we integrate a\ndifferential convolutional approach to enhance anomaly detection, bolstering\nthe security and efficacy of one of the largest online payment merchants in\nChina. The scalability and adaptability of our model promise broad\napplicability in various transactional contexts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2023-12-22T03:15:17+00:00",
    "updated": "2023-12-22T03:15:17+00:00",
    "url": "http://arxiv.org/pdf/2312.14406v1"
  },
  {
    "id": "2402.13169v1",
    "title": "Formal Verification for Blockchain-based Insurance Claims Processing",
    "authors": [
      "Roshan Lal Neupane",
      "Ernest Bonnah",
      "Bishnu Bhusal",
      "Kiran Neupane",
      "Khaza Anuarul Hoque",
      "Prasad Calyam"
    ],
    "abstract": "Insurance claims processing involves multi-domain entities and multi-source\ndata, along with a number of human-agent interactions. Use of Blockchain\ntechnology-based platform can significantly improve scalability and response\ntime for processing of claims which are otherwise manually-intensive and\ntime-consuming. However, the chaincodes involved within the processes that\nissue claims, approve or deny them as required, need to be formally verified to\nensure secure and reliable processing of transactions in Blockchain. In this\npaper, we use a formal modeling approach to verify various processes and their\nunderlying chaincodes relating to different stages in insurance claims\nprocessing viz., issuance, approval, denial, and flagging for fraud\ninvestigation by using linear temporal logic (LTL). We simulate the formalism\non the chaincodes and analyze the breach of chaincodes via model checking.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-02-20T17:29:59+00:00",
    "updated": "2024-02-20T17:29:59+00:00",
    "url": "http://arxiv.org/pdf/2402.13169v1"
  },
  {
    "id": "2402.11837v2",
    "title": "Self-Guided Robust Graph Structure Refinement",
    "authors": [
      "Yeonjun In",
      "Kanghoon Yoon",
      "Kibum Kim",
      "Kijung Shin",
      "Chanyoung Park"
    ],
    "abstract": "Recent studies have revealed that GNNs are vulnerable to adversarial attacks.\nTo defend against such attacks, robust graph structure refinement (GSR) methods\naim at minimizing the effect of adversarial edges based on node features, graph\nstructure, or external information. However, we have discovered that existing\nGSR methods are limited by narrowassumptions, such as assuming clean node\nfeatures, moderate structural attacks, and the availability of external clean\ngraphs, resulting in the restricted applicability in real-world scenarios. In\nthis paper, we propose a self-guided GSR framework (SG-GSR), which utilizes a\nclean sub-graph found within the given attacked graph itself. Furthermore, we\npropose a novel graph augmentation and a group-training strategy to handle the\ntwo technical challenges in the clean sub-graph extraction: 1) loss of\nstructural information, and 2) imbalanced node degree distribution. Extensive\nexperiments demonstrate the effectiveness of SG-GSR under various scenarios\nincluding non-targeted attacks, targeted attacks, feature attacks, e-commerce\nfraud, and noisy node labels. Our code is available at\nhttps://github.com/yeonjun-in/torch-SG-GSR.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-02-19T05:00:07+00:00",
    "updated": "2024-03-02T05:43:05+00:00",
    "url": "http://arxiv.org/pdf/2402.11837v2"
  },
  {
    "id": "2402.11231v1",
    "title": "Enhancing Security in Blockchain Networks: Anomalies, Frauds, and Advanced Detection Techniques",
    "authors": [
      "Joerg Osterrieder",
      "Stephen Chan",
      "Jeffrey Chu",
      "Yuanyuan Zhang",
      "Branka Hadji Misheva",
      "Codruta Mare"
    ],
    "abstract": "Blockchain technology, a foundational distributed ledger system, enables\nsecure and transparent multi-party transactions. Despite its advantages,\nblockchain networks are susceptible to anomalies and frauds, posing significant\nrisks to their integrity and security. This paper offers a detailed examination\nof blockchain's key definitions and properties, alongside a thorough analysis\nof the various anomalies and frauds that undermine these networks. It describes\nan array of detection and prevention strategies, encompassing statistical and\nmachine learning methods, game-theoretic solutions, digital forensics,\nreputation-based systems, and comprehensive risk assessment techniques. Through\ncase studies, we explore practical applications of anomaly and fraud detection\nin blockchain networks, extracting valuable insights and implications for both\ncurrent practice and future research. Moreover, we spotlight emerging trends\nand challenges within the field, proposing directions for future investigation\nand technological development. Aimed at both practitioners and researchers,\nthis paper seeks to provide a technical, in-depth overview of anomaly and fraud\ndetection within blockchain networks, marking a significant step forward in the\nsearch for enhanced network security and reliability.",
    "categories": [
      "cs.CR",
      "q-fin.GN"
    ],
    "published": "2024-02-17T09:27:30+00:00",
    "updated": "2024-02-17T09:27:30+00:00",
    "url": "http://arxiv.org/pdf/2402.11231v1"
  },
  {
    "id": "2402.11209v3",
    "title": "When Simple is Near Optimal in Security Games",
    "authors": [
      "Devansh Jalota",
      "Michael Ostrovsky",
      "Marco Pavone"
    ],
    "abstract": "Fraud is ubiquitous across applications and involve users bypassing the rule\nof law, often with the strategic aim of obtaining some benefit that would\notherwise be unattainable within the bounds of lawful conduct. However, user\nfraud can be detrimental.\n  To mitigate the harms of user fraud, we study the problem of policing fraud\nas a security game between an administrator and users. In this game, an\nadministrator deploys $R$ security resources (e.g., police officers) across $L$\nlocations and levies fines against users engaging in fraud at those locations.\nFor this security game, we study both payoff and revenue maximization\nadministrator objectives. In both settings, we show that computing the optimal\nadministrator strategy is NP-hard and develop natural greedy algorithm variants\nfor the respective settings that achieve at least half the payoff or revenue as\nthe payoff-maximizing or revenue-maximizing solutions, respectively. We also\nestablish a resource augmentation guarantee that our proposed greedy algorithms\nwith one extra resource, i.e., $R+1$ resources, achieve at least the same\npayoff (revenue) as the payoff-maximizing (revenue-maximizing) outcome with $R$\nresources. Moreover, in the setting when user types are homogeneous, we develop\na near-linear time algorithm for the revenue maximization problem and a\npolynomial time approximation scheme for the payoff maximization problem.\n  Next, we present numerical experiments based on a case study of parking\nenforcement at Stanford University's campus, highlighting the efficacy of our\nalgorithms in increasing parking permit earnings at the university by over\n\\$300,000 annually. Finally, we study several model extensions, including\nincorporating contracts to bridge the gap between the payoff and\nrevenue-maximizing outcomes and generalizing our model to incorporate\nadditional constraints beyond a resource budget constraint.",
    "categories": [
      "cs.GT",
      "cs.CC",
      "econ.TH",
      "math.OC"
    ],
    "published": "2024-02-17T07:00:25+00:00",
    "updated": "2024-08-15T05:21:01+00:00",
    "url": "http://arxiv.org/pdf/2402.11209v3"
  },
  {
    "id": "2402.09830v1",
    "title": "Utilizing GANs for Fraud Detection: Model Training with Synthetic Transaction Data",
    "authors": [
      "Mengran Zhu",
      "Yulu Gong",
      "Yafei Xiang",
      "Hanyi Yu",
      "Shuning Huo"
    ],
    "abstract": "Anomaly detection is a critical challenge across various research domains,\naiming to identify instances that deviate from normal data distributions. This\npaper explores the application of Generative Adversarial Networks (GANs) in\nfraud detection, comparing their advantages with traditional methods. GANs, a\ntype of Artificial Neural Network (ANN), have shown promise in modeling complex\ndata distributions, making them effective tools for anomaly detection. The\npaper systematically describes the principles of GANs and their derivative\nmodels, emphasizing their application in fraud detection across different\ndatasets. And by building a collection of adversarial verification graphs, we\nwill effectively prevent fraud caused by bots or automated systems and ensure\nthat the users in the transaction are real. The objective of the experiment is\nto design and implement a fake face verification code and fraud detection\nsystem based on Generative Adversarial network (GANs) algorithm to enhance the\nsecurity of the transaction process.The study demonstrates the potential of\nGANs in enhancing transaction security through deep learning techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "published": "2024-02-15T09:48:20+00:00",
    "updated": "2024-02-15T09:48:20+00:00",
    "url": "http://arxiv.org/pdf/2402.09830v1"
  },
  {
    "id": "2402.09581v2",
    "title": "Combatting deepfakes: Policies to address national security threats and rights violations",
    "authors": [
      "Andrea Miotti",
      "Akash Wasil"
    ],
    "abstract": "This paper provides policy recommendations to address threats from deepfakes.\nFirst, we provide background information about deepfakes and review the harms\nthey pose. We describe how deepfakes are currently used to proliferate sexual\nabuse material, commit fraud, manipulate voter behavior, and pose threats to\nnational security. Second, we review previous legislative proposals designed to\naddress deepfakes. Third, we present a comprehensive policy proposal that\nfocuses on addressing multiple parts of the deepfake supply chain. The deepfake\nsupply chain begins with a small number of model developers, model providers,\nand compute providers, and it expands to include billions of potential deepfake\ncreators. We describe this supply chain in greater detail and describe how\nentities at each step of the supply chain ought to take reasonable measures to\nprevent the creation and proliferation of deepfakes. Finally, we address\npotential counterpoints of our proposal. Overall, deepfakes will present\nincreasingly severe threats to global security and individual liberties. To\naddress these threats, we call on policymakers to enact legislation that\naddresses multiple parts of the deepfake supply chain.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2024-02-14T21:05:55+00:00",
    "updated": "2024-02-19T18:39:40+00:00",
    "url": "http://arxiv.org/pdf/2402.09581v2"
  },
  {
    "id": "2403.00775v1",
    "title": "Detecting Anomalous Events in Object-centric Business Processes via Graph Neural Networks",
    "authors": [
      "Alessandro Niro",
      "Michael Werner"
    ],
    "abstract": "Detecting anomalies is important for identifying inefficiencies, errors, or\nfraud in business processes. Traditional process mining approaches focus on\nanalyzing 'flattened', sequential, event logs based on a single case notion.\nHowever, many real-world process executions exhibit a graph-like structure,\nwhere events can be associated with multiple cases. Flattening event logs\nrequires selecting a single case identifier which creates a gap with the real\nevent data and artificially introduces anomalies in the event logs.\nObject-centric process mining avoids these limitations by allowing events to be\nrelated to different cases. This study proposes a novel framework for anomaly\ndetection in business processes that exploits graph neural networks and the\nenhanced information offered by object-centric process mining. We first\nreconstruct and represent the process dependencies of the object-centric event\nlogs as attributed graphs and then employ a graph convolutional autoencoder\narchitecture to detect anomalous events. Our results show that our approach\nprovides promising performance in detecting anomalies at the activity type and\nattributes level, although it struggles to detect anomalies in the temporal\norder of events.",
    "categories": [
      "q-fin.ST",
      "cs.DB",
      "cs.LG"
    ],
    "published": "2024-02-14T14:17:56+00:00",
    "updated": "2024-02-14T14:17:56+00:00",
    "url": "http://arxiv.org/pdf/2403.00775v1"
  },
  {
    "id": "2402.09495v2",
    "title": "On the Potential of Network-Based Features for Fraud Detection",
    "authors": [
      "Catayoun Azarm",
      "Erman Acar",
      "Mickey van Zeelt"
    ],
    "abstract": "Online transaction fraud presents substantial challenges to businesses and\nconsumers, risking significant financial losses. Conventional rule-based\nsystems struggle to keep pace with evolving fraud tactics, leading to high\nfalse positive rates and missed detections. Machine learning techniques offer a\npromising solution by leveraging historical data to identify fraudulent\npatterns. This article explores using the personalised PageRank (PPR) algorithm\nto capture the social dynamics of fraud by analysing relationships between\nfinancial accounts. The primary objective is to compare the performance of\ntraditional features with the addition of PPR in fraud detection models.\nResults indicate that integrating PPR enhances the model's predictive power,\nsurpassing the baseline model. Additionally, the PPR feature provides unique\nand valuable information, evidenced by its high feature importance score.\nFeature stability analysis confirms consistent feature distributions across\ntraining and test datasets.",
    "categories": [
      "q-fin.RM",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2024-02-14T13:20:09+00:00",
    "updated": "2024-02-19T11:58:13+00:00",
    "url": "http://arxiv.org/pdf/2402.09495v2"
  },
  {
    "id": "2402.08918v3",
    "title": "SimMLP: Training MLPs on Graphs without Supervision",
    "authors": [
      "Zehong Wang",
      "Zheyuan Zhang",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "abstract": "Graph Neural Networks (GNNs) have demonstrated their effectiveness in various\ngraph learning tasks, yet their reliance on neighborhood aggregation during\ninference poses challenges for deployment in latency-sensitive applications,\nsuch as real-time financial fraud detection. To address this limitation, recent\nstudies have proposed distilling knowledge from teacher GNNs into student\nMulti-Layer Perceptrons (MLPs) trained on node content, aiming to accelerate\ninference. However, these approaches often inadequately explore structural\ninformation when inferring unseen nodes. To this end, we introduce SimMLP, a\nSelf-supervised framework for learning MLPs on graphs, designed to fully\nintegrate rich structural information into MLPs. Notably, SimMLP is the first\nMLP-learning method that can achieve equivalence to GNNs in the optimal case.\nThe key idea is to employ self-supervised learning to align the representations\nencoded by graph context-aware GNNs and neighborhood dependency-free MLPs,\nthereby fully integrating the structural information into MLPs. We provide a\ncomprehensive theoretical analysis, demonstrating the equivalence between\nSimMLP and GNNs based on mutual information and inductive bias, highlighting\nSimMLP's advanced structural learning capabilities. Additionally, we conduct\nextensive experiments on 20 benchmark datasets, covering node classification,\nlink prediction, and graph classification, to showcase SimMLP's superiority\nover state-of-the-art baselines, particularly in scenarios involving unseen\nnodes (e.g., inductive and cold-start node classification) where structural\ninsights are crucial. Our codes are available at:\nhttps://github.com/Zehong-Wang/SimMLP.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "published": "2024-02-14T03:16:13+00:00",
    "updated": "2024-12-06T02:46:38+00:00",
    "url": "http://arxiv.org/pdf/2402.08918v3"
  },
  {
    "id": "2402.08202v1",
    "title": "Confronting Discrimination in Classification: Smote Based on Marginalized Minorities in the Kernel Space for Imbalanced Data",
    "authors": [
      "Lingyun Zhong"
    ],
    "abstract": "Financial fraud detection poses a typical challenge characterized by class\nimbalance, where instances of fraud are extremely rare but can lead to\nunpredictable economic losses if misidentified. Precisely classifying these\ncritical minority samples represents a challenging task within the\nclassification. The primary difficulty arises from mainstream classifiers,\nwhich often exhibit \"implicit discrimination\" against minority samples in\nevaluation metrics, which results in frequent misclassifications, and the key\nto the problem lies in the overlap of feature spaces between majority and\nminority samples. To address these challenges, oversampling is a feasible\nsolution, yet current classical oversampling methods often lack the necessary\ncaution in sample selection, exacerbating feature space overlap. In response,\nwe propose a novel classification oversampling approach based on the decision\nboundary and sample proximity relationships. This method carefully considers\nthe distance between critical samples and the decision hyperplane, as well as\nthe density of surrounding samples, resulting in an adaptive oversampling\nstrategy in the kernel space. Finally, we test the proposed method on a classic\nfinancial fraud dataset, and the results show that our proposed method provides\nan effective and robust solution that can improve the classification accuracy\nof minorities.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-02-13T04:03:09+00:00",
    "updated": "2024-02-13T04:03:09+00:00",
    "url": "http://arxiv.org/pdf/2402.08202v1"
  },
  {
    "id": "2402.07860v2",
    "title": "On the Detection of Reviewer-Author Collusion Rings From Paper Bidding",
    "authors": [
      "Steven Jecmen",
      "Nihar B. Shah",
      "Fei Fang",
      "Leman Akoglu"
    ],
    "abstract": "A major threat to the peer-review systems of computer science conferences is\nthe existence of \"collusion rings\" between reviewers. In such collusion rings,\nreviewers who have also submitted their own papers to the conference work\ntogether to manipulate the conference's paper assignment, with the aim of being\nassigned to review each other's papers. The most straightforward way that\ncolluding reviewers can manipulate the paper assignment is by indicating their\ninterest in each other's papers through strategic paper bidding. One potential\napproach to solve this important problem would be to detect the colluding\nreviewers from their manipulated bids, after which the conference can take\nappropriate action. While prior work has developed effective techniques to\ndetect other kinds of fraud, no research has yet established that detecting\ncollusion rings is even possible. In this work, we tackle the question of\nwhether it is feasible to detect collusion rings from the paper bidding. To\nanswer this question, we conduct empirical analysis of two realistic conference\nbidding datasets, including evaluations of existing algorithms for fraud\ndetection in other applications. We find that collusion rings can achieve\nconsiderable success at manipulating the paper assignment while remaining\nhidden from detection: for example, in one dataset, undetected colluders are\nable to achieve assignment to up to 30% of the papers authored by other\ncolluders. In addition, when 10 colluders bid on all of each other's papers, no\ndetection algorithm outputs a group of reviewers with more than 31% overlap\nwith the true colluders. These results suggest that collusion cannot be\neffectively detected from the bidding using popular existing tools,\ndemonstrating the need to develop more complex detection algorithms as well as\nthose that leverage additional metadata (e.g., reviewer-paper text-similarity\nscores).",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.GT"
    ],
    "published": "2024-02-12T18:12:09+00:00",
    "updated": "2024-03-10T23:46:41+00:00",
    "url": "http://arxiv.org/pdf/2402.07860v2"
  },
  {
    "id": "2402.07241v2",
    "title": "Proof of Diligence: Cryptoeconomic Security for Rollups",
    "authors": [
      "Peiyao Sheng",
      "Ranvir Rana",
      "Senthil Bala",
      "Himanshu Tyagi",
      "Pramod Viswanath"
    ],
    "abstract": "Layer 1 (L1) blockchains such as Ethereum are secured under an \"honest\nsupermajority of stake\" assumption for a large pool of validators who verify\neach and every transaction on it. This high security comes at a scalability\ncost which not only effects the throughput of the blockchain but also results\nin high gas fees for executing transactions on chain. The most successful\nsolution for this problem is provided by optimistic rollups, Layer 2 (L2)\nblockchains that execute transactions outside L1 but post the transaction data\non L1.\n  The security for such L2 chains is argued, informally, under the assumption\nthat a set of nodes will check the transaction data posted on L1 and raise an\nalarm (a fraud proof) if faulty transactions are detected. However, all current\ndeployments lack a proper incentive mechanism for ensuring that these nodes\nwill do their job ``diligently'', and simply rely on a cursory incentive\nalignment argument for security.\n  We solve this problem by introducing an incentivized watchtower network\ndesigned to serve as the first line of defense for rollups. Our main\ncontribution is a ``Proof of Diligence'' protocol that requires watchtowers to\ncontinuously provide a proof that they have verified L2 assertions and get\nrewarded for the same. Proof of Diligence protocol includes a\ncarefully-designed incentive mechanism that is provably secure when watchtowers\nare rational actors, under a mild rational independence assumption.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-02-11T16:40:33+00:00",
    "updated": "2024-07-23T20:15:03+00:00",
    "url": "http://arxiv.org/pdf/2402.07241v2"
  },
  {
    "id": "2402.05396v3",
    "title": "TASER: Temporal Adaptive Sampling for Fast and Accurate Dynamic Graph Representation Learning",
    "authors": [
      "Gangda Deng",
      "Hongkuan Zhou",
      "Hanqing Zeng",
      "Yinglong Xia",
      "Christopher Leung",
      "Jianbo Li",
      "Rajgopal Kannan",
      "Viktor Prasanna"
    ],
    "abstract": "Recently, Temporal Graph Neural Networks (TGNNs) have demonstrated\nstate-of-the-art performance in various high-impact applications, including\nfraud detection and content recommendation. Despite the success of TGNNs, they\nare prone to the prevalent noise found in real-world dynamic graphs like\ntime-deprecated links and skewed interaction distribution. The noise causes two\ncritical issues that significantly compromise the accuracy of TGNNs: (1) models\nare supervised by inferior interactions, and (2) noisy input induces high\nvariance in the aggregated messages. However, current TGNN denoising techniques\ndo not consider the diverse and dynamic noise pattern of each node. In\naddition, they also suffer from the excessive mini-batch generation overheads\ncaused by traversing more neighbors. We believe the remedy for fast and\naccurate TGNNs lies in temporal adaptive sampling. In this work, we propose\nTASER, the first adaptive sampling method for TGNNs optimized for accuracy,\nefficiency, and scalability. TASER adapts its mini-batch selection based on\ntraining dynamics and temporal neighbor selection based on the contextual,\nstructural, and temporal properties of past interactions. To alleviate the\nbottleneck in mini-batch generation, TASER implements a pure GPU-based temporal\nneighbor finder and a dedicated GPU feature cache. We evaluate the performance\nof TASER using two state-of-the-art backbone TGNNs. On five popular datasets,\nTASER outperforms the corresponding baselines by an average of 2.3% in Mean\nReciprocal Rank (MRR) while achieving an average of 5.1x speedup in training\ntime.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2024-02-08T04:16:35+00:00",
    "updated": "2024-11-23T10:42:11+00:00",
    "url": "http://arxiv.org/pdf/2402.05396v3"
  },
  {
    "id": "2402.04607v1",
    "title": "Google Scholar is manipulatable",
    "authors": [
      "Hazem Ibrahim",
      "Fengyuan Liu",
      "Yasir Zaki",
      "Talal Rahwan"
    ],
    "abstract": "Citations are widely considered in scientists' evaluation. As such,\nscientists may be incentivized to inflate their citation counts. While previous\nliterature has examined self-citations and citation cartels, it remains unclear\nwhether scientists can purchase citations. Here, we compile a dataset of ~1.6\nmillion profiles on Google Scholar to examine instances of citation fraud on\nthe platform. We survey faculty at highly-ranked universities, and confirm that\nGoogle Scholar is widely used when evaluating scientists. Intrigued by a\ncitation-boosting service that we unravelled during our investigation, we\ncontacted the service while undercover as a fictional author, and managed to\npurchase 50 citations. These findings provide conclusive evidence that\ncitations can be bought in bulk, and highlight the need to look beyond citation\ncounts.",
    "categories": [
      "cs.CE",
      "cs.DL",
      "cs.SI",
      "physics.soc-ph"
    ],
    "published": "2024-02-07T06:08:23+00:00",
    "updated": "2024-02-07T06:08:23+00:00",
    "url": "http://arxiv.org/pdf/2402.04607v1"
  },
  {
    "id": "2403.05546v1",
    "title": "Unified Occupancy on a Public Transport Network through Combination of AFC and APC Data",
    "authors": [
      "Amir Dib",
      "Noëlie Cherrier",
      "Martin Graive",
      "Baptiste Rérolle",
      "Eglantine Schmitt"
    ],
    "abstract": "In a transport network, the onboard occupancy is key for gaining insights\ninto travelers' habits and adjusting the offer. Traditionally, operators have\nrelied on field studies to evaluate ridership of a typical workday. However,\nautomated fare collection (AFC) and automatic passenger counting (APC) data,\nwhich provide complete temporal coverage, are often available but\nunderexploited. It should be noted, however, that each data source comes with\nits own biases: AFC data may not account for fraud, while not all vehicles are\nequipped with APC systems.\n  This paper introduces the unified occupancy method, a geostatistical model to\nextrapolate occupancy to every course of a public transportation network by\ncombining AFC and APC data with partial coverage. Unified occupancy completes\nmissing APC information for courses on lines where other courses have APC\nmeasures, as well as for courses on lines where no APC data is available at\nall. The accuracy of this method is evaluated on real data from several public\ntransportation networks in France.",
    "categories": [
      "cs.CY",
      "cs.CE",
      "cs.LG",
      "stat.AP"
    ],
    "published": "2024-02-06T16:33:56+00:00",
    "updated": "2024-02-06T16:33:56+00:00",
    "url": "http://arxiv.org/pdf/2403.05546v1"
  },
  {
    "id": "2402.03147v1",
    "title": "Detecting Scams Using Large Language Models",
    "authors": [
      "Liming Jiang"
    ],
    "abstract": "Large Language Models (LLMs) have gained prominence in various applications,\nincluding security. This paper explores the utility of LLMs in scam detection,\na critical aspect of cybersecurity. Unlike traditional applications, we propose\na novel use case for LLMs to identify scams, such as phishing, advance fee\nfraud, and romance scams. We present notable security applications of LLMs and\ndiscuss the unique challenges posed by scams. Specifically, we outline the key\nsteps involved in building an effective scam detector using LLMs, emphasizing\ndata collection, preprocessing, model selection, training, and integration into\ntarget systems. Additionally, we conduct a preliminary evaluation using GPT-3.5\nand GPT-4 on a duplicated email, highlighting their proficiency in identifying\ncommon signs of phishing or scam emails. The results demonstrate the models'\neffectiveness in recognizing suspicious elements, but we emphasize the need for\na comprehensive assessment across various language tasks. The paper concludes\nby underlining the importance of ongoing refinement and collaboration with\ncybersecurity experts to adapt to evolving threats.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-02-05T16:13:54+00:00",
    "updated": "2024-02-05T16:13:54+00:00",
    "url": "http://arxiv.org/pdf/2402.03147v1"
  },
  {
    "id": "2402.00653v1",
    "title": "Coherent Feed Forward Quantum Neural Network",
    "authors": [
      "Utkarsh Singh",
      "Aaron Z. Goldberg",
      "Khabat Heshami"
    ],
    "abstract": "Quantum machine learning, focusing on quantum neural networks (QNNs), remains\na vastly uncharted field of study. Current QNN models primarily employ\nvariational circuits on an ansatz or a quantum feature map, often requiring\nmultiple entanglement layers. This methodology not only increases the\ncomputational cost of the circuit beyond what is practical on near-term quantum\ndevices but also misleadingly labels these models as neural networks, given\ntheir divergence from the structure of a typical feed-forward neural network\n(FFNN). Moreover, the circuit depth and qubit needs of these models scale\npoorly with the number of data features, resulting in an efficiency challenge\nfor real-world machine-learning tasks. We introduce a bona fide QNN model,\nwhich seamlessly aligns with the versatility of a traditional FFNN in terms of\nits adaptable intermediate layers and nodes, absent from intermediate\nmeasurements such that our entire model is coherent. This model stands out with\nits reduced circuit depth and number of requisite C-NOT gates to outperform\nprevailing QNN models. Furthermore, the qubit count in our model remains\nunaffected by the data's feature quantity. We test our proposed model on\nvarious benchmarking datasets such as the diagnostic breast cancer (Wisconsin)\nand credit card fraud detection datasets. We compare the outcomes of our model\nwith the existing QNN methods to showcase the advantageous efficacy of our\napproach, even with a reduced requirement on quantum resources. Our model paves\nthe way for application of quantum neural networks to real relevant machine\nlearning problems.",
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "published": "2024-02-01T15:13:26+00:00",
    "updated": "2024-02-01T15:13:26+00:00",
    "url": "http://arxiv.org/pdf/2402.00653v1"
  },
  {
    "id": "2401.17555v2",
    "title": "opML: Optimistic Machine Learning on Blockchain",
    "authors": [
      "KD Conway",
      "Cathie So",
      "Xiaohang Yu",
      "Kartin Wong"
    ],
    "abstract": "The integration of machine learning with blockchain technology has witnessed\nincreasing interest, driven by the vision of decentralized, secure, and\ntransparent AI services. In this context, we introduce opML (Optimistic Machine\nLearning on chain), an innovative approach that empowers blockchain systems to\nconduct AI model inference. opML lies a interactive fraud proof protocol,\nreminiscent of the optimistic rollup systems. This mechanism ensures\ndecentralized and verifiable consensus for ML services, enhancing trust and\ntransparency. Unlike zkML (Zero-Knowledge Machine Learning), opML offers\ncost-efficient and highly efficient ML services, with minimal participation\nrequirements. Remarkably, opML enables the execution of extensive language\nmodels, such as 7B-LLaMA, on standard PCs without GPUs, significantly expanding\naccessibility. By combining the capabilities of blockchain and AI through opML,\nwe embark on a transformative journey toward accessible, secure, and efficient\non-chain machine learning.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-01-31T02:43:38+00:00",
    "updated": "2024-02-05T05:23:59+00:00",
    "url": "http://arxiv.org/pdf/2401.17555v2"
  },
  {
    "id": "2401.15700v1",
    "title": "AI-based Personalization and Trust in Digital Finance",
    "authors": [
      "Vijaya Kanaparthi"
    ],
    "abstract": "Personalized services bridge the gap between a financial institution and its\ncustomers and are built on trust. The more we trust the product, the keener we\nare to disclose our personal information in order to receive a highly\npersonalized service that maximizes consumer value. Artificial Intelligence\n(AI) can help financial institutions tailor relevant products and services to\ntheir customers as well as improve their credit risk management, compliance,\nand fraud detection capabilities by incorporating chatbots and face recognition\nsystems. The present study has analyzed sixteen research papers using the\nPRISMA model to perform a Systematic Literature Review (SLR). It has identified\nfive research gaps and corresponding questions to analyze the present scenario.\nOne of the gaps is credit risk detection for improved personalization and\ntrust. Finally, an AI-based credit risk detection model has been built using\nfour supervised machine learning classifiers viz., Support Vector Machine,\nRandom Forest, Decision Tree, and Logistic Regression. Performance comparison\nshows an optimal performance of the model giving accuracy of ~89%, precision of\n~88%, recall of ~89%, specificity of ~89%, F1_score of ~88%, and AUC of 0.77\nfor the Random Forest classifier. This model is foreseen to be most suitable\nfor envisaging customer characteristics for which personalized credit risk\nmitigation strategies are particularly effective as compared to other existing\nworks presented in this study.",
    "categories": [
      "cs.CE"
    ],
    "published": "2024-01-28T16:50:36+00:00",
    "updated": "2024-01-28T16:50:36+00:00",
    "url": "http://arxiv.org/pdf/2401.15700v1"
  },
  {
    "id": "2401.15668v2",
    "title": "Lips Are Lying: Spotting the Temporal Inconsistency between Audio and Visual in Lip-Syncing DeepFakes",
    "authors": [
      "Weifeng Liu",
      "Tianyi She",
      "Jiawei Liu",
      "Boheng Li",
      "Dongyu Yao",
      "Ziyou Liang",
      "Run Wang"
    ],
    "abstract": "In recent years, DeepFake technology has achieved unprecedented success in\nhigh-quality video synthesis, but these methods also pose potential and severe\nsecurity threats to humanity. DeepFake can be bifurcated into entertainment\napplications like face swapping and illicit uses such as lip-syncing fraud.\nHowever, lip-forgery videos, which neither change identity nor have discernible\nvisual artifacts, present a formidable challenge to existing DeepFake detection\nmethods. Our preliminary experiments have shown that the effectiveness of the\nexisting methods often drastically decrease or even fail when tackling\nlip-syncing videos. In this paper, for the first time, we propose a novel\napproach dedicated to lip-forgery identification that exploits the\ninconsistency between lip movements and audio signals. We also mimic human\nnatural cognition by capturing subtle biological links between lips and head\nregions to boost accuracy. To better illustrate the effectiveness and advances\nof our proposed method, we create a high-quality LipSync dataset, AVLips, by\nemploying the state-of-the-art lip generators. We hope this high-quality and\ndiverse dataset could be well served the further research on this challenging\nand interesting field. Experimental results show that our approach gives an\naverage accuracy of more than 95.3% in spotting lip-syncing videos,\nsignificantly outperforming the baselines. Extensive experiments demonstrate\nthe capability to tackle deepfakes and the robustness in surviving diverse\ninput transformations. Our method achieves an accuracy of up to 90.2% in\nreal-world scenarios (e.g., WeChat video call) and shows its powerful\ncapabilities in real scenario deployment. To facilitate the progress of this\nresearch community, we release all resources at\nhttps://github.com/AaronComo/LipFD.",
    "categories": [
      "cs.CV"
    ],
    "published": "2024-01-28T14:22:11+00:00",
    "updated": "2024-10-28T08:29:38+00:00",
    "url": "http://arxiv.org/pdf/2401.15668v2"
  },
  {
    "id": "2404.00022v1",
    "title": "Analysing and Organising Human Communications for AI Fairness-Related Decisions: Use Cases from the Public Sector",
    "authors": [
      "Mirthe Dankloff",
      "Vanja Skoric",
      "Giovanni Sileno",
      "Sennay Ghebreab",
      "Jacco Van Ossenbruggen",
      "Emma Beauxis-Aussalet"
    ],
    "abstract": "AI algorithms used in the public sector, e.g., for allocating social benefits\nor predicting fraud, often involve multiple public and private stakeholders at\nvarious phases of the algorithm's life-cycle. Communication issues between\nthese diverse stakeholders can lead to misinterpretation and misuse of\nalgorithms. We investigate the communication processes for AI fairness-related\ndecisions by conducting interviews with practitioners working on algorithmic\nsystems in the public sector. By applying qualitative coding analysis, we\nidentify key elements of communication processes that underlie fairness-related\nhuman decisions. We analyze the division of roles, tasks, skills, and\nchallenges perceived by stakeholders. We formalize the underlying communication\nissues within a conceptual framework that i. represents the communication\npatterns ii. outlines missing elements, such as actors who miss skills for\ntheir tasks. The framework is used for describing and analyzing key\norganizational issues for fairness-related decisions. Three general patterns\nemerge from the analysis: 1. Policy-makers, civil servants, and domain experts\nare less involved compared to developers throughout a system's life-cycle. This\nleads to developers taking on extra roles such as advisor, while they\npotentially miss the required skills and guidance from domain experts. 2.\nEnd-users and policy-makers often lack the technical skills to interpret a\nsystem's limitations, and rely on developer roles for making decisions\nconcerning fairness issues. 3. Citizens are structurally absent throughout a\nsystem's life-cycle, which may lead to decisions that do not include relevant\nconsiderations from impacted stakeholders.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "published": "2024-03-20T14:20:42+00:00",
    "updated": "2024-03-20T14:20:42+00:00",
    "url": "http://arxiv.org/pdf/2404.00022v1"
  },
  {
    "id": "2403.11219v1",
    "title": "Causality from Bottom to Top: A Survey",
    "authors": [
      "Abraham Itzhak Weinberg",
      "Cristiano Premebida",
      "Diego Resende Faria"
    ],
    "abstract": "Causality has become a fundamental approach for explaining the relationships\nbetween events, phenomena, and outcomes in various fields of study. It has\ninvaded various fields and applications, such as medicine, healthcare,\neconomics, finance, fraud detection, cybersecurity, education, public policy,\nrecommender systems, anomaly detection, robotics, control, sociology,\nmarketing, and advertising. In this paper, we survey its development over the\npast five decades, shedding light on the differences between causality and\nother approaches, as well as the preconditions for using it. Furthermore, the\npaper illustrates how causality interacts with new approaches such as\nArtificial Intelligence (AI), Generative AI (GAI), Machine and Deep Learning,\nReinforcement Learning (RL), and Fuzzy Logic. We study the impact of causality\non various fields, its contribution, and its interaction with state-of-the-art\napproaches. Additionally, the paper exemplifies the trustworthiness and\nexplainability of causality models. We offer several ways to evaluate causality\nmodels and discuss future directions.",
    "categories": [
      "cs.AI"
    ],
    "published": "2024-03-17T13:39:43+00:00",
    "updated": "2024-03-17T13:39:43+00:00",
    "url": "http://arxiv.org/pdf/2403.11219v1"
  },
  {
    "id": "2403.10903v4",
    "title": "DTOR: Decision Tree Outlier Regressor to explain anomalies",
    "authors": [
      "Riccardo Crupi",
      "Daniele Regoli",
      "Alessandro Damiano Sabatino",
      "Immacolata Marano",
      "Massimiliano Brinis",
      "Luca Albertazzi",
      "Andrea Cirillo",
      "Andrea Claudio Cosentini"
    ],
    "abstract": "Explaining outliers occurrence and mechanism of their occurrence can be\nextremely important in a variety of domains. Malfunctions, frauds, threats, in\naddition to being correctly identified, oftentimes need a valid explanation in\norder to effectively perform actionable counteracts. The ever more widespread\nuse of sophisticated Machine Learning approach to identify anomalies make such\nexplanations more challenging. We present the Decision Tree Outlier Regressor\n(DTOR), a technique for producing rule-based explanations for individual data\npoints by estimating anomaly scores generated by an anomaly detection model.\nThis is accomplished by first applying a Decision Tree Regressor, which\ncomputes the estimation score, and then extracting the relative path associated\nwith the data point score. Our results demonstrate the robustness of DTOR even\nin datasets with a large number of features. Additionally, in contrast to other\nrule-based approaches, the generated rules are consistently satisfied by the\npoints to be explained. Furthermore, our evaluation metrics indicate comparable\nperformance to Anchors in outlier explanation tasks, with reduced execution\ntime.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2024-03-16T11:38:31+00:00",
    "updated": "2024-05-12T17:20:11+00:00",
    "url": "http://arxiv.org/pdf/2403.10903v4"
  },
  {
    "id": "2403.08027v1",
    "title": "McCatch: Scalable Microcluster Detection in Dimensional and Nondimensional Datasets",
    "authors": [
      "Braulio V. Sánchez Vinces",
      "Robson L. F. Cordeiro",
      "Christos Faloutsos"
    ],
    "abstract": "How could we have an outlier detector that works even with nondimensional\ndata, and ranks together both singleton microclusters ('one-off' outliers) and\nnonsingleton microclusters by their anomaly scores? How to obtain scores that\nare principled in one scalable and 'hands-off' manner? Microclusters of\noutliers indicate coalition or repetition in fraud activities, etc.; their\nidentification is thus highly desirable. This paper presents McCatch: a new\nalgorithm that detects microclusters by leveraging our proposed 'Oracle' plot\n(1NN Distance versus Group 1NN Distance). We study 31 real and synthetic\ndatasets with up to 1M data elements to show that McCatch is the only method\nthat answers both of the questions above; and, it outperforms 11 other methods,\nespecially when the data has nonsingleton microclusters or is nondimensional.\nWe also showcase McCatch's ability to detect meaningful microclusters in\ngraphs, fingerprints, logs of network connections, text data, and satellite\nimagery. For example, it found a 30-elements microcluster of confirmed 'Denial\nof Service' attacks in the network logs, taking only ~3 minutes for 222K data\nelements on a stock desktop.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-03-12T18:55:23+00:00",
    "updated": "2024-03-12T18:55:23+00:00",
    "url": "http://arxiv.org/pdf/2403.08027v1"
  },
  {
    "id": "2403.06906v3",
    "title": "Cost-Sensitive Learning to Defer to Multiple Experts with Workload Constraints",
    "authors": [
      "Jean V. Alves",
      "Diogo Leitão",
      "Sérgio Jesus",
      "Marco O. P. Sampaio",
      "Javier Liébana",
      "Pedro Saleiro",
      "Mário A. T. Figueiredo",
      "Pedro Bizarro"
    ],
    "abstract": "Learning to defer (L2D) aims to improve human-AI collaboration systems by\nlearning how to defer decisions to humans when they are more likely to be\ncorrect than an ML classifier. Existing research in L2D overlooks key\nreal-world aspects that impede its practical adoption, namely: i) neglecting\ncost-sensitive scenarios, where type I and type II errors have different costs;\nii) requiring concurrent human predictions for every instance of the training\ndataset; and iii) not dealing with human work-capacity constraints. To address\nthese issues, we propose the \\textit{deferral under cost and capacity\nconstraints framework} (DeCCaF). DeCCaF is a novel L2D approach, employing\nsupervised learning to model the probability of human error under less\nrestrictive data requirements (only one expert prediction per instance) and\nusing constraint programming to globally minimize the error cost, subject to\nworkload limitations. We test DeCCaF in a series of cost-sensitive fraud\ndetection scenarios with different teams of 9 synthetic fraud analysts, with\nindividual work-capacity constraints. The results demonstrate that our approach\nperforms significantly better than the baselines in a wide array of scenarios,\nachieving an average $8.4\\%$ reduction in the misclassification cost. The code\nused for the experiments is available at https://github.com/feedzai/deccaf",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2024-03-11T16:57:20+00:00",
    "updated": "2024-08-19T18:18:30+00:00",
    "url": "http://arxiv.org/pdf/2403.06906v3"
  },
  {
    "id": "2403.06537v2",
    "title": "On the Consideration of AI Openness: Can Good Intent Be Abused?",
    "authors": [
      "Yeeun Kim",
      "Hyunseo Shin",
      "Eunkyung Choi",
      "Hongseok Oh",
      "Hyunjun Kim",
      "Wonseok Hwang"
    ],
    "abstract": "Open source is a driving force behind scientific advancement.However, this\nopenness is also a double-edged sword, with the inherent risk that innovative\ntechnologies can be misused for purposes harmful to society. What is the\nlikelihood that an open source AI model or dataset will be used to commit a\nreal-world crime, and if a criminal does exploit it, will the people behind the\ntechnology be able to escape legal liability? To address these questions, we\nexplore a legal domain where individual choices can have a significant impact\non society. Specifically, we build the EVE-V1 dataset that comprises 200\nquestion-answer pairs related to criminal offenses based on 200 Korean\nprecedents first to explore the possibility of malicious models emerging. We\nfurther developed EVE-V2 using 600 fraud-related precedents to confirm the\nexistence of malicious models that can provide harmful advice on a wide range\nof criminal topics to test the domain generalization ability. Remarkably,\nwidely used open-source large-scale language models (LLMs) provide unethical\nand detailed information about criminal activities when fine-tuned with EVE. We\nalso take an in-depth look at the legal issues that malicious language models\nand their builders could realistically face. Our findings highlight the\nparadoxical dilemma that open source accelerates scientific progress, but\nrequires great care to minimize the potential for misuse. Warning: This paper\ncontains content that some may find unethical.",
    "categories": [
      "cs.CL"
    ],
    "published": "2024-03-11T09:24:06+00:00",
    "updated": "2025-01-07T05:52:37+00:00",
    "url": "http://arxiv.org/pdf/2403.06537v2"
  },
  {
    "id": "2403.06454v1",
    "title": "When Crypto Economics Meet Graph Analytics and Learning",
    "authors": [
      "Bingqiao Luo"
    ],
    "abstract": "Utilizing graph analytics and learning has proven to be an effective method\nfor exploring aspects of crypto economics such as network effects,\ndecentralization, tokenomics, and fraud detection. However, the majority of\nexisting research predominantly focuses on leading cryptocurrencies, namely\nBitcoin (BTC) and Ethereum (ETH), overlooking the vast diversity among the more\nthan 10,000 cryptocurrency projects. This oversight may result in skewed\ninsights. In our paper, we aim to broaden the scope of investigation to\nencompass the entire spectrum of cryptocurrencies, examining various coins\nacross their entire life cycles. Furthermore, we intend to pioneer advanced\nmethodologies, including graph transfer learning and the innovative concept of\n\"graph of graphs\". By extending our research beyond the confines of BTC and\nETH, our goal is to enhance the depth of our understanding of crypto economics\nand to advance the development of more intricate graph-based techniques.",
    "categories": [
      "cs.CE"
    ],
    "published": "2024-03-11T06:15:50+00:00",
    "updated": "2024-03-11T06:15:50+00:00",
    "url": "http://arxiv.org/pdf/2403.06454v1"
  },
  {
    "id": "2407.08758v1",
    "title": "Credit Card Fraud Detection in the Nigerian Financial Sector: A Comparison of Unsupervised TensorFlow-Based Anomaly Detection Techniques, Autoencoders and PCA Algorithm",
    "authors": [
      "Jennifer Onyeama"
    ],
    "abstract": "Credit card fraud is a major cause of national concern in the Nigerian\nfinancial sector, affecting hundreds of transactions per second and impacting\ninternational ecommerce negatively. Despite the rapid spread and adoption of\nonline marketing, millions of Nigerians are prevented from transacting in\nseveral countries with local credit cards due to bans and policies directed at\nrestricting credit card fraud. Presently, a myriad of technologies exist to\ndetect fraudulent transactions, a few of which are adopted by Nigerian\nfinancial institutions to proactively manage the situation. Fraud detection\nallows institutions to restrict offenders from networks and with a centralized\nbanking identity management system, such as the Bank Verification Number used\nby the Central Bank of Nigeria, offenders who may have stolen other identities\ncan be backtraced and their bank accounts frozen. This paper aims to compare\nthe effectiveness of two fraud detection technologies that are projected to\nwork fully independent of human intervention to possibly predict and detect\nfraudulent credit card transactions. Autoencoders as an unsupervised tensorflow\nbased anomaly detection technique generally offers greater performance in\ndimensionality reduction than the Principal Component Analysis, and this theory\nwas tested out on Nigerian credit card transaction data. Results demonstrate\nthat autoencoders are better suited to analyzing complex and extensive datasets\nand offer more reliable results with minimal mislabeling than the PCA\nalgorithm.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-03-08T21:22:05+00:00",
    "updated": "2024-03-08T21:22:05+00:00",
    "url": "http://arxiv.org/pdf/2407.08758v1"
  },
  {
    "id": "2403.04468v1",
    "title": "A Survey of Graph Neural Networks in Real world: Imbalance, Noise, Privacy and OOD Challenges",
    "authors": [
      "Wei Ju",
      "Siyu Yi",
      "Yifan Wang",
      "Zhiping Xiao",
      "Zhengyang Mao",
      "Hourun Li",
      "Yiyang Gu",
      "Yifang Qin",
      "Nan Yin",
      "Senzhang Wang",
      "Xinwang Liu",
      "Xiao Luo",
      "Philip S. Yu",
      "Ming Zhang"
    ],
    "abstract": "Graph-structured data exhibits universality and widespread applicability\nacross diverse domains, such as social network analysis, biochemistry,\nfinancial fraud detection, and network security. Significant strides have been\nmade in leveraging Graph Neural Networks (GNNs) to achieve remarkable success\nin these areas. However, in real-world scenarios, the training environment for\nmodels is often far from ideal, leading to substantial performance degradation\nof GNN models due to various unfavorable factors, including imbalance in data\ndistribution, the presence of noise in erroneous data, privacy protection of\nsensitive information, and generalization capability for out-of-distribution\n(OOD) scenarios. To tackle these issues, substantial efforts have been devoted\nto improving the performance of GNN models in practical real-world scenarios,\nas well as enhancing their reliability and robustness. In this paper, we\npresent a comprehensive survey that systematically reviews existing GNN models,\nfocusing on solutions to the four mentioned real-world challenges including\nimbalance, noise, privacy, and OOD in practical scenarios that many existing\nreviews have not considered. Specifically, we first highlight the four key\nchallenges faced by existing GNNs, paving the way for our exploration of\nreal-world GNN models. Subsequently, we provide detailed discussions on these\nfour aspects, dissecting how these solutions contribute to enhancing the\nreliability and robustness of GNN models. Last but not least, we outline\npromising directions and offer future perspectives in the field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "cs.SI"
    ],
    "published": "2024-03-07T13:10:37+00:00",
    "updated": "2024-03-07T13:10:37+00:00",
    "url": "http://arxiv.org/pdf/2403.04468v1"
  },
  {
    "id": "2403.00331v2",
    "title": "WindGP: Efficient Graph Partitioning on Heterogenous Machines",
    "authors": [
      "Li Zeng",
      "Haohan Huang",
      "Binfan Zheng",
      "Kang Yang",
      "Shengcheng Shao",
      "Jinhua Zhou",
      "Jun Xie",
      "Rongqian Zhao",
      "Xin Chen"
    ],
    "abstract": "Graph Partitioning is widely used in many real-world applications such as\nfraud detection and social network analysis, in order to enable the distributed\ngraph computing on large graphs. However, existing works fail to balance the\ncomputation cost and communication cost on machines with different power\n(including computing capability, network bandwidth and memory size), as they\nonly consider replication factor and neglect the difference of machines in\nrealistic data centers. In this paper, we propose a general graph partitioning\nalgorithm WindGP, which can support fast and high-quality edge partitioning on\nheterogeneous machines. WindGP designs novel preprocessing techniques to\nsimplify the metric and balance the computation cost according to the\ncharacteristics of graphs and machines. Also, best-first search is proposed\ninstead of BFS and DFS, in order to generate clusters with high cohesion.\nFurthermore, WindGP adaptively tunes the partition results by sophisticated\nlocal search methods. Extensive experiments show that WindGP outperforms all\nstate-of-the-art partition methods by 1.35 - 27 times on both dense and sparse\ndistributed graph algorithms, and has good scalability with graph size and\nmachine number.",
    "categories": [
      "cs.DC"
    ],
    "published": "2024-03-01T07:22:57+00:00",
    "updated": "2024-03-06T08:58:24+00:00",
    "url": "http://arxiv.org/pdf/2403.00331v2"
  },
  {
    "id": "2402.19399v3",
    "title": "An Empirical Analysis of Scam Tokens on Ethereum Blockchain",
    "authors": [
      "Vahidin Jeleskovic"
    ],
    "abstract": "This article presents an empirical investigation into the determinants of\ntotal revenue generated by counterfeit tokens on Uniswap. It offers a detailed\noverview of the counterfeit token fraud process, along with a systematic\nsummary of characteristics associated with such fraudulent activities observed\nin Uniswap. The study primarily examines the relationship between revenue from\ncounterfeit token scams and their defining characteristics, and analyzes the\ninfluence of market economic factors such as return on market capitalization\nand price return on Ethereum. Key findings include a significant increase in\noverall transactions of counterfeit tokens on their first day of fraud, and a\nrise in upfront fraud costs leading to corresponding increases in revenue.\nFurthermore, a negative correlation is identified between the total revenue of\ncounterfeit tokens and the volatility of Ethereum market capitalization return,\nwhile price return volatility on Ethereum is found to have a positive impact on\ncounterfeit token revenue, albeit requiring further investigation for a\ncomprehensive understanding. Additionally, the number of subscribers for the\nreal token correlates positively with the realized volume of scam tokens,\nindicating that a larger community following the legitimate token may\ninadvertently contribute to the visibility and success of counterfeit tokens.\nConversely, the number of Telegram subscribers exhibits a negative impact on\nthe realized volume of scam tokens, suggesting that a higher level of scrutiny\nor awareness within Telegram communities may act as a deterrent to fraudulent\nactivities. Finally, the timing of when the scam token is introduced on the\nEthereum blockchain may have a negative impact on its success. Notably, the\ncumulative amount scammed by only 42 counterfeit tokens amounted to almost\n11214 Ether.",
    "categories": [
      "q-fin.TR",
      "econ.EM"
    ],
    "published": "2024-02-29T17:57:05+00:00",
    "updated": "2024-03-05T23:47:21+00:00",
    "url": "http://arxiv.org/pdf/2402.19399v3"
  },
  {
    "id": "2402.18085v4",
    "title": "PITCH: AI-assisted Tagging of Deepfake Audio Calls using Challenge-Response",
    "authors": [
      "Govind Mittal",
      "Arthur Jakobsson",
      "Kelly O. Marshall",
      "Chinmay Hegde",
      "Nasir Memon"
    ],
    "abstract": "The rise of AI voice-cloning technology, particularly audio Real-time\nDeepfakes (RTDFs), has intensified social engineering attacks by enabling\nreal-time voice impersonation that bypasses conventional enrollment-based\nauthentication. This technology represents an existential threat to phone-based\nauthentication systems, while total identity fraud losses reached $43 billion.\nUnlike traditional robocalls, these personalized AI-generated voice attacks\ntarget high-value accounts and circumvent existing defensive measures, creating\nan urgent cybersecurity challenge. To address this, we propose PITCH, a robust\nchallenge-response method to detect and tag interactive deepfake audio calls.\nWe developed a comprehensive taxonomy of audio challenges based on the human\nauditory system, linguistics, and environmental factors, yielding 20\nprospective challenges. Testing against leading voice-cloning systems using a\nnovel dataset (18,600 original and 1.6 million deepfake samples from 100\nusers), PITCH's challenges enhanced machine detection capabilities to 88.7%\nAUROC score, enabling us to identify 10 highly-effective challenges.\n  For human evaluation, we filtered a challenging, balanced subset on which\nhuman evaluators independently achieved 72.6% accuracy, while machines scored\n87.7%. Recognizing that call environments require human control, we developed a\nnovel human-AI collaborative system that tags suspicious calls as\n\"Deepfake-likely.\" Contrary to prior findings, we discovered that integrating\nhuman intuition with machine precision offers complementary advantages, giving\nusers maximum control while boosting detection accuracy to 84.5%. This\nsignificant improvement situates PITCH's potential as an AI-assisted\npre-screener for verifying calls, offering an adaptable approach to combat\nreal-time voice-cloning attacks while maintaining human decision authority.",
    "categories": [
      "cs.SD",
      "cs.CR",
      "eess.AS"
    ],
    "published": "2024-02-28T06:17:55+00:00",
    "updated": "2025-05-26T14:21:47+00:00",
    "url": "http://arxiv.org/pdf/2402.18085v4"
  },
  {
    "id": "2402.17472v4",
    "title": "RAGFormer: Learning Semantic Attributes and Topological Structure for Fraud Detection",
    "authors": [
      "Haolin Li",
      "Shuyang Jiang",
      "Lifeng Zhang",
      "Siyuan Du",
      "Guangnan Ye",
      "Hongfeng Chai"
    ],
    "abstract": "Fraud detection remains a challenging task due to the complex and deceptive\nnature of fraudulent activities. Current approaches primarily concentrate on\nlearning only one perspective of the graph: either the topological structure of\nthe graph or the attributes of individual nodes. However, we conduct empirical\nstudies to reveal that these two types of features, while nearly orthogonal,\nare each independently effective. As a result, previous methods can not fully\ncapture the comprehensive characteristics of the fraud graph. To address this\ndilemma, we present a novel framework called Relation-Aware GNN with\ntransFormer~(RAGFormer) which simultaneously embeds both semantic and\ntopological features into a target node. The simple yet effective network\nconsists of a semantic encoder, a topology encoder, and an attention fusion\nmodule. The semantic encoder utilizes Transformer to learn semantic features\nand node interactions across different relations. We introduce Relation-Aware\nGNN as the topology encoder to learn topological features and node interactions\nwithin each relation. These two complementary features are interleaved through\nan attention fusion module to support prediction by both orthogonal features.\nExtensive experiments on two popular public datasets demonstrate that RAGFormer\nachieves state-of-the-art performance. The significant improvement of RAGFormer\nin an industrial credit card fraud detection dataset further validates the\napplicability of our method in real-world business scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2024-02-27T12:53:15+00:00",
    "updated": "2025-02-11T12:29:00+00:00",
    "url": "http://arxiv.org/pdf/2402.17472v4"
  },
  {
    "id": "2405.00026v1",
    "title": "Enhancing Credit Card Fraud Detection A Neural Network and SMOTE Integrated Approach",
    "authors": [
      "Mengran Zhu",
      "Ye Zhang",
      "Yulu Gong",
      "Changxin Xu",
      "Yafei Xiang"
    ],
    "abstract": "Credit card fraud detection is a critical challenge in the financial sector,\ndemanding sophisticated approaches to accurately identify fraudulent\ntransactions. This research proposes an innovative methodology combining Neural\nNetworks (NN) and Synthet ic Minority Over-sampling Technique (SMOTE) to\nenhance the detection performance. The study addresses the inherent imbalance\nin credit card transaction data, focusing on technical advancements for robust\nand precise fraud detection. Results demonstrat e that the integration of NN\nand SMOTE exhibits superior precision, recall, and F1-score compared to\ntraditional models, highlighting its potential as an advanced solution for\nhandling imbalanced datasets in credit card fraud detection scenarios. This\nrese arch contributes to the ongoing efforts to develop effective and efficient\nmechanisms for safeguarding financial transactions from fraudulent activities.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "published": "2024-02-27T02:26:04+00:00",
    "updated": "2024-02-27T02:26:04+00:00",
    "url": "http://arxiv.org/pdf/2405.00026v1"
  },
  {
    "id": "2402.16162v1",
    "title": "Catch Me If You Can: Combatting Fraud in Artificial Currency Based Government Benefits Programs",
    "authors": [
      "Devansh Jalota",
      "Matthew Tsao",
      "Marco Pavone"
    ],
    "abstract": "Artificial currencies have grown in popularity in many real-world resource\nallocation settings, gaining traction in government benefits programs like food\nassistance and transit benefits programs. However, such programs are\nsusceptible to misreporting fraud, wherein users can misreport their private\nattributes to gain access to more artificial currency (credits) than they are\nentitled to. To address the problem of misreporting fraud in artificial\ncurrency based benefits programs, we introduce an audit mechanism that induces\na two-stage game between an administrator and users. In our proposed mechanism,\nthe administrator running the benefits program can audit users at some cost and\nlevy fines against them for misreporting their information. For this audit\ngame, we study the natural solution concept of a signaling game equilibrium and\ninvestigate conditions on the administrator budget to establish the existence\nof equilibria. The computation of equilibria can be done via linear programming\nin our problem setting through an appropriate design of the audit rules. Our\nanalysis also provides upper bounds that hold in any signaling game equilibrium\non the expected excess payments made by the administrator and the probability\nthat users misreport their information. We further show that the decrease in\nmisreporting fraud corresponding to our audit mechanism far outweighs the\nadministrator spending to run it by establishing that its total costs are lower\nthan that of the status quo with no audits. Finally, to highlight the practical\nviability of our audit mechanism in mitigating misreporting fraud, we present a\ncase study based on the Washington D.C. federal transit benefits program. In\nthis case study, the proposed audit mechanism achieves several orders of\nmagnitude improvement in total cost compared to a no-audit strategy for some\nparameter ranges.",
    "categories": [
      "eess.SY",
      "cs.GT",
      "cs.SY"
    ],
    "published": "2024-02-25T17:48:21+00:00",
    "updated": "2024-02-25T17:48:21+00:00",
    "url": "http://arxiv.org/pdf/2402.16162v1"
  },
  {
    "id": "2402.14983v1",
    "title": "Privacy-Enhancing Collaborative Information Sharing through Federated Learning -- A Case of the Insurance Industry",
    "authors": [
      "Panyi Dong",
      "Zhiyu Quan",
      "Brandon Edwards",
      "Shih-han Wang",
      "Runhuan Feng",
      "Tianyang Wang",
      "Patrick Foley",
      "Prashant Shah"
    ],
    "abstract": "The report demonstrates the benefits (in terms of improved claims loss\nmodeling) of harnessing the value of Federated Learning (FL) to learn a single\nmodel across multiple insurance industry datasets without requiring the\ndatasets themselves to be shared from one company to another. The application\nof FL addresses two of the most pressing concerns: limited data volume and data\nvariety, which are caused by privacy concerns, the rarity of claim events, the\nlack of informative rating factors, etc.. During each round of FL,\ncollaborators compute improvements on the model using their local private data,\nand these insights are combined to update a global model. Such aggregation of\ninsights allows for an increase to the effectiveness in forecasting claims\nlosses compared to models individually trained at each collaborator.\nCritically, this approach enables machine learning collaboration without the\nneed for raw data to leave the compute infrastructure of each respective data\nowner. Additionally, the open-source framework, OpenFL, that is used in our\nexperiments is designed so that it can be run using confidential computing as\nwell as with additional algorithmic protections against leakage of information\nvia the shared model updates. In such a way, FL is implemented as a\nprivacy-enhancing collaborative learning technique that addresses the\nchallenges posed by the sensitivity and privacy of data in traditional machine\nlearning solutions. This paper's application of FL can also be expanded to\nother areas including fraud detection, catastrophe modeling, etc., that have a\nsimilar need to incorporate data privacy into machine learning collaborations.\nOur framework and empirical results provide a foundation for future\ncollaborations among insurers, regulators, academic researchers, and InsurTech\nexperts.",
    "categories": [
      "cs.LG",
      "cs.CR",
      "q-fin.RM"
    ],
    "published": "2024-02-22T21:46:24+00:00",
    "updated": "2024-02-22T21:46:24+00:00",
    "url": "http://arxiv.org/pdf/2402.14983v1"
  },
  {
    "id": "2402.14708v2",
    "title": "CaT-GNN: Enhancing Credit Card Fraud Detection via Causal Temporal Graph Neural Networks",
    "authors": [
      "Yifan Duan",
      "Guibin Zhang",
      "Shilong Wang",
      "Xiaojiang Peng",
      "Wang Ziqi",
      "Junyuan Mao",
      "Hao Wu",
      "Xinke Jiang",
      "Kun Wang"
    ],
    "abstract": "Credit card fraud poses a significant threat to the economy. While Graph\nNeural Network (GNN)-based fraud detection methods perform well, they often\noverlook the causal effect of a node's local structure on predictions. This\npaper introduces a novel method for credit card fraud detection, the\n\\textbf{\\underline{Ca}}usal \\textbf{\\underline{T}}emporal\n\\textbf{\\underline{G}}raph \\textbf{\\underline{N}}eural \\textbf{N}etwork\n(CaT-GNN), which leverages causal invariant learning to reveal inherent\ncorrelations within transaction data. By decomposing the problem into discovery\nand intervention phases, CaT-GNN identifies causal nodes within the transaction\ngraph and applies a causal mixup strategy to enhance the model's robustness and\ninterpretability. CaT-GNN consists of two key components: Causal-Inspector and\nCausal-Intervener. The Causal-Inspector utilizes attention weights in the\ntemporal attention mechanism to identify causal and environment nodes without\nintroducing additional parameters. Subsequently, the Causal-Intervener performs\na causal mixup enhancement on environment nodes based on the set of nodes.\nEvaluated on three datasets, including a private financial dataset and two\npublic datasets, CaT-GNN demonstrates superior performance over existing\nstate-of-the-art methods. Our findings highlight the potential of integrating\ncausal reasoning with graph neural networks to improve fraud detection\ncapabilities in financial transactions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.ST"
    ],
    "published": "2024-02-22T17:08:09+00:00",
    "updated": "2024-11-27T12:15:06+00:00",
    "url": "http://arxiv.org/pdf/2402.14708v2"
  },
  {
    "id": "2402.14389v1",
    "title": "Securing Transactions: A Hybrid Dependable Ensemble Machine Learning Model using IHT-LR and Grid Search",
    "authors": [
      "Md. Alamin Talukder",
      "Rakib Hossen",
      "Md Ashraf Uddin",
      "Mohammed Nasir Uddin",
      "Uzzal Kumar Acharjee"
    ],
    "abstract": "Financial institutions and businesses face an ongoing challenge from\nfraudulent transactions, prompting the need for effective detection methods.\nDetecting credit card fraud is crucial for identifying and preventing\nunauthorized transactions.Timely detection of fraud enables investigators to\ntake swift actions to mitigate further losses. However, the investigation\nprocess is often time-consuming, limiting the number of alerts that can be\nthoroughly examined each day. Therefore, the primary objective of a fraud\ndetection model is to provide accurate alerts while minimizing false alarms and\nmissed fraud cases. In this paper, we introduce a state-of-the-art hybrid\nensemble (ENS) dependable Machine learning (ML) model that intelligently\ncombines multiple algorithms with proper weighted optimization using Grid\nsearch, including Decision Tree (DT), Random Forest (RF), K-Nearest Neighbor\n(KNN), and Multilayer Perceptron (MLP), to enhance fraud identification. To\naddress the data imbalance issue, we employ the Instant Hardness Threshold\n(IHT) technique in conjunction with Logistic Regression (LR), surpassing\nconventional approaches. Our experiments are conducted on a publicly available\ncredit card dataset comprising 284,807 transactions. The proposed model\nachieves impressive accuracy rates of 99.66%, 99.73%, 98.56%, and 99.79%, and a\nperfect 100% for the DT, RF, KNN, MLP and ENS models, respectively. The hybrid\nensemble model outperforms existing works, establishing a new benchmark for\ndetecting fraudulent transactions in high-frequency scenarios. The results\nhighlight the effectiveness and reliability of our approach, demonstrating\nsuperior performance metrics and showcasing its exceptional potential for\nreal-world fraud detection applications.",
    "categories": [
      "cs.LG",
      "q-fin.GN"
    ],
    "published": "2024-02-22T09:01:42+00:00",
    "updated": "2024-02-22T09:01:42+00:00",
    "url": "http://arxiv.org/pdf/2402.14389v1"
  },
  {
    "id": "2402.14205v1",
    "title": "Compression Robust Synthetic Speech Detection Using Patched Spectrogram Transformer",
    "authors": [
      "Amit Kumar Singh Yadav",
      "Ziyue Xiang",
      "Kratika Bhagtani",
      "Paolo Bestagini",
      "Stefano Tubaro",
      "Edward J. Delp"
    ],
    "abstract": "Many deep learning synthetic speech generation tools are readily available.\nThe use of synthetic speech has caused financial fraud, impersonation of\npeople, and misinformation to spread. For this reason forensic methods that can\ndetect synthetic speech have been proposed. Existing methods often overfit on\none dataset and their performance reduces substantially in practical scenarios\nsuch as detecting synthetic speech shared on social platforms. In this paper we\npropose, Patched Spectrogram Synthetic Speech Detection Transformer (PS3DT), a\nsynthetic speech detector that converts a time domain speech signal to a\nmel-spectrogram and processes it in patches using a transformer neural network.\nWe evaluate the detection performance of PS3DT on ASVspoof2019 dataset. Our\nexperiments show that PS3DT performs well on ASVspoof2019 dataset compared to\nother approaches using spectrogram for synthetic speech detection. We also\ninvestigate generalization performance of PS3DT on In-the-Wild dataset. PS3DT\ngeneralizes well than several existing methods on detecting synthetic speech\nfrom an out-of-distribution dataset. We also evaluate robustness of PS3DT to\ndetect telephone quality synthetic speech and synthetic speech shared on social\nplatforms (compressed speech). PS3DT is robust to compression and can detect\ntelephone quality synthetic speech better than several existing methods.",
    "categories": [
      "cs.SD",
      "cs.CV",
      "cs.LG",
      "eess.AS",
      "eess.SP"
    ],
    "published": "2024-02-22T01:18:55+00:00",
    "updated": "2024-02-22T01:18:55+00:00",
    "url": "http://arxiv.org/pdf/2402.14205v1"
  },
  {
    "id": "2402.13169v1",
    "title": "Formal Verification for Blockchain-based Insurance Claims Processing",
    "authors": [
      "Roshan Lal Neupane",
      "Ernest Bonnah",
      "Bishnu Bhusal",
      "Kiran Neupane",
      "Khaza Anuarul Hoque",
      "Prasad Calyam"
    ],
    "abstract": "Insurance claims processing involves multi-domain entities and multi-source\ndata, along with a number of human-agent interactions. Use of Blockchain\ntechnology-based platform can significantly improve scalability and response\ntime for processing of claims which are otherwise manually-intensive and\ntime-consuming. However, the chaincodes involved within the processes that\nissue claims, approve or deny them as required, need to be formally verified to\nensure secure and reliable processing of transactions in Blockchain. In this\npaper, we use a formal modeling approach to verify various processes and their\nunderlying chaincodes relating to different stages in insurance claims\nprocessing viz., issuance, approval, denial, and flagging for fraud\ninvestigation by using linear temporal logic (LTL). We simulate the formalism\non the chaincodes and analyze the breach of chaincodes via model checking.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-02-20T17:29:59+00:00",
    "updated": "2024-02-20T17:29:59+00:00",
    "url": "http://arxiv.org/pdf/2402.13169v1"
  },
  {
    "id": "2404.10989v1",
    "title": "FairSSD: Understanding Bias in Synthetic Speech Detectors",
    "authors": [
      "Amit Kumar Singh Yadav",
      "Kratika Bhagtani",
      "Davide Salvi",
      "Paolo Bestagini",
      "Edward J. Delp"
    ],
    "abstract": "Methods that can generate synthetic speech which is perceptually\nindistinguishable from speech recorded by a human speaker, are easily\navailable. Several incidents report misuse of synthetic speech generated from\nthese methods to commit fraud. To counter such misuse, many methods have been\nproposed to detect synthetic speech. Some of these detectors are more\ninterpretable, can generalize to detect synthetic speech in the wild and are\nrobust to noise. However, limited work has been done on understanding bias in\nthese detectors. In this work, we examine bias in existing synthetic speech\ndetectors to determine if they will unfairly target a particular gender, age\nand accent group. We also inspect whether these detectors will have a higher\nmisclassification rate for bona fide speech from speech-impaired speakers w.r.t\nfluent speakers. Extensive experiments on 6 existing synthetic speech detectors\nusing more than 0.9 million speech signals demonstrate that most detectors are\ngender, age and accent biased, and future work is needed to ensure fairness. To\nsupport future research, we release our evaluation dataset, models used in our\nstudy and source code at https://gitlab.com/viper-purdue/fairssd.",
    "categories": [
      "cs.CV",
      "cs.LG",
      "cs.MM",
      "cs.SD",
      "eess.AS"
    ],
    "published": "2024-04-17T01:53:03+00:00",
    "updated": "2024-04-17T01:53:03+00:00",
    "url": "http://arxiv.org/pdf/2404.10989v1"
  },
  {
    "id": "2404.09802v1",
    "title": "The Performance of Sequential Deep Learning Models in Detecting Phishing Websites Using Contextual Features of URLs",
    "authors": [
      "Saroj Gopali",
      "Akbar S. Namin",
      "Faranak Abri",
      "Keith S. Jones"
    ],
    "abstract": "Cyber attacks continue to pose significant threats to individuals and\norganizations, stealing sensitive data such as personally identifiable\ninformation, financial information, and login credentials. Hence, detecting\nmalicious websites before they cause any harm is critical to preventing fraud\nand monetary loss. To address the increasing number of phishing attacks,\nprotective mechanisms must be highly responsive, adaptive, and scalable.\nFortunately, advances in the field of machine learning, coupled with access to\nvast amounts of data, have led to the adoption of various deep learning models\nfor timely detection of these cyber crimes. This study focuses on the detection\nof phishing websites using deep learning models such as Multi-Head Attention,\nTemporal Convolutional Network (TCN), BI-LSTM, and LSTM where URLs of the\nphishing websites are treated as a sequence. The results demonstrate that\nMulti-Head Attention and BI-LSTM model outperform some other deep\nlearning-based algorithms such as TCN and LSTM in producing better precision,\nrecall, and F1-scores.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2024-04-15T13:58:22+00:00",
    "updated": "2024-04-15T13:58:22+00:00",
    "url": "http://arxiv.org/pdf/2404.09802v1"
  },
  {
    "id": "2404.05159v1",
    "title": "Semantic Stealth: Adversarial Text Attacks on NLP Using Several Methods",
    "authors": [
      "Roopkatha Dey",
      "Aivy Debnath",
      "Sayak Kumar Dutta",
      "Kaustav Ghosh",
      "Arijit Mitra",
      "Arghya Roy Chowdhury",
      "Jaydip Sen"
    ],
    "abstract": "In various real-world applications such as machine translation, sentiment\nanalysis, and question answering, a pivotal role is played by NLP models,\nfacilitating efficient communication and decision-making processes in domains\nranging from healthcare to finance. However, a significant challenge is posed\nto the robustness of these natural language processing models by text\nadversarial attacks. These attacks involve the deliberate manipulation of input\ntext to mislead the predictions of the model while maintaining human\ninterpretability. Despite the remarkable performance achieved by\nstate-of-the-art models like BERT in various natural language processing tasks,\nthey are found to remain vulnerable to adversarial perturbations in the input\ntext. In addressing the vulnerability of text classifiers to adversarial\nattacks, three distinct attack mechanisms are explored in this paper using the\nvictim model BERT: BERT-on-BERT attack, PWWS attack, and Fraud Bargain's Attack\n(FBA). Leveraging the IMDB, AG News, and SST2 datasets, a thorough comparative\nanalysis is conducted to assess the effectiveness of these attacks on the BERT\nclassifier model. It is revealed by the analysis that PWWS emerges as the most\npotent adversary, consistently outperforming other methods across multiple\nevaluation scenarios, thereby emphasizing its efficacy in generating\nadversarial examples for text classification. Through comprehensive\nexperimentation, the performance of these attacks is assessed and the findings\nindicate that the PWWS attack outperforms others, demonstrating lower runtime,\nhigher accuracy, and favorable semantic similarity scores. The key insight of\nthis paper lies in the assessment of the relative performances of three\nprevalent state-of-the-art attack mechanisms.",
    "categories": [
      "cs.CL",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2024-04-08T02:55:01+00:00",
    "updated": "2024-04-08T02:55:01+00:00",
    "url": "http://arxiv.org/pdf/2404.05159v1"
  },
  {
    "id": "2404.08673v1",
    "title": "Sentiment analysis and random forest to classify LLM versus human source applied to Scientific Texts",
    "authors": [
      "Javier J. Sanchez-Medina"
    ],
    "abstract": "After the launch of ChatGPT v.4 there has been a global vivid discussion on\nthe ability of this artificial intelligence powered platform and some other\nsimilar ones for the automatic production of all kinds of texts, including\nscientific and technical texts. This has triggered a reflection in many\ninstitutions on whether education and academic procedures should be adapted to\nthe fact that in future many texts we read will not be written by humans\n(students, scholars, etc.), at least, not entirely. In this work it is proposed\na new methodology to classify texts coming from an automatic text production\nengine or a human, based on Sentiment Analysis as a source for feature\nengineering independent variables and then train with them a Random Forest\nclassification algorithm. Using four different sentiment lexicons, a number of\nnew features where produced, and then fed to a machine learning random forest\nmethodology, to train such a model. Results seem very convincing that this may\nbe a promising research line to detect fraud, in such environments where human\nare supposed to be the source of texts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "68"
    ],
    "published": "2024-04-05T16:14:36+00:00",
    "updated": "2024-04-05T16:14:36+00:00",
    "url": "http://arxiv.org/pdf/2404.08673v1"
  },
  {
    "id": "2404.03874v1",
    "title": "VELLET: Verifiable Embedded Wallet for Securing Authenticity and Integrity",
    "authors": [
      "Hiroki Watanabe",
      "Kohei Ichihara",
      "Takumi Aita"
    ],
    "abstract": "The blockchain ecosystem, particularly with the rise of Web3 and Non-Fungible\nTokens (NFTs), has experienced a significant increase in users and\napplications. However, this expansion is challenged by the need to connect\nearly adopters with a wider user base. A notable difficulty in this process is\nthe complex interfaces of blockchain wallets, which can be daunting for those\nfamiliar with traditional payment methods. To address this issue, the category\nof \"embedded wallets\" has emerged as a promising solution. These wallets are\nseamlessly integrated into the front-end of decentralized applications (Dapps),\nsimplifying the onboarding process for users and making access more widely\navailable. However, our insights indicate that this simplification introduces a\ntrade-off between ease of use and security. Embedded wallets lack transparency\nand auditability, leading to obscured transactions by the front end and a\npronounced risk of fraud and phishing attacks. This paper proposes a new\nprotocol to enhance the security of embedded wallets. Our VELLET protocol\nintroduces a wallet verifier that can match the audit trail of embedded wallets\non smart contracts, incorporating a process to verify authenticity and\nintegrity. In the implementation architecture of the VELLET protocol, we\nsuggest using the Text Record feature of the Ethereum Name Service (ENS), known\nas a decentralized domain name service, to serve as a repository for managing\nthe audit trails of smart contracts. This approach has been demonstrated to\nreduce the necessity for new smart contract development and operational costs,\nproving cost-effective through a proof-of-concept. This protocol is a vital\nstep in reducing security risks associated with embedded wallets, ensuring\ntheir convenience does not undermine user security and trust.",
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "published": "2024-04-05T03:23:19+00:00",
    "updated": "2024-04-05T03:23:19+00:00",
    "url": "http://arxiv.org/pdf/2404.03874v1"
  },
  {
    "id": "2404.03775v1",
    "title": "A Systems Theoretic Approach to Online Machine Learning",
    "authors": [
      "Anli du Preez",
      "Peter A. Beling",
      "Tyler Cody"
    ],
    "abstract": "The machine learning formulation of online learning is incomplete from a\nsystems theoretic perspective. Typically, machine learning research emphasizes\ndomains and tasks, and a problem solving worldview. It focuses on algorithm\nparameters, features, and samples, and neglects the perspective offered by\nconsidering system structure and system behavior or dynamics. Online learning\nis an active field of research and has been widely explored in terms of\nstatistical theory and computational algorithms, however, in general, the\nliterature still lacks formal system theoretical frameworks for modeling online\nlearning systems and resolving systems-related concept drift issues.\nFurthermore, while the machine learning formulation serves to classify methods\nand literature, the systems theoretic formulation presented herein serves to\nprovide a framework for the top-down design of online learning systems,\nincluding a novel definition of online learning and the identification of key\ndesign parameters. The framework is formulated in terms of input-output systems\nand is further divided into system structure and system behavior. Concept drift\nis a critical challenge faced in online learning, and this work formally\napproaches it as part of the system behavior characteristics. Healthcare\nprovider fraud detection using machine learning is used as a case study\nthroughout the paper to ground the discussion in a real-world online learning\nchallenge.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "published": "2024-04-04T19:36:47+00:00",
    "updated": "2024-04-04T19:36:47+00:00",
    "url": "http://arxiv.org/pdf/2404.03775v1"
  },
  {
    "id": "2404.02595v5",
    "title": "QFNN-FFD: Quantum Federated Neural Network for Financial Fraud Detection",
    "authors": [
      "Nouhaila Innan",
      "Alberto Marchisio",
      "Mohamed Bennai",
      "Muhammad Shafique"
    ],
    "abstract": "This study introduces the Quantum Federated Neural Network for Financial\nFraud Detection (QFNN-FFD), a cutting-edge framework merging Quantum Machine\nLearning (QML) and quantum computing with Federated Learning (FL) for financial\nfraud detection. Using quantum technologies' computational power and the robust\ndata privacy protections offered by FL, QFNN-FFD emerges as a secure and\nefficient method for identifying fraudulent transactions within the financial\nsector. Implementing a dual-phase training model across distributed clients\nenhances data integrity and enables superior performance metrics, achieving\nprecision rates consistently above 95%. Additionally, QFNN-FFD demonstrates\nexceptional resilience by maintaining an impressive 80% accuracy, highlighting\nits robustness and readiness for real-world applications. This combination of\nhigh performance, security, and robustness against noise positions QFNN-FFD as\na transformative advancement in financial technology solutions and establishes\nit as a new benchmark for privacy-focused fraud detection systems. This\nframework facilitates the broader adoption of secure, quantum-enhanced\nfinancial services and inspires future innovations that could use QML to tackle\ncomplex challenges in other areas requiring high confidentiality and accuracy.",
    "categories": [
      "quant-ph",
      "cs.LG",
      "q-fin.RM"
    ],
    "published": "2024-04-03T09:19:46+00:00",
    "updated": "2025-07-13T04:24:08+00:00",
    "url": "http://arxiv.org/pdf/2404.02595v5"
  },
  {
    "id": "2404.04281v2",
    "title": "Similar Data Points Identification with LLM: A Human-in-the-loop Strategy Using Summarization and Hidden State Insights",
    "authors": [
      "Xianlong Zeng",
      "Yijing Gao",
      "Fanghao Song",
      "Ang Liu"
    ],
    "abstract": "This study introduces a simple yet effective method for identifying similar\ndata points across non-free text domains, such as tabular and image data, using\nLarge Language Models (LLMs). Our two-step approach involves data point\nsummarization and hidden state extraction. Initially, data is condensed via\nsummarization using an LLM, reducing complexity and highlighting essential\ninformation in sentences. Subsequently, the summarization sentences are fed\nthrough another LLM to extract hidden states, serving as compact, feature-rich\nrepresentations. This approach leverages the advanced comprehension and\ngenerative capabilities of LLMs, offering a scalable and efficient strategy for\nsimilarity identification across diverse datasets. We demonstrate the\neffectiveness of our method in identifying similar data points on multiple\ndatasets. Additionally, our approach enables non-technical domain experts, such\nas fraud investigators or marketing operators, to quickly identify similar data\npoints tailored to specific scenarios, demonstrating its utility in practical\napplications. In general, our results open new avenues for leveraging LLMs in\ndata analysis across various domains",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2024-04-03T03:17:28+00:00",
    "updated": "2024-09-27T23:15:50+00:00",
    "url": "http://arxiv.org/pdf/2404.04281v2"
  },
  {
    "id": "2404.00060v1",
    "title": "Temporal Graph Networks for Graph Anomaly Detection in Financial Networks",
    "authors": [
      "Yejin Kim",
      "Youngbin Lee",
      "Minyoung Choe",
      "Sungju Oh",
      "Yongjae Lee"
    ],
    "abstract": "This paper explores the utilization of Temporal Graph Networks (TGN) for\nfinancial anomaly detection, a pressing need in the era of fintech and\ndigitized financial transactions. We present a comprehensive framework that\nleverages TGN, capable of capturing dynamic changes in edges within financial\nnetworks, for fraud detection. Our study compares TGN's performance against\nstatic Graph Neural Network (GNN) baselines, as well as cutting-edge hypergraph\nneural network baselines using DGraph dataset for a realistic financial\ncontext. Our results demonstrate that TGN significantly outperforms other\nmodels in terms of AUC metrics. This superior performance underlines TGN's\npotential as an effective tool for detecting financial fraud, showcasing its\nability to adapt to the dynamic and complex nature of modern financial systems.\nWe also experimented with various graph embedding modules within the TGN\nframework and compared the effectiveness of each module. In conclusion, we\ndemonstrated that, even with variations within TGN, it is possible to achieve\ngood performance in the anomaly detection task.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2024-03-27T07:17:16+00:00",
    "updated": "2024-03-27T07:17:16+00:00",
    "url": "http://arxiv.org/pdf/2404.00060v1"
  },
  {
    "id": "2405.11230v1",
    "title": "OTLP: Output Thresholding Using Mixed Integer Linear Programming",
    "authors": [
      "Baran Koseoglu",
      "Luca Traverso",
      "Mohammed Topiwalla",
      "Egor Kraev",
      "Zoltan Szopory"
    ],
    "abstract": "Output thresholding is the technique to search for the best threshold to be\nused during inference for any classifiers that can produce probability\nestimates on train and testing datasets. It is particularly useful in high\nimbalance classification problems where the default threshold is not able to\nrefer to imbalance in class distributions and fail to give the best\nperformance. This paper proposes OTLP, a thresholding framework using mixed\ninteger linear programming which is model agnostic, can support different\nobjective functions and different set of constraints for a diverse set of\nproblems including both balanced and imbalanced classification problems. It is\nparticularly useful in real world applications where the theoretical\nthresholding techniques are not able to address to product related requirements\nand complexity of the applications which utilize machine learning models.\nThrough the use of Credit Card Fraud Detection Dataset, we evaluate the\nusefulness of the framework.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-05-18T08:51:42+00:00",
    "updated": "2024-05-18T08:51:42+00:00",
    "url": "http://arxiv.org/pdf/2405.11230v1"
  },
  {
    "id": "2405.11146v2",
    "title": "Election Polls on Social Media: Prevalence, Biases, and Voter Fraud Beliefs",
    "authors": [
      "Stephen Scarano",
      "Vijayalakshmi Vasudevan",
      "Mattia Samory",
      "Kai-Cheng Yang",
      "JungHwan Yang",
      "Przemyslaw A. Grabowicz"
    ],
    "abstract": "Social media platforms allow users to create polls to gather public opinion\non diverse topics. However, we know little about what such polls are used for\nand how reliable they are, especially in significant contexts like elections.\nFocusing on the 2020 presidential elections in the U.S., this study shows that\noutcomes of election polls on Twitter deviate from election results despite\ntheir prevalence. Leveraging demographic inference and statistical analysis, we\nfind that Twitter polls are disproportionately authored by older males and\nexhibit a large bias towards candidate Donald Trump relative to representative\nmainstream polls. We investigate potential sources of biased outcomes from the\npoint of view of inauthentic, automated, and counter-normative behavior. Using\nsocial media experiments and interviews with poll authors, we identify\ninconsistencies between public vote counts and those privately visible to poll\nauthors, with the gap potentially attributable to purchased votes. We also find\nthat Twitter accounts participating in election polls are more likely to be\nbots, and election poll outcomes tend to be more biased, before the election\nday than after. Finally, we identify instances of polls spreading voter fraud\nconspiracy theories and estimate that a couple thousand of such polls were\nposted in 2020. The study discusses the implications of biased election polls\nin the context of transparency and accountability of social media platforms.",
    "categories": [
      "cs.SI",
      "cs.CY",
      "physics.soc-ph"
    ],
    "published": "2024-05-18T02:29:35+00:00",
    "updated": "2024-05-22T18:54:28+00:00",
    "url": "http://arxiv.org/pdf/2405.11146v2"
  },
  {
    "id": "2405.11034v1",
    "title": "Safety in Graph Machine Learning: Threats and Safeguards",
    "authors": [
      "Song Wang",
      "Yushun Dong",
      "Binchi Zhang",
      "Zihan Chen",
      "Xingbo Fu",
      "Yinhan He",
      "Cong Shen",
      "Chuxu Zhang",
      "Nitesh V. Chawla",
      "Jundong Li"
    ],
    "abstract": "Graph Machine Learning (Graph ML) has witnessed substantial advancements in\nrecent years. With their remarkable ability to process graph-structured data,\nGraph ML techniques have been extensively utilized across diverse applications,\nincluding critical domains like finance, healthcare, and transportation.\nDespite their societal benefits, recent research highlights significant safety\nconcerns associated with the widespread use of Graph ML models. Lacking\nsafety-focused designs, these models can produce unreliable predictions,\ndemonstrate poor generalizability, and compromise data confidentiality. In\nhigh-stakes scenarios such as financial fraud detection, these vulnerabilities\ncould jeopardize both individuals and society at large. Therefore, it is\nimperative to prioritize the development of safety-oriented Graph ML models to\nmitigate these risks and enhance public confidence in their applications. In\nthis survey paper, we explore three critical aspects vital for enhancing safety\nin Graph ML: reliability, generalizability, and confidentiality. We categorize\nand analyze threats to each aspect under three headings: model threats, data\nthreats, and attack threats. This novel taxonomy guides our review of effective\nstrategies to protect against these threats. Our systematic review lays a\ngroundwork for future research aimed at developing practical, safety-centered\nGraph ML models. Furthermore, we highlight the significance of safe Graph ML\npractices and suggest promising avenues for further investigation in this\ncrucial area.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-05-17T18:11:11+00:00",
    "updated": "2024-05-17T18:11:11+00:00",
    "url": "http://arxiv.org/pdf/2405.11034v1"
  },
  {
    "id": "2407.12143v1",
    "title": "False consensus biases AI against vulnerable stakeholders",
    "authors": [
      "Mengchen Dong",
      "Jean-François Bonnefon",
      "Iyad Rahwan"
    ],
    "abstract": "The deployment of AI systems for welfare benefit allocation allows for\naccelerated decision-making and faster provision of critical help, but has\nalready led to an increase in unfair benefit denials and false fraud\naccusations. Collecting data in the US and the UK (N = 2449), we explore the\npublic acceptability of such speed-accuracy trade-offs in populations of\nclaimants and non-claimants. We observe a general willingness to trade off\nspeed gains for modest accuracy losses, but this aggregate view masks notable\ndivergences between claimants and non-claimants. Although welfare claimants\ncomprise a relatively small proportion of the general population (e.g., 20% in\nthe US representative sample), this vulnerable group is much less willing to\naccept AI deployed in welfare systems, raising concerns that solely using\naggregate data for calibration could lead to policies misaligned with\nstakeholder preferences. Our study further uncovers asymmetric insights between\nclaimants and non-claimants. The latter consistently overestimate claimant\nwillingness to accept speed-accuracy trade-offs, even when financially\nincentivized for accurate perspective-taking. This suggests that policy\ndecisions influenced by the dominant voice of non-claimants, however\nwell-intentioned, may neglect the actual preferences of those directly affected\nby welfare AI systems. Our findings underline the need for stakeholder\nengagement and transparent communication in the design and deployment of these\nsystems, particularly in contexts marked by power imbalances.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "published": "2024-05-17T14:33:47+00:00",
    "updated": "2024-05-17T14:33:47+00:00",
    "url": "http://arxiv.org/pdf/2407.12143v1"
  },
  {
    "id": "2405.10119v1",
    "title": "Applications of Quantum Machine Learning for Quantitative Finance",
    "authors": [
      "Piotr Mironowicz",
      "Akshata Shenoy H.",
      "Antonio Mandarino",
      "A. Ege Yilmaz",
      "Thomas Ankenbrand"
    ],
    "abstract": "Machine learning and quantum machine learning (QML) have gained significant\nimportance, as they offer powerful tools for tackling complex computational\nproblems across various domains. This work gives an extensive overview of QML\nuses in quantitative finance, an important discipline in the financial\nindustry. We examine the connection between quantum computing and machine\nlearning in financial applications, spanning a range of use cases including\nfraud detection, underwriting, Value at Risk, stock market prediction,\nportfolio optimization, and option pricing by overviewing the corpus of\nliterature concerning various financial subdomains.",
    "categories": [
      "quant-ph"
    ],
    "published": "2024-05-16T14:15:44+00:00",
    "updated": "2024-05-16T14:15:44+00:00",
    "url": "http://arxiv.org/pdf/2405.10119v1"
  },
  {
    "id": "2405.07582v1",
    "title": "FRRffusion: Unveiling Authenticity with Diffusion-Based Face Retouching Reversal",
    "authors": [
      "Fengchuang Xing",
      "Xiaowen Shi",
      "Yuan-Gen Wang",
      "Chunsheng Yang"
    ],
    "abstract": "Unveiling the real appearance of retouched faces to prevent malicious users\nfrom deceptive advertising and economic fraud has been an increasing concern in\nthe era of digital economics. This article makes the first attempt to\ninvestigate the face retouching reversal (FRR) problem. We first collect an FRR\ndataset, named deepFRR, which contains 50,000 StyleGAN-generated\nhigh-resolution (1024*1024) facial images and their corresponding retouched\nones by a commercial online API. To our best knowledge, deepFRR is the first\nFRR dataset tailored for training the deep FRR models. Then, we propose a novel\ndiffusion-based FRR approach (FRRffusion) for the FRR task. Our FRRffusion\nconsists of a coarse-to-fine two-stage network: A diffusion-based Facial\nMorpho-Architectonic Restorer (FMAR) is constructed to generate the basic\ncontours of low-resolution faces in the first stage, while a Transformer-based\nHyperrealistic Facial Detail Generator (HFDG) is designed to create\nhigh-resolution facial details in the second stage. Tested on deepFRR, our\nFRRffusion surpasses the GP-UNIT and Stable Diffusion methods by a large margin\nin four widespread quantitative metrics. Especially, the de-retouched images by\nour FRRffusion are visually much closer to the raw face images than both the\nretouched face images and those restored by the GP-UNIT and Stable Diffusion\nmethods in terms of qualitative evaluation with 85 subjects. These results\nsufficiently validate the efficacy of our work, bridging the recently-standing\ngap between the FRR and generic image restoration tasks. The dataset and code\nare available at https://github.com/GZHU-DVL/FRRffusion.",
    "categories": [
      "cs.CV"
    ],
    "published": "2024-05-13T09:38:49+00:00",
    "updated": "2024-05-13T09:38:49+00:00",
    "url": "http://arxiv.org/pdf/2405.07582v1"
  },
  {
    "id": "2406.07563v1",
    "title": "Guardians of Anonymity: Exploring Tactics to Combat Cyber Threats in Onion Routing Environments",
    "authors": [
      "Karwan Mustafa Kareem"
    ],
    "abstract": "Onion routing networks, also known as darknets, are private networks that\nenable anonymous communication over the Internet. They are used by individuals\nand organizations to protect their privacy, but they also attract\ncybercriminals who exploit the anonymity provided by these networks for illegal\nactivities. This paper comprehensively analyzes cybercrime threats and\ncountermeasures in onion routing networks. We review the various types of\ncybercrime that occur in these networks, including drug trafficking, fraud,\nhacking, and other illicit activities. We then discuss the challenges\nassociated with detecting and mitigating cybercrime in onion routing networks,\nsuch as the difficulty of tracing illegal activities back to their source due\nto the strong anonymity guarantees provided by these networks. We also explore\nthe countermeasures that have been proposed and implemented to combat\ncybercrime in onion routing networks, including law enforcement efforts,\ntechnological solutions, and policy interventions. Finally, we highlight the\nlimitations of existing countermeasures and identify potential directions for\nfuture research in this area, including the need for interdisciplinary\napproaches that combine technical, legal, and social perspectives to\neffectively combat cybercrime in onion routing networks.",
    "categories": [
      "cs.CR",
      "cs.NI"
    ],
    "published": "2024-05-11T23:18:00+00:00",
    "updated": "2024-05-11T23:18:00+00:00",
    "url": "http://arxiv.org/pdf/2406.07563v1"
  },
  {
    "id": "2405.04837v1",
    "title": "Enhancing Data Integrity and Traceability in Industry Cyber Physical Systems (ICPS) through Blockchain Technology: A Comprehensive Approach",
    "authors": [
      "Mohammad Ikbal Hossain",
      "Tanja Steigner",
      "Muhammad Imam Hussain",
      "Afroja Akther"
    ],
    "abstract": "Blockchain technology, heralded as a transformative innovation, has\nfar-reaching implications beyond its initial application in cryptocurrencies.\nThis study explores the potential of blockchain in enhancing data integrity and\ntraceability within Industry Cyber-Physical Systems (ICPS), a crucial aspect in\nthe era of Industry 4.0. ICPS, integrating computational and physical\ncomponents, is pivotal in managing critical infrastructure like manufacturing,\npower grids, and transportation networks. However, they face challenges in\nsecurity, privacy, and reliability. With its inherent immutability,\ntransparency, and distributed consensus, blockchain presents a groundbreaking\napproach to address these challenges. It ensures robust data reliability and\ntraceability across ICPS, enhancing transaction transparency and facilitating\nsecure data sharing. This research unearths various blockchain applications in\nICPS, including supply chain management, quality control, contract management,\nand data sharing. Each application demonstrates blockchain's capacity to\nstreamline processes, reduce fraud, and enhance system efficiency. In supply\nchain management, blockchain provides real-time auditing and compliance. For\nquality control, it establishes tamper-proof records, boosting consumer\nconfidence. In contract management, smart contracts automate execution,\nenhancing efficiency. Blockchain also fosters secure collaboration in ICPS,\nwhich is crucial for system stability and safety. This study emphasizes the\nneed for further research on blockchain's practical implementation in ICPS,\nfocusing on challenges like scalability, system integration, and security\nvulnerabilities. It also suggests examining blockchain's economic and\norganizational impacts in ICPS to understand its feasibility and long-term\nadvantages.",
    "categories": [
      "cs.CR",
      "cs.SY",
      "eess.SY"
    ],
    "published": "2024-05-08T06:22:37+00:00",
    "updated": "2024-05-08T06:22:37+00:00",
    "url": "http://arxiv.org/pdf/2405.04837v1"
  },
  {
    "id": "2405.04181v2",
    "title": "Detecting music deepfakes is easy but actually hard",
    "authors": [
      "Darius Afchar",
      "Gabriel Meseguer-Brocal",
      "Romain Hennequin"
    ],
    "abstract": "In the face of a new era of generative models, the detection of artificially\ngenerated content has become a matter of utmost importance. The ability to\ncreate credible minute-long music deepfakes in a few seconds on user-friendly\nplatforms poses a real threat of fraud on streaming services and unfair\ncompetition to human artists. This paper demonstrates the possibility (and\nsurprising ease) of training classifiers on datasets comprising real audio and\nfake reconstructions, achieving a convincing accuracy of 99.8%. To our\nknowledge, this marks the first publication of a music deepfake detector, a\ntool that will help in the regulation of music forgery. Nevertheless, informed\nby decades of literature on forgery detection in other fields, we stress that a\ngood test score is not the end of the story. We step back from the\nstraightforward ML framework and expose many facets that could be problematic\nwith such a deployed detector: calibration, robustness to audio manipulation,\ngeneralisation to unseen models, interpretability and possibility for recourse.\nThis second part acts as a position for future research steps in the field and\na caveat to a flourishing market of fake content checkers.",
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ],
    "published": "2024-05-07T10:39:19+00:00",
    "updated": "2024-05-22T09:31:21+00:00",
    "url": "http://arxiv.org/pdf/2405.04181v2"
  },
  {
    "id": "2405.03992v1",
    "title": "Research on financial fraud algorithm based on federal learning and big data technology",
    "authors": [
      "Xinye Sha"
    ],
    "abstract": "With the deepening of the digitization degree of financial business,\nfinancial fraud presents more complex and hidden characteristics, which poses a\nsevere challenge to the risk prevention and control ability of financial\ninstitutions. At the same time, the vigorous development of big data technology\nprovides massive potential information resources, and federated learning, as an\nemerging distributed machine learning paradigm, can realize multi-party data\ncollaborative modeling under the premise of protecting data privacy. This paper\nfirstly elaborates the basic principle, advantages and unique value of\nfederated learning in solving data silos and protecting user privacy. Aiming at\nthe needs of financial fraud detection, this paper discusses the design of\nfederal learning architecture suitable for this scenario, including selecting\nsuitable model type (such as neural network), setting reasonable data\npartitioning and updating rules. The central theme of the dissertation revolves\naround the exploration and execution of an algorithm for detecting financial\nfraud, which is grounded in federated learning methodologies. With a federated\nlearning framework, each participant trains the model locally and exchanges\nonly model parameters rather than raw data, enabling iterative optimization of\nthe global model while protecting data privacy. To ascertain the efficacy and\nsuperiority of the suggested algorithm, a meticulous experimental investigation\nis both devised and executed. A real-world financial fraud dataset is selected\nto compare the fraud detection performance using traditional centralized\nlearning and federated learning. The findings from the experiments reveal that\nthe federated learning-based financial fraud algorithm achieves a substantial\nreduction in the likelihood of data privacy breaches without compromising on\nhigh detection accuracies.",
    "categories": [
      "cs.CE"
    ],
    "published": "2024-05-07T04:11:03+00:00",
    "updated": "2024-05-07T04:11:03+00:00",
    "url": "http://arxiv.org/pdf/2405.03992v1"
  },
  {
    "id": "2405.01852v1",
    "title": "Tokenization of Real Estate Assets Using Blockchain",
    "authors": [
      "Shashank Joshi",
      "Arhan Choudhury"
    ],
    "abstract": "Blockchain technology is one of the key technologies that have revolutionized\nvarious facets of society, such as the banking, healthcare, and other critical\necosystems. One area that can harness the usage of blockchain is the real\nestate sector. The most lucrative long-term investment is real estate, followed\nby gold, equities, mutual funds, and savings accounts. Nevertheless, it has\nadministrative overheads such as lack of transparency, fraud, several\nintermediaries, title issues, paperwork, an increasing number of arbitrations,\nand the lack of liquidity. This paper proposes a framework that uses blockchain\nas an underlying technology. With the aid of blockchain and the suite of tools,\nit supports many of these problems that can be alleviated in the real estate\ninvestment ecosystem. These include smart contracts, immutable record\nmanagement, tokenization, record tracking, and time-stamped storage.\nTokenization of real estate lowers the entry barrier by fixing liquidity and\ninteroperability and improving the interaction between various stakeholders.",
    "categories": [
      "cs.DC",
      "cs.CR",
      "cs.ET"
    ],
    "published": "2024-05-03T04:50:17+00:00",
    "updated": "2024-05-03T04:50:17+00:00",
    "url": "http://arxiv.org/pdf/2405.01852v1"
  },
  {
    "id": "2405.01448v1",
    "title": "GTX: A Transactional Graph Data System For HTAP Workloads",
    "authors": [
      "Libin Zhou",
      "Walid Aref"
    ],
    "abstract": "Processing, managing, and analyzing dynamic graphs are the cornerstone in\nmultiple application domains including fraud detection, recommendation system,\ngraph neural network training, etc. This demo presents GTX, a latch-free\nwrite-optimized transactional graph data system that supports high throughput\nread-write transactions while maintaining competitive graph analytics. GTX has\na unique latch-free graph storage and a transaction and concurrency control\nprotocol for dynamic power-law graphs. GTX leverages atomic operations to\neliminate latches, proposes a delta-based multi-version storage, and designs a\nhybrid transaction commit protocol to reduce interference between concurrent\noperations. To further improve its throughput, we design a delta-chains index\nto support efficient edge lookups. GTX manages concurrency control at\ndelta-chain level, and provides adaptive concurrency according to the workload.\nReal-world graph access and updates exhibit temporal localities and hotspots.\nUnlike other transactional graph systems that experience significant\nperformance degradation, GTX is the only system that can adapt to temporal\nlocalities and hotspots in graph updates and maintain\nmillion-transactions-per-second throughput. GTX is prototyped as a graph\nlibrary and is evaluated using a graph library evaluation tool using real and\nsynthetic datasets.",
    "categories": [
      "cs.DB",
      "H.2.4"
    ],
    "published": "2024-05-02T16:32:37+00:00",
    "updated": "2024-05-02T16:32:37+00:00",
    "url": "http://arxiv.org/pdf/2405.01448v1"
  },
  {
    "id": "2405.00793v1",
    "title": "The Impact of IMSI Catcher Deployments on Cellular Network Security: Challenges and Countermeasures in 4G and 5G Networks",
    "authors": [
      "Karwan Mustafa Kareem"
    ],
    "abstract": "IMSI (International Mobile Subscriber Identity) catchers, also known as\n\"Stingrays\" or \"cell site simulators,\" are rogue devices that pose a\nsignificant threat to cellular network security [1]. IMSI catchers can\nintercept and manipulate cellular communications, compromising the privacy and\nsecurity of mobile devices and their users. With the advent of 4G and 5G\nnetworks, IMSI catchers have become more sophisticated and pose new challenges\nto cellular network security [2]. This paper provides an overview of the impact\nof IMSI catcher deployments on cellular network security in the context of 4G\nand 5G networks. It discusses the challenges posed by IMSI catchers, including\nthe unauthorized collection of IMSI numbers, interception of communications,\nand potential misuse of subscriber information. It also highlights the\npotential consequences of IMSI catcher deployments, including the compromise of\nuser privacy, financial fraud, and unauthorized surveillance. The paper further\nreviews the countermeasures that can be employed to mitigate the risks posed by\nIMSI catchers. These countermeasures include network-based solutions such as\nsignal analysis, encryption, and authentication mechanisms, as well as\nuser-based solutions such as mobile applications and device settings. The paper\nalso discusses the limitations and effectiveness of these countermeasures in\nthe context of 4G and 5G networks. Finally, the paper identifies research gaps\nand future directions for enhancing cellular network security against IMSI\ncatchers in the era of 4G and 5G networks. This includes the need for improved\nencryption algorithms, authentication mechanisms, and detection techniques to\neffectively detect and prevent IMSI catcher deployments. The paper also\nemphasizes the importance of regulatory and policy measures to govern the\ndeployment and use of IMSI catchers to protect user privacy and security.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-05-01T18:08:03+00:00",
    "updated": "2024-05-01T18:08:03+00:00",
    "url": "http://arxiv.org/pdf/2405.00793v1"
  },
  {
    "id": "2405.05918v1",
    "title": "Safeguarding People's Financial Health in Metaverse with Emotionally Intelligent Virtual Buddy",
    "authors": [
      "Syed Ali Asif",
      "Emma Cao",
      "Hang Chen",
      "Chien-Chung Shen",
      "Yan-Ming Chiou"
    ],
    "abstract": "The Metaverse, an immersive virtual world, has emerged as a shared space\nwhere people engage in various activities ranging from social interactions to\ncommerce. Cryptocurrencies [3] and Non-Fungible Tokens (NFTs) [6] play pivotal\nroles within this virtual realm, reshaping interactions and transactions.\nCryptocurrencies, utilizing cryptographic techniques for security, enable\ndecentralized and secure transactions, and NFTs represent ownership or proof of\nauthenticity of unique digital assets through the blockchain technology. While\nNFTs and cryptocurrencies offer innovative opportunities for ownership,\ntrading, and monetization within the metaverse, their use also introduces\npotential risks and negative consequences, such as financial scams and fraud,\nhighlighting the need for users to exercise caution and diligence in their\nvirtual transactions.",
    "categories": [
      "cs.HC"
    ],
    "published": "2024-04-23T17:45:22+00:00",
    "updated": "2024-04-23T17:45:22+00:00",
    "url": "http://arxiv.org/pdf/2405.05918v1"
  },
  {
    "id": "2405.05923v1",
    "title": "Darkverse -- A New DarkWeb?",
    "authors": [
      "Raymond Chan",
      "Benjamin W. J. Kwok",
      "Adriel Yeo",
      "Kan Chen",
      "Jeannie S. Lee"
    ],
    "abstract": "The \"Darkverse\" could be the negative harmful area of the Metaverse; a new\nvirtual immersive environment for the facilitation of illicit activity such as\nmisinformation, fraud, harassment, and illegal marketplaces. This paper\nexplores the potential for inappropriate activities within the Metaverse, and\nthe similarities between the Darkverse and the Dark Web. Challenges and future\ndirections for investigation are also discussed, including user identification,\ncreation of privacy-preserving frameworks and other data monitoring methods.",
    "categories": [
      "cs.HC"
    ],
    "published": "2024-04-23T17:37:33+00:00",
    "updated": "2024-04-23T17:37:33+00:00",
    "url": "http://arxiv.org/pdf/2405.05923v1"
  },
  {
    "id": "2404.14746v1",
    "title": "A Customer Level Fraudulent Activity Detection Benchmark for Enhancing Machine Learning Model Research and Evaluation",
    "authors": [
      "Phoebe Jing",
      "Yijing Gao",
      "Xianlong Zeng"
    ],
    "abstract": "In the field of fraud detection, the availability of comprehensive and\nprivacy-compliant datasets is crucial for advancing machine learning research\nand developing effective anti-fraud systems. Traditional datasets often focus\non transaction-level information, which, while useful, overlooks the broader\ncontext of customer behavior patterns that are essential for detecting\nsophisticated fraud schemes. The scarcity of such data, primarily due to\nprivacy concerns, significantly hampers the development and testing of\npredictive models that can operate effectively at the customer level.\nAddressing this gap, our study introduces a benchmark that contains structured\ndatasets specifically designed for customer-level fraud detection. The\nbenchmark not only adheres to strict privacy guidelines to ensure user\nconfidentiality but also provides a rich source of information by encapsulating\ncustomer-centric features. We have developed the benchmark that allows for the\ncomprehensive evaluation of various machine learning models, facilitating a\ndeeper understanding of their strengths and weaknesses in predicting fraudulent\nactivities. Through this work, we seek to bridge the existing gap in data\navailability, offering researchers and practitioners a valuable resource that\nempowers the development of next-generation fraud detection techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2024-04-23T04:57:44+00:00",
    "updated": "2024-04-23T04:57:44+00:00",
    "url": "http://arxiv.org/pdf/2404.14746v1"
  },
  {
    "id": "2404.14581v1",
    "title": "The Adversarial AI-Art: Understanding, Generation, Detection, and Benchmarking",
    "authors": [
      "Yuying Li",
      "Zeyan Liu",
      "Junyi Zhao",
      "Liangqin Ren",
      "Fengjun Li",
      "Jiebo Luo",
      "Bo Luo"
    ],
    "abstract": "Generative AI models can produce high-quality images based on text prompts.\nThe generated images often appear indistinguishable from images generated by\nconventional optical photography devices or created by human artists (i.e.,\nreal images). While the outstanding performance of such generative models is\ngenerally well received, security concerns arise. For instance, such image\ngenerators could be used to facilitate fraud or scam schemes, generate and\nspread misinformation, or produce fabricated artworks. In this paper, we\npresent a systematic attempt at understanding and detecting AI-generated images\n(AI-art) in adversarial scenarios. First, we collect and share a dataset of\nreal images and their corresponding artificial counterparts generated by four\npopular AI image generators. The dataset, named ARIA, contains over 140K images\nin five categories: artworks (painting), social media images, news photos,\ndisaster scenes, and anime pictures. This dataset can be used as a foundation\nto support future research on adversarial AI-art. Next, we present a user study\nthat employs the ARIA dataset to evaluate if real-world users can distinguish\nwith or without reference images. In a benchmarking study, we further evaluate\nif state-of-the-art open-source and commercial AI image detectors can\neffectively identify the images in the ARIA dataset. Finally, we present a\nResNet-50 classifier and evaluate its accuracy and transferability on the ARIA\ndataset.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2024-04-22T21:00:13+00:00",
    "updated": "2024-04-22T21:00:13+00:00",
    "url": "http://arxiv.org/pdf/2404.14581v1"
  },
  {
    "id": "2404.14304v2",
    "title": "Explaining Arguments' Strength: Unveiling the Role of Attacks and Supports (Technical Report)",
    "authors": [
      "Xiang Yin",
      "Potyka Nico",
      "Francesca Toni"
    ],
    "abstract": "Quantitatively explaining the strength of arguments under gradual semantics\nhas recently received increasing attention. Specifically, several works in the\nliterature provide quantitative explanations by computing the attribution\nscores of arguments. These works disregard the importance of attacks and\nsupports, even though they play an essential role when explaining arguments'\nstrength. In this paper, we propose a novel theory of Relation Attribution\nExplanations (RAEs), adapting Shapley values from game theory to offer\nfine-grained insights into the role of attacks and supports in quantitative\nbipolar argumentation towards obtaining the arguments' strength. We show that\nRAEs satisfy several desirable properties. We also propose a probabilistic\nalgorithm to approximate RAEs efficiently. Finally, we show the application\nvalue of RAEs in fraud detection and large language models case studies.",
    "categories": [
      "cs.AI"
    ],
    "published": "2024-04-22T16:02:48+00:00",
    "updated": "2024-05-10T17:37:43+00:00",
    "url": "http://arxiv.org/pdf/2404.14304v2"
  },
  {
    "id": "2406.13166v3",
    "title": "Enhancing supply chain security with automated machine learning",
    "authors": [
      "Haibo Wang",
      "Lutfu S. Sua",
      "Bahram Alidaee"
    ],
    "abstract": "The increasing scale and complexity of global supply chains have led to new\nchallenges spanning various fields, such as supply chain disruptions due to\nlong waiting lines at the ports, material shortages, and inflation. Coupled\nwith the size of supply chains and the availability of vast amounts of data,\nefforts towards tackling such challenges have led to an increasing interest in\napplying machine learning methods in many aspects of supply chains. Unlike\nother solutions, ML techniques, including Random Forest, XGBoost, LightGBM, and\nNeural Networks, make predictions and approximate optimal solutions faster.\nThis paper presents an automated ML framework to enhance supply chain security\nby detecting fraudulent activities, predicting maintenance needs, and\nforecasting material backorders. Using datasets of varying sizes, results show\nthat fraud detection achieves an 88% accuracy rate using sampling methods,\nmachine failure prediction reaches 93.4% accuracy, and material backorder\nprediction achieves 89.3% accuracy. Hyperparameter tuning significantly\nimproved the performance of these models, with certain supervised techniques\nlike XGBoost and LightGBM reaching up to 100% precision. This research\ncontributes to supply chain security by streamlining data preprocessing,\nfeature selection, model optimization, and inference deployment, addressing\ncritical challenges and boosting operational efficiency.",
    "categories": [
      "cs.LG",
      "econ.GN",
      "math.OC",
      "q-fin.EC"
    ],
    "published": "2024-06-19T02:45:32+00:00",
    "updated": "2025-07-22T18:22:57+00:00",
    "url": "http://arxiv.org/pdf/2406.13166v3"
  },
  {
    "id": "2406.11389v1",
    "title": "SEFraud: Graph-based Self-Explainable Fraud Detection via Interpretative Mask Learning",
    "authors": [
      "Kaidi Li",
      "Tianmeng Yang",
      "Min Zhou",
      "Jiahao Meng",
      "Shendi Wang",
      "Yihui Wu",
      "Boshuai Tan",
      "Hu Song",
      "Lujia Pan",
      "Fan Yu",
      "Zhenli Sheng",
      "Yunhai Tong"
    ],
    "abstract": "Graph-based fraud detection has widespread application in modern industry\nscenarios, such as spam review and malicious account detection. While\nconsiderable efforts have been devoted to designing adequate fraud detectors,\nthe interpretability of their results has often been overlooked. Previous works\nhave attempted to generate explanations for specific instances using post-hoc\nexplaining methods such as a GNNExplainer. However, post-hoc explanations can\nnot facilitate the model predictions and the computational cost of these\nmethods cannot meet practical requirements, thus limiting their application in\nreal-world scenarios. To address these issues, we propose SEFraud, a novel\ngraph-based self-explainable fraud detection framework that simultaneously\ntackles fraud detection and result in interpretability. Concretely, SEFraud\nfirst leverages customized heterogeneous graph transformer networks with\nlearnable feature masks and edge masks to learn expressive representations from\nthe informative heterogeneously typed transactions. A new triplet loss is\nfurther designed to enhance the performance of mask learning. Empirical results\non various datasets demonstrate the effectiveness of SEFraud as it shows\nconsiderable advantages in both the fraud detection performance and\ninterpretability of prediction results. Moreover, SEFraud has been deployed and\noffers explainable fraud detection service for the largest bank in China,\nIndustrial and Commercial Bank of China Limited (ICBC). Results collected from\nthe production environment of ICBC show that SEFraud can provide accurate\ndetection results and comprehensive explanations that align with the expert\nbusiness understanding, confirming its efficiency and applicability in\nlarge-scale online services.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-06-17T10:18:53+00:00",
    "updated": "2024-06-17T10:18:53+00:00",
    "url": "http://arxiv.org/pdf/2406.11389v1"
  },
  {
    "id": "2406.15482v1",
    "title": "Blockchain for Academic Integrity: Developing the Blockchain Academic Credential Interoperability Protocol (BACIP)",
    "authors": [
      "Juan A. Berrios Moya"
    ],
    "abstract": "This research introduces the Blockchain Academic Credential Interoperability\nProtocol (BACIP), designed to significantly enhance the security, privacy, and\ninteroperability of verifying academic credentials globally, addressing the\nwidespread issue of academic fraud. BACIP integrates dual blockchain\narchitecture, smart contracts, and zero-knowledge proofs to offer a scalable\nand transparent framework aimed at reducing fraud and improving the mobility\nand opportunities for students and professionals worldwide. The research\nmethodology adopts a mixed-methods approach, involving a rigorous review of\npertinent literature and systematic integration of advanced technological\ncomponents. This includes both qualitative and quantitative analyses that\nunderpin the development of a universally compatible system. Preliminary\nevaluations suggest that BACIP could enhance verification efficiency and\nbolster security against tampering and unauthorized access. While the\ntheoretical framework and practical implementations have laid a solid\nfoundation, the protocol's real-world efficacy awaits empirical validation in a\nproduction environment. Future research will focus on deploying a prototype,\nestablishing robust validation policies, and defining precise testing\nparameters. This critical phase is indispensable for a thorough assessment of\nBACIP's operational robustness and its compliance with international\neducational standards. This work contributes significantly to the academic\nfield by proposing a robust model for managing and safeguarding academic\ncredentials, thus laying a strong foundation for further innovation in\ncredential verification using blockchain technology.",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "published": "2024-06-17T06:11:51+00:00",
    "updated": "2024-06-17T06:11:51+00:00",
    "url": "http://arxiv.org/pdf/2406.15482v1"
  },
  {
    "id": "2406.06965v4",
    "title": "Evolving from Single-modal to Multi-modal Facial Deepfake Detection: Progress and Challenges",
    "authors": [
      "Ping Liu",
      "Qiqi Tao",
      "Joey Tianyi Zhou"
    ],
    "abstract": "As synthetic media, including video, audio, and text, become increasingly\nindistinguishable from real content, the risks of misinformation, identity\nfraud, and social manipulation escalate. This survey traces the evolution of\ndeepfake detection from early single-modal methods to sophisticated multi-modal\napproaches that integrate audio-visual and text-visual cues. We present a\nstructured taxonomy of detection techniques and analyze the transition from\nGAN-based to diffusion model-driven deepfakes, which introduce new challenges\ndue to their heightened realism and robustness against detection. Unlike prior\nsurveys that primarily focus on single-modal detection or earlier deepfake\ntechniques, this work provides the most comprehensive study to date,\nencompassing the latest advancements in multi-modal deepfake detection,\ngeneralization challenges, proactive defense mechanisms, and emerging datasets\nspecifically designed to support new interpretability and reasoning tasks. We\nfurther explore the role of Vision-Language Models (VLMs) and Multimodal Large\nLanguage Models (MLLMs) in strengthening detection robustness against\nincreasingly sophisticated deepfake attacks. By systematically categorizing\nexisting methods and identifying emerging research directions, this survey\nserves as a foundation for future advancements in combating AI-generated facial\nforgeries. A curated list of all related papers can be found at\n\\href{https://github.com/qiqitao77/Comprehensive-Advances-in-Deepfake-Detection-Spanning-Diverse-Modalities}{https://github.com/qiqitao77/Awesome-Comprehensive-Deepfake-Detection}.",
    "categories": [
      "cs.CV"
    ],
    "published": "2024-06-11T05:48:04+00:00",
    "updated": "2025-04-03T07:47:44+00:00",
    "url": "http://arxiv.org/pdf/2406.06965v4"
  },
  {
    "id": "2406.06202v1",
    "title": "Federated learning in food research",
    "authors": [
      "Zuzanna Fendor",
      "Bas H. M. van der Velden",
      "Xinxin Wang",
      "Andrea Jr. Carnoli",
      "Osman Mutlu",
      "Ali Hürriyetoğlu"
    ],
    "abstract": "Research in the food domain is at times limited due to data sharing\nobstacles, such as data ownership, privacy requirements, and regulations. While\nimportant, these obstacles can restrict data-driven methods such as machine\nlearning. Federated learning, the approach of training models on locally kept\ndata and only sharing the learned parameters, is a potential technique to\nalleviate data sharing obstacles. This systematic review investigates the use\nof federated learning within the food domain, structures included papers in a\nfederated learning framework, highlights knowledge gaps, and discusses\npotential applications. A total of 41 papers were included in the review. The\ncurrent applications include solutions to water and milk quality assessment,\ncybersecurity of water processing, pesticide residue risk analysis, weed\ndetection, and fraud detection, focusing on centralized horizontal federated\nlearning. One of the gaps found was the lack of vertical or transfer federated\nlearning and decentralized architectures.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-06-10T11:58:11+00:00",
    "updated": "2024-06-10T11:58:11+00:00",
    "url": "http://arxiv.org/pdf/2406.06202v1"
  },
  {
    "id": "2406.04690v1",
    "title": "Higher-order Structure Based Anomaly Detection on Attributed Networks",
    "authors": [
      "Xu Yuan",
      "Na Zhou",
      "Shuo Yu",
      "Huafei Huang",
      "Zhikui Chen",
      "Feng Xia"
    ],
    "abstract": "Anomaly detection (such as telecom fraud detection and medical image\ndetection) has attracted the increasing attention of people. The complex\ninteraction between multiple entities widely exists in the network, which can\nreflect specific human behavior patterns. Such patterns can be modeled by\nhigher-order network structures, thus benefiting anomaly detection on\nattributed networks. However, due to the lack of an effective mechanism in most\nexisting graph learning methods, these complex interaction patterns fail to be\napplied in detecting anomalies, hindering the progress of anomaly detection to\nsome extent. In order to address the aforementioned issue, we present a\nhigher-order structure based anomaly detection (GUIDE) method. We exploit\nattribute autoencoder and structure autoencoder to reconstruct node attributes\nand higher-order structures, respectively. Moreover, we design a graph\nattention layer to evaluate the significance of neighbors to nodes through\ntheir higher-order structure differences. Finally, we leverage node attribute\nand higher-order structure reconstruction errors to find anomalies. Extensive\nexperiments on five real-world datasets (i.e., ACM, Citation, Cora, DBLP, and\nPubmed) are implemented to verify the effectiveness of GUIDE. Experimental\nresults in terms of ROC-AUC, PR-AUC, and Recall@K show that GUIDE significantly\noutperforms the state-of-art methods.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2024-06-07T07:02:50+00:00",
    "updated": "2024-06-07T07:02:50+00:00",
    "url": "http://arxiv.org/pdf/2406.04690v1"
  },
  {
    "id": "2406.04658v3",
    "title": "Advanced Payment Security System:XGBoost, LightGBM and SMOTE Integrated",
    "authors": [
      "Qi Zheng",
      "Chang Yu",
      "Jin Cao",
      "Yongshun Xu",
      "Qianwen Xing",
      "Yinxin Jin"
    ],
    "abstract": "With the rise of various online and mobile payment systems, transaction fraud\nhas become a significant threat to financial security. This study explores the\napplication of advanced machine learning models, specifically based on XGBoost\nand LightGBM, for developing a more accurate and robust Payment Security\nProtection Model. To enhance data reliability, we meticulously processed the\ndata sources and applied SMOTE (Synthetic Minority Over-sampling Technique) to\naddress class imbalance and improve data representation. By selecting highly\ncorrelated features, we aimed to strengthen the training process and boost\nmodel performance. We conducted thorough performance evaluations of our\nproposed models, comparing them against traditional methods including Random\nForest, Neural Network, and Logistic Regression. Using metrics such as\nPrecision, Recall, and F1 Score, we rigorously assessed their effectiveness.\nOur detailed analyses and comparisons reveal that the combination of SMOTE with\nXGBoost and LightGBM offers a highly efficient and powerful mechanism for\npayment security protection. Moreover, the integration of XGBoost and LightGBM\nin a Local Ensemble model further demonstrated outstanding performance. After\nincorporating SMOTE, the new combined model achieved a significant improvement\nof nearly 6\\% over traditional models and around 5\\% over its sub-models,\nshowcasing remarkable results.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2024-06-07T05:56:43+00:00",
    "updated": "2024-11-12T16:44:20+00:00",
    "url": "http://arxiv.org/pdf/2406.04658v3"
  },
  {
    "id": "2406.03733v4",
    "title": "Credit Card Fraud Detection Using Advanced Transformer Model",
    "authors": [
      "Chang Yu",
      "Yongshun Xu",
      "Jin Cao",
      "Ye Zhang",
      "Yinxin Jin",
      "Mengran Zhu"
    ],
    "abstract": "With the proliferation of various online and mobile payment systems, credit\ncard fraud has emerged as a significant threat to financial security. This\nstudy focuses on innovative applications of the latest Transformer models for\nmore robust and precise fraud detection. To ensure the reliability of the data,\nwe meticulously processed the data sources, balancing the dataset to address\nthe issue of data sparsity significantly. We also selected highly correlated\nvectors to strengthen the training process.To guarantee the reliability and\npracticality of the new Transformer model, we conducted performance comparisons\nwith several widely adopted models, including Support Vector Machine (SVM),\nRandom Forest, Neural Network, and Logistic Regression. We rigorously compared\nthese models using metrics such as Precision, Recall, and F1 Score. Through\nthese detailed analyses and comparisons, we present to the readers a highly\nefficient and powerful anti-fraud mechanism with promising prospects. The\nresults demonstrate that the Transformer model not only excels in traditional\napplications but also shows great potential in niche areas like fraud\ndetection, offering a substantial advancement in the field.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2024-06-06T04:12:57+00:00",
    "updated": "2024-11-12T16:44:14+00:00",
    "url": "http://arxiv.org/pdf/2406.03733v4"
  },
  {
    "id": "2406.03079v1",
    "title": "Cryptocurrency Frauds for Dummies: How ChatGPT introduces us to fraud?",
    "authors": [
      "Wail Zellagui",
      "Abdessamad Imine",
      "Yamina Tadjeddine"
    ],
    "abstract": "Recent advances in the field of large language models (LLMs), particularly\nthe ChatGPT family, have given rise to a powerful and versatile machine\ninterlocutor, packed with knowledge and challenging our understanding of\nlearning. This interlocutor is a double-edged sword: it can be harnessed for a\nwide variety of beneficial tasks, but it can also be used to cause harm. This\nstudy explores the complicated interaction between ChatGPT and the growing\nproblem of cryptocurrency fraud. Although ChatGPT is known for its adaptability\nand ethical considerations when used for harmful purposes, we highlight the\ndeep connection that may exist between ChatGPT and fraudulent actions in the\nvolatile cryptocurrency ecosystem. Based on our categorization of\ncryptocurrency frauds, we show how to influence outputs, bypass ethical terms,\nand achieve specific fraud goals by manipulating ChatGPT prompts. Furthermore,\nour findings emphasize the importance of realizing that ChatGPT could be a\nvaluable instructor even for novice fraudsters, as well as understanding and\nsafely deploying complex language models, particularly in the context of\ncryptocurrency frauds. Finally, our study underlines the importance of using\nLLMs responsibly and ethically in the digital currency sector, identifying\npotential risks and resolving ethical issues. It should be noted that our work\nis not intended to encourage and promote fraud, but rather to raise awareness\nof the risks of fraud associated with the use of ChatGPT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2024-06-05T09:09:32+00:00",
    "updated": "2024-06-05T09:09:32+00:00",
    "url": "http://arxiv.org/pdf/2406.03079v1"
  },
  {
    "id": "2406.03507v1",
    "title": "Robust Prediction Model for Multidimensional and Unbalanced Datasets",
    "authors": [
      "Pooja Thakar",
      "Anil Mehta",
      "Manisha"
    ],
    "abstract": "Data Mining is a promising field and is applied in multiple domains for its\npredictive capabilities. Data in the real world cannot be readily used for data\nmining as it suffers from the problems of multidimensionality, unbalance and\nmissing values. It is difficult to use its predictive capabilities by novice\nusers. It is difficult for a beginner to find the relevant set of attributes\nfrom a large pool of data available. The paper presents a Robust Prediction\nModel that finds a relevant set of attributes; resolves the problems of\nunbalanced and multidimensional real-life datasets and helps in finding\npatterns for informed decision making. Model is tested upon five different\ndatasets in the domain of Health Sector, Education, Business and Fraud\nDetection. The results showcase the robust behaviour of the model and its\napplicability in various domains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2024-06-05T06:28:39+00:00",
    "updated": "2024-06-05T06:28:39+00:00",
    "url": "http://arxiv.org/pdf/2406.03507v1"
  },
  {
    "id": "2406.02316v1",
    "title": "Fast and Secure Decentralized Optimistic Rollups Using Setchain",
    "authors": [
      "Margarita Capretto",
      "Martín Ceresa",
      "Antonio Fernández Anta",
      "Pedro Moreno-Sánchez",
      "César Sánchez"
    ],
    "abstract": "Modern blockchains face a scalability challenge due to the intrinsic\nthroughput limitations of consensus protocols. Layer 2 optimistic rollups (L2)\nare a faster alternative that offer the same interface in terms of smart\ncontract development and user interaction. Optimistic rollups perform most\ncomputations offchain and make light use of an underlying blockchain (L1) to\nguarantee correct behavior, implementing a cheaper blockchain on a blockchain\nsolution. With optimistic rollups, a sequencer calculates offchain batches of\nL2 transactions and commits batches (compressed or hashed) to the L1\nblockchain. The use of hashes requires a data service to translate hashes into\ntheir corresponding batches. Current L2 implementations consist of a\ncentralized sequencer (central authority) and an optional data availability\ncommittee (DAC).\n  In this paper, we propose a decentralized L2 optimistic rollup based on\nSetchain, a decentralized Byzantine-tolerant implementation of sets. The main\ncontribution is a fully decentralized \"arranger\" where arrangers are a formal\ndefinition combining sequencers and DACs. We prove our implementation correct\nand show empirical evidence that our solution scales. A final contribution is a\nsystem of incentives (payments) for servers that implement the sequencer and\ndata availability committee protocols correctly, and a fraud-proof mechanism to\ndetect violations of the protocol.",
    "categories": [
      "cs.CR",
      "cs.DC",
      "cs.LO"
    ],
    "published": "2024-06-04T13:45:12+00:00",
    "updated": "2024-06-04T13:45:12+00:00",
    "url": "http://arxiv.org/pdf/2406.02316v1"
  },
  {
    "id": "2406.06578v1",
    "title": "SMS Spam Detection and Classification to Combat Abuse in Telephone Networks Using Natural Language Processing",
    "authors": [
      "Dare Azeez Oyeyemi",
      "Adebola K. Ojo"
    ],
    "abstract": "In the modern era, mobile phones have become ubiquitous, and Short Message\nService (SMS) has grown to become a multi-million-dollar service due to the\nwidespread adoption of mobile devices and the millions of people who use SMS\ndaily. However, SMS spam has also become a pervasive problem that endangers\nusers' privacy and security through phishing and fraud. Despite numerous spam\nfiltering techniques, there is still a need for a more effective solution to\naddress this problem [1]. This research addresses the pervasive issue of SMS\nspam, which poses threats to users' privacy and security. Despite existing spam\nfiltering techniques, the high false-positive rate persists as a challenge. The\nstudy introduces a novel approach utilizing Natural Language Processing (NLP)\nand machine learning models, particularly BERT (Bidirectional Encoder\nRepresentations from Transformers), for SMS spam detection and classification.\nData preprocessing techniques, such as stop word removal and tokenization, are\napplied, along with feature extraction using BERT. Machine learning models,\nincluding SVM, Logistic Regression, Naive Bayes, Gradient Boosting, and Random\nForest, are integrated with BERT for differentiating spam from ham messages.\nEvaluation results revealed that the Na\\\"ive Bayes classifier + BERT model\nachieves the highest accuracy at 97.31% with the fastest execution time of 0.3\nseconds on the test dataset. This approach demonstrates a notable enhancement\nin spam detection efficiency and a low false-positive rate. The developed model\npresents a valuable solution to combat SMS spam, ensuring faster and more\naccurate detection. This model not only safeguards users' privacy but also\nassists network providers in effectively identifying and blocking SMS spam\nmessages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2024-06-04T13:44:36+00:00",
    "updated": "2024-06-04T13:44:36+00:00",
    "url": "http://arxiv.org/pdf/2406.06578v1"
  },
  {
    "id": "2406.01813v1",
    "title": "Diffusion Boosted Trees",
    "authors": [
      "Xizewen Han",
      "Mingyuan Zhou"
    ],
    "abstract": "Combining the merits of both denoising diffusion probabilistic models and\ngradient boosting, the diffusion boosting paradigm is introduced for tackling\nsupervised learning problems. We develop Diffusion Boosted Trees (DBT), which\ncan be viewed as both a new denoising diffusion generative model parameterized\nby decision trees (one single tree for each diffusion timestep), and a new\nboosting algorithm that combines the weak learners into a strong learner of\nconditional distributions without making explicit parametric assumptions on\ntheir density forms. We demonstrate through experiments the advantages of DBT\nover deep neural network-based diffusion models as well as the competence of\nDBT on real-world regression tasks, and present a business application (fraud\ndetection) of DBT for classification on tabular data with the ability of\nlearning to defer.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "stat.AP",
      "stat.ME"
    ],
    "published": "2024-06-03T22:11:38+00:00",
    "updated": "2024-06-03T22:11:38+00:00",
    "url": "http://arxiv.org/pdf/2406.01813v1"
  },
  {
    "id": "2406.00987v2",
    "title": "Enhancing Fairness in Unsupervised Graph Anomaly Detection through Disentanglement",
    "authors": [
      "Wenjing Chang",
      "Kay Liu",
      "Philip S. Yu",
      "Jianjun Yu"
    ],
    "abstract": "Graph anomaly detection (GAD) is increasingly crucial in various\napplications, ranging from financial fraud detection to fake news detection.\nHowever, current GAD methods largely overlook the fairness problem, which might\nresult in discriminatory decisions skewed toward certain demographic groups\ndefined on sensitive attributes (e.g., gender, religion, ethnicity, etc.). This\ngreatly limits the applicability of these methods in real-world scenarios in\nlight of societal and ethical restrictions. To address this critical gap, we\nmake the first attempt to integrate fairness with utility in GAD\ndecision-making. Specifically, we devise a novel DisEntangle-based\nFairnEss-aware aNomaly Detection framework on the attributed graph, named\nDEFEND. DEFEND first introduces disentanglement in GNNs to capture informative\nyet sensitive-irrelevant node representations, effectively reducing societal\nbias inherent in graph representation learning. Besides, to alleviate\ndiscriminatory bias in evaluating anomalous nodes, DEFEND adopts a\nreconstruction-based anomaly detection, which concentrates solely on node\nattributes without incorporating any graph structure. Additionally, given the\ninherent association between input and sensitive attributes, DEFEND constrains\nthe correlation between the reconstruction error and the predicted sensitive\nattributes. Our empirical evaluations on real-world datasets reveal that DEFEND\nperforms effectively in GAD and significantly enhances fairness compared to\nstate-of-the-art baselines. To foster reproducibility, our code is available at\nhttps://github.com/AhaChang/DEFEND.",
    "categories": [
      "cs.LG",
      "cs.CY",
      "cs.SI"
    ],
    "published": "2024-06-03T04:48:45+00:00",
    "updated": "2025-03-03T14:14:00+00:00",
    "url": "http://arxiv.org/pdf/2406.00987v2"
  },
  {
    "id": "2405.19762v1",
    "title": "The Kosmosis Use-Case of Crypto Rug Pull Detection and Prevention",
    "authors": [
      "Philipp Stangl",
      "Christoph P. Neumann"
    ],
    "abstract": "Current methods to prevent crypto asset fraud are based on the analysis of\ntransaction graphs within blockchain networks. While effective for identifying\ntransaction patterns indicative of fraud, it does not capture the semantics of\ntransactions and is constrained to blockchain data. Consequently, preventive\nmethods based on transaction graphs are inherently limited. In response to\nthese limitations, we propose the Kosmosis approach, which aims to\nincrementally construct a knowledge graph as new blockchain and social media\ndata become available. During construction, it aims to extract the semantics of\ntransactions and connect blockchain addresses to their real-world entities by\nfusing blockchain and social media data in a knowledge graph. This enables\nnovel preventive methods against rug pulls as a form of crypto asset fraud. To\ndemonstrate the effectiveness and practical applicability of the Kosmosis\napproach, we examine a series of real-world rug pulls from 2021. Through this\ncase, we illustrate how Kosmosis can aid in identifying and preventing such\nfraudulent activities by leveraging the insights from the constructed knowledge\ngraph.",
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "published": "2024-05-30T07:17:57+00:00",
    "updated": "2024-05-30T07:17:57+00:00",
    "url": "http://arxiv.org/pdf/2405.19762v1"
  },
  {
    "id": "2405.19383v4",
    "title": "Network Analytics for Anti-Money Laundering -- A Systematic Literature Review and Experimental Evaluation",
    "authors": [
      "Bruno Deprez",
      "Toon Vanderschueren",
      "Bart Baesens",
      "Tim Verdonck",
      "Wouter Verbeke"
    ],
    "abstract": "Money laundering presents a pervasive challenge, burdening society by\nfinancing illegal activities. The use of network information is increasingly\nbeing explored to effectively combat money laundering, given it involves\nconnected parties. This led to a surge in research on network analytics for\nanti-money laundering (AML). The literature is, however, fragmented and a\ncomprehensive overview of existing work is missing. This results in limited\nunderstanding of the methods to apply and their comparative detection power.\nThis paper presents an extensive and unique literature review, based on 97\npapers from Web of Science and Scopus, resulting in a taxonomy following a\nrecently proposed fraud analytics framework. We conclude that most research\nrelies on expert-based rules and manual features, while deep learning methods\nhave been gaining traction. This paper also presents a comprehensive framework\nto evaluate and compare the performance of prominent methods in a standardized\nsetup. We compare manual feature engineering, random walk-based, and deep\nlearning methods on two publicly available data sets. We conclude that (1)\nnetwork analytics increases the predictive power, but caution is needed when\napplying GNNs in the face of class imbalance and network topology, and that (2)\ncare should be taken with synthetic data as this can give overly optimistic\nresults. The open-source implementation facilitates researchers and\npractitioners to extend this work on proprietary data, promoting a standardised\napproach for the analysis and evaluation of network analytics for AML.",
    "categories": [
      "cs.SI",
      "cs.LG"
    ],
    "published": "2024-05-29T08:48:52+00:00",
    "updated": "2025-07-22T12:16:19+00:00",
    "url": "http://arxiv.org/pdf/2405.19383v4"
  },
  {
    "id": "2405.18741v2",
    "title": "Genshin: General Shield for Natural Language Processing with Large Language Models",
    "authors": [
      "Xiao Peng",
      "Tao Liu",
      "Ying Wang"
    ],
    "abstract": "Large language models (LLMs) like ChatGPT, Gemini, or LLaMA have been\ntrending recently, demonstrating considerable advancement and generalizability\npower in countless domains. However, LLMs create an even bigger black box\nexacerbating opacity, with interpretability limited to few approaches. The\nuncertainty and opacity embedded in LLMs' nature restrict their application in\nhigh-stakes domains like financial fraud, phishing, etc. Current approaches\nmainly rely on traditional textual classification with posterior interpretable\nalgorithms, suffering from attackers who may create versatile adversarial\nsamples to break the system's defense, forcing users to make trade-offs between\nefficiency and robustness. To address this issue, we propose a novel cascading\nframework called Genshin (General Shield for Natural Language Processing with\nLarge Language Models), utilizing LLMs as defensive one-time plug-ins. Unlike\nmost applications of LLMs that try to transform text into something new or\nstructural, Genshin uses LLMs to recover text to its original state. Genshin\naims to combine the generalizability of the LLM, the discrimination of the\nmedian model, and the interpretability of the simple model. Our experiments on\nthe task of sentimental analysis and spam detection have shown fatal flaws of\nthe current median models and exhilarating results on LLMs' recovery ability,\ndemonstrating that Genshin is both effective and efficient. In our ablation\nstudy, we unearth several intriguing observations. Utilizing the LLM defender,\na tool derived from the 4th paradigm, we have reproduced BERT's 15% optimal\nmask rate results in the 3rd paradigm of NLP. Additionally, when employing the\nLLM as a potential adversarial tool, attackers are capable of executing\neffective attacks that are nearly semantically lossless.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2024-05-29T04:04:05+00:00",
    "updated": "2024-06-03T08:35:07+00:00",
    "url": "http://arxiv.org/pdf/2405.18741v2"
  },
  {
    "id": "2405.18596v1",
    "title": "An Explainable XGBoost-based Approach on Assessing Detection of Deception and Disinformation",
    "authors": [
      "Alex V Mbaziira",
      "Maha F Sabir"
    ],
    "abstract": "Threat actors continue to exploit geopolitical and global public events\nlaunch aggressive campaigns propagating disinformation over the Internet. In\nthis paper we extend our prior research in detecting disinformation using\npsycholinguistic and computational linguistic processes linked to deception and\ncybercrime to gain an understanding of the features impact the predictive\noutcome of machine learning models. In this paper we attempt to determine\npatterns of deception in disinformation in hybrid models trained on\ndisinformation and scams, fake positive and negative online reviews, or fraud\nusing the eXtreme Gradient Boosting machine learning algorithm. Four hybrid\nmodels are generated which are models trained on disinformation and fraud\n(DIS+EN), disinformation and scams (DIS+FB), disinformation and favorable fake\nreviews (DIS+POS) and disinformation and unfavorable fake reviews (DIS+NEG).\nThe four hybrid models detected deception and disinformation with predictive\naccuracies ranging from 75% to 85%. The outcome of the models was evaluated\nwith SHAP to determine the impact of the features.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-05-28T21:16:14+00:00",
    "updated": "2024-05-28T21:16:14+00:00",
    "url": "http://arxiv.org/pdf/2405.18596v1"
  },
  {
    "id": "2405.13692v2",
    "title": "Challenging Gradient Boosted Decision Trees with Tabular Transformers for Fraud Detection at Booking.com",
    "authors": [
      "Sergei Krutikov",
      "Bulat Khaertdinov",
      "Rodion Kiriukhin",
      "Shubham Agrawal",
      "Mozhdeh Ariannezhad",
      "Kees Jan De Vries"
    ],
    "abstract": "Transformer-based neural networks, empowered by Self-Supervised Learning\n(SSL), have demonstrated unprecedented performance across various domains.\nHowever, related literature suggests that tabular Transformers may struggle to\noutperform classical Machine Learning algorithms, such as Gradient Boosted\nDecision Trees (GBDT). In this paper, we aim to challenge GBDTs with tabular\nTransformers on a typical task faced in e-commerce, namely fraud detection. Our\nstudy is additionally motivated by the problem of selection bias, often\noccurring in real-life fraud detection systems. It is caused by the production\nsystem affecting which subset of traffic becomes labeled. This issue is\ntypically addressed by sampling randomly a small part of the whole production\ndata, referred to as a Control Group. This subset follows a target distribution\nof production data and therefore is usually preferred for training\nclassification models with standard ML algorithms. Our methodology leverages\nthe capabilities of Transformers to learn transferable representations using\nall available data by means of SSL, giving it an advantage over classical\nmethods. Furthermore, we conduct large-scale experiments, pre-training tabular\nTransformers on vast amounts of data instances and fine-tuning them on smaller\ntarget datasets. The proposed approach outperforms heavily tuned GBDTs by a\nconsiderable margin of the Average Precision (AP) score in offline evaluations.\nFinally, we report the results of an online A/B experiment. Experimental\nresults confirm the superiority of tabular Transformers compared to GBDTs in\nproduction, demonstrated by a statistically significant improvement in our\nbusiness metric.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-05-22T14:38:48+00:00",
    "updated": "2025-06-30T08:01:46+00:00",
    "url": "http://arxiv.org/pdf/2405.13692v2"
  },
  {
    "id": "2407.13025v2",
    "title": "From Principles to Practices: Lessons Learned from Applying Partnership on AI's (PAI) Synthetic Media Framework to 11 Use Cases",
    "authors": [
      "Claire R. Leibowicz",
      "Christian H. Cardona"
    ],
    "abstract": "2023 was the year the world woke up to generative AI, and 2024 is the year\npolicymakers are responding more firmly. Importantly, this policy momentum is\ntaking place alongside real world creation and distribution of synthetic media.\nSocial media platforms, news organizations, dating apps, image generation\ncompanies, and more are already navigating a world of AI-generated visuals and\nsounds, already changing hearts and minds, as policymakers try to catch up.\nHow, then, can AI governance capture the complexity of the synthetic media\nlandscape? How can it attend to synthetic media's myriad uses, ranging from\nstorytelling to privacy preservation, to deception, fraud, and defamation,\ntaking into account the many stakeholders involved in its development,\ncreation, and distribution? And what might it mean to govern synthetic media in\na manner that upholds the truth while bolstering freedom of expression? What\nfollows is the first known collection of diverse examples of the implementation\nof synthetic media governance that responds to these questions, specifically\nthrough Partnership on AI's (PAI) Responsible Practices for Synthetic Media - a\nvoluntary, normative Framework for creating, distributing, and building\ntechnology for synthetic media responsibly, launched in February 2023. In this\npaper, we present a case bank of real world examples that help operationalize\nthe Framework - highlighting areas synthetic media governance can be applied,\naugmented, expanded, and refined for use, in practice. Read together, the cases\nemphasize distinct elements of AI policymaking and seven emergent best\npractices supporting transparency, safety, expression, and digital dignity\nonline: consent, disclosure, and differentiation between harmful and creative\nuse cases.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "published": "2024-07-17T21:27:56+00:00",
    "updated": "2024-07-19T15:57:35+00:00",
    "url": "http://arxiv.org/pdf/2407.13025v2"
  },
  {
    "id": "2407.12618v1",
    "title": "A Brief Review of Quantum Machine Learning for Financial Services",
    "authors": [
      "Mina Doosti",
      "Petros Wallden",
      "Conor Brian Hamill",
      "Robert Hankache",
      "Oliver Thomson Brown",
      "Chris Heunen"
    ],
    "abstract": "This review paper examines state-of-the-art algorithms and techniques in\nquantum machine learning with potential applications in finance. We discuss QML\ntechniques in supervised learning tasks, such as Quantum Variational\nClassifiers, Quantum Kernel Estimation, and Quantum Neural Networks (QNNs),\nalong with quantum generative AI techniques like Quantum Transformers and\nQuantum Graph Neural Networks (QGNNs). The financial applications considered\ninclude risk management, credit scoring, fraud detection, and stock price\nprediction. We also provide an overview of the challenges, potential, and\nlimitations of QML, both in these specific areas and more broadly across the\nfield. We hope that this can serve as a quick guide for data scientists,\nprofessionals in the financial sector, and enthusiasts in this area to\nunderstand why quantum computing and QML in particular could be interesting to\nexplore in their field of expertise.",
    "categories": [
      "quant-ph",
      "cs.CE"
    ],
    "published": "2024-07-17T14:44:47+00:00",
    "updated": "2024-07-17T14:44:47+00:00",
    "url": "http://arxiv.org/pdf/2407.12618v1"
  },
  {
    "id": "2407.12896v1",
    "title": "A Survey of Scam Exposure, Victimization, Types, Vectors, and Reporting in 12 Countries",
    "authors": [
      "Mo Houtti",
      "Abhishek Roy",
      "Venkata Narsi Reddy Gangula",
      "Ashley Marie Walker"
    ],
    "abstract": "Scams are a widespread issue with severe consequences for both victims and\nperpetrators, but existing data collection is fragmented, precluding global and\ncomparative local understanding. The present study addresses this gap through a\nnationally representative survey (n = 8,369) on scam exposure, victimization,\ntypes, vectors, and reporting in 12 countries: Belgium, Egypt, France, Hungary,\nIndonesia, Mexico, Romania, Slovakia, South Africa, South Korea, Sweden, and\nthe United Kingdom. We analyze 6 survey questions to build a detailed\nquantitative picture of the scams landscape in each country, and compare across\ncountries to identify global patterns. We find, first, that residents of less\naffluent countries suffer financial loss from scams more often. Second, we find\nthat the internet plays a key role in scams across the globe, and that GNI\nper-capita is strongly associated with specific scam types and contact vectors.\nThird, we find widespread under-reporting, with residents of less affluent\ncountries being less likely to know how to report a scam. Our findings\ncontribute valuable insights for researchers, practitioners, and policymakers\nin the online fraud and scam prevention space.",
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "published": "2024-07-17T14:35:56+00:00",
    "updated": "2024-07-17T14:35:56+00:00",
    "url": "http://arxiv.org/pdf/2407.12896v1"
  },
  {
    "id": "2407.12440v1",
    "title": "GraphGuard: Contrastive Self-Supervised Learning for Credit-Card Fraud Detection in Multi-Relational Dynamic Graphs",
    "authors": [
      "Kristófer Reynisson",
      "Marco Schreyer",
      "Damian Borth"
    ],
    "abstract": "Credit card fraud has significant implications at both an individual and\nsocietal level, making effective prevention essential. Current methods rely\nheavily on feature engineering and labeled information, both of which have\nsignificant limitations. In this work, we present GraphGuard, a novel\ncontrastive self-supervised graph-based framework for detecting fraudulent\ncredit card transactions. We conduct experiments on a real-world dataset and a\nsynthetic dataset. Our results provide a promising initial direction for\nexploring the effectiveness of graph-based self-supervised approaches for\ncredit card fraud detection.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-07-17T09:50:58+00:00",
    "updated": "2024-07-17T09:50:58+00:00",
    "url": "http://arxiv.org/pdf/2407.12440v1"
  },
  {
    "id": "2407.12220v2",
    "title": "Questionable practices in machine learning",
    "authors": [
      "Gavin Leech",
      "Juan J. Vazquez",
      "Niclas Kupper",
      "Misha Yagudin",
      "Laurence Aitchison"
    ],
    "abstract": "Evaluating modern ML models is hard. The strong incentive for researchers and\ncompanies to report a state-of-the-art result on some metric often leads to\nquestionable research practices (QRPs): bad practices which fall short of\noutright research fraud. We describe 44 such practices which can undermine\nreported results, giving examples where possible. Our list emphasises the\nevaluation of large language models (LLMs) on public benchmarks. We also\ndiscuss \"irreproducible research practices\", i.e. decisions that make it\ndifficult or impossible for other researchers to reproduce, build on or audit\nprevious research.",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CY"
    ],
    "published": "2024-07-17T00:06:30+00:00",
    "updated": "2024-10-30T12:14:35+00:00",
    "url": "http://arxiv.org/pdf/2407.12220v2"
  },
  {
    "id": "2407.10308v1",
    "title": "AI Detectors are Poor Western Blot Classifiers: A Study of Accuracy and Predictive Values",
    "authors": [
      "Romain-Daniel Gosselin"
    ],
    "abstract": "The recent rise of generative artificial intelligence (GenAI) capable of\ncreating scientific images presents a challenge in the fight against academic\nfraud. This study evaluates the efficacy of three free web-based AI detectors\nin identifying AI-generated images of Western blots, which is a very common\ntechnique in biology. We tested these detectors on a collection of artificial\nWestern blot images (n=48) that were created using ChatGPT 4 DALLE 3 and on\nauthentic Western blots (n=48) that were sampled from articles published within\nfour biology journals in 2015; this was before the rise of generative AI based\non large language models. The results reveal that the sensitivity (0.9583 for\nIs It AI, 0.1875 for Hive Moderation, and 0.7083 for Illuminarty) and\nspecificity (0.5417 for Is It AI, 0.8750 for Hive Moderation, and 0.4167 for\nIlluminarty) are very different. Positive predictive values (PPV) across\nvarious AI prevalence were low, for example reaching 0.1885 for Is It AI,\n0.1429 for Hive Moderation, and 0.1189 for Illuminarty at an AI prevalence of\n0.1. This highlights the difficulty in confidently determining image\nauthenticity based on the output of a single detector. Reducing the size of\nWestern blots from four to two lanes reduced test sensitivities and increased\ntest specificities but did not markedly affect overall detector accuracies and\nalso only slightly improved the PPV of one detector (Is It AI). These findings\nstrongly argue against the use of free AI detectors to detect fake scientific\nimages, and they demonstrate the urgent need for more robust detection tools\nthat are specifically trained on scientific content such as Western blot\nimages.",
    "categories": [
      "q-bio.QM"
    ],
    "published": "2024-07-14T19:57:27+00:00",
    "updated": "2024-07-14T19:57:27+00:00",
    "url": "http://arxiv.org/pdf/2407.10308v1"
  },
  {
    "id": "2407.11076v2",
    "title": "A concise proof of Benford's law",
    "authors": [
      "Luohan Wang",
      "Bo-Qiang Ma"
    ],
    "abstract": "This article presents a concise proof of the famous Benford's law when the\ndistribution has a Riemann integrable probability density function and provides\na criterion to judge whether a distribution obeys the law. The proof is\nintuitive and elegant, accessible to anyone with basic knowledge of calculus,\nrevealing that the law originates from the basic property of the human number\nsystem. The criterion can bring great convenience to the field of fraud\ndetection.",
    "categories": [
      "math.ST",
      "math.PR",
      "stat.OT",
      "stat.TH"
    ],
    "published": "2024-07-13T06:59:02+00:00",
    "updated": "2024-08-06T01:16:31+00:00",
    "url": "http://arxiv.org/pdf/2407.11076v2"
  },
  {
    "id": "2407.06529v1",
    "title": "Advanced Financial Fraud Detection Using GNN-CL Model",
    "authors": [
      "Yu Cheng",
      "Junjie Guo",
      "Shiqing Long",
      "You Wu",
      "Mengfang Sun",
      "Rong Zhang"
    ],
    "abstract": "The innovative GNN-CL model proposed in this paper marks a breakthrough in\nthe field of financial fraud detection by synergistically combining the\nadvantages of graph neural networks (gnn), convolutional neural networks (cnn)\nand long short-term memory (LSTM) networks. This convergence enables\nmultifaceted analysis of complex transaction patterns, improving detection\naccuracy and resilience against complex fraudulent activities. A key novelty of\nthis paper is the use of multilayer perceptrons (MLPS) to estimate node\nsimilarity, effectively filtering out neighborhood noise that can lead to false\npositives. This intelligent purification mechanism ensures that only the most\nrelevant information is considered, thereby improving the model's understanding\nof the network structure. Feature weakening often plagues graph-based models\ndue to the dilution of key signals. In order to further address the challenge\nof feature weakening, GNN-CL adopts reinforcement learning strategies. By\ndynamically adjusting the weights assigned to central nodes, it reinforces the\nimportance of these influential entities to retain important clues of fraud\neven in less informative data. Experimental evaluations on Yelp datasets show\nthat the results highlight the superior performance of GNN-CL compared to\nexisting methods.",
    "categories": [
      "cs.LG",
      "q-fin.ST"
    ],
    "published": "2024-07-09T03:59:06+00:00",
    "updated": "2024-07-09T03:59:06+00:00",
    "url": "http://arxiv.org/pdf/2407.06529v1"
  },
  {
    "id": "2407.05934v1",
    "title": "Graph Anomaly Detection with Noisy Labels by Reinforcement Learning",
    "authors": [
      "Zhu Wang",
      "Shuang Zhou",
      "Junnan Dong",
      "Chang Yang",
      "Xiao Huang",
      "Shengjie Zhao"
    ],
    "abstract": "Graph anomaly detection (GAD) has been widely applied in many areas, e.g.,\nfraud detection in finance and robot accounts in social networks. Existing\nmethods are dedicated to identifying the outlier nodes that deviate from normal\nones. While they heavily rely on high-quality annotation, which is hard to\nobtain in real-world scenarios, this could lead to severely degraded\nperformance based on noisy labels. Thus, we are motivated to cut the edges of\nsuspicious nodes to alleviate the impact of noise. However, it remains\ndifficult to precisely identify the nodes with noisy labels. Moreover, it is\nhard to quantitatively evaluate the regret of cutting the edges, which may have\neither positive or negative influences. To this end, we propose a novel\nframework REGAD, i.e., REinforced Graph Anomaly Detector. Specifically, we aim\nto maximize the performance improvement (AUC) of a base detector by cutting\nnoisy edges approximated through the nodes with high-confidence labels. (i) We\ndesign a tailored action and search space to train a policy network to\ncarefully prune edges step by step, where only a few suspicious edges are\nprioritized in each step. (ii) We design a policy-in-the-loop mechanism to\niteratively optimize the policy based on the feedback from base detector. The\noverall performance is evaluated by the cumulative rewards. Extensive\nexperiments are conducted on three datasets under different anomaly ratios. The\nresults indicate the superior performance of our proposed REGAD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2024-07-08T13:41:21+00:00",
    "updated": "2024-07-08T13:41:21+00:00",
    "url": "http://arxiv.org/pdf/2407.05934v1"
  },
  {
    "id": "2407.05625v3",
    "title": "New User Event Prediction Through the Lens of Causal Inference",
    "authors": [
      "Henry Shaowu Yuchi",
      "Shixiang Zhu",
      "Li Dong",
      "Yigit M. Arisoy",
      "Matthew C. Spencer"
    ],
    "abstract": "Modeling and analysis for event series generated by users of heterogeneous\nbehavioral patterns are closely involved in our daily lives, including credit\ncard fraud detection, online platform user recommendation, and social network\nanalysis. The most commonly adopted approach to this task is to assign users to\nbehavior-based categories and analyze each of them separately. However, this\nrequires extensive data to fully understand the user behavior, presenting\nchallenges in modeling newcomers without significant historical knowledge. In\nthis work, we propose a novel discrete event prediction framework for new users\nwith limited history, without needing to know the user's category. We treat the\nuser event history as the \"treatment\" for future events and the user category\nas the key confounder. Thus, the prediction problem can be framed as\ncounterfactual outcome estimation, where each event is re-weighted by its\ninverse propensity score. We demonstrate the improved performance of the\nproposed framework with a numerical simulation study and two real-world\napplications, including Netflix rating prediction and seller contact prediction\nfor customer support at Amazon.",
    "categories": [
      "stat.ME",
      "cs.LG"
    ],
    "published": "2024-07-08T05:35:54+00:00",
    "updated": "2025-04-04T04:07:39+00:00",
    "url": "http://arxiv.org/pdf/2407.05625v3"
  },
  {
    "id": "2407.05529v1",
    "title": "Behind the Deepfake: 8% Create; 90% Concerned. Surveying public exposure to and perceptions of deepfakes in the UK",
    "authors": [
      "Tvesha Sippy",
      "Florence Enock",
      "Jonathan Bright",
      "Helen Z. Margetts"
    ],
    "abstract": "This article examines public exposure to and perceptions of deepfakes based\non insights from a nationally representative survey of 1403 UK adults. The\nsurvey is one of the first of its kind since recent improvements in deepfake\ntechnology and widespread adoption of political deepfakes. The findings reveal\nthree key insights. First, on average, 15% of people report exposure to harmful\ndeepfakes, including deepfake pornography, deepfake frauds/scams and other\npotentially harmful deepfakes such as those that spread health/religious\nmisinformation/propaganda. In terms of common targets, exposure to deepfakes\nfeaturing celebrities was 50.2%, whereas those featuring politicians was 34.1%.\nAnd 5.7% of respondents recall exposure to a selection of high profile\npolitical deepfakes in the UK. Second, while exposure to harmful deepfakes was\nrelatively low, awareness of and fears about deepfakes were high (and women\nwere significantly more likely to report experiencing such fears than men). As\nwith fears, general concerns about the spread of deepfakes were also high;\n90.4% of the respondents were either very concerned or somewhat concerned about\nthis issue. Most respondents (at least 91.8%) were concerned that deepfakes\ncould add to online child sexual abuse material, increase distrust in\ninformation and manipulate public opinion. Third, while awareness about\ndeepfakes was high, usage of deepfake tools was relatively low (8%). Most\nrespondents were not confident about their detection abilities and were\ntrustful of audiovisual content online. Our work highlights how the problem of\ndeepfakes has become embedded in public consciousness in just a few years; it\nalso highlights the need for media literacy programmes and other policy\ninterventions to address the spread of harmful deepfakes.",
    "categories": [
      "cs.CY"
    ],
    "published": "2024-07-08T00:22:51+00:00",
    "updated": "2024-07-08T00:22:51+00:00",
    "url": "http://arxiv.org/pdf/2407.05529v1"
  },
  {
    "id": "2407.04794v2",
    "title": "On Evaluating The Performance of Watermarked Machine-Generated Texts Under Adversarial Attacks",
    "authors": [
      "Zesen Liu",
      "Tianshuo Cong",
      "Xinlei He",
      "Qi Li"
    ],
    "abstract": "Large Language Models (LLMs) excel in various applications, including text\ngeneration and complex tasks. However, the misuse of LLMs raises concerns about\nthe authenticity and ethical implications of the content they produce, such as\ndeepfake news, academic fraud, and copyright infringement. Watermarking\ntechniques, which embed identifiable markers in machine-generated text, offer a\npromising solution to these issues by allowing for content verification and\norigin tracing. Unfortunately, the robustness of current LLM watermarking\nschemes under potential watermark removal attacks has not been comprehensively\nexplored.\n  In this paper, to fill this gap, we first systematically comb the mainstream\nwatermarking schemes and removal attacks on machine-generated texts, and then\nwe categorize them into pre-text (before text generation) and post-text (after\ntext generation) classes so that we can conduct diversified analyses. In our\nexperiments, we evaluate eight watermarks (five pre-text, three post-text) and\ntwelve attacks (two pre-text, ten post-text) across 87 scenarios. Evaluation\nresults indicate that (1) KGW and Exponential watermarks offer high text\nquality and watermark retention but remain vulnerable to most attacks; (2)\nPost-text attacks are found to be more efficient and practical than pre-text\nattacks; (3) Pre-text watermarks are generally more imperceptible, as they do\nnot alter text fluency, unlike post-text watermarks; (4) Additionally, combined\nattack methods can significantly increase effectiveness, highlighting the need\nfor more robust watermarking solutions. Our study underscores the\nvulnerabilities of current techniques and the necessity for developing more\nresilient schemes.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2024-07-05T18:09:06+00:00",
    "updated": "2024-11-28T11:28:39+00:00",
    "url": "http://arxiv.org/pdf/2407.04794v2"
  },
  {
    "id": "2407.00591v1",
    "title": "DDRM: Distributed Drone Reputation Management for Trust and Reliability in Crowdsourced Drone Services",
    "authors": [
      "Junaid Akram",
      "Ali Anaissi"
    ],
    "abstract": "This study introduces the Distributed Drone Reputation Management (DDRM)\nframework, designed to fortify trust and authenticity within the Internet of\nDrone Things (IoDT) ecosystem. As drones increasingly play a pivotal role\nacross diverse sectors, integrating crowdsourced drone services within the IoDT\nhas emerged as a vital avenue for democratizing access to these services. A\ncritical challenge, however, lies in ensuring the authenticity and reliability\nof drone service reviews. Leveraging the Ethereum blockchain, DDRM addresses\nthis challenge by instituting a verifiable and transparent review mechanism.\nThe framework innovates with a dual-token system, comprising the Service Review\nAuthorization Token (SRAT) for facilitating review authorization and the Drone\nReputation Enhancement Token (DRET) for rewarding and recognizing drones\ndemonstrating consistent reliability. Comprehensive analysis within this paper\nshowcases DDRM's resilience against various reputation frauds and underscores\nits operational effectiveness, particularly in enhancing the efficiency and\nreliability of drone services.",
    "categories": [
      "cs.DC"
    ],
    "published": "2024-06-30T05:08:49+00:00",
    "updated": "2024-06-30T05:08:49+00:00",
    "url": "http://arxiv.org/pdf/2407.00591v1"
  },
  {
    "id": "2407.00534v1",
    "title": "Blockchain based Decentralized Petition System",
    "authors": [
      "Jagdeep Kaur",
      "Kevin Antony",
      "Nikhil Pujar",
      "Ankit Jha"
    ],
    "abstract": "A decentralized online petition system enables individuals or groups to\ncreate, sign, and share petitions without a central authority. Using blockchain\ntechnology, these systems ensure the integrity and transparency of the petition\nprocess by recording every signature or action on the blockchain, making\nalterations or deletions impossible. This provides a permanent, tamper-proof\nrecord of the petition's progress. Such systems allow users to bypass\ntraditional intermediaries like government or social media platforms, fostering\nmore democratic and transparent decision-making.\n  This paper reviews research on petition systems, highlighting the\nshortcomings of existing systems such as lack of accountability, vulnerability\nto hacking, and security issues. The proposed blockchain-based implementation\naims to overcome these challenges. Decentralized voting systems have garnered\ninterest recently due to their potential to provide secure and transparent\nvoting platforms without intermediaries, addressing issues like voter fraud,\nmanipulation, and trust in the electoral process.\n  We propose a decentralized voting system web application using blockchain\ntechnology to ensure the integrity and security of the voting process. This\nsystem aims to provide a transparent, decentralized decision-making process\nthat counts every vote while eliminating the need for centralized authorities.\nThe paper presents an overview of the system architecture, design\nconsiderations, and implementation details, along with the potential benefits\nand limitations.\n  Finally, we discuss future research directions, examining the technical\naspects of the application, including underlying algorithms and protocols. Our\nresearch aims to enhance the integrity and accessibility of democratic\nprocesses, improve security, and ensure fairness, transparency, and\ntamper-proofness.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-06-29T21:44:35+00:00",
    "updated": "2024-06-29T21:44:35+00:00",
    "url": "http://arxiv.org/pdf/2407.00534v1"
  },
  {
    "id": "2407.15014v1",
    "title": "Influence of Personality Traits on Plagiarism Through Collusion in Programming Assignments",
    "authors": [
      "Parthasarathy PD",
      "Ishaan Kapoor",
      "Swaroop Joshi",
      "Sujith Thomas"
    ],
    "abstract": "Educating students about academic integrity expectations has been suggested\nas one of the ways to reduce malpractice in take-home programming assignments.\nWe test this hypothesis using data collected from an artificial intelligence\ncourse with 105 participants (N=105) at a university in India. The AI course\nhad two programming assignments. Plagiarism through collusion was quantified\nusing the Measure of Software Similarity (MOSS) tool. Students were educated\nabout what constitutes academic dishonesty and were required to take an honor\npledge before the start of the second take-home programming assignment. The two\nprogramming assignments were novel and did not have solutions available on the\ninternet. We expected the mean percentage of similar lines of code to be\nsignificantly less in the second programming assignment. However, our results\nshow no significant difference in the mean percentage of similar lines of code\nacross the two programming assignments. We also study how the Big-five\npersonality traits affect the propensity for plagiarism in the two take-home\nassignments. Our results across both assignments show that the extraversion\ntrait of the Big Five personality exhibits a positive association, and the\nconscientiousness trait exhibits a negative association with plagiarism\ntendencies. Our result suggests that the policy of educating students about\nacademic integrity will have a limited impact as long as students perceive an\nopportunity for plagiarism to be present. We explain our results using the\nFraud triangle model.",
    "categories": [
      "cs.CY"
    ],
    "published": "2024-06-29T10:26:48+00:00",
    "updated": "2024-06-29T10:26:48+00:00",
    "url": "http://arxiv.org/pdf/2407.15014v1"
  },
  {
    "id": "2406.18032v1",
    "title": "A Communication Satellite Servises Based Decentralized Network Protocol",
    "authors": [
      "Xiao Yan",
      "Bernie Gao"
    ],
    "abstract": "In this paper, we present a decentralized network protocol, Space Network\nProtocol, based on Communication Satellite Services. The protocol outlines a\nmethod for distributing information about the status of satellite communication\nservices across the entire blockchain network, facilitating fairness and\ntransparency in all communication services. Our primary objective is to\nstandardize the services delivered by all satellite networks under the\ncommunication satellite protocol. This standard remains intact regardless of\npotential unreliability associated with the satellites or the terminal\nhardware. We proposed PoD (Proof of Distribution) to verify if the\ncommunication satellites are online and PoF (Proof of Flow) to authenticate the\nactual data flow provided by the communication satellites. In addition, we also\nproposed PoM (Proof of Mesh) to verify if the communication satellites have\nsuccessfully meshed together. Utilizing zero-knowledge proof and multi-party\ncryptographic computations, we can evaluate the service provisioning parameters\nof each satellite, even in the presence of potential terminal or network node\nfraud. This method offers technical support for the modeling of distributed\nnetwork services.",
    "categories": [
      "cs.CR",
      "cs.DC",
      "cs.NI"
    ],
    "published": "2024-06-26T03:01:40+00:00",
    "updated": "2024-06-26T03:01:40+00:00",
    "url": "http://arxiv.org/pdf/2406.18032v1"
  },
  {
    "id": "2406.15583v2",
    "title": "Detecting AI-Generated Text: Factors Influencing Detectability with Current Methods",
    "authors": [
      "Kathleen C. Fraser",
      "Hillary Dawkins",
      "Svetlana Kiritchenko"
    ],
    "abstract": "Large language models (LLMs) have advanced to a point that even humans have\ndifficulty discerning whether a text was generated by another human, or by a\ncomputer. However, knowing whether a text was produced by human or artificial\nintelligence (AI) is important to determining its trustworthiness, and has\napplications in many domains including detecting fraud and academic dishonesty,\nas well as combating the spread of misinformation and political propaganda. The\ntask of AI-generated text (AIGT) detection is therefore both very challenging,\nand highly critical. In this survey, we summarize state-of-the art approaches\nto AIGT detection, including watermarking, statistical and stylistic analysis,\nand machine learning classification. We also provide information about existing\ndatasets for this task. Synthesizing the research findings, we aim to provide\ninsight into the salient factors that combine to determine how \"detectable\"\nAIGT text is under different scenarios, and to make practical recommendations\nfor future work towards this significant technical and societal challenge.",
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "published": "2024-06-21T18:31:49+00:00",
    "updated": "2025-04-14T17:42:35+00:00",
    "url": "http://arxiv.org/pdf/2406.15583v2"
  },
  {
    "id": "2406.14370v1",
    "title": "Enhanced Bank Check Security: Introducing a Novel Dataset and Transformer-Based Approach for Detection and Verification",
    "authors": [
      "Muhammad Saif Ullah Khan",
      "Tahira Shehzadi",
      "Rabeya Noor",
      "Didier Stricker",
      "Muhammad Zeshan Afzal"
    ],
    "abstract": "Automated signature verification on bank checks is critical for fraud\nprevention and ensuring transaction authenticity. This task is challenging due\nto the coexistence of signatures with other textual and graphical elements on\nreal-world documents. Verification systems must first detect the signature and\nthen validate its authenticity, a dual challenge often overlooked by current\ndatasets and methodologies focusing only on verification. To address this gap,\nwe introduce a novel dataset specifically designed for signature verification\non bank checks. This dataset includes a variety of signature styles embedded\nwithin typical check elements, providing a realistic testing ground for\nadvanced detection methods. Moreover, we propose a novel approach for\nwriter-independent signature verification using an object detection network.\nOur detection-based verification method treats genuine and forged signatures as\ndistinct classes within an object detection framework, effectively handling\nboth detection and verification. We employ a DINO-based network augmented with\na dilation module to detect and verify signatures on check images\nsimultaneously. Our approach achieves an AP of 99.2 for genuine and 99.4 for\nforged signatures, a significant improvement over the DINO baseline, which\nscored 93.1 and 89.3 for genuine and forged signatures, respectively. This\nimprovement highlights our dilation module's effectiveness in reducing both\nfalse positives and negatives. Our results demonstrate substantial advancements\nin detection-based signature verification technology, offering enhanced\nsecurity and efficiency in financial document processing.",
    "categories": [
      "cs.CV"
    ],
    "published": "2024-06-20T14:42:14+00:00",
    "updated": "2024-06-20T14:42:14+00:00",
    "url": "http://arxiv.org/pdf/2406.14370v1"
  },
  {
    "id": "2406.13166v3",
    "title": "Enhancing supply chain security with automated machine learning",
    "authors": [
      "Haibo Wang",
      "Lutfu S. Sua",
      "Bahram Alidaee"
    ],
    "abstract": "The increasing scale and complexity of global supply chains have led to new\nchallenges spanning various fields, such as supply chain disruptions due to\nlong waiting lines at the ports, material shortages, and inflation. Coupled\nwith the size of supply chains and the availability of vast amounts of data,\nefforts towards tackling such challenges have led to an increasing interest in\napplying machine learning methods in many aspects of supply chains. Unlike\nother solutions, ML techniques, including Random Forest, XGBoost, LightGBM, and\nNeural Networks, make predictions and approximate optimal solutions faster.\nThis paper presents an automated ML framework to enhance supply chain security\nby detecting fraudulent activities, predicting maintenance needs, and\nforecasting material backorders. Using datasets of varying sizes, results show\nthat fraud detection achieves an 88% accuracy rate using sampling methods,\nmachine failure prediction reaches 93.4% accuracy, and material backorder\nprediction achieves 89.3% accuracy. Hyperparameter tuning significantly\nimproved the performance of these models, with certain supervised techniques\nlike XGBoost and LightGBM reaching up to 100% precision. This research\ncontributes to supply chain security by streamlining data preprocessing,\nfeature selection, model optimization, and inference deployment, addressing\ncritical challenges and boosting operational efficiency.",
    "categories": [
      "cs.LG",
      "econ.GN",
      "math.OC",
      "q-fin.EC"
    ],
    "published": "2024-06-19T02:45:32+00:00",
    "updated": "2025-07-22T18:22:57+00:00",
    "url": "http://arxiv.org/pdf/2406.13166v3"
  },
  {
    "id": "2408.09393v1",
    "title": "Federated Graph Learning with Structure Proxy Alignment",
    "authors": [
      "Xingbo Fu",
      "Zihan Chen",
      "Binchi Zhang",
      "Chen Chen",
      "Jundong Li"
    ],
    "abstract": "Federated Graph Learning (FGL) aims to learn graph learning models over graph\ndata distributed in multiple data owners, which has been applied in various\napplications such as social recommendation and financial fraud detection.\nInherited from generic Federated Learning (FL), FGL similarly has the data\nheterogeneity issue where the label distribution may vary significantly for\ndistributed graph data across clients. For instance, a client can have the\nmajority of nodes from a class, while another client may have only a few nodes\nfrom the same class. This issue results in divergent local objectives and\nimpairs FGL convergence for node-level tasks, especially for node\nclassification. Moreover, FGL also encounters a unique challenge for the node\nclassification task: the nodes from a minority class in a client are more\nlikely to have biased neighboring information, which prevents FGL from learning\nexpressive node embeddings with Graph Neural Networks (GNNs). To grapple with\nthe challenge, we propose FedSpray, a novel FGL framework that learns local\nclass-wise structure proxies in the latent space and aligns them to obtain\nglobal structure proxies in the server. Our goal is to obtain the aligned\nstructure proxies that can serve as reliable, unbiased neighboring information\nfor node classification. To achieve this, FedSpray trains a global\nfeature-structure encoder and generates unbiased soft targets with structure\nproxies to regularize local training of GNN models in a personalized way. We\nconduct extensive experiments over four datasets, and experiment results\nvalidate the superiority of FedSpray compared with other baselines. Our code is\navailable at https://github.com/xbfu/FedSpray.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "published": "2024-08-18T07:32:54+00:00",
    "updated": "2024-08-18T07:32:54+00:00",
    "url": "http://arxiv.org/pdf/2408.09393v1"
  },
  {
    "id": "2408.10263v2",
    "title": "Kolmogorov Arnold Networks in Fraud Detection: Bridging the Gap Between Theory and Practice",
    "authors": [
      "Yang Lu",
      "Felix Zhan"
    ],
    "abstract": "This study evaluates the applicability of Kolmogorov-Arnold Networks (KAN) in\nfraud detection, finding that their effectiveness is context-dependent. We\npropose a quick decision rule using Principal Component Analysis (PCA) to\nassess the suitability of KAN: if data can be effectively separated in two\ndimensions using splines, KAN may outperform traditional models; otherwise,\nother methods could be more appropriate. We also introduce a heuristic approach\nto hyperparameter tuning, significantly reducing computational costs. These\nfindings suggest that while KAN has potential, its use should be guided by\ndata-specific assessments.",
    "categories": [
      "cs.LG",
      "cs.NE",
      "I.2.0"
    ],
    "published": "2024-08-15T18:58:21+00:00",
    "updated": "2024-09-03T22:23:06+00:00",
    "url": "http://arxiv.org/pdf/2408.10263v2"
  },
  {
    "id": "2408.08131v1",
    "title": "Detection and Impact of Debit/Credit Card Fraud: Victims' Experiences",
    "authors": [
      "Eman Alashwali",
      "Ragashree Mysuru Chandrashekar",
      "Mandy Lanyon",
      "Lorrie Faith Cranor"
    ],
    "abstract": "It might be intuitive to expect that small or reimbursed financial loss\nresulting from credit or debit card fraud would have low or no financial impact\non victims. However, little is known about the extent to which financial fraud\nimpacts victims psychologically, how victims detect the fraud, which detection\nmethods are most efficient, and how the fraud detection and reporting processes\ncan be improved. To answer these questions, we conducted a 150-participant\nsurvey of debit/credit card fraud victims in the US. Our results show that\nsignificantly more participants reported that they were impacted\npsychologically than financially. However, we found no relationship between the\namount of direct financial loss and psychological impact, suggesting that\npeople are at risk of being psychologically impacted regardless of the amount\nlost to fraud. Despite the fact that bank or card issuer notifications were\nrelated to faster detection of fraud, more participants reported detecting the\nfraud after reviewing their card or account statements rather than from\nnotifications. This suggests that notifications may be underutilized. Finally,\nwe provide a set of recommendations distilled from victims' experiences to\nimprove the debit/credit card fraud detection and reporting processes.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-08-15T13:06:49+00:00",
    "updated": "2024-08-15T13:06:49+00:00",
    "url": "http://arxiv.org/pdf/2408.08131v1"
  },
  {
    "id": "2408.07892v4",
    "title": "Personhood credentials: Artificial intelligence and the value of privacy-preserving tools to distinguish who is real online",
    "authors": [
      "Steven Adler",
      "Zoë Hitzig",
      "Shrey Jain",
      "Catherine Brewer",
      "Wayne Chang",
      "Renée DiResta",
      "Eddy Lazzarin",
      "Sean McGregor",
      "Wendy Seltzer",
      "Divya Siddarth",
      "Nouran Soliman",
      "Tobin South",
      "Connor Spelliscy",
      "Manu Sporny",
      "Varya Srivastava",
      "John Bailey",
      "Brian Christian",
      "Andrew Critch",
      "Ronnie Falcon",
      "Heather Flanagan",
      "Kim Hamilton Duffy",
      "Eric Ho",
      "Claire R. Leibowicz",
      "Srikanth Nadhamuni",
      "Alan Z. Rozenshtein",
      "David Schnurr",
      "Evan Shapiro",
      "Lacey Strahm",
      "Andrew Trask",
      "Zoe Weinberg",
      "Cedric Whitney",
      "Tom Zick"
    ],
    "abstract": "Anonymity is an important principle online. However, malicious actors have\nlong used misleading identities to conduct fraud, spread disinformation, and\ncarry out other deceptive schemes. With the advent of increasingly capable AI,\nbad actors can amplify the potential scale and effectiveness of their\noperations, intensifying the challenge of balancing anonymity and\ntrustworthiness online. In this paper, we analyze the value of a new tool to\naddress this challenge: \"personhood credentials\" (PHCs), digital credentials\nthat empower users to demonstrate that they are real people -- not AIs -- to\nonline services, without disclosing any personal information. Such credentials\ncan be issued by a range of trusted institutions -- governments or otherwise. A\nPHC system, according to our definition, could be local or global, and does not\nneed to be biometrics-based. Two trends in AI contribute to the urgency of the\nchallenge: AI's increasing indistinguishability from people online (i.e.,\nlifelike content and avatars, agentic activity), and AI's increasing\nscalability (i.e., cost-effectiveness, accessibility). Drawing on a long\nhistory of research into anonymous credentials and \"proof-of-personhood\"\nsystems, personhood credentials give people a way to signal their\ntrustworthiness on online platforms, and offer service providers new tools for\nreducing misuse by bad actors. In contrast, existing countermeasures to\nautomated deception -- such as CAPTCHAs -- are inadequate against sophisticated\nAI, while stringent identity verification solutions are insufficiently private\nfor many use-cases. After surveying the benefits of personhood credentials, we\nalso examine deployment risks and design challenges. We conclude with\nactionable next steps for policymakers, technologists, and standards bodies to\nconsider in consultation with the public.",
    "categories": [
      "cs.CY"
    ],
    "published": "2024-08-15T02:41:25+00:00",
    "updated": "2025-01-17T20:50:14+00:00",
    "url": "http://arxiv.org/pdf/2408.07892v4"
  },
  {
    "id": "2408.07369v1",
    "title": "ProCom: A Few-shot Targeted Community Detection Algorithm",
    "authors": [
      "Xixi Wu",
      "Kaiyu Xiong",
      "Yun Xiong",
      "Xiaoxin He",
      "Yao Zhang",
      "Yizhu Jiao",
      "Jiawei Zhang"
    ],
    "abstract": "Targeted community detection aims to distinguish a particular type of\ncommunity in the network. This is an important task with a lot of real-world\napplications, e.g., identifying fraud groups in transaction networks.\nTraditional community detection methods fail to capture the specific features\nof the targeted community and detect all types of communities indiscriminately.\nSemi-supervised community detection algorithms, emerged as a feasible\nalternative, are inherently constrained by their limited adaptability and\nsubstantial reliance on a large amount of labeled data, which demands extensive\ndomain knowledge and manual effort.\n  In this paper, we address the aforementioned weaknesses in targeted community\ndetection by focusing on few-shot scenarios. We propose ProCom, a novel\nframework that extends the ``pre-train, prompt'' paradigm, offering a\nlow-resource, high-efficiency, and transferable solution. Within the framework,\nwe devise a dual-level context-aware pre-training method that fosters a deep\nunderstanding of latent communities in the network, establishing a rich\nknowledge foundation for downstream task. In the prompt learning stage, we\nreformulate the targeted community detection task into pre-training objectives,\nallowing the extraction of specific knowledge relevant to the targeted\ncommunity to facilitate effective and efficient inference. By leveraging both\nthe general community knowledge acquired during pre-training and the specific\ninsights gained from the prompt communities, ProCom exhibits remarkable\nadaptability across different datasets. We conduct extensive experiments on\nfive benchmarks to evaluate the ProCom framework, demonstrating its SOTA\nperformance under few-shot scenarios, strong efficiency, and transferability\nacross diverse datasets.",
    "categories": [
      "cs.SI"
    ],
    "published": "2024-08-14T08:34:00+00:00",
    "updated": "2024-08-14T08:34:00+00:00",
    "url": "http://arxiv.org/pdf/2408.07369v1"
  },
  {
    "id": "2408.06956v1",
    "title": "PayOff: A Regulated Central Bank Digital Currency with Private Offline Payments",
    "authors": [
      "Carolin Beer",
      "Sheila Zingg",
      "Kari Kostiainen",
      "Karl Wüst",
      "Vedran Capkun",
      "Srdjan Capkun"
    ],
    "abstract": "The European Central Bank is preparing for the potential issuance of a\ncentral bank digital currency (CBDC), called the digital euro. A recent\nregulatory proposal by the European Commission defines several requirements for\nthe digital euro, such as support for both online and offline payments. Offline\npayments are expected to enable cash-like privacy, local payment settlement,\nand the enforcement of holding limits. While other central banks have expressed\nsimilar desired functionality, achieving such offline payments poses a novel\ntechnical challenge. We observe that none of the existing research solutions,\nincluding offline E-cash schemes, are fully compliant. Proposed solutions based\non secure elements offer no guarantees in case of compromise and can therefore\nlead to significant payment fraud.\n  The main contribution of this paper is PayOff, a novel CBDC design motivated\nby the digital euro regulation, which focuses on offline payments. We analyze\nthe security implications of local payment settlement and identify new security\nobjectives. PayOff protects user privacy, supports complex regulations such as\nholding limits, and implements safeguards to increase robustness against secure\nelement failure. Our analysis shows that PayOff provides strong privacy and\nidentifies residual leakages that may arise in real-world deployments. Our\nevaluation shows that offline payments can be fast and that the central bank\ncan handle high payment loads with moderate computing resources. However, the\nmain limitation of PayOff is that offline payment messages and storage\nrequirements grow in the number of payments that the sender makes or receives\nwithout going online in between.",
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "published": "2024-08-13T15:15:06+00:00",
    "updated": "2024-08-13T15:15:06+00:00",
    "url": "http://arxiv.org/pdf/2408.06956v1"
  },
  {
    "id": "2408.05366v4",
    "title": "The DeepSpeak Dataset",
    "authors": [
      "Sarah Barrington",
      "Matyas Bohacek",
      "Hany Farid"
    ],
    "abstract": "Deepfakes represent a growing concern across domains such as impostor hiring,\nfraud, and disinformation. Despite significant efforts to develop robust\ndetection classifiers to distinguish the real from the fake, commonly used\ntraining datasets remain inadequate: relying on low-quality and outdated\ndeepfake generators, consisting of content scraped from online repositories\nwithout participant consent, lacking in multimodal coverage, and rarely\nemploying identity-matching protocols to ensure realistic fakes. To overcome\nthese limitations, we present the DeepSpeak dataset, a diverse and multimodal\ndataset comprising over 100 hours of authentic and deepfake audiovisual\ncontent. We contribute: i) more than 50 hours of real, self-recorded data\ncollected from 500 diverse and consenting participants using a custom-built\ndata collection tool, ii) more than 50 hours of state-of-the-art audio and\nvisual deepfakes generated using 14 video synthesis engines and three voice\ncloning engines, and iii) an embedding-based, identity-matching approach to\nensure the creation of convincing, high-quality identity swaps that\nrealistically simulate adversarial deepfake attacks. We also perform\nlarge-scale evaluations of state-of-the-art deepfake detectors and show that,\nwithout retraining, these detectors fail to generalize to the DeepSpeak\ndataset. These evaluations highlight the importance of a large and diverse\ndataset containing deepfakes from the latest generative-AI tools.",
    "categories": [
      "cs.CV"
    ],
    "published": "2024-08-09T22:29:43+00:00",
    "updated": "2025-07-26T19:52:33+00:00",
    "url": "http://arxiv.org/pdf/2408.05366v4"
  },
  {
    "id": "2408.04967v3",
    "title": "ADD 2023: Towards Audio Deepfake Detection and Analysis in the Wild",
    "authors": [
      "Jiangyan Yi",
      "Chu Yuan Zhang",
      "Jianhua Tao",
      "Chenglong Wang",
      "Xinrui Yan",
      "Yong Ren",
      "Hao Gu",
      "Junzuo Zhou"
    ],
    "abstract": "The growing prominence of the field of audio deepfake detection is driven by\nits wide range of applications, notably in protecting the public from potential\nfraud and other malicious activities, prompting the need for greater attention\nand research in this area. The ADD 2023 challenge goes beyond binary real/fake\nclassification by emulating real-world scenarios, such as the identification of\nmanipulated intervals in partially fake audio and determining the source\nresponsible for generating any fake audio, both with real-life implications,\nnotably in audio forensics, law enforcement, and construction of reliable and\ntrustworthy evidence. To further foster research in this area, in this article,\nwe describe the dataset that was used in the fake game, manipulation region\nlocation and deepfake algorithm recognition tracks of the challenge. We also\nfocus on the analysis of the technical methodologies by the top-performing\nparticipants in each task and note the commonalities and differences in their\napproaches. Finally, we discuss the current technical limitations as identified\nthrough the technical analysis, and provide a roadmap for future research\ndirections. The dataset is available for download at\nhttp://addchallenge.cn/downloadADD2023.",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "published": "2024-08-09T09:32:37+00:00",
    "updated": "2024-12-11T07:40:26+00:00",
    "url": "http://arxiv.org/pdf/2408.04967v3"
  },
  {
    "id": "2408.04092v1",
    "title": "Programmable Dataflows: Abstraction and Programming Model for Data Sharing",
    "authors": [
      "Siyuan Xia",
      "Chris Zhu",
      "Tapan Srivastava",
      "Bridget Fahey",
      "Raul Castro Fernandez"
    ],
    "abstract": "Data sharing is central to a wide variety of applications such as fraud\ndetection, ad matching, and research. The lack of data sharing abstractions\nmakes the solution to each data sharing problem bespoke and cost-intensive,\nhampering value generation. In this paper, we first introduce a data sharing\nmodel to represent every data sharing problem with a sequence of dataflows.\nFrom the model, we distill an abstraction, the contract, which agents use to\ncommunicate the intent of a dataflow and evaluate its consequences, before the\ndataflow takes place. This helps agents move towards a common sharing goal\nwithout violating any regulatory and privacy constraints. Then, we design and\nimplement the contract programming model (CPM), which allows agents to program\ndata sharing applications catered to each problem's needs.\n  Contracts permit data sharing, but their interactive nature may introduce\ninefficiencies. To mitigate those inefficiencies, we extend the CPM so that it\ncan save intermediate outputs of dataflows, and skip computation if a dataflow\ntries to access data that it does not have access to. In our evaluation, we\nshow that 1) the contract abstraction is general enough to represent a wide\nrange of sharing problems, 2) we can write programs for complex data sharing\nproblems and exhibit qualitative improvements over other alternate\ntechnologies, and 3) quantitatively, our optimizations make sharing programs\nwritten with the CPM efficient.",
    "categories": [
      "cs.DB"
    ],
    "published": "2024-08-07T21:15:57+00:00",
    "updated": "2024-08-07T21:15:57+00:00",
    "url": "http://arxiv.org/pdf/2408.04092v1"
  },
  {
    "id": "2408.03526v1",
    "title": "Minimum Enclosing Ball Synthetic Minority Oversampling Technique from a Geometric Perspective",
    "authors": [
      "Yi-Yang Shangguan",
      "Shi-Shun Chen",
      "Xiao-Yang Li"
    ],
    "abstract": "Class imbalance refers to the significant difference in the number of samples\nfrom different classes within a dataset, making it challenging to identify\nminority class samples correctly. This issue is prevalent in real-world\nclassification tasks, such as software defect prediction, medical diagnosis,\nand fraud detection. The synthetic minority oversampling technique (SMOTE) is\nwidely used to address class imbalance issue, which is based on interpolation\nbetween randomly selected minority class samples and their neighbors. However,\ntraditional SMOTE and most of its variants only interpolate between existing\nsamples, which may be affected by noise samples in some cases and synthesize\nsamples that lack diversity. To overcome these shortcomings, this paper\nproposes the Minimum Enclosing Ball SMOTE (MEB-SMOTE) method from a geometry\nperspective. Specifically, MEB is innovatively introduced into the oversampling\nmethod to construct a representative point. Then, high-quality samples are\nsynthesized by interpolation between this representative point and the existing\nsamples. The rationale behind constructing a representative point is discussed,\ndemonstrating that the center of MEB is more suitable as the representative\npoint. To exhibit the superiority of MEB-SMOTE, experiments are conducted on 15\nreal-world imbalanced datasets. The results indicate that MEB-SMOTE can\neffectively improve the classification performance on imbalanced datasets.",
    "categories": [
      "cs.LG",
      "cs.CG"
    ],
    "published": "2024-08-07T03:37:25+00:00",
    "updated": "2024-08-07T03:37:25+00:00",
    "url": "http://arxiv.org/pdf/2408.03526v1"
  },
  {
    "id": "2408.01690v2",
    "title": "IDNet: A Novel Dataset for Identity Document Analysis and Fraud Detection",
    "authors": [
      "Hong Guan",
      "Yancheng Wang",
      "Lulu Xie",
      "Soham Nag",
      "Rajeev Goel",
      "Niranjan Erappa Narayana Swamy",
      "Yingzhen Yang",
      "Chaowei Xiao",
      "Jonathan Prisby",
      "Ross Maciejewski",
      "Jia Zou"
    ],
    "abstract": "Effective fraud detection and analysis of government-issued identity\ndocuments, such as passports, driver's licenses, and identity cards, are\nessential in thwarting identity theft and bolstering security on online\nplatforms. The training of accurate fraud detection and analysis tools depends\non the availability of extensive identity document datasets. However, current\npublicly available benchmark datasets for identity document analysis, including\nMIDV-500, MIDV-2020, and FMIDV, fall short in several respects: they offer a\nlimited number of samples, cover insufficient varieties of fraud patterns, and\nseldom include alterations in critical personal identifying fields like\nportrait images, limiting their utility in training models capable of detecting\nrealistic frauds while preserving privacy.\n  In response to these shortcomings, our research introduces a new benchmark\ndataset, IDNet, designed to advance privacy-preserving fraud detection efforts.\nThe IDNet dataset comprises 837,060 images of synthetically generated identity\ndocuments, totaling approximately 490 gigabytes, categorized into 20 types from\n$10$ U.S. states and 10 European countries. We evaluate the utility and present\nuse cases of the dataset, illustrating how it can aid in training\nprivacy-preserving fraud detection methods, facilitating the generation of\ncamera and video capturing of identity documents, and testing schema\nunification and other identity document management functionalities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "published": "2024-08-03T07:05:40+00:00",
    "updated": "2024-09-03T22:30:34+00:00",
    "url": "http://arxiv.org/pdf/2408.01690v2"
  },
  {
    "id": "2408.00641v3",
    "title": "Enhancing Ethereum Fraud Detection via Generative and Contrastive Self-supervision",
    "authors": [
      "Chenxiang Jin",
      "Jiajun Zhou",
      "Chenxuan Xie",
      "Shanqing Yu",
      "Qi Xuan",
      "Xiaoniu Yang"
    ],
    "abstract": "The rampant fraudulent activities on Ethereum hinder the healthy development\nof the blockchain ecosystem, necessitating the reinforcement of regulations.\nHowever, multiple imbalances involving account interaction frequencies and\ninteraction types in the Ethereum transaction environment pose significant\nchallenges to data mining-based fraud detection research. To address this, we\nfirst propose the concept of meta-interactions to refine interaction behaviors\nin Ethereum, and based on this, we present a dual self-supervision enhanced\nEthereum fraud detection framework, named Meta-IFD. This framework initially\nintroduces a generative self-supervision mechanism to augment the interaction\nfeatures of accounts, followed by a contrastive self-supervision mechanism to\ndifferentiate various behavior patterns, and ultimately characterizes the\nbehavioral representations of accounts and mines potential fraud risks through\nmulti-view interaction feature learning. Extensive experiments on real Ethereum\ndatasets demonstrate the effectiveness and superiority of our framework in\ndetecting common Ethereum fraud behaviors such as Ponzi schemes and phishing\nscams. Additionally, the generative module can effectively alleviate the\ninteraction distribution imbalance in Ethereum data, while the contrastive\nmodule significantly enhances the framework's ability to distinguish different\nbehavior patterns. The source code will be available in\nhttps://github.com/GISec-Team/Meta-IFD.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-08-01T15:30:43+00:00",
    "updated": "2024-12-20T08:44:07+00:00",
    "url": "http://arxiv.org/pdf/2408.00641v3"
  },
  {
    "id": "2408.00513v1",
    "title": "VecAug: Unveiling Camouflaged Frauds with Cohort Augmentation for Enhanced Detection",
    "authors": [
      "Fei Xiao",
      "Shaofeng Cai",
      "Gang Chen",
      "H. V. Jagadish",
      "Beng Chin Ooi",
      "Meihui Zhang"
    ],
    "abstract": "Fraud detection presents a challenging task characterized by ever-evolving\nfraud patterns and scarce labeled data. Existing methods predominantly rely on\ngraph-based or sequence-based approaches. While graph-based approaches connect\nusers through shared entities to capture structural information, they remain\nvulnerable to fraudsters who can disrupt or manipulate these connections. In\ncontrast, sequence-based approaches analyze users' behavioral patterns,\noffering robustness against tampering but overlooking the interactions between\nsimilar users. Inspired by cohort analysis in retention and healthcare, this\npaper introduces VecAug, a novel cohort-augmented learning framework that\naddresses these challenges by enhancing the representation learning of target\nusers with personalized cohort information. To this end, we first propose a\nvector burn-in technique for automatic cohort identification, which retrieves a\ntask-specific cohort for each target user. Then, to fully exploit the cohort\ninformation, we introduce an attentive cohort aggregation technique for\naugmenting target user representations. To improve the robustness of such\ncohort augmentation, we also propose a novel label-aware cohort neighbor\nseparation mechanism to distance negative cohort neighbors and calibrate the\naggregated cohort information. By integrating this cohort information with\ntarget user representations, VecAug enhances the modeling capacity and\ngeneralization capabilities of the model to be augmented. Our framework is\nflexible and can be seamlessly integrated with existing fraud detection models.\nWe deploy our framework on e-commerce platforms and evaluate it on three fraud\ndetection datasets, and results show that VecAug improves the detection\nperformance of base models by up to 2.48\\% in AUC and 22.5\\% in R@P$_{0.9}$,\noutperforming state-of-the-art methods significantly.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-08-01T12:39:27+00:00",
    "updated": "2024-08-01T12:39:27+00:00",
    "url": "http://arxiv.org/pdf/2408.00513v1"
  },
  {
    "id": "2408.00055v2",
    "title": "When Audits and Recounts Distract from Election Integrity: The 2020 U.S. Presidential Election in Georgia",
    "authors": [
      "Philip B. Stark"
    ],
    "abstract": "Georgia was central to efforts to overturn the 2020 Presidential election,\nincluding a call from then-president Trump to Georgia Secretary of State\nRaffensperger asking Raffensperger to `find' 11,780 votes. Raffensperger has\nmaintained that a `100% full-count risk-limiting audit' and a machine recount\nagreed with the initial machine-count results, which proved that the reported\nelection results were accurate and that `no votes were flipped.' There is no\nindication of widespread fraud, but there is reason to distrust the election\noutcome: the two machine counts and the manual `audit' tallies disagree\nsubstantially, even about the number of ballots cast. Some ballots in Fulton\nCounty were included in the original count at least twice; some were included\nin the machine recount at least thrice. Audit results for some tally batches\nwere omitted from the reported audit totals. The two machine counts and the\naudit were not probative of who won because of poor processes and controls: a\nlack of secure physical chain of custody, ballot accounting, pollbook\nreconciliation, and accounting for other election materials such as memory\ncards. Moreover, most voters voted with demonstrably untrustworthy\nballot-marking devices, so even a perfect handcount or audit would not\nnecessarily reveal who really won. True risk-limiting audits (RLAs) and\nrigorous recounts can limit the risk that an incorrect electoral outcome will\nbe certified rather than being corrected. But no procedure can limit that risk\nwithout a trustworthy record of the vote. And even a properly conducted RLA of\nsome contests in an election does not show that any other contests in that\nelection were decided correctly. The 2020 U.S. Presidential election in Georgia\nillustrates unrecoverable errors that can render recounts and audits `security\ntheater' that distract from the more serious problems rather than justifying\ntrust.",
    "categories": [
      "stat.AP"
    ],
    "published": "2024-07-31T17:09:36+00:00",
    "updated": "2024-09-05T16:46:15+00:00",
    "url": "http://arxiv.org/pdf/2408.00055v2"
  },
  {
    "id": "2407.20662v1",
    "title": "DocXPand-25k: a large and diverse benchmark dataset for identity documents analysis",
    "authors": [
      "Julien Lerouge",
      "Guillaume Betmont",
      "Thomas Bres",
      "Evgeny Stepankevich",
      "Alexis Bergès"
    ],
    "abstract": "Identity document (ID) image analysis has become essential for many online\nservices, like bank account opening or insurance subscription. In recent years,\nmuch research has been conducted on subjects like document localization, text\nrecognition and fraud detection, to achieve a level of accuracy reliable enough\nto automatize identity verification. However, there are only a few available\ndatasets to benchmark ID analysis methods, mainly because of privacy\nrestrictions, security requirements and legal reasons.\n  In this paper, we present the DocXPand-25k dataset, which consists of 24,994\nrichly labeled IDs images, generated using custom-made vectorial templates\nrepresenting nine fictitious ID designs, including four identity cards, two\nresidence permits and three passports designs. These synthetic IDs feature\nartificially generated personal information (names, dates, identifiers, faces,\nbarcodes, ...), and present a rich diversity in the visual layouts and textual\ncontents.\n  We collected about 5.8k diverse backgrounds coming from real-world photos,\nscans and screenshots of IDs to guarantee the variety of the backgrounds. The\nsoftware we wrote to generate these images has been published\n(https://github.com/QuickSign/docxpand/) under the terms of the MIT license,\nand our dataset has been published\n(https://github.com/QuickSign/docxpand/releases/tag/v1.0.0) under the terms of\nthe CC-BY-NC-SA 4.0 License.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2024-07-30T08:55:27+00:00",
    "updated": "2024-07-30T08:55:27+00:00",
    "url": "http://arxiv.org/pdf/2407.20662v1"
  },
  {
    "id": "2407.19979v2",
    "title": "Privacy-preserving Fuzzy Name Matching for Sharing Financial Intelligence",
    "authors": [
      "Harsh Kasyap",
      "Ugur Ilker Atmaca",
      "Carsten Maple",
      "Graham Cormode",
      "Jiancong He"
    ],
    "abstract": "Financial institutions rely on data for many operations, including a need to\ndrive efficiency, enhance services and prevent financial crime. Data sharing\nacross an organisation or between institutions can facilitate rapid,\nevidence-based decision-making, including identifying money laundering and\nfraud. However, modern data privacy regulations impose restrictions on data\nsharing. For this reason, privacy-enhancing technologies are being increasingly\nemployed to allow organisations to derive shared intelligence while ensuring\nregulatory compliance.\n  This paper examines the case in which regulatory restrictions mean a party\ncannot share data on accounts of interest with another (internal or external)\nparty to determine individuals that hold accounts in both datasets. The names\nof account holders may be recorded differently in each dataset. We introduce a\nnovel privacy-preserving scheme for fuzzy name matching across institutions,\nemploying fully homomorphic encryption over MinHash signatures. The efficiency\nof the proposed scheme is enhanced using a clustering mechanism. Our scheme\nensures privacy by only revealing the possibility of a potential match to the\nquerying party. The practicality and effectiveness are evaluated using\ndifferent datasets, and compared against state-of-the-art schemes. It takes\naround 100 and 1000 seconds to search 1000 names from 10k and 100k names,\nrespectively, meeting the requirements of financial institutions. Furthermore,\nit exhibits significant performance improvement in reducing communication\noverhead by 30-300 times.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-07-29T13:11:53+00:00",
    "updated": "2024-11-08T12:24:53+00:00",
    "url": "http://arxiv.org/pdf/2407.19979v2"
  },
  {
    "id": "2407.19684v1",
    "title": "Application of Computer Technology in Financial Investment",
    "authors": [
      "Xinye Sha"
    ],
    "abstract": "In order to understand the application of computer technology in financial\ninvestment, the author proposes a research on the application of computer\ntechnology in financial investment. The author used user transaction data from\na certain online payment platform as a sample, with a total of 284908 sample\nrecords, including 593 positive samples (fraud samples) and 285214 negative\nsamples (normal samples), to conduct an empirical study on user fraud detection\nbased on data mining. In this process, facing the problem of imbalanced\npositive and negative samples, the author proposes to use the Under Sampling\nmethod to construct sub samples, and then perform feature scaling, outlier\ndetection, feature screening and other processing on the sub samples. Then,\nfour classification models, logistic regression, K-nearest neighbor algorithm,\ndecision tree, and support vector machine, are trained on the processed sub\nsamples. The prediction results of the four models are evaluated, and the\nresults show that the recall rate, Fl score, and AUC value of the logistic\nregression model are the highest, indicating that the detection method based on\ncomputer data mining is practical and feasible.",
    "categories": [
      "cs.CE"
    ],
    "published": "2024-07-29T03:58:37+00:00",
    "updated": "2024-07-29T03:58:37+00:00",
    "url": "http://arxiv.org/pdf/2407.19684v1"
  },
  {
    "id": "2407.21062v2",
    "title": "Hybrid Heuristic Algorithms for Adiabatic Quantum Machine Learning Models",
    "authors": [
      "Bahram Alidaee",
      "Haibo Wang",
      "Lutfu Sua",
      "Wade Liu"
    ],
    "abstract": "Numerous established machine learning models and various neural network\narchitectures can be restructured as Quadratic Unconstrained Binary\nOptimization (QUBO) problems. A significant challenge in Adiabatic Quantum\nMachine Learning (AQML) is the computational demand of the training phase. To\nmitigate this, approximation techniques inspired by quantum annealing, like\nSimulated Annealing and Multiple Start Tabu Search (MSTS), have been employed\nto expedite QUBO-based AQML training. This paper introduces a novel hybrid\nalgorithm that incorporates an \"r-flip\" strategy. This strategy is aimed at\nsolving large-scale QUBO problems more effectively, offering better solution\nquality and lower computational costs compared to existing MSTS methods. The\nr-flip approach has practical applications in diverse fields, including\ncross-docking, supply chain management, machine scheduling, and fraud\ndetection. The paper details extensive computational experiments comparing this\nr-flip enhanced hybrid heuristic against a standard MSTS approach. These tests\nutilize both standard benchmark problems and three particularly large QUBO\ninstances. The results indicate that the r-flip enhanced method consistently\nproduces high-quality solutions efficiently, operating within practical time\nconstraints.",
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "published": "2024-07-26T19:31:58+00:00",
    "updated": "2025-05-14T04:10:32+00:00",
    "url": "http://arxiv.org/pdf/2407.21062v2"
  },
  {
    "id": "2407.17765v1",
    "title": "Utilizing Blockchain and Smart Contracts for Enhanced Fraud Prevention and Minimization in Health Insurance through Multi-Signature Claim Processing",
    "authors": [
      "Md Al Amin",
      "Rushabh Shah",
      "Hemanth Tummala",
      "Indrajit Ray"
    ],
    "abstract": "Healthcare insurance provides financial support to access medical services\nfor patients while ensuring timely and guaranteed payment for providers.\nInsurance fraud poses a significant challenge to insurance companies and\npolicyholders, leading to increased costs and compromised healthcare treatment\nand service delivery. Most frauds, like phantom billing, upcoding, and\nunbundling, happen due to the lack of required entity participation. Also,\nclaim activities are not transparent and accountable. Fraud can be prevented\nand minimized by involving every entity and making actions transparent and\naccountable. This paper proposes a blockchain-powered smart contract-based\ninsurance claim processing mechanism to prevent and minimize fraud in response\nto this prevailing issue. All entities patients, providers, and insurance\ncompanies actively participate in the claim submission, approval, and\nacknowledgment process through a multi-signature technique. Also, every\nactivity is captured and recorded in the blockchain using smart contracts to\nmake every action transparent and accountable so that no entity can deny its\nactions and responsibilities. Blockchains' immutable storage property and\nstrong integrity guarantee that recorded activities are not modified. As\nhealthcare systems and insurance companies continue to deal with fraud\nchallenges, this proposed approach holds the potential to significantly reduce\nfraudulent activities, ultimately benefiting both insurers and policyholders.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-07-25T04:42:31+00:00",
    "updated": "2024-07-25T04:42:31+00:00",
    "url": "http://arxiv.org/pdf/2407.17765v1"
  },
  {
    "id": "2407.17333v2",
    "title": "Global Confidence Degree Based Graph Neural Network for Financial Fraud Detection",
    "authors": [
      "Jiaxun Liu",
      "Yue Tian",
      "Guanjun Liu"
    ],
    "abstract": "Graph Neural Networks (GNNs) are widely used in financial fraud detection due\nto their excellent ability on handling graph-structured financial data and\nmodeling multilayer connections by aggregating information of neighbors.\nHowever, these GNN-based methods focus on extracting neighbor-level information\nbut neglect a global perspective. This paper presents the concept and\ncalculation formula of Global Confidence Degree (GCD) and thus designs\nGCD-based GNN (GCD-GNN) that can address the challenges of camouflage in\nfraudulent activities and thus can capture more global information. To obtain a\nprecise GCD for each node, we use a multilayer perceptron to transform features\nand then the new features and the corresponding prototype are used to eliminate\nunnecessary information. The GCD of a node evaluates the typicality of the node\nand thus we can leverage GCD to generate attention values for message\naggregation. This process is carried out through both the original GCD and its\ninverse, allowing us to capture both the typical neighbors with high GCD and\nthe atypical ones with low GCD. Extensive experiments on two public datasets\ndemonstrate that GCD-GNN outperforms state-of-the-art baselines, highlighting\nthe effectiveness of GCD. We also design a lightweight GCD-GNN\n(GCD-GNN$_{light}$) that also outperforms the baselines but is slightly weaker\nthan GCD-GNN on fraud detection performance. However, GCD-GNN$_{light}$\nobviously outperforms GCD-GNN on convergence and inference speed.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-07-24T14:55:37+00:00",
    "updated": "2024-08-18T06:39:56+00:00",
    "url": "http://arxiv.org/pdf/2407.17333v2"
  },
  {
    "id": "2407.17170v2",
    "title": "Domain Generalized Recaptured Screen Image Identification Using SWIN Transformer",
    "authors": [
      "Preeti Mehta",
      "Aman Sagar",
      "Suchi Kumari"
    ],
    "abstract": "An increasing number of classification approaches have been developed to\naddress the issue of image rebroadcast and recapturing, a standard attack\nstrategy in insurance frauds, face spoofing, and video piracy. However, most of\nthem neglected scale variations and domain generalization scenarios, performing\npoorly in instances involving domain shifts, typically made worse by\ninter-domain and cross-domain scale variances. To overcome these issues, we\npropose a cascaded data augmentation and SWIN transformer domain generalization\nframework (DAST-DG) in the current research work Initially, we examine the\ndisparity in dataset representation. A feature generator is trained to make\nauthentic images from various domains indistinguishable. This process is then\napplied to recaptured images, creating a dual adversarial learning setup.\nExtensive experiments demonstrate that our approach is practical and surpasses\nstate-of-the-art methods across different databases. Our model achieves an\naccuracy of approximately 82\\% with a precision of 95\\% on high-variance\ndatasets.",
    "categories": [
      "cs.CV"
    ],
    "published": "2024-07-24T11:22:02+00:00",
    "updated": "2024-07-25T06:40:39+00:00",
    "url": "http://arxiv.org/pdf/2407.17170v2"
  },
  {
    "id": "2407.15264v1",
    "title": "LSM-GNN: Large-scale Storage-based Multi-GPU GNN Training by Optimizing Data Transfer Scheme",
    "authors": [
      "Jeongmin Brian Park",
      "Kun Wu",
      "Vikram Sharma Mailthody",
      "Zaid Quresh",
      "Scott Mahlke",
      "Wen-mei Hwu"
    ],
    "abstract": "Graph Neural Networks (GNNs) are widely used today in recommendation systems,\nfraud detection, and node/link classification tasks. Real world GNNs continue\nto scale in size and require a large memory footprint for storing graphs and\nembeddings that often exceed the memory capacities of the target GPUs used for\ntraining. To address limited memory capacities, traditional GNN training\napproaches use graph partitioning and sharding techniques to scale up across\nmultiple GPUs within a node and/or scale out across multiple nodes. However,\nthis approach suffers from the high computational costs of graph partitioning\nalgorithms and inefficient communication across GPUs.\n  To address these overheads, we propose Large-scale Storage-based Multi-GPU\nGNN framework (LSM-GNN), a storagebased approach to train GNN models that\nutilizes a novel communication layer enabling GPU software caches to function\nas a system-wide shared cache with low overheads.LSM-GNN incorporates a hybrid\neviction policy that intelligently manages cache space by using both static and\ndynamic node information to significantly enhance cache performance.\nFurthermore, we introduce the Preemptive Victim-buffer Prefetcher (PVP), a\nmechanism for prefetching node feature data from a Victim Buffer located in CPU\npinned-memory to further reduce the pressure on the storage devices.\nExperimental results show that despite the lower compute capabilities and\nmemory capacities, LSM-GNN in a single node with two GPUs offers superior\nperformance over two-node-four-GPU Dist-DGL baseline and provides up to 3.75x\nspeed up on end-to-end epoch time while running large-scale GNN training",
    "categories": [
      "cs.DC",
      "cs.LG"
    ],
    "published": "2024-07-21T20:41:39+00:00",
    "updated": "2024-07-21T20:41:39+00:00",
    "url": "http://arxiv.org/pdf/2407.15264v1"
  },
  {
    "id": "2409.10951v1",
    "title": "Fair Anomaly Detection For Imbalanced Groups",
    "authors": [
      "Ziwei Wu",
      "Lecheng Zheng",
      "Yuancheng Yu",
      "Ruizhong Qiu",
      "John Birge",
      "Jingrui He"
    ],
    "abstract": "Anomaly detection (AD) has been widely studied for decades in many real-world\napplications, including fraud detection in finance, and intrusion detection for\ncybersecurity, etc. Due to the imbalanced nature between protected and\nunprotected groups and the imbalanced distributions of normal examples and\nanomalies, the learning objectives of most existing anomaly detection methods\ntend to solely concentrate on the dominating unprotected group. Thus, it has\nbeen recognized by many researchers about the significance of ensuring model\nfairness in anomaly detection. However, the existing fair anomaly detection\nmethods tend to erroneously label most normal examples from the protected group\nas anomalies in the imbalanced scenario where the unprotected group is more\nabundant than the protected group. This phenomenon is caused by the improper\ndesign of learning objectives, which statistically focus on learning the\nfrequent patterns (i.e., the unprotected group) while overlooking the\nunder-represented patterns (i.e., the protected group). To address these\nissues, we propose FairAD, a fairness-aware anomaly detection method targeting\nthe imbalanced scenario. It consists of a fairness-aware contrastive learning\nmodule and a rebalancing autoencoder module to ensure fairness and handle the\nimbalanced data issue, respectively. Moreover, we provide the theoretical\nanalysis that shows our proposed contrastive learning regularization guarantees\ngroup fairness. Empirical studies demonstrate the effectiveness and efficiency\nof FairAD across multiple real-world datasets.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-09-17T07:38:45+00:00",
    "updated": "2024-09-17T07:38:45+00:00",
    "url": "http://arxiv.org/pdf/2409.10951v1"
  },
  {
    "id": "2409.10850v1",
    "title": "An Anti-disguise Authentication System Using the First Impression of Avatar in Metaverse",
    "authors": [
      "Zhenyong Zhang",
      "Kedi Yang",
      "Youliang Tian",
      "Jianfeng Ma"
    ],
    "abstract": "Metaverse is a vast virtual world parallel to the physical world, where the\nuser acts as an avatar to enjoy various services that break through the\ntemporal and spatial limitations of the physical world. Metaverse allows users\nto create arbitrary digital appearances as their own avatars by which an\nadversary may disguise his/her avatar to fraud others. In this paper, we\npropose an anti-disguise authentication method that draws on the idea of the\nfirst impression from the physical world to recognize an old friend.\nSpecifically, the first meeting scenario in the metaverse is stored and\nrecalled to help the authentication between avatars. To prevent the adversary\nfrom replacing and forging the first impression, we construct a chameleon-based\nsigncryption mechanism and design a ciphertext authentication protocol to\nensure the public verifiability of encrypted identities. The security analysis\nshows that the proposed signcryption mechanism meets not only the security\nrequirement but also the public verifiability. Besides, the ciphertext\nauthentication protocol has the capability of defending against the replacing\nand forging attacks on the first impression. Extensive experiments show that\nthe proposed avatar authentication system is able to achieve anti-disguise\nauthentication at a low storage consumption on the blockchain.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-09-17T02:37:44+00:00",
    "updated": "2024-09-17T02:37:44+00:00",
    "url": "http://arxiv.org/pdf/2409.10850v1"
  },
  {
    "id": "2409.10111v1",
    "title": "Evaluating the Efficacy of Instance Incremental vs. Batch Learning in Delayed Label Environments: An Empirical Study on Tabular Data Streaming for Fraud Detection",
    "authors": [
      "Kodjo Mawuena Amekoe",
      "Mustapha Lebbah",
      "Gregoire Jaffre",
      "Hanene Azzag",
      "Zaineb Chelly Dagdia"
    ],
    "abstract": "Real-world tabular learning production scenarios typically involve evolving\ndata streams, where data arrives continuously and its distribution may change\nover time. In such a setting, most studies in the literature regarding\nsupervised learning favor the use of instance incremental algorithms due to\ntheir ability to adapt to changes in the data distribution. Another significant\nreason for choosing these algorithms is \\textit{avoid storing observations in\nmemory} as commonly done in batch incremental settings. However, the design of\ninstance incremental algorithms often assumes immediate availability of labels,\nwhich is an optimistic assumption. In many real-world scenarios, such as fraud\ndetection or credit scoring, labels may be delayed. Consequently, batch\nincremental algorithms are widely used in many real-world tasks. This raises an\nimportant question: \"In delayed settings, is instance incremental learning the\nbest option regarding predictive performance and computational efficiency?\"\nUnfortunately, this question has not been studied in depth, probably due to the\nscarcity of real datasets containing delayed information. In this study, we\nconduct a comprehensive empirical evaluation and analysis of this question\nusing a real-world fraud detection problem and commonly used generated\ndatasets. Our findings indicate that instance incremental learning is not the\nsuperior option, considering on one side state-of-the-art models such as\nAdaptive Random Forest (ARF) and other side batch learning models such as\nXGBoost. Additionally, when considering the interpretability of the learning\nsystems, batch incremental solutions tend to be favored. Code:\n\\url{https://github.com/anselmeamekoe/DelayedLabelStream}",
    "categories": [
      "cs.LG",
      "cs.CE",
      "cs.NE"
    ],
    "published": "2024-09-16T09:20:01+00:00",
    "updated": "2024-09-16T09:20:01+00:00",
    "url": "http://arxiv.org/pdf/2409.10111v1"
  },
  {
    "id": "2409.09892v1",
    "title": "Dynamic Fraud Detection: Integrating Reinforcement Learning into Graph Neural Networks",
    "authors": [
      "Yuxin Dong",
      "Jianhua Yao",
      "Jiajing Wang",
      "Yingbin Liang",
      "Shuhan Liao",
      "Minheng Xiao"
    ],
    "abstract": "Financial fraud refers to the act of obtaining financial benefits through\ndishonest means. Such behavior not only disrupts the order of the financial\nmarket but also harms economic and social development and breeds other illegal\nand criminal activities. With the popularization of the internet and online\npayment methods, many fraudulent activities and money laundering behaviors in\nlife have shifted from offline to online, posing a great challenge to\nregulatory authorities. How to efficiently detect these financial fraud\nactivities has become an urgent issue that needs to be resolved. Graph neural\nnetworks are a type of deep learning model that can utilize the interactive\nrelationships within graph structures, and they have been widely applied in the\nfield of fraud detection. However, there are still some issues. First,\nfraudulent activities only account for a very small part of transaction\ntransfers, leading to an inevitable problem of label imbalance in fraud\ndetection. At the same time, fraudsters often disguise their behavior, which\ncan have a negative impact on the final prediction results. In addition,\nexisting research has overlooked the importance of balancing neighbor\ninformation and central node information. For example, when the central node\nhas too many neighbors, the features of the central node itself are often\nneglected. Finally, fraud activities and patterns are constantly changing over\ntime, so considering the dynamic evolution of graph edge relationships is also\nvery important.",
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "published": "2024-09-15T23:08:31+00:00",
    "updated": "2024-09-15T23:08:31+00:00",
    "url": "http://arxiv.org/pdf/2409.09892v1"
  },
  {
    "id": "2409.09792v1",
    "title": "Enhancing Data Quality through Self-learning on Imbalanced Financial Risk Data",
    "authors": [
      "Xu Sun",
      "Zixuan Qin",
      "Shun Zhang",
      "Yuexian Wang",
      "Li Huang"
    ],
    "abstract": "In the financial risk domain, particularly in credit default prediction and\nfraud detection, accurate identification of high-risk class instances is\nparamount, as their occurrence can have significant economic implications.\nAlthough machine learning models have gained widespread adoption for risk\nprediction, their performance is often hindered by the scarcity and diversity\nof high-quality data. This limitation stems from factors in datasets such as\nsmall risk sample sizes, high labeling costs, and severe class imbalance, which\nimpede the models' ability to learn effectively and accurately forecast\ncritical events. This study investigates data pre-processing techniques to\nenhance existing financial risk datasets by introducing TriEnhance, a\nstraightforward technique that entails: (1) generating synthetic samples\nspecifically tailored to the minority class, (2) filtering using binary\nfeedback to refine samples, and (3) self-learning with pseudo-labels. Our\nexperiments across six benchmark datasets reveal the efficacy of TriEnhance,\nwith a notable focus on improving minority class calibration, a key factor for\ndeveloping more robust financial risk prediction systems.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-09-15T16:59:15+00:00",
    "updated": "2024-09-15T16:59:15+00:00",
    "url": "http://arxiv.org/pdf/2409.09792v1"
  },
  {
    "id": "2409.09770v2",
    "title": "Cluster Aware Graph Anomaly Detection",
    "authors": [
      "Lecheng Zheng",
      "John R. Birge",
      "Haiyue Wu",
      "Yifang Zhang",
      "Jingrui He"
    ],
    "abstract": "Graph anomaly detection has gained significant attention across various\ndomains, particularly in critical applications like fraud detection in\ne-commerce platforms and insider threat detection in cybersecurity. Usually,\nthese data are composed of multiple types (e.g., user information and\ntransaction records for financial data), thus exhibiting view heterogeneity.\nHowever, in the era of big data, the heterogeneity of views and the lack of\nlabel information pose substantial challenges to traditional approaches.\nExisting unsupervised graph anomaly detection methods often struggle with\nhigh-dimensionality issues, rely on strong assumptions about graph structures\nor fail to handle complex multi-view graphs. To address these challenges, we\npropose a cluster aware multi-view graph anomaly detection method, called CARE.\nOur approach captures both local and global node affinities by augmenting the\ngraph's adjacency matrix with the pseudo-label (i.e., soft membership\nassignments) without any strong assumption about the graph. To mitigate\npotential biases from the pseudo-label, we introduce a similarity-guided loss.\nTheoretically, we show that the proposed similarity-guided loss is a variant of\ncontrastive learning loss, and we present how this loss alleviates the bias\nintroduced by pseudo-label with the connection to graph spectral clustering.\nExperimental results on several datasets demonstrate the effectiveness and\nefficiency of our proposed framework. Specifically, CARE outperforms the\nsecond-best competitors by more than 39% on the Amazon dataset with respect to\nAUPRC and 18.7% on the YelpChi dataset with respect to AUROC. The code of our\nmethod is available at the GitHub link:\nhttps://github.com/zhenglecheng/CARE-demo.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-09-15T15:41:59+00:00",
    "updated": "2025-02-19T01:41:40+00:00",
    "url": "http://arxiv.org/pdf/2409.09770v2"
  },
  {
    "id": "2409.07956v2",
    "title": "Community detection in multi-layer networks by regularized debiased spectral clustering",
    "authors": [
      "Huan Qing"
    ],
    "abstract": "Community detection is a crucial problem in the analysis of multi-layer\nnetworks. While regularized spectral clustering methods using the classical\nregularized Laplacian matrix have shown great potential in handling sparse\nsingle-layer networks, to our knowledge, their potential in multi-layer network\ncommunity detection remains unexplored. To address this gap, in this work, we\nintroduce a new method, called regularized debiased sum of squared adjacency\nmatrices (RDSoS), to detect communities in multi-layer networks. RDSoS is\ndeveloped based on a novel regularized Laplacian matrix that regularizes the\ndebiased sum of squared adjacency matrices. In contrast, the classical\nregularized Laplacian matrix typically regularizes the adjacency matrix of a\nsingle-layer network. Therefore, at a high level, our regularized Laplacian\nmatrix extends the classical one to multi layer networks. We establish the\nconsistency property of RDSoS under the multi-layer stochastic block model\n(MLSBM) and further extend RDSoS and its theoretical results to the\ndegree-corrected version of the MLSBM model. Additionally, we introduce a sum\nof squared adjacency matrices modularity (SoS-modularity) to measure the\nquality of community partitions in multi-layer networks and estimate the number\nof communities by maximizing this metric. Our methods offer promising\napplications for predicting gene functions, improving recommender systems,\ndetecting medical insurance fraud, and facilitating link prediction.\nExperimental results demonstrate that our methods exhibit insensitivity to the\nselection of the regularizer, generally outperform state-of-the-art techniques,\nuncover the assortative property of real networks, and that our SoS-modularity\nprovides a more accurate assessment of community quality compared to the\naverage of the Newman-Girvan modularity across layers.",
    "categories": [
      "stat.ME",
      "cs.SI"
    ],
    "published": "2024-09-12T11:36:20+00:00",
    "updated": "2025-04-29T11:07:14+00:00",
    "url": "http://arxiv.org/pdf/2409.07956v2"
  },
  {
    "id": "2409.07567v2",
    "title": "Cybersecurity Challenge Analysis of Work-from-Anywhere (WFA) and Recommendations guided by a User Study",
    "authors": [
      "Mohammed Mahyoub",
      "Ashraf Matrawy",
      "Kamal Isleem",
      "Olakunle Ibitoye"
    ],
    "abstract": "Many organizations were forced to quickly transition to the\nwork-from-anywhere (WFA) model as a necessity to continue with their operations\nand remain in business despite the restrictions imposed during the COVID-19\npandemic. Many decisions were made in a rush, and cybersecurity decency tools\nwere not in place to support this transition. In this paper, we first attempt\nto uncover some challenges and implications related to the cybersecurity of the\nWFA model. Secondly, we conducted an online user study to investigate the\nreadiness and cybersecurity awareness of employers and their employees who\nshifted to work remotely from anywhere. The user study questionnaire addressed\ndifferent resilience perspectives of individuals and organizations. The\ncollected data includes 45 responses from remotely working employees of\ndifferent organizational types: universities, government, private, and\nnon-profit organizations. Despite the importance of security training and\nguidelines, it was surprising that many participants had not received them. A\nrobust communication strategy is necessary to ensure that employees are\ninformed and updated on security incidents that the organization encounters.\nAdditionally, there is an increased need to pay attention to the\nsecurity-related attributes of employees, such as their behavior, awareness,\nand compliance. Finally, we outlined best practice recommendations and\nmitigation tips guided by the study results to help individuals and\norganizations resist cybercrime and fraud and mitigate WFA-related\ncybersecurity risks.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-09-11T18:47:04+00:00",
    "updated": "2025-06-28T15:10:16+00:00",
    "url": "http://arxiv.org/pdf/2409.07567v2"
  },
  {
    "id": "2409.06072v1",
    "title": "DetoxBench: Benchmarking Large Language Models for Multitask Fraud & Abuse Detection",
    "authors": [
      "Joymallya Chakraborty",
      "Wei Xia",
      "Anirban Majumder",
      "Dan Ma",
      "Walid Chaabene",
      "Naveed Janvekar"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nnatural language processing tasks. However, their practical application in\nhigh-stake domains, such as fraud and abuse detection, remains an area that\nrequires further exploration. The existing applications often narrowly focus on\nspecific tasks like toxicity or hate speech detection. In this paper, we\npresent a comprehensive benchmark suite designed to assess the performance of\nLLMs in identifying and mitigating fraudulent and abusive language across\nvarious real-world scenarios. Our benchmark encompasses a diverse set of tasks,\nincluding detecting spam emails, hate speech, misogynistic language, and more.\nWe evaluated several state-of-the-art LLMs, including models from Anthropic,\nMistral AI, and the AI21 family, to provide a comprehensive assessment of their\ncapabilities in this critical domain. The results indicate that while LLMs\nexhibit proficient baseline performance in individual fraud and abuse detection\ntasks, their performance varies considerably across tasks, particularly\nstruggling with tasks that demand nuanced pragmatic reasoning, such as\nidentifying diverse forms of misogynistic language. These findings have\nimportant implications for the responsible development and deployment of LLMs\nin high-risk applications. Our benchmark suite can serve as a tool for\nresearchers and practitioners to systematically evaluate LLMs for multi-task\nfraud detection and drive the creation of more robust, trustworthy, and\nethically-aligned systems for fraud and abuse detection.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2024-09-09T21:12:03+00:00",
    "updated": "2024-09-09T21:12:03+00:00",
    "url": "http://arxiv.org/pdf/2409.06072v1"
  },
  {
    "id": "2409.06739v1",
    "title": "Kramnik vs Nakamura: A Chess Scandal",
    "authors": [
      "Shiva Maharaj",
      "Nick Polson",
      "Vadim Sokolov"
    ],
    "abstract": "We provide a statistical analysis of the recent controversy between Vladimir\nKramnik (ex chess world champion) and Hikaru Nakamura. Hikaru Nakamura is a\nchess prodigy and a five-time United States chess champion. Kramnik called into\nquestion Nakamura's 45.5 out of 46 win streak in an online blitz contest at\nchess.com. We assess the weight of evidence using a priori assessment of\nViswanathan Anand and the streak evidence. Based on this evidence, we show that\nNakamura has a 99.6 percent chance of not cheating. We study the statistical\nfallacies prevalent in both their analyses. On the one hand Kramnik bases his\nargument on the probability of such a streak is very small. This falls\nprecisely into the Prosecutor's Fallacy. On the other hand, Nakamura tries to\nrefute the argument using a cherry-picking argument. This violates the\nlikelihood principle. We conclude with a discussion of the relevant statistical\nliterature on the topic of fraud detection and the analysis of streaks in\nsports data.",
    "categories": [
      "stat.AP"
    ],
    "published": "2024-09-09T20:51:02+00:00",
    "updated": "2024-09-09T20:51:02+00:00",
    "url": "http://arxiv.org/pdf/2409.06739v1"
  },
  {
    "id": "2409.07494v2",
    "title": "Ethereum Fraud Detection via Joint Transaction Language Model and Graph Representation Learning",
    "authors": [
      "Jianguo Sun",
      "Yifan Jia",
      "Yanbin Wang",
      "Yiwei Liu",
      "Zhang Sheng",
      "Ye Tian"
    ],
    "abstract": "Ethereum faces growing fraud threats. Current fraud detection methods,\nwhether employing graph neural networks or sequence models, fail to consider\nthe semantic information and similarity patterns within transactions. Moreover,\nthese approaches do not leverage the potential synergistic benefits of\ncombining both types of models. To address these challenges, we propose\nTLMG4Eth that combines a transaction language model with graph-based methods to\ncapture semantic, similarity, and structural features of transaction data in\nEthereum. We first propose a transaction language model that converts numerical\ntransaction data into meaningful transaction sentences, enabling the model to\nlearn explicit transaction semantics. Then, we propose a transaction attribute\nsimilarity graph to learn transaction similarity information, enabling us to\ncapture intuitive insights into transaction anomalies. Additionally, we\nconstruct an account interaction graph to capture the structural information of\nthe account transaction network. We employ a deep multi-head attention network\nto fuse transaction semantic and similarity embeddings, and ultimately propose\na joint training approach for the multi-head attention network and the account\ninteraction graph to obtain the synergistic benefits of both.",
    "categories": [
      "cs.CR",
      "cs.LG",
      "q-fin.GN"
    ],
    "published": "2024-09-09T07:13:44+00:00",
    "updated": "2025-02-18T12:26:02+00:00",
    "url": "http://arxiv.org/pdf/2409.07494v2"
  },
  {
    "id": "2409.04373v1",
    "title": "Evaluating Fairness in Transaction Fraud Models: Fairness Metrics, Bias Audits, and Challenges",
    "authors": [
      "Parameswaran Kamalaruban",
      "Yulu Pi",
      "Stuart Burrell",
      "Eleanor Drage",
      "Piotr Skalski",
      "Jason Wong",
      "David Sutton"
    ],
    "abstract": "Ensuring fairness in transaction fraud detection models is vital due to the\npotential harms and legal implications of biased decision-making. Despite\nextensive research on algorithmic fairness, there is a notable gap in the study\nof bias in fraud detection models, mainly due to the field's unique challenges.\nThese challenges include the need for fairness metrics that account for fraud\ndata's imbalanced nature and the tradeoff between fraud protection and service\nquality. To address this gap, we present a comprehensive fairness evaluation of\ntransaction fraud models using public synthetic datasets, marking the first\nalgorithmic bias audit in this domain. Our findings reveal three critical\ninsights: (1) Certain fairness metrics expose significant bias only after\nnormalization, highlighting the impact of class imbalance. (2) Bias is\nsignificant in both service quality-related parity metrics and fraud\nprotection-related parity metrics. (3) The fairness through unawareness\napproach, which involved removing sensitive attributes such as gender, does not\nimprove bias mitigation within these datasets, likely due to the presence of\ncorrelated proxies. We also discuss socio-technical fairness-related challenges\nin transaction fraud models. These insights underscore the need for a nuanced\napproach to fairness in fraud detection, balancing protection and service\nquality, and moving beyond simple bias mitigation strategies. Future work must\nfocus on refining fairness metrics and developing methods tailored to the\nunique complexities of the transaction fraud domain.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-09-06T16:08:27+00:00",
    "updated": "2024-09-06T16:08:27+00:00",
    "url": "http://arxiv.org/pdf/2409.04373v1"
  },
  {
    "id": "2409.04101v1",
    "title": "Ultra-imbalanced classification guided by statistical information",
    "authors": [
      "Yin Jin",
      "Ningtao Wang",
      "Ruofan Wu",
      "Pengfei Shi",
      "Xing Fu",
      "Weiqiang Wang"
    ],
    "abstract": "Imbalanced data are frequently encountered in real-world classification\ntasks. Previous works on imbalanced learning mostly focused on learning with a\nminority class of few samples. However, the notion of imbalance also applies to\ncases where the minority class contains abundant samples, which is usually the\ncase for industrial applications like fraud detection in the area of financial\nrisk management. In this paper, we take a population-level approach to\nimbalanced learning by proposing a new formulation called\n\\emph{ultra-imbalanced classification} (UIC). Under UIC, loss functions behave\ndifferently even if infinite amount of training samples are available. To\nunderstand the intrinsic difficulty of UIC problems, we borrow ideas from\ninformation theory and establish a framework to compare different loss\nfunctions through the lens of statistical information. A novel learning\nobjective termed Tunable Boosting Loss is developed which is provably resistant\nagainst data imbalance under UIC, as well as being empirically efficient\nverified by extensive experimental studies on both public and industrial\ndatasets.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-09-06T08:07:09+00:00",
    "updated": "2024-09-06T08:07:09+00:00",
    "url": "http://arxiv.org/pdf/2409.04101v1"
  },
  {
    "id": "2409.02839v4",
    "title": "Jäger: Automated Telephone Call Traceback",
    "authors": [
      "David Adei",
      "Varun Madathil",
      "Sathvik Prasad",
      "Bradley Reaves",
      "Alessandra Scafuro"
    ],
    "abstract": "Unsolicited telephone calls that facilitate fraud or unlawful telemarketing\ncontinue to overwhelm network users and the regulators who prosecute them. The\nfirst step in prosecuting phone abuse is traceback -- identifying the call\noriginator. This fundamental investigative task currently requires hours of\nmanual effort per call. In this paper, we introduce J\\\"ager, a distributed\nsecure call traceback system. J\\\"ager can trace a call in a few seconds, even\nwith partial deployment, while cryptographically preserving the privacy of call\nparties, carrier trade secrets like peers and call volume, and limiting the\nthreat of bulk analysis. We establish definitions and requirements of secure\ntraceback, then develop a suite of protocols that meet these requirements using\nwitness encryption, oblivious pseudorandom functions, and group signatures. We\nprove these protocols secure in the universal composibility framework. We then\ndemonstrate that J\\\"ager has low compute and bandwidth costs per call, and\nthese costs scale linearly with call volume. J\\\"ager provides an efficient,\nsecure, privacy-preserving system to revolutionize telephone abuse\ninvestigation with minimal costs to operators.",
    "categories": [
      "cs.CR",
      "cs.CY",
      "cs.NI"
    ],
    "published": "2024-09-04T16:09:28+00:00",
    "updated": "2024-09-17T17:51:43+00:00",
    "url": "http://arxiv.org/pdf/2409.02839v4"
  },
  {
    "id": "2409.00577v1",
    "title": "Fast Prototyping of Distributed Stream Processing Applications with stream2gym",
    "authors": [
      "Md. Monzurul Amin Ifath",
      "Miguel Neves",
      "Israat Haque"
    ],
    "abstract": "Stream processing applications have been widely adopted due to real-time data\nanalytics demands, e.g., fraud detection, video analytics, IoT applications.\nUnfortunately, prototyping and testing these applications is still a cumbersome\nprocess for developers that usually requires an expensive testbed and deep\nmulti-disciplinary expertise, including in areas such as networking,\ndistributed systems, and data engineering. As a result, it takes a long time to\ndeploy stream processing applications into production and yet users face\nseveral correctness and performance issues. In this paper, we present\nstream2gym, a tool for the fast prototyping of large-scale distributed stream\nprocessing applications. stream2gym builds on Mininet, a widely adopted network\nemulation platform, and provides a high-level interface to enable developers to\neasily test their applications under various operating conditions. We\ndemonstrate the benefits of stream2gym by prototyping and testing several\napplications as well as reproducing key findings from prior research work in\nvideo analytics and network traffic monitoring. Moreover, we show stream2gym\npresents accurate results compared to a hardware testbed while consuming a\nsmall amount of resources (enough to be supported in a single commodity laptop\neven when emulating a dozen of processing nodes).",
    "categories": [
      "cs.DC",
      "cs.NI"
    ],
    "published": "2024-09-01T01:54:44+00:00",
    "updated": "2024-09-01T01:54:44+00:00",
    "url": "http://arxiv.org/pdf/2409.00577v1"
  },
  {
    "id": "2409.00294v1",
    "title": "Quantum Machine Learning for Anomaly Detection in Consumer Electronics",
    "authors": [
      "Sounak Bhowmik",
      "Himanshu Thapliyal"
    ],
    "abstract": "Anomaly detection is a crucial task in cyber security. Technological\nadvancement brings new cyber-physical threats like network intrusion, financial\nfraud, identity theft, and property invasion. In the rapidly changing world,\nwith frequently emerging new types of anomalies, classical machine learning\nmodels are insufficient to prevent all the threats. Quantum Machine Learning\n(QML) is emerging as a powerful computational tool that can detect anomalies\nmore efficiently. In this work, we have introduced QML and its applications for\nanomaly detection in consumer electronics. We have shown a generic framework\nfor applying QML algorithms in anomaly detection tasks. We have also briefly\ndiscussed popular supervised, unsupervised, and reinforcement learning-based\nQML algorithms and included five case studies of recent works to show their\napplications in anomaly detection in the consumer electronics field.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2024-08-30T23:28:00+00:00",
    "updated": "2024-08-30T23:28:00+00:00",
    "url": "http://arxiv.org/pdf/2409.00294v1"
  },
  {
    "id": "2409.10531v1",
    "title": "Googling the Big Lie: Search Engines, News Media, and the US 2020 Election Conspiracy",
    "authors": [
      "Ernesto de León",
      "Mykola Makhortykh",
      "Aleksandra Urman",
      "Roberto Ulloa"
    ],
    "abstract": "The conspiracy theory that the US 2020 presidential election was fraudulent -\nthe Big Lie - remained a prominent part of the media agenda months after the\nelection. Whether and how search engines prioritized news stories that sought\nto thoroughly debunk the claims, provide a simple negation, or support the\nconspiracy is crucial for understanding information exposure on the topic. We\ninvestigate how search engines provided news on this conspiracy by conducting a\nlarge-scale algorithm audit evaluating differences between three search engines\n(Google, DuckDuckGo, and Bing), across three locations (Ohio, California, and\nthe UK), and using eleven search queries. Results show that simply denying the\nconspiracy is the largest debunking strategy across all search engines. While\nGoogle has a strong mainstreaming effect on articles explicitly focused on the\nBig Lie - providing thorough debunks and alternative explanations - DuckDuckGo\nand Bing display, depending on the location, a large share of articles either\nsupporting the conspiracy or failing to debunk it. Lastly, we find that niche\nideologically driven search queries (e.g., \"sharpie marker ballots Arizona\") do\nnot lead to more conspiracy-supportive material. Instead, content supporting\nthe conspiracy is largely a product of broader ideology-agnostic search queries\n(e.g., \"voter fraud 2020\").",
    "categories": [
      "cs.IR",
      "cs.CY"
    ],
    "published": "2024-08-30T23:10:37+00:00",
    "updated": "2024-08-30T23:10:37+00:00",
    "url": "http://arxiv.org/pdf/2409.10531v1"
  },
  {
    "id": "2408.17352v1",
    "title": "AASIST3: KAN-Enhanced AASIST Speech Deepfake Detection using SSL Features and Additional Regularization for the ASVspoof 2024 Challenge",
    "authors": [
      "Kirill Borodin",
      "Vasiliy Kudryavtsev",
      "Dmitrii Korzh",
      "Alexey Efimenko",
      "Grach Mkrtchian",
      "Mikhail Gorodnichev",
      "Oleg Y. Rogov"
    ],
    "abstract": "Automatic Speaker Verification (ASV) systems, which identify speakers based\non their voice characteristics, have numerous applications, such as user\nauthentication in financial transactions, exclusive access control in smart\ndevices, and forensic fraud detection. However, the advancement of deep\nlearning algorithms has enabled the generation of synthetic audio through\nText-to-Speech (TTS) and Voice Conversion (VC) systems, exposing ASV systems to\npotential vulnerabilities. To counteract this, we propose a novel architecture\nnamed AASIST3. By enhancing the existing AASIST framework with\nKolmogorov-Arnold networks, additional layers, encoders, and pre-emphasis\ntechniques, AASIST3 achieves a more than twofold improvement in performance. It\ndemonstrates minDCF results of 0.5357 in the closed condition and 0.1414 in the\nopen condition, significantly enhancing the detection of synthetic voices and\nimproving ASV security.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "published": "2024-08-30T15:30:01+00:00",
    "updated": "2024-08-30T15:30:01+00:00",
    "url": "http://arxiv.org/pdf/2408.17352v1"
  },
  {
    "id": "2408.14552v1",
    "title": "Aiding Humans in Financial Fraud Decision Making: Toward an XAI-Visualization Framework",
    "authors": [
      "Angelos Chatzimparmpas",
      "Evanthia Dimara"
    ],
    "abstract": "AI prevails in financial fraud detection and decision making. Yet, due to\nconcerns about biased automated decision making or profiling, regulations\nmandate that final decisions are made by humans. Financial fraud investigators\nface the challenge of manually synthesizing vast amounts of unstructured\ninformation, including AI alerts, transaction histories, social media insights,\nand governmental laws. Current Visual Analytics (VA) systems primarily support\nisolated aspects of this process, such as explaining binary AI alerts and\nvisualizing transaction patterns, thus adding yet another layer of information\nto the overall complexity. In this work, we propose a framework where the VA\nsystem supports decision makers throughout all stages of financial fraud\ninvestigation, including data collection, information synthesis, and human\ncriteria iteration. We illustrate how VA can claim a central role in AI-aided\ndecision making, ensuring that human judgment remains in control while\nminimizing potential biases and labor-intensive tasks.",
    "categories": [
      "cs.LG",
      "cs.CY",
      "cs.HC"
    ],
    "published": "2024-08-26T18:10:07+00:00",
    "updated": "2024-08-26T18:10:07+00:00",
    "url": "http://arxiv.org/pdf/2408.14552v1"
  },
  {
    "id": "2408.12989v1",
    "title": "RIFF: Inducing Rules for Fraud Detection from Decision Trees",
    "authors": [
      "João Lucas Martins",
      "João Bravo",
      "Ana Sofia Gomes",
      "Carlos Soares",
      "Pedro Bizarro"
    ],
    "abstract": "Financial fraud is the cause of multi-billion dollar losses annually.\nTraditionally, fraud detection systems rely on rules due to their transparency\nand interpretability, key features in domains where decisions need to be\nexplained. However, rule systems require significant input from domain experts\nto create and tune, an issue that rule induction algorithms attempt to mitigate\nby inferring rules directly from data. We explore the application of these\nalgorithms to fraud detection, where rule systems are constrained to have a low\nfalse positive rate (FPR) or alert rate, by proposing RIFF, a rule induction\nalgorithm that distills a low FPR rule set directly from decision trees. Our\nexperiments show that the induced rules are often able to maintain or improve\nperformance of the original models for low FPR tasks, while substantially\nreducing their complexity and outperforming rules hand-tuned by experts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2024-08-23T11:14:20+00:00",
    "updated": "2024-08-23T11:14:20+00:00",
    "url": "http://arxiv.org/pdf/2408.12989v1"
  },
  {
    "id": "2408.13277v2",
    "title": "An Improved Phase Coding Audio Steganography Algorithm",
    "authors": [
      "Guang Yang"
    ],
    "abstract": "Advances in AI technology have made voice cloning increasingly accessible,\nleading to a rise in fraud involving AI-generated audio forgeries. This\nhighlights the need to covertly embed information and verify the authenticity\nand integrity of audio. Digital Audio Watermarking plays a crucial role in this\ncontext. This study presents an improved Phase Coding audio steganography\nalgorithm that segments the audio signal dynamically, embedding data into the\nmid-frequency phase components. This approach enhances resistance to\nsteganalysis, simplifies computation, and ensures secure audio integrity.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-08-21T19:25:31+00:00",
    "updated": "2024-08-27T06:58:34+00:00",
    "url": "http://arxiv.org/pdf/2408.13277v2"
  },
  {
    "id": "2408.11203v1",
    "title": "Detecting Fraudulent Services on Quantum Cloud Platforms via Dynamic Fingerprinting",
    "authors": [
      "Jindi Wu",
      "Tianjie Hu",
      "Qun Li"
    ],
    "abstract": "Noisy Intermediate-Scale Quantum (NISQ) devices, while accessible via cloud\nplatforms, face challenges due to limited availability and suboptimal quality.\nThese challenges raise the risk of cloud providers offering fraudulent\nservices. This emphasizes the need for users to detect such fraud to protect\ntheir investments and ensure computational integrity. This study introduces a\nnovel dynamic fingerprinting method for detecting fraudulent service provision\non quantum cloud platforms, specifically targeting machine substitution and\nprofile fabrication attacks. The dynamic fingerprint is constructed using a\n\\textit{single} probing circuit to capture the unique error characteristics of\nquantum devices, making this approach practical because of its trivial\ncomputational costs. When the user examines the service, the execution results\nof the probing circuit act as the device-side fingerprint of the quantum device\nproviding the service. The user then generates the user-side fingerprint by\nestimating the expected execution result, assuming the correct device is in\nuse. We propose an algorithm for users to construct the user-side fingerprint\nwith linear complexity. By comparing the device-side and user-side\nfingerprints, users can effectively detect fraudulent services. Our experiments\non the IBM Quantum platform, involving seven devices with varying capabilities,\nconfirm the method's effectiveness.",
    "categories": [
      "cs.CR",
      "quant-ph"
    ],
    "published": "2024-08-20T21:26:59+00:00",
    "updated": "2024-08-20T21:26:59+00:00",
    "url": "http://arxiv.org/pdf/2408.11203v1"
  },
  {
    "id": "2408.11047v3",
    "title": "Quantum machine learning algorithms for anomaly detection: A review",
    "authors": [
      "Sebastiano Corli",
      "Lorenzo Moro",
      "Daniele Dragoni",
      "Massimiliano Dispenza",
      "Enrico Prati"
    ],
    "abstract": "The advent of quantum computers has justified the development of quantum\nmachine learning algorithms , based on the adaptation of the principles of\nmachine learning to the formalism of qubits. Among such quantum algorithms,\nanomaly detection represents an important problem crossing several disciplines\nfrom cybersecurity, to fraud detection to particle physics. We summarize the\nkey concepts involved in quantum computing, introducing the formal concept of\nquantum speed up. The review provides a structured map of anomaly detection\nbased on quantum machine learning. We have grouped existing algorithms\naccording to the different learning methods, namely quantum supervised, quantum\nunsupervised and quantum reinforcement learning, respectively. We provide an\nestimate of the hardware resources to provide sufficient computational power in\nthe future. The review provides a systematic and compact understanding of the\ntechniques belonging to each category. We eventually provide a discussion on\nthe computational complexity of the learning methods in real application\ndomains.",
    "categories": [
      "quant-ph"
    ],
    "published": "2024-08-20T17:55:25+00:00",
    "updated": "2025-03-03T16:01:45+00:00",
    "url": "http://arxiv.org/pdf/2408.11047v3"
  },
  {
    "id": "2408.09676v1",
    "title": "Image-based Freeform Handwriting Authentication with Energy-oriented Self-Supervised Learning",
    "authors": [
      "Jingyao Wang",
      "Luntian Mou",
      "Changwen Zheng",
      "Wen Gao"
    ],
    "abstract": "Freeform handwriting authentication verifies a person's identity from their\nwriting style and habits in messy handwriting data. This technique has gained\nwidespread attention in recent years as a valuable tool for various fields,\ne.g., fraud prevention and cultural heritage protection. However, it still\nremains a challenging task in reality due to three reasons: (i) severe damage,\n(ii) complex high-dimensional features, and (iii) lack of supervision. To\naddress these issues, we propose SherlockNet, an energy-oriented two-branch\ncontrastive self-supervised learning framework for robust and fast freeform\nhandwriting authentication. It consists of four stages: (i) pre-processing:\nconverting manuscripts into energy distributions using a novel plug-and-play\nenergy-oriented operator to eliminate the influence of noise; (ii) generalized\npre-training: learning general representation through two-branch momentum-based\nadaptive contrastive learning with the energy distributions, which handles the\nhigh-dimensional features and spatial dependencies of handwriting; (iii)\npersonalized fine-tuning: calibrating the learned knowledge using a small\namount of labeled data from downstream tasks; and (iv) practical application:\nidentifying individual handwriting from scrambled, missing, or forged data\nefficiently and conveniently. Considering the practicality, we construct EN-HA,\na novel dataset that simulates data forgery and severe damage in real\napplications. Finally, we conduct extensive experiments on six benchmark\ndatasets including our EN-HA, and the results prove the robustness and\nefficiency of SherlockNet.",
    "categories": [
      "cs.CV"
    ],
    "published": "2024-08-19T03:33:39+00:00",
    "updated": "2024-08-19T03:33:39+00:00",
    "url": "http://arxiv.org/pdf/2408.09676v1"
  },
  {
    "id": "2408.09393v1",
    "title": "Federated Graph Learning with Structure Proxy Alignment",
    "authors": [
      "Xingbo Fu",
      "Zihan Chen",
      "Binchi Zhang",
      "Chen Chen",
      "Jundong Li"
    ],
    "abstract": "Federated Graph Learning (FGL) aims to learn graph learning models over graph\ndata distributed in multiple data owners, which has been applied in various\napplications such as social recommendation and financial fraud detection.\nInherited from generic Federated Learning (FL), FGL similarly has the data\nheterogeneity issue where the label distribution may vary significantly for\ndistributed graph data across clients. For instance, a client can have the\nmajority of nodes from a class, while another client may have only a few nodes\nfrom the same class. This issue results in divergent local objectives and\nimpairs FGL convergence for node-level tasks, especially for node\nclassification. Moreover, FGL also encounters a unique challenge for the node\nclassification task: the nodes from a minority class in a client are more\nlikely to have biased neighboring information, which prevents FGL from learning\nexpressive node embeddings with Graph Neural Networks (GNNs). To grapple with\nthe challenge, we propose FedSpray, a novel FGL framework that learns local\nclass-wise structure proxies in the latent space and aligns them to obtain\nglobal structure proxies in the server. Our goal is to obtain the aligned\nstructure proxies that can serve as reliable, unbiased neighboring information\nfor node classification. To achieve this, FedSpray trains a global\nfeature-structure encoder and generates unbiased soft targets with structure\nproxies to regularize local training of GNN models in a personalized way. We\nconduct extensive experiments over four datasets, and experiment results\nvalidate the superiority of FedSpray compared with other baselines. Our code is\navailable at https://github.com/xbfu/FedSpray.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "published": "2024-08-18T07:32:54+00:00",
    "updated": "2024-08-18T07:32:54+00:00",
    "url": "http://arxiv.org/pdf/2408.09393v1"
  },
  {
    "id": "2410.19783v1",
    "title": "Exploring Older Adults' Perceptions and Experiences with Online Dating",
    "authors": [
      "Muskan Fatima",
      "Naheem Noah",
      "Sanchari Das"
    ],
    "abstract": "The rise of online dating apps has transformed how individuals connect and\nseek companionship, with an increase in usage among older adults. While these\nplatforms offer opportunities for emotional support and social connection, they\nalso present significant challenges, including a concerning trend of online\ndating scams targeting this demographic. To address these issues, we conducted\na semi-structured interview focused on the online dating experiences of older\nadults (65+). Initially, we conducted a pre-screening survey, followed by\nfocused semi-structured interviews with 11 of the selected older adults.\nThrough this study, we investigate older adults' security and privacy concerns,\nthe significance of design elements and accessibility, and identify areas\nneeding improvement. Our findings reveal challenges such as deceptive\npractices, including catfishing and fraud, concerns over disclosing sensitive\ninformation, non-inclusive app design features, and the need for more\ninformative visualization of match requests. We offer recommendations for\nenhanced identity verification, inclusive privacy controls by app developers,\nand increased digital literacy efforts to enable older adults to navigate these\nplatforms safely and confidently.",
    "categories": [
      "cs.CY"
    ],
    "published": "2024-10-14T18:41:04+00:00",
    "updated": "2024-10-14T18:41:04+00:00",
    "url": "http://arxiv.org/pdf/2410.19783v1"
  },
  {
    "id": "2410.10929v7",
    "title": "ASTM :Autonomous Smart Traffic Management System Using Artificial Intelligence CNN and LSTM",
    "authors": [
      "Christofel Rio Goenawan"
    ],
    "abstract": "In the modern world, the development of Artificial Intelligence (AI) has\ncontributed to improvements in various areas, including automation, computer\nvision, fraud detection, and more. AI can be leveraged to enhance the\nefficiency of Autonomous Smart Traffic Management (ASTM) systems and reduce\ntraffic congestion rates. This paper presents an Autonomous Smart Traffic\nManagement (STM) system that uses AI to improve traffic flow rates. The system\nemploys the YOLO V5 Convolutional Neural Network to detect vehicles in traffic\nmanagement images. Additionally, it predicts the number of vehicles for the\nnext 12 hours using a Recurrent Neural Network with Long Short-Term Memory\n(RNN-LSTM). The Smart Traffic Management Cycle Length Analysis manages the\ntraffic cycle length based on these vehicle predictions, aided by AI. From the\nresults of the RNN-LSTM model for predicting vehicle numbers over the next 12\nhours, we observe that the model predicts traffic with a Mean Squared Error\n(MSE) of 4.521 vehicles and a Root Mean Squared Error (RMSE) of 2.232 vehicles.\nAfter simulating the STM system in the CARLA simulation environment, we found\nthat the Traffic Management Congestion Flow Rate with ASTM (21 vehicles per\nminute) is 50\\% higher than the rate without STM (around 15 vehicles per\nminute). Additionally, the Traffic Management Vehicle Pass Delay with STM (5\nseconds per vehicle) is 70\\% lower than without STM (around 12 seconds per\nvehicle). These results demonstrate that the STM system using AI can increase\ntraffic flow by 50\\% and reduce vehicle pass delays by 70\\%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2024-10-14T16:35:27+00:00",
    "updated": "2025-02-10T12:09:23+00:00",
    "url": "http://arxiv.org/pdf/2410.10929v7"
  },
  {
    "id": "2410.09284v1",
    "title": "Enhanced Federated Anomaly Detection Through Autoencoders Using Summary Statistics-Based Thresholding",
    "authors": [
      "Sofiane Laridi",
      "Gregory Palmer",
      "Kam-Ming Mark Tam"
    ],
    "abstract": "In Federated Learning (FL), anomaly detection (AD) is a challenging task due\nto the decentralized nature of data and the presence of non-IID data\ndistributions. This study introduces a novel federated threshold calculation\nmethod that leverages summary statistics from both normal and anomalous data to\nimprove the accuracy and robustness of anomaly detection using autoencoders\n(AE) in a federated setting. Our approach aggregates local summary statistics\nacross clients to compute a global threshold that optimally separates anomalies\nfrom normal data while ensuring privacy preservation. We conducted extensive\nexperiments using publicly available datasets, including Credit Card Fraud\nDetection, Shuttle, and Covertype, under various data distribution scenarios.\nThe results demonstrate that our method consistently outperforms existing\nfederated and local threshold calculation techniques, particularly in handling\nnon-IID data distributions. This study also explores the impact of different\ndata distribution scenarios and the number of clients on the performance of\nfederated anomaly detection. Our findings highlight the potential of using\nsummary statistics for threshold calculation in improving the scalability and\naccuracy of federated anomaly detection systems.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-10-11T22:21:14+00:00",
    "updated": "2024-10-11T22:21:14+00:00",
    "url": "http://arxiv.org/pdf/2410.09284v1"
  },
  {
    "id": "2410.09024v3",
    "title": "AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents",
    "authors": [
      "Maksym Andriushchenko",
      "Alexandra Souly",
      "Mateusz Dziemian",
      "Derek Duenas",
      "Maxwell Lin",
      "Justin Wang",
      "Dan Hendrycks",
      "Andy Zou",
      "Zico Kolter",
      "Matt Fredrikson",
      "Eric Winsor",
      "Jerome Wynne",
      "Yarin Gal",
      "Xander Davies"
    ],
    "abstract": "The robustness of LLMs to jailbreak attacks, where users design prompts to\ncircumvent safety measures and misuse model capabilities, has been studied\nprimarily for LLMs acting as simple chatbots. Meanwhile, LLM agents -- which\nuse external tools and can execute multi-stage tasks -- may pose a greater risk\nif misused, but their robustness remains underexplored. To facilitate research\non LLM agent misuse, we propose a new benchmark called AgentHarm. The benchmark\nincludes a diverse set of 110 explicitly malicious agent tasks (440 with\naugmentations), covering 11 harm categories including fraud, cybercrime, and\nharassment. In addition to measuring whether models refuse harmful agentic\nrequests, scoring well on AgentHarm requires jailbroken agents to maintain\ntheir capabilities following an attack to complete a multi-step task. We\nevaluate a range of leading LLMs, and find (1) leading LLMs are surprisingly\ncompliant with malicious agent requests without jailbreaking, (2) simple\nuniversal jailbreak templates can be adapted to effectively jailbreak agents,\nand (3) these jailbreaks enable coherent and malicious multi-step agent\nbehavior and retain model capabilities. To enable simple and reliable\nevaluation of attacks and defenses for LLM-based agents, we publicly release\nAgentHarm at https://huggingface.co/datasets/ai-safety-institute/AgentHarm.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2024-10-11T17:39:22+00:00",
    "updated": "2025-04-18T14:30:31+00:00",
    "url": "http://arxiv.org/pdf/2410.09024v3"
  },
  {
    "id": "2410.21284v1",
    "title": "AI-driven innovation in medicaid: enhancing access, cost efficiency, and population health management",
    "authors": [
      "Balaji Shesharao Ingole",
      "Vishnu Ramineni",
      "Manjunatha Sughaturu Krishnappa",
      "Vivekananda Jayaram"
    ],
    "abstract": "The U.S. Medicaid program is experiencing critical challenges that include\nrapidly increasing healthcare costs, uneven care accessibility, and the\nchallenge associated with addressing a varied set of population health needs.\nThis paper investigates the transformative potential of Artificial Intelligence\n(AI) in reshaping Medicaid by streamlining operations, improving patient\nresults, and lowering costs. We delve into the pivotal role of AI in predictive\nanalytics, care coordination, the detection of fraud, and personalized\nmedicine. By leveraging insights from advanced data models and addressing\nchallenges particular to Medicaid, we put forward AI-driven solutions that\nprioritize equitable care and improved public health outcomes. This study\nunderscores the urgency of integrating AI into Medicaid to not only improve\noperational effectiveness but also to create a more accessible and equitable\nhealthcare system for all beneficiaries.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "published": "2024-10-11T07:14:42+00:00",
    "updated": "2024-10-11T07:14:42+00:00",
    "url": "http://arxiv.org/pdf/2410.21284v1"
  },
  {
    "id": "2410.08390v1",
    "title": "KnowGraph: Knowledge-Enabled Anomaly Detection via Logical Reasoning on Graph Data",
    "authors": [
      "Andy Zhou",
      "Xiaojun Xu",
      "Ramesh Raghunathan",
      "Alok Lal",
      "Xinze Guan",
      "Bin Yu",
      "Bo Li"
    ],
    "abstract": "Graph-based anomaly detection is pivotal in diverse security applications,\nsuch as fraud detection in transaction networks and intrusion detection for\nnetwork traffic. Standard approaches, including Graph Neural Networks (GNNs),\noften struggle to generalize across shifting data distributions. Meanwhile,\nreal-world domain knowledge is more stable and a common existing component of\nreal-world detection strategies. To explicitly integrate such knowledge into\ndata-driven models such as GCNs, we propose KnowGraph, which integrates domain\nknowledge with data-driven learning for enhanced graph-based anomaly detection.\nKnowGraph comprises two principal components: (1) a statistical learning\ncomponent that utilizes a main model for the overarching detection task,\naugmented by multiple specialized knowledge models that predict domain-specific\nsemantic entities; (2) a reasoning component that employs probabilistic\ngraphical models to execute logical inferences based on model outputs, encoding\ndomain knowledge through weighted first-order logic formulas. Extensive\nexperiments on these large-scale real-world datasets show that KnowGraph\nconsistently outperforms state-of-the-art baselines in both transductive and\ninductive settings, achieving substantial gains in average precision when\ngeneralizing to completely unseen test graphs. Further ablation studies\ndemonstrate the effectiveness of the proposed reasoning component in improving\ndetection performance, especially under extreme class imbalance. These results\nhighlight the potential of integrating domain knowledge into data-driven models\nfor high-stakes, graph-based security applications.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2024-10-10T21:53:33+00:00",
    "updated": "2024-10-10T21:53:33+00:00",
    "url": "http://arxiv.org/pdf/2410.08390v1"
  },
  {
    "id": "2410.08121v1",
    "title": "Heterogeneous Graph Auto-Encoder for CreditCard Fraud Detection",
    "authors": [
      "Moirangthem Tiken Singh",
      "Rabinder Kumar Prasad",
      "Gurumayum Robert Michael",
      "N K Kaphungkui",
      "N. Hemarjit Singh"
    ],
    "abstract": "The digital revolution has significantly impacted financial transactions,\nleading to a notable increase in credit card usage. However, this convenience\ncomes with a trade-off: a substantial rise in fraudulent activities.\nTraditional machine learning methods for fraud detection often struggle to\ncapture the inherent interconnectedness within financial data. This paper\nproposes a novel approach for credit card fraud detection that leverages Graph\nNeural Networks (GNNs) with attention mechanisms applied to heterogeneous graph\nrepresentations of financial data. Unlike homogeneous graphs, heterogeneous\ngraphs capture intricate relationships between various entities in the\nfinancial ecosystem, such as cardholders, merchants, and transactions,\nproviding a richer and more comprehensive data representation for fraud\nanalysis. To address the inherent class imbalance in fraud data, where genuine\ntransactions significantly outnumber fraudulent ones, the proposed approach\nintegrates an autoencoder. This autoencoder, trained on genuine transactions,\nlearns a latent representation and flags deviations during reconstruction as\npotential fraud. This research investigates two key questions: (1) How\neffectively can a GNN with an attention mechanism detect and prevent credit\ncard fraud when applied to a heterogeneous graph? (2) How does the efficacy of\nthe autoencoder with attention approach compare to traditional methods? The\nresults are promising, demonstrating that the proposed model outperforms\nbenchmark algorithms such as Graph Sage and FI-GRL, achieving a superior AUC-PR\nof 0.89 and an F1-score of 0.81. This research significantly advances fraud\ndetection systems and the overall security of financial transactions by\nleveraging GNNs with attention mechanisms and addressing class imbalance\nthrough an autoencoder.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2024-10-10T17:05:27+00:00",
    "updated": "2024-10-10T17:05:27+00:00",
    "url": "http://arxiv.org/pdf/2410.08121v1"
  },
  {
    "id": "2410.07888v1",
    "title": "Deepfake detection in videos with multiple faces using geometric-fakeness features",
    "authors": [
      "Kirill Vyshegorodtsev",
      "Dmitry Kudiyarov",
      "Alexander Balashov",
      "Alexander Kuzmin"
    ],
    "abstract": "Due to the development of facial manipulation techniques in recent years\ndeepfake detection in video stream became an important problem for face\nbiometrics, brand monitoring or online video conferencing solutions. In case of\na biometric authentication, if you replace a real datastream with a deepfake,\nyou can bypass a liveness detection system. Using a deepfake in a video\nconference, you can penetrate into a private meeting. Deepfakes of victims or\npublic figures can also be used by fraudsters for blackmailing, extorsion and\nfinancial fraud. Therefore, the task of detecting deepfakes is relevant to\nensuring privacy and security. In existing approaches to a deepfake detection\ntheir performance deteriorates when multiple faces are present in a video\nsimultaneously or when there are other objects erroneously classified as faces.\nIn our research we propose to use geometric-fakeness features (GFF) that\ncharacterize a dynamic degree of a face presence in a video and its per-frame\ndeepfake scores. To analyze temporal inconsistencies in GFFs between the frames\nwe train a complex deep learning model that outputs a final deepfake\nprediction. We employ our approach to analyze videos with multiple faces that\nare simultaneously present in a video. Such videos often occur in practice\ne.g., in an online video conference. In this case, real faces appearing in a\nframe together with a deepfake face will significantly affect a deepfake\ndetection and our approach allows to counter this problem. Through extensive\nexperiments we demonstrate that our approach outperforms current\nstate-of-the-art methods on popular benchmark datasets such as FaceForensics++,\nDFDC, Celeb-DF and WildDeepFake. The proposed approach remains accurate when\ntrained to detect multiple different deepfake generation techniques.",
    "categories": [
      "cs.CV",
      "cs.CR"
    ],
    "published": "2024-10-10T13:10:34+00:00",
    "updated": "2024-10-10T13:10:34+00:00",
    "url": "http://arxiv.org/pdf/2410.07888v1"
  },
  {
    "id": "2410.08243v1",
    "title": "Self-Attention Mechanism in Multimodal Context for Banking Transaction Flow",
    "authors": [
      "Cyrile Delestre",
      "Yoann Sola"
    ],
    "abstract": "Banking Transaction Flow (BTF) is a sequential data found in a number of\nbanking activities such as marketing, credit risk or banking fraud. It is a\nmultimodal data composed of three modalities: a date, a numerical value and a\nwording. We propose in this work an application of self-attention mechanism to\nthe processing of BTFs. We trained two general models on a large amount of BTFs\nin a self-supervised way: one RNN-based model and one Transformer-based model.\nWe proposed a specific tokenization in order to be able to process BTFs. The\nperformance of these two models was evaluated on two banking downstream tasks:\na transaction categorization task and a credit risk task. The results show that\nfine-tuning these two pre-trained models allowed to perform better than the\nstate-of-the-art approaches for both tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2024-10-10T08:13:39+00:00",
    "updated": "2024-10-10T08:13:39+00:00",
    "url": "http://arxiv.org/pdf/2410.08243v1"
  },
  {
    "id": "2410.06857v1",
    "title": "Digital Dotted Lines: Design and Evaluation of a Prototype for Digitally Signing Documents Using Identity Wallets",
    "authors": [
      "Yorick Last",
      "Jorrit Geels",
      "Hanna Schraffenberger"
    ],
    "abstract": "Documents are largely stored and shared digitally. Yet, digital documents are\nstill commonly signed using (copies of) handwritten signatures, which are\nsensitive to fraud. Though secure, cryptography-based signature solutions\nexist, they are hardly used due to usability issues. This paper proposes to use\ndigital identity wallets for securely and intuitively signing digital documents\nwith verified personal data. Using expert feedback, we implemented this vision\nin an interactive prototype. The prototype was assessed in a moderated\nusability test (N = 15) and a subsequent unmoderated remote usability test (N =\n99). While participants generally expressed satisfaction with the system, they\nalso misunderstood how to interpret the signature information displayed by the\nprototype. Specifically, signed documents were also trusted when the document\nwas signed with irrelevant personal data of the signer. We conclude that such\nunwarranted trust forms a threat to usable digital signatures and requires\nattention by the usable security community.",
    "categories": [
      "cs.HC"
    ],
    "published": "2024-10-09T13:20:13+00:00",
    "updated": "2024-10-09T13:20:13+00:00",
    "url": "http://arxiv.org/pdf/2410.06857v1"
  },
  {
    "id": "2410.06815v1",
    "title": "Shap-Select: Lightweight Feature Selection Using SHAP Values and Regression",
    "authors": [
      "Egor Kraev",
      "Baran Koseoglu",
      "Luca Traverso",
      "Mohammed Topiwalla"
    ],
    "abstract": "Feature selection is an essential process in machine learning, especially\nwhen dealing with high-dimensional datasets. It helps reduce the complexity of\nmachine learning models, improve performance, mitigate overfitting, and\ndecrease computation time. This paper presents a novel feature selection\nframework, shap-select. The framework conducts a linear or logistic regression\nof the target on the Shapley values of the features, on the validation set, and\nuses the signs and significance levels of the regression coefficients to\nimplement an efficient heuristic for feature selection in tabular regression\nand classification tasks. We evaluate shap-select on the Kaggle credit card\nfraud dataset, demonstrating its effectiveness compared to established methods\nsuch as Recursive Feature Elimination (RFE), HISEL (a mutual information-based\nfeature selection method), Boruta and a simpler Shapley value-based method. Our\nfindings show that shap-select combines interpretability, computational\nefficiency, and performance, offering a robust solution for feature selection.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-10-09T12:14:06+00:00",
    "updated": "2024-10-09T12:14:06+00:00",
    "url": "http://arxiv.org/pdf/2410.06815v1"
  },
  {
    "id": "2410.06572v1",
    "title": "Can DeepFake Speech be Reliably Detected?",
    "authors": [
      "Hongbin Liu",
      "Youzheng Chen",
      "Arun Narayanan",
      "Athula Balachandran",
      "Pedro J. Moreno",
      "Lun Wang"
    ],
    "abstract": "Recent advances in text-to-speech (TTS) systems, particularly those with\nvoice cloning capabilities, have made voice impersonation readily accessible,\nraising ethical and legal concerns due to potential misuse for malicious\nactivities like misinformation campaigns and fraud. While synthetic speech\ndetectors (SSDs) exist to combat this, they are vulnerable to ``test domain\nshift\", exhibiting decreased performance when audio is altered through\ntranscoding, playback, or background noise. This vulnerability is further\nexacerbated by deliberate manipulation of synthetic speech aimed at deceiving\ndetectors. This work presents the first systematic study of such active\nmalicious attacks against state-of-the-art open-source SSDs. White-box attacks,\nblack-box attacks, and their transferability are studied from both attack\neffectiveness and stealthiness, using both hardcoded metrics and human ratings.\nThe results highlight the urgent need for more robust detection methods in the\nface of evolving adversarial threats.",
    "categories": [
      "cs.SD",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2024-10-09T06:13:48+00:00",
    "updated": "2024-10-09T06:13:48+00:00",
    "url": "http://arxiv.org/pdf/2410.06572v1"
  },
  {
    "id": "2410.04386v1",
    "title": "Data Distribution Valuation",
    "authors": [
      "Xinyi Xu",
      "Shuaiqi Wang",
      "Chuan-Sheng Foo",
      "Bryan Kian Hsiang Low",
      "Giulia Fanti"
    ],
    "abstract": "Data valuation is a class of techniques for quantitatively assessing the\nvalue of data for applications like pricing in data marketplaces. Existing data\nvaluation methods define a value for a discrete dataset. However, in many use\ncases, users are interested in not only the value of the dataset, but that of\nthe distribution from which the dataset was sampled. For example, consider a\nbuyer trying to evaluate whether to purchase data from different vendors. The\nbuyer may observe (and compare) only a small preview sample from each vendor,\nto decide which vendor's data distribution is most useful to the buyer and\npurchase. The core question is how should we compare the values of data\ndistributions from their samples? Under a Huber characterization of the data\nheterogeneity across vendors, we propose a maximum mean discrepancy (MMD)-based\nvaluation method which enables theoretically principled and actionable policies\nfor comparing data distributions from samples. We empirically demonstrate that\nour method is sample-efficient and effective in identifying valuable data\ndistributions against several existing baselines, on multiple real-world\ndatasets (e.g., network intrusion detection, credit card fraud detection) and\ndownstream applications (classification, regression).",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-10-06T07:56:53+00:00",
    "updated": "2024-10-06T07:56:53+00:00",
    "url": "http://arxiv.org/pdf/2410.04386v1"
  },
  {
    "id": "2410.04324v4",
    "title": "Where are we in audio deepfake detection? A systematic analysis over generative and detection models",
    "authors": [
      "Xiang Li",
      "Pin-Yu Chen",
      "Wenqi Wei"
    ],
    "abstract": "Recent advances in Text-to-Speech (TTS) and Voice-Conversion (VC) using\ngenerative Artificial Intelligence (AI) technology have made it possible to\ngenerate high-quality and realistic human-like audio. This poses growing\nchallenges in distinguishing AI-synthesized speech from the genuine human voice\nand could raise concerns about misuse for impersonation, fraud, spreading\nmisinformation, and scams. However, existing detection methods for\nAI-synthesized audio have not kept pace and often fail to generalize across\ndiverse datasets. In this paper, we introduce SONAR, a synthetic AI-Audio\nDetection Framework and Benchmark, aiming to provide a comprehensive evaluation\nfor distinguishing cutting-edge AI-synthesized auditory content. SONAR includes\na novel evaluation dataset sourced from 9 diverse audio synthesis platforms,\nincluding leading TTS providers and state-of-the-art TTS models. It is the\nfirst framework to uniformly benchmark AI-audio detection across both\ntraditional and foundation model-based detection systems. Through extensive\nexperiments, (1) we reveal the limitations of existing detection methods and\ndemonstrate that foundation models exhibit stronger generalization\ncapabilities, likely due to their model size and the scale and quality of\npretraining data. (2) Speech foundation models demonstrate robust cross-lingual\ngeneralization capabilities, maintaining strong performance across diverse\nlanguages despite being fine-tuned solely on English speech data. This finding\nalso suggests that the primary challenges in audio deepfake detection are more\nclosely tied to the realism and quality of synthetic audio rather than\nlanguage-specific characteristics. (3) We explore the effectiveness and\nefficiency of few-shot fine-tuning in improving generalization, highlighting\nits potential for tailored applications, such as personalized detection systems\nfor specific entities or individuals.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "published": "2024-10-06T01:03:42+00:00",
    "updated": "2025-03-22T01:10:56+00:00",
    "url": "http://arxiv.org/pdf/2410.04324v4"
  },
  {
    "id": "2410.04154v2",
    "title": "Applying Quantum Autoencoders for Time Series Anomaly Detection",
    "authors": [
      "Robin Frehner",
      "Kurt Stockinger"
    ],
    "abstract": "Anomaly detection is an important problem with applications in various\ndomains such as fraud detection, pattern recognition or medical diagnosis.\nSeveral algorithms have been introduced using classical computing approaches.\nHowever, using quantum computing for solving anomaly detection problems in time\nseries data is a widely unexplored research field.\n  This paper explores the application of quantum autoencoders to time series\nanomaly detection. We investigate two primary techniques for classifying\nanomalies: (1) Analyzing the reconstruction error generated by the quantum\nautoencoder and (2) latent representation analysis. Our simulated experimental\nresults, conducted across various ansaetze, demonstrate that quantum\nautoencoders consistently outperform classical deep learning-based autoencoders\nacross multiple datasets. Specifically, quantum autoencoders achieve superior\nanomaly detection performance while utilizing 60-230 times fewer parameters and\nrequiring five times fewer training iterations. In addition, we implement our\nquantum encoder on real quantum hardware. Our experimental results demonstrate\nthat quantum autoencoders achieve anomaly detection performance on par with\ntheir simulated counterparts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET",
      "quant-ph"
    ],
    "published": "2024-10-05T13:29:25+00:00",
    "updated": "2024-10-09T13:56:28+00:00",
    "url": "http://arxiv.org/pdf/2410.04154v2"
  },
  {
    "id": "2410.03487v1",
    "title": "A Multimodal Framework for Deepfake Detection",
    "authors": [
      "Kashish Gandhi",
      "Prutha Kulkarni",
      "Taran Shah",
      "Piyush Chaudhari",
      "Meera Narvekar",
      "Kranti Ghag"
    ],
    "abstract": "The rapid advancement of deepfake technology poses a significant threat to\ndigital media integrity. Deepfakes, synthetic media created using AI, can\nconvincingly alter videos and audio to misrepresent reality. This creates risks\nof misinformation, fraud, and severe implications for personal privacy and\nsecurity. Our research addresses the critical issue of deepfakes through an\ninnovative multimodal approach, targeting both visual and auditory elements.\nThis comprehensive strategy recognizes that human perception integrates\nmultiple sensory inputs, particularly visual and auditory information, to form\na complete understanding of media content. For visual analysis, a model that\nemploys advanced feature extraction techniques was developed, extracting nine\ndistinct facial characteristics and then applying various machine learning and\ndeep learning models. For auditory analysis, our model leverages\nmel-spectrogram analysis for feature extraction and then applies various\nmachine learning and deep learningmodels. To achieve a combined analysis, real\nand deepfake audio in the original dataset were swapped for testing purposes\nand ensured balanced samples. Using our proposed models for video and audio\nclassification i.e. Artificial Neural Network and VGG19, the overall sample is\nclassified as deepfake if either component is identified as such. Our\nmultimodal framework combines visual and auditory analyses, yielding an\naccuracy of 94%.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "published": "2024-10-04T14:59:10+00:00",
    "updated": "2024-10-04T14:59:10+00:00",
    "url": "http://arxiv.org/pdf/2410.03487v1"
  },
  {
    "id": "2410.13877v2",
    "title": "Model Validation Practice in Banking: A Structured Approach for Predictive Models",
    "authors": [
      "Agus Sudjianto",
      "Aijun Zhang"
    ],
    "abstract": "This paper presents a comprehensive overview of model validation practices\nand advancement in the banking industry based on the experience of managing\nModel Risk Management (MRM) since the inception of regulatory guidance\nSR11-7/OCC11-12 over a decade ago. Model validation in banking is a crucial\nprocess designed to ensure that predictive models, which are often used for\ncredit risk, fraud detection, and capital planning, operate reliably and meet\nregulatory standards. This practice ensures that models are conceptually sound,\nproduce valid outcomes, and are consistently monitored over time. Model\nvalidation in banking is a multi-faceted process with three key components:\nconceptual soundness evaluation, outcome analysis, and on-going monitoring to\nensure that the models are not only designed correctly but also perform\nreliably and consistently in real-world environments. Effective validation\nhelps banks mitigate risks, meet regulatory requirements, and maintain trust in\nthe models that underpin critical business decisions.",
    "categories": [
      "cs.CY",
      "stat.AP"
    ],
    "published": "2024-10-02T17:46:52+00:00",
    "updated": "2024-11-10T22:09:45+00:00",
    "url": "http://arxiv.org/pdf/2410.13877v2"
  },
  {
    "id": "2410.00875v1",
    "title": "Review of blockchain application with Graph Neural Networks, Graph Convolutional Networks and Convolutional Neural Networks",
    "authors": [
      "Amy Ancelotti",
      "Claudia Liason"
    ],
    "abstract": "This paper reviews the applications of Graph Neural Networks (GNNs), Graph\nConvolutional Networks (GCNs), and Convolutional Neural Networks (CNNs) in\nblockchain technology. As the complexity and adoption of blockchain networks\ncontinue to grow, traditional analytical methods are proving inadequate in\ncapturing the intricate relationships and dynamic behaviors of decentralized\nsystems. To address these limitations, deep learning models such as GNNs, GCNs,\nand CNNs offer robust solutions by leveraging the unique graph-based and\ntemporal structures inherent in blockchain architectures. GNNs and GCNs, in\nparticular, excel in modeling the relational data of blockchain nodes and\ntransactions, making them ideal for applications such as fraud detection,\ntransaction verification, and smart contract analysis. Meanwhile, CNNs can be\nadapted to analyze blockchain data when represented as structured matrices,\nrevealing hidden temporal and spatial patterns in transaction flows. This paper\nexplores how these models enhance the efficiency, security, and scalability of\nboth linear blockchains and Directed Acyclic Graph (DAG)-based systems,\nproviding a comprehensive overview of their strengths and future research\ndirections. By integrating advanced neural network techniques, we aim to\ndemonstrate the potential of these models in revolutionizing blockchain\nanalytics, paving the way for more sophisticated decentralized applications and\nimproved network performance.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-10-01T17:11:22+00:00",
    "updated": "2024-10-01T17:11:22+00:00",
    "url": "http://arxiv.org/pdf/2410.00875v1"
  },
  {
    "id": "2410.00727v3",
    "title": "\"Show Me What's Wrong!\": Combining Charts and Text to Guide Data Analysis",
    "authors": [
      "Beatriz Feliciano",
      "Rita Costa",
      "Jean Alves",
      "Javier Liébana",
      "Diogo Duarte",
      "Pedro Bizarro"
    ],
    "abstract": "Analyzing and finding anomalies in multi-dimensional datasets is a cumbersome\nbut vital task across different domains. In the context of financial fraud\ndetection, analysts must quickly identify suspicious activity among\ntransactional data. This is an iterative process made of complex exploratory\ntasks such as recognizing patterns, grouping, and comparing. To mitigate the\ninformation overload inherent to these steps, we present a tool combining\nautomated information highlights, Large Language Model generated textual\ninsights, and visual analytics, facilitating exploration at different levels of\ndetail. We perform a segmentation of the data per analysis area and visually\nrepresent each one, making use of automated visual cues to signal which require\nmore attention. Upon user selection of an area, our system provides textual and\ngraphical summaries. The text, acting as a link between the high-level and\ndetailed views of the chosen segment, allows for a quick understanding of\nrelevant details. A thorough exploration of the data comprising the selection\ncan be done through graphical representations. The feedback gathered in a study\nperformed with seven domain experts suggests our tool effectively supports and\nguides exploratory analysis, easing the identification of suspicious\ninformation.",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.HC"
    ],
    "published": "2024-10-01T14:16:10+00:00",
    "updated": "2024-10-26T17:04:35+00:00",
    "url": "http://arxiv.org/pdf/2410.00727v3"
  },
  {
    "id": "2410.09069v2",
    "title": "Explainable AI for Fraud Detection: An Attention-Based Ensemble of CNNs, GNNs, and A Confidence-Driven Gating Mechanism",
    "authors": [
      "Mehdi Hosseini Chagahi",
      "Niloufar Delfan",
      "Saeed Mohammadi Dashtaki",
      "Behzad Moshiri",
      "Md. Jalil Piran"
    ],
    "abstract": "The rapid expansion of e-commerce and the widespread use of credit cards in\nonline purchases and financial transactions have significantly heightened the\nimportance of promptly and accurately detecting credit card fraud (CCF). Not\nonly do fraudulent activities in financial transactions lead to substantial\nmonetary losses for banks and financial institutions, but they also undermine\nuser trust in digital services. This study presents a new stacking-based\napproach for CCF detection by adding two extra layers to the usual\nclassification process: an attention layer and a confidence-based combination\nlayer. In the attention layer, we combine soft outputs from a convolutional\nneural network (CNN) and a recurrent neural network (RNN) using the dependent\nordered weighted averaging (DOWA) operator, and from a graph neural network\n(GNN) and a long short-term memory (LSTM) network using the induced ordered\nweighted averaging (IOWA) operator. These weighted outputs capture different\npredictive signals, increasing the model's accuracy. Next, in the\nconfidence-based layer, we select whichever aggregate (DOWA or IOWA) shows\nlower uncertainty to feed into a meta-learner. To make the model more\nexplainable, we use shapley additive explanations (SHAP) to identify the top\nten most important features for distinguishing between fraud and normal\ntransactions. These features are then used in our attention-based model.\nExperiments on three datasets show that our method achieves high accuracy and\nrobust generalization, making it effective for CCF detection.",
    "categories": [
      "q-fin.RM",
      "cs.LG"
    ],
    "published": "2024-10-01T09:56:23+00:00",
    "updated": "2025-02-22T11:00:27+00:00",
    "url": "http://arxiv.org/pdf/2410.09069v2"
  },
  {
    "id": "2410.09066v1",
    "title": "AI versus AI in Financial Crimes and Detection: GenAI Crime Waves to Co-Evolutionary AI",
    "authors": [
      "Eren Kurshan",
      "Dhagash Mehta",
      "Bayan Bruss",
      "Tucker Balch"
    ],
    "abstract": "Adoption of AI by criminal entities across traditional and emerging financial\ncrime paradigms has been a disturbing recent trend. Particularly concerning is\nthe proliferation of generative AI, which has empowered criminal activities\nranging from sophisticated phishing schemes to the creation of hard-to-detect\ndeep fakes, and to advanced spoofing attacks to biometric authentication\nsystems. The exploitation of AI by criminal purposes continues to escalate,\npresenting an unprecedented challenge. AI adoption causes an increasingly\ncomplex landscape of fraud typologies intertwined with cybersecurity\nvulnerabilities.\n  Overall, GenAI has a transformative effect on financial crimes and fraud.\nAccording to some estimates, GenAI will quadruple the fraud losses by 2027 with\na staggering annual growth rate of over 30% [27]. As crime patterns become more\nintricate, personalized, and elusive, deploying effective defensive AI\nstrategies becomes indispensable. However, several challenges hinder the\nnecessary progress of AI-based fincrime detection systems. This paper examines\nthe latest trends in AI/ML-driven financial crimes and detection systems. It\nunderscores the urgent need for developing agile AI defenses that can\neffectively counteract the rapidly emerging threats. It also aims to highlight\nthe need for cooperation across the financial services industry to tackle the\nGenAI induced crime waves.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-09-30T15:41:41+00:00",
    "updated": "2024-09-30T15:41:41+00:00",
    "url": "http://arxiv.org/pdf/2410.09066v1"
  },
  {
    "id": "2410.00055v1",
    "title": "Survey of Security and Data Attacks on Machine Unlearning In Financial and E-Commerce",
    "authors": [
      "Carl E. J. Brodzinski"
    ],
    "abstract": "This paper surveys the landscape of security and data attacks on machine\nunlearning, with a focus on financial and e-commerce applications. We discuss\nkey privacy threats such as Membership Inference Attacks and Data\nReconstruction Attacks, where adversaries attempt to infer or reconstruct data\nthat should have been removed. In addition, we explore security attacks\nincluding Machine Unlearning Data Poisoning, Unlearning Request Attacks, and\nMachine Unlearning Jailbreak Attacks, which target the underlying mechanisms of\nunlearning to manipulate or corrupt the model. To mitigate these risks, various\ndefense strategies are examined, including differential privacy, robust\ncryptographic guarantees, and Zero-Knowledge Proofs (ZKPs), offering verifiable\nand tamper-proof unlearning mechanisms. These approaches are essential for\nsafeguarding data integrity and privacy in high-stakes financial and e-commerce\ncontexts, where compromised models can lead to fraud, data leaks, and\nreputational damage. This survey highlights the need for continued research and\ninnovation in secure machine unlearning, as well as the importance of\ndeveloping strong defenses against evolving attack vectors.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2024-09-29T00:30:36+00:00",
    "updated": "2024-09-29T00:30:36+00:00",
    "url": "http://arxiv.org/pdf/2410.00055v1"
  },
  {
    "id": "2409.18931v1",
    "title": "Social Media Bot Policies: Evaluating Passive and Active Enforcement",
    "authors": [
      "Kristina Radivojevic",
      "Christopher McAleer",
      "Catrell Conley",
      "Cormac Kennedy",
      "Paul Brenner"
    ],
    "abstract": "The emergence of Multimodal Foundation Models (MFMs) holds significant\npromise for transforming social media platforms. However, this advancement also\nintroduces substantial security and ethical concerns, as it may facilitate\nmalicious actors in the exploitation of online users. We aim to evaluate the\nstrength of security protocols on prominent social media platforms in\nmitigating the deployment of MFM bots. We examined the bot and content policies\nof eight popular social media platforms: X (formerly Twitter), Instagram,\nFacebook, Threads, TikTok, Mastodon, Reddit, and LinkedIn. Using Selenium, we\ndeveloped a web bot to test bot deployment and AI-generated content policies\nand their enforcement mechanisms. Our findings indicate significant\nvulnerabilities within the current enforcement mechanisms of these platforms.\nDespite having explicit policies against bot activity, all platforms failed to\ndetect and prevent the operation of our MFM bots. This finding reveals a\ncritical gap in the security measures employed by these social media platforms,\nunderscoring the potential for malicious actors to exploit these weaknesses to\ndisseminate misinformation, commit fraud, or manipulate users.",
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "published": "2024-09-27T17:28:25+00:00",
    "updated": "2024-09-27T17:28:25+00:00",
    "url": "http://arxiv.org/pdf/2409.18931v1"
  },
  {
    "id": "2409.18455v1",
    "title": "Review of Digital Asset Development with Graph Neural Network Unlearning",
    "authors": [
      "Zara Lisbon"
    ],
    "abstract": "In the rapidly evolving landscape of digital assets, the imperative for\nrobust data privacy and compliance with regulatory frameworks has intensified.\nThis paper investigates the critical role of Graph Neural Networks (GNNs) in\nthe management of digital assets and introduces innovative unlearning\ntechniques specifically tailored to GNN architectures. We categorize unlearning\nstrategies into two primary classes: data-driven approximation, which\nmanipulates the graph structure to isolate and remove the influence of specific\nnodes, and model-driven approximation, which modifies the internal parameters\nand architecture of the GNN itself. By examining recent advancements in these\nunlearning methodologies, we highlight their applicability in various use\ncases, including fraud detection, risk assessment, token relationship\nprediction, and decentralized governance. We discuss the challenges inherent in\nbalancing model performance with the requirements for data unlearning,\nparticularly in the context of real-time financial applications. Furthermore,\nwe propose a hybrid approach that combines the strengths of both unlearning\nstrategies to enhance the efficiency and effectiveness of GNNs in digital asset\necosystems. Ultimately, this paper aims to provide a comprehensive framework\nfor understanding and implementing GNN unlearning techniques, paving the way\nfor secure and compliant deployment of machine learning in the digital asset\ndomain.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2024-09-27T05:31:04+00:00",
    "updated": "2024-09-27T05:31:04+00:00",
    "url": "http://arxiv.org/pdf/2409.18455v1"
  },
  {
    "id": "2409.18393v1",
    "title": "Social media algorithms can curb misinformation, but do they?",
    "authors": [
      "Chhandak Bagchi",
      "Filippo Menczer",
      "Jennifer Lundquist",
      "Monideepa Tarafdar",
      "Anthony Paik",
      "Przemyslaw A. Grabowicz"
    ],
    "abstract": "A recent article in $\\textit{Science}$ by Guess et al. estimated the effect\nof Facebook's news feed algorithm on exposure to misinformation and political\ninformation among Facebook users. However, its reporting and conclusions did\nnot account for a series of temporary emergency changes to Facebook's news feed\nalgorithm in the wake of the 2020 U.S. presidential election that were designed\nto diminish the spread of voter-fraud misinformation. Here, we demonstrate that\nthese emergency measures systematically reduced the amount of misinformation in\nthe control group of the study, which was using the news feed algorithm. This\nissue may have led readers to misinterpret the results of the study and to\nconclude that the Facebook news feed algorithm used outside of the study period\nmitigates political misinformation as compared to reverse chronological feed.",
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "published": "2024-09-27T02:16:09+00:00",
    "updated": "2024-09-27T02:16:09+00:00",
    "url": "http://arxiv.org/pdf/2409.18393v1"
  },
  {
    "id": "2409.19022v2",
    "title": "Application of AI-based Models for Online Fraud Detection and Analysis",
    "authors": [
      "Antonis Papasavva",
      "Shane Johnson",
      "Ed Lowther",
      "Samantha Lundrigan",
      "Enrico Mariconti",
      "Anna Markovska",
      "Nilufer Tuptuk"
    ],
    "abstract": "Fraud is a prevalent offence that extends beyond financial loss, causing\npsychological and physical harm to victims. The advancements in online\ncommunication technologies alowed for online fraud to thrive in this vast\nnetwork, with fraudsters increasingly using these channels for deception. With\nthe progression of technologies like AI, there is a growing concern that fraud\nwill scale up, using sophisticated methods, like deep-fakes in phishing\ncampaigns, all generated by language generation models like ChatGPT. However,\nthe application of AI in detecting and analyzing online fraud remains\nunderstudied. We conduct a Systematic Literature Review on AI and NLP\ntechniques for online fraud detection. The review adhered the PRISMA-ScR\nprotocol, with eligibility criteria including relevance to online fraud, use of\ntext data, and AI methodologies. We screened 2,457 academic records, 350 met\nour eligibility criteria, and included 223. We report the state-of-the-art NLP\ntechniques for analysing various online fraud categories; the training data\nsources; the NLP algorithms and models built; and the performance metrics\nemployed for model evaluation. We find that current research on online fraud is\ndivided into various scam activitiesand identify 16 different frauds that\nresearchers focus on. This SLR enhances the academic understanding of AI-based\ndetection methods for online fraud and offers insights for policymakers, law\nenforcement, and businesses on safeguarding against such activities. We\nconclude that focusing on specific scams lacks generalization, as multiple\nmodels are required for different fraud types. The evolving nature of scams\nlimits the effectiveness of models trained on outdated data. We also identify\nissues in data limitations, training bias reporting, and selective presentation\nof metrics in model performance reporting, which can lead to potential biases\nin model evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2024-09-25T14:47:03+00:00",
    "updated": "2025-04-15T19:05:24+00:00",
    "url": "http://arxiv.org/pdf/2409.19022v2"
  },
  {
    "id": "2409.15656v2",
    "title": "The First Early Evidence of the Use of Browser Fingerprinting for Online Tracking",
    "authors": [
      "Zengrui Liu",
      "Jimmy Dani",
      "Yinzhi Cao",
      "Shujiang Wu",
      "Nitesh Saxena"
    ],
    "abstract": "While advertising has become commonplace in today's online interactions,\nthere is a notable dearth of research investigating the extent to which browser\nfingerprinting is harnessed for user tracking and targeted advertising. Prior\nstudies only measured whether fingerprinting-related scripts are being run on\nthe websites but that in itself does not necessarily mean that fingerprinting\nis being used for the privacy-invasive purpose of online tracking because\nfingerprinting might be deployed for the defensive purposes of bot/fraud\ndetection and user authentication. It is imperative to address the mounting\nconcerns regarding the utilization of browser fingerprinting in the realm of\nonline advertising.\n  This paper introduces ``FPTrace'' (fingerprinting-based tracking assessment\nand comprehensive evaluation framework), a framework to assess\nfingerprinting-based user tracking by analyzing ad changes from browser\nfingerprinting adjustments. Using FPTrace, we emulate user interactions,\ncapture ad bid data, and monitor HTTP traffic. Our large-scale study reveals\nstrong evidence of browser fingerprinting for ad tracking and targeting, shown\nby bid value disparities and reduced HTTP records after fingerprinting changes.\nWe also show fingerprinting can bypass GDPR/CCPA opt-outs, enabling\nprivacy-invasive tracking.\n  In conclusion, our research unveils the widespread employment of browser\nfingerprinting in online advertising, prompting critical considerations\nregarding user privacy and data security within the digital advertising\nlandscape.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-09-24T01:39:16+00:00",
    "updated": "2025-02-19T12:34:29+00:00",
    "url": "http://arxiv.org/pdf/2409.15656v2"
  },
  {
    "id": "2409.13406v1",
    "title": "Credit Card Fraud Detection: A Deep Learning Approach",
    "authors": [
      "Sourav Verma",
      "Joydip Dhar"
    ],
    "abstract": "Credit card is one of the most extensive methods of instalment for both\nonline and offline mode of payment for electronic transactions in recent times.\ncredit cards invention has provided significant ease in electronic\ntransactions. However, it has also provided new fraud opportunities for\ncriminals, which results in increased fraud rates. Substantial amount of money\nhas been lost by many institutions and individuals due to fraudulent credit\ncard transactions. Adapting improved and dynamic fraud recognition frameworks\nthus became essential for all credit card distributing banks to mitigate their\nlosses. In fact, the problem of fraudulent credit card transactions implicates\na number of relevant real-time challenges, namely: Concept drift, Class\nimbalance, and Verification latency. However, the vast majority of current\nsystems are based on artificial intelligence (AI), Fuzzy logic, Machine\nLearning, Data mining, Genetic Algorithms, and so on, rely on assumptions that\nhardly address all the relevant challenges of fraud-detection system (FDS).\nThis paper aims to understand & implement Deep Learning algorithms in order to\nobtain a high fraud coverage with very low false positive rate. Also, it aims\nto implement an auto-encoder as an unsupervised (semi-supervised) method of\nlearning common patterns. Keywords: Credit card fraud, Fraud-detection system\n(FDS), Electronic transactions, Concept drift, Class imbalance, Verification\nlatency, Machine Learning, Deep Learning",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-09-20T11:13:16+00:00",
    "updated": "2024-09-20T11:13:16+00:00",
    "url": "http://arxiv.org/pdf/2409.13406v1"
  },
  {
    "id": "2409.13349v2",
    "title": "ID-Guard: A Universal Framework for Combating Facial Manipulation via Breaking Identification",
    "authors": [
      "Zuomin Qu",
      "Wei Lu",
      "Xiangyang Luo",
      "Qian Wang",
      "Xiaochun Cao"
    ],
    "abstract": "The misuse of deep learning-based facial manipulation poses a significant\nthreat to civil rights. To prevent this fraud at its source, proactive defense\nhas been proposed to disrupt the manipulation process by adding invisible\nadversarial perturbations into images, making the forged output unconvincing to\nobservers. However, the non-specific disruption against the output may lead to\nthe retention of identifiable facial features, potentially resulting in the\nstigmatization of the individual. This paper proposes a universal framework for\ncombating facial manipulation, termed ID-Guard. Specifically, this framework\noperates with a single forward pass of an encoder-decoder network to produce a\ncross-model transferable adversarial perturbation. A novel Identity Destruction\nModule (IDM) is introduced to degrade identifiable features in forged faces. We\noptimize the perturbation generation by framing the disruption of different\nfacial manipulations as a multi-task learning problem, and a dynamic weight\nstrategy is devised to enhance cross-model performance. Experimental results\ndemonstrate that the proposed ID-Guard exhibits strong efficacy in defending\nagainst various facial manipulation models, effectively degrading identifiable\nregions in manipulated images. It also enables disrupted images to evade facial\ninpainting and image recognition systems. Additionally, ID-Guard can seamlessly\nfunction as a plug-and-play component, integrating with other tasks such as\nadversarial training.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2024-09-20T09:30:08+00:00",
    "updated": "2025-04-10T07:58:51+00:00",
    "url": "http://arxiv.org/pdf/2409.13349v2"
  },
  {
    "id": "2409.11876v1",
    "title": "QUBO-based SVM for credit card fraud detection on a real QPU",
    "authors": [
      "Ettore Canonici",
      "Filippo Caruso"
    ],
    "abstract": "Among all the physical platforms for the realization of a Quantum Processing\nUnit (QPU), neutral atom devices are emerging as one of the main players. Their\nscalability, long coherence times, and the absence of manufacturing errors make\nthem a viable candidate.. Here, we use a binary classifier model whose training\nis reformulated as a Quadratic Unconstrained Binary Optimization (QUBO) problem\nand implemented on a neutral atom QPU. In particular, we test it on a Credit\nCard Fraud (CCF) dataset. We propose several versions of the model, including\nexploiting the model in ensemble learning schemes. We show that one of our\nproposed versions seems to achieve higher performance and lower errors,\nvalidating our claims by comparing the most popular Machine Learning (ML)\nmodels with QUBO SVM models trained with ideal, noisy simulations and even via\na real QPU. In addition, the data obtained via real QPU extend up to 24 atoms,\nconfirming the model's noise robustness. We also show, by means of numerical\nsimulations, how a certain amount of noise leads surprisingly to enhanced\nresults. Our results represent a further step towards new quantum ML algorithms\nrunning on neutral atom QPUs for cybersecurity applications.",
    "categories": [
      "quant-ph",
      "81V45 (Primary) 81P68 (Secondary)",
      "I.2.0; J.2; I.5.0"
    ],
    "published": "2024-09-18T11:11:25+00:00",
    "updated": "2024-09-18T11:11:25+00:00",
    "url": "http://arxiv.org/pdf/2409.11876v1"
  },
  {
    "id": "2409.10951v1",
    "title": "Fair Anomaly Detection For Imbalanced Groups",
    "authors": [
      "Ziwei Wu",
      "Lecheng Zheng",
      "Yuancheng Yu",
      "Ruizhong Qiu",
      "John Birge",
      "Jingrui He"
    ],
    "abstract": "Anomaly detection (AD) has been widely studied for decades in many real-world\napplications, including fraud detection in finance, and intrusion detection for\ncybersecurity, etc. Due to the imbalanced nature between protected and\nunprotected groups and the imbalanced distributions of normal examples and\nanomalies, the learning objectives of most existing anomaly detection methods\ntend to solely concentrate on the dominating unprotected group. Thus, it has\nbeen recognized by many researchers about the significance of ensuring model\nfairness in anomaly detection. However, the existing fair anomaly detection\nmethods tend to erroneously label most normal examples from the protected group\nas anomalies in the imbalanced scenario where the unprotected group is more\nabundant than the protected group. This phenomenon is caused by the improper\ndesign of learning objectives, which statistically focus on learning the\nfrequent patterns (i.e., the unprotected group) while overlooking the\nunder-represented patterns (i.e., the protected group). To address these\nissues, we propose FairAD, a fairness-aware anomaly detection method targeting\nthe imbalanced scenario. It consists of a fairness-aware contrastive learning\nmodule and a rebalancing autoencoder module to ensure fairness and handle the\nimbalanced data issue, respectively. Moreover, we provide the theoretical\nanalysis that shows our proposed contrastive learning regularization guarantees\ngroup fairness. Empirical studies demonstrate the effectiveness and efficiency\nof FairAD across multiple real-world datasets.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-09-17T07:38:45+00:00",
    "updated": "2024-09-17T07:38:45+00:00",
    "url": "http://arxiv.org/pdf/2409.10951v1"
  },
  {
    "id": "2409.10850v1",
    "title": "An Anti-disguise Authentication System Using the First Impression of Avatar in Metaverse",
    "authors": [
      "Zhenyong Zhang",
      "Kedi Yang",
      "Youliang Tian",
      "Jianfeng Ma"
    ],
    "abstract": "Metaverse is a vast virtual world parallel to the physical world, where the\nuser acts as an avatar to enjoy various services that break through the\ntemporal and spatial limitations of the physical world. Metaverse allows users\nto create arbitrary digital appearances as their own avatars by which an\nadversary may disguise his/her avatar to fraud others. In this paper, we\npropose an anti-disguise authentication method that draws on the idea of the\nfirst impression from the physical world to recognize an old friend.\nSpecifically, the first meeting scenario in the metaverse is stored and\nrecalled to help the authentication between avatars. To prevent the adversary\nfrom replacing and forging the first impression, we construct a chameleon-based\nsigncryption mechanism and design a ciphertext authentication protocol to\nensure the public verifiability of encrypted identities. The security analysis\nshows that the proposed signcryption mechanism meets not only the security\nrequirement but also the public verifiability. Besides, the ciphertext\nauthentication protocol has the capability of defending against the replacing\nand forging attacks on the first impression. Extensive experiments show that\nthe proposed avatar authentication system is able to achieve anti-disguise\nauthentication at a low storage consumption on the blockchain.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-09-17T02:37:44+00:00",
    "updated": "2024-09-17T02:37:44+00:00",
    "url": "http://arxiv.org/pdf/2409.10850v1"
  },
  {
    "id": "2412.00020v1",
    "title": "Partitioning Message Passing for Graph Fraud Detection",
    "authors": [
      "Wei Zhuo",
      "Zemin Liu",
      "Bryan Hooi",
      "Bingsheng He",
      "Guang Tan",
      "Rizal Fathony",
      "Jia Chen"
    ],
    "abstract": "Label imbalance and homophily-heterophily mixture are the fundamental\nproblems encountered when applying Graph Neural Networks (GNNs) to Graph Fraud\nDetection (GFD) tasks. Existing GNN-based GFD models are designed to augment\ngraph structure to accommodate the inductive bias of GNNs towards homophily, by\nexcluding heterophilic neighbors during message passing. In our work, we argue\nthat the key to applying GNNs for GFD is not to exclude but to {\\em\ndistinguish} neighbors with different labels. Grounded in this perspective, we\nintroduce Partitioning Message Passing (PMP), an intuitive yet effective\nmessage passing paradigm expressly crafted for GFD. Specifically, in the\nneighbor aggregation stage of PMP, neighbors with different classes are\naggregated with distinct node-specific aggregation functions. By this means,\nthe center node can adaptively adjust the information aggregated from its\nheterophilic and homophilic neighbors, thus avoiding the model gradient being\ndominated by benign nodes which occupy the majority of the population. We\ntheoretically establish a connection between the spatial formulation of PMP and\nspectral analysis to characterize that PMP operates an adaptive node-specific\nspectral graph filter, which demonstrates the capability of PMP to handle\nheterophily-homophily mixed graphs. Extensive experimental results show that\nPMP can significantly boost the performance on GFD tasks.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "published": "2024-11-16T11:30:53+00:00",
    "updated": "2024-11-16T11:30:53+00:00",
    "url": "http://arxiv.org/pdf/2412.00020v1"
  },
  {
    "id": "2411.07224v1",
    "title": "TempCharBERT: Keystroke Dynamics for Continuous Access Control Based on Pre-trained Language Models",
    "authors": [
      "Matheus Simão",
      "Fabiano Prado",
      "Omar Abdul Wahab",
      "Anderson Avila"
    ],
    "abstract": "With the widespread of digital environments, reliable authentication and\ncontinuous access control has become crucial. It can minimize cyber attacks and\nprevent frauds, specially those associated with identity theft. A particular\ninterest lies on keystroke dynamics (KD), which refers to the task of\nrecognizing individuals' identity based on their unique typing style. In this\nwork, we propose the use of pre-trained language models (PLMs) to recognize\nsuch patterns. Although PLMs have shown high performance on multiple NLP\nbenchmarks, the use of these models on specific tasks requires customization.\nBERT and RoBERTa, for instance, rely on subword tokenization, and they cannot\nbe directly applied to KD, which requires temporal-character information to\nrecognize users. Recent character-aware PLMs are able to process both subwords\nand character-level information and can be an alternative solution.\nNotwithstanding, they are still not suitable to be directly fine-tuned for KD\nas they are not optimized to account for user's temporal typing information\n(e.g., hold time and flight time). To overcome this limitation, we propose\nTempCharBERT, an architecture that incorporates temporal-character information\nin the embedding layer of CharBERT. This allows modeling keystroke dynamics for\nthe purpose of user identification and authentication. Our results show a\nsignificant improvement with this customization. We also showed the feasibility\nof training TempCharBERT on a federated learning settings in order to foster\ndata privacy.",
    "categories": [
      "cs.CR",
      "cs.CL"
    ],
    "published": "2024-11-11T18:44:17+00:00",
    "updated": "2024-11-11T18:44:17+00:00",
    "url": "http://arxiv.org/pdf/2411.07224v1"
  },
  {
    "id": "2411.06772v1",
    "title": "A Text Classification Model Combining Adversarial Training with Pre-trained Language Model and neural networks: A Case Study on Telecom Fraud Incident Texts",
    "authors": [
      "Liu Zhuoxian",
      "Shi Tuo",
      "Hu Xiaofeng"
    ],
    "abstract": "Front-line police officers often categorize all police call reported cases of\nTelecom Fraud into 14 subcategories to facilitate targeted prevention measures,\nsuch as precise public education. However, the associated data is characterized\nby its large volume, diverse information content, and variations in expression.\nCurrently, there is a lack of efficient and accurate intelligent models to\nreplace manual classification, which, while precise, is relatively inefficient.\nTo address these challenges, this paper proposes a text classification model\nthat combines adversarial training with Pre-trained Language Model and neural\nnetworks. The Linguistically-motivated Pre-trained Language Model model\nextracts three types of language features and then utilizes the Fast Gradient\nMethod algorithm to perturb the generated embedding layer. Subsequently, the\nBi-directional Long Short-Term Memory and Convolutional Neural Networks\nnetworks extract contextual syntactic information and local semantic\ninformation, respectively. The model achieved an 83.9% classification accuracy\nwhen trained on a portion of telecom fraud case data provided by the\noperational department. The model established in this paper has been deployed\nin the operational department, freeing up a significant amount of manpower and\nimproving the department's efficiency in combating Telecom Fraud crimes.\nFurthermore, considering the universality of the model established in this\npaper, other application scenarios await further exploration.",
    "categories": [
      "cs.AI"
    ],
    "published": "2024-11-11T07:52:38+00:00",
    "updated": "2024-11-11T07:52:38+00:00",
    "url": "http://arxiv.org/pdf/2411.06772v1"
  },
  {
    "id": "2411.06749v1",
    "title": "KLCBL: An Improved Police Incident Classification Model",
    "authors": [
      "Liu Zhuoxian",
      "Shi Tuo",
      "Hu Xiaofeng"
    ],
    "abstract": "Police incident data is crucial for public security intelligence, yet\ngrassroots agencies struggle with efficient classification due to manual\ninefficiency and automated system limitations, especially in telecom and online\nfraud cases. This research proposes a multichannel neural network model, KLCBL,\nintegrating Kolmogorov-Arnold Networks (KAN), a linguistically enhanced text\npreprocessing approach (LERT), Convolutional Neural Network (CNN), and\nBidirectional Long Short-Term Memory (BiLSTM) for police incident\nclassification. Evaluated with real data, KLCBL achieved 91.9% accuracy,\noutperforming baseline models. The model addresses classification challenges,\nenhances police informatization, improves resource allocation, and offers broad\napplicability to other classification tasks.",
    "categories": [
      "cs.AI"
    ],
    "published": "2024-11-11T07:02:23+00:00",
    "updated": "2024-11-11T07:02:23+00:00",
    "url": "http://arxiv.org/pdf/2411.06749v1"
  },
  {
    "id": "2411.06538v1",
    "title": "A Next-Generation Approach to Airline Reservations: Integrating Cloud Microservices with AI and Blockchain for Enhanced Operational Performance",
    "authors": [
      "Biman Barua",
      "M. Shamim Kaiser"
    ],
    "abstract": "This research proposes the development of a next generation airline\nreservation system that incorporates the Cloud microservices, distributed\nartificial intelligence modules and the blockchain technology to improve on the\nefficiency, safety and customer satisfaction. The traditional reservation\nsystems encounter issues related to the expansion of the systems, the integrity\nof the data provided and the level of service offered to the customers, which\nis the main focus of this architecture through the modular and data centric\ndesign approaches. This will allow different operations such as reservations,\npayments, and customer data management among others to be performed separately\nthereby facilitating high availability of the system by 30% and enhancing\nperformance of the system by 40% on its scalability. Such systems contain AI\ndriven modules that utilize the past booking patterns along with the profile of\nthe customer to estimate the demand and make recommendations, which increases\nto 25 % of customer engagement. Moreover, blockchain is effective in engaging\nan incorruptible ledger system for the all transactions therefore mitigating\nfraud incidences and increasing the clarity by 20%. The system was subjected to\nanalysis using a simulator and using machine learning evaluations that rated it\nagainst other conventional systems. The results show that there were clear\nenhancements in the speed of transactions where the rates of secure data\nprocessing rose by 35%, and the system response time by 15 %. The system can\nalso be used for other high transaction industries like logistics and\nhospitality. This structural design is indicative of how the use of advanced\ntechnologies will revolutionize the airline reservation sector. The\nimplications are growing effectiveness, improvement in security and greater\ncustomer contentment.",
    "categories": [
      "cs.AI",
      "cs.CE"
    ],
    "published": "2024-11-10T17:38:30+00:00",
    "updated": "2024-11-10T17:38:30+00:00",
    "url": "http://arxiv.org/pdf/2411.06538v1"
  },
  {
    "id": "2411.05733v1",
    "title": "Differential Privacy Under Class Imbalance: Methods and Empirical Insights",
    "authors": [
      "Lucas Rosenblatt",
      "Yuliia Lut",
      "Eitan Turok",
      "Marco Avella-Medina",
      "Rachel Cummings"
    ],
    "abstract": "Imbalanced learning occurs in classification settings where the distribution\nof class-labels is highly skewed in the training data, such as when predicting\nrare diseases or in fraud detection. This class imbalance presents a\nsignificant algorithmic challenge, which can be further exacerbated when\nprivacy-preserving techniques such as differential privacy are applied to\nprotect sensitive training data. Our work formalizes these challenges and\nprovides a number of algorithmic solutions. We consider DP variants of\npre-processing methods that privately augment the original dataset to reduce\nthe class imbalance; these include oversampling, SMOTE, and private synthetic\ndata generation. We also consider DP variants of in-processing techniques,\nwhich adjust the learning algorithm to account for the imbalance; these include\nmodel bagging, class-weighted empirical risk minimization and class-weighted\ndeep learning. For each method, we either adapt an existing imbalanced learning\ntechnique to the private setting or demonstrate its incompatibility with\ndifferential privacy. Finally, we empirically evaluate these privacy-preserving\nimbalanced learning methods under various data and distributional settings. We\nfind that private synthetic data methods perform well as a data pre-processing\nstep, while class-weighted ERMs are an alternative in higher-dimensional\nsettings where private synthetic data suffers from the curse of dimensionality.",
    "categories": [
      "cs.LG",
      "cs.CR",
      "68P27",
      "I.2.0; F.0; G.3; J.0"
    ],
    "published": "2024-11-08T17:46:56+00:00",
    "updated": "2024-11-08T17:46:56+00:00",
    "url": "http://arxiv.org/pdf/2411.05733v1"
  },
  {
    "id": "2411.05463v1",
    "title": "Dave: a decentralized, secure, and lively fraud-proof algorithm",
    "authors": [
      "Diego Nehab",
      "Gabriel Coutinho de Paula",
      "Augusto Teixeira"
    ],
    "abstract": "In this paper, we introduce a new fraud-proof algorithm that offers an\nunprecedented combination of decentralization, security, and liveness. The\nresources that must be mobilized by an honest participant to defeat an\nadversary grow only logarithmically with what the adversary ultimately loses.\nAs a consequence, there is no need to introduce high bonds that prevent an\nadversary from creating too many Sybils. This makes the system very inclusive\nand frees participants from having to pool resources among themselves to engage\nthe protocol. Finally, the maximum delay to finalization also grows only\nlogarithmically with total adversarial expenditure, with the smallest\nmultiplicative factor to date. In summary: the entire dispute completes in 2--5\nchallenge periods, the only way to break consensus is to censor the honest\nparty for more than one challenge period, and the costs of engaging in the\ndispute are minimal.",
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "published": "2024-11-08T10:31:05+00:00",
    "updated": "2024-11-08T10:31:05+00:00",
    "url": "http://arxiv.org/pdf/2411.05463v1"
  },
  {
    "id": "2411.04459v1",
    "title": "GPT-Guided Monte Carlo Tree Search for Symbolic Regression in Financial Fraud Detection",
    "authors": [
      "Prashank Kadam"
    ],
    "abstract": "With the increasing number of financial services available online, the rate\nof financial fraud has also been increasing. The traffic and transaction rates\non the internet have increased considerably, leading to a need for fast\ndecision-making. Financial institutions also have stringent regulations that\noften require transparency and explainability of the decision-making process.\nHowever, most state-of-the-art algorithms currently used in the industry are\nhighly parameterized black-box models that rely on complex computations to\ngenerate a score. These algorithms are inherently slow and lack the\nexplainability and speed of traditional rule-based learners. This work\nintroduces SR-MCTS (Symbolic Regression MCTS), which utilizes a foundational\nGPT model to guide the MCTS, significantly enhancing its convergence speed and\nthe quality of the generated expressions which are further extracted to rules.\nOur experiments show that SR-MCTS can detect fraud more efficiently than widely\nused methods in the industry while providing substantial insights into the\ndecision-making process.",
    "categories": [
      "cs.CE",
      "cs.LG",
      "J.1"
    ],
    "published": "2024-11-07T06:12:38+00:00",
    "updated": "2024-11-07T06:12:38+00:00",
    "url": "http://arxiv.org/pdf/2411.04459v1"
  },
  {
    "id": "2411.05859v1",
    "title": "Enhancing Financial Fraud Detection with Human-in-the-Loop Feedback and Feedback Propagation",
    "authors": [
      "Prashank Kadam"
    ],
    "abstract": "Human-in-the-loop (HITL) feedback mechanisms can significantly enhance\nmachine learning models, particularly in financial fraud detection, where fraud\npatterns change rapidly, and fraudulent nodes are sparse. Even small amounts of\nfeedback from Subject Matter Experts (SMEs) can notably boost model\nperformance. This paper examines the impact of HITL feedback on both\ntraditional and advanced techniques using proprietary and publicly available\ndatasets. Our results show that HITL feedback improves model accuracy, with\ngraph-based techniques benefiting the most. We also introduce a novel feedback\npropagation method that extends feedback across the dataset, further enhancing\ndetection accuracy. By leveraging human expertise, this approach addresses\nchallenges related to evolving fraud patterns, data sparsity, and model\ninterpretability, ultimately improving model robustness and streamlining the\nannotation process.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "J.1"
    ],
    "published": "2024-11-07T05:22:36+00:00",
    "updated": "2024-11-07T05:22:36+00:00",
    "url": "http://arxiv.org/pdf/2411.05859v1"
  },
  {
    "id": "2411.05857v2",
    "title": "Financial Fraud Detection using Jump-Attentive Graph Neural Networks",
    "authors": [
      "Prashank Kadam"
    ],
    "abstract": "As the availability of financial services online continues to grow, the\nincidence of fraud has surged correspondingly. Fraudsters continually seek new\nand innovative ways to circumvent the detection algorithms in place.\nTraditionally, fraud detection relied on rule-based methods, where rules were\nmanually created based on transaction data features. However, these techniques\nsoon became ineffective due to their reliance on manual rule creation and their\ninability to detect complex data patterns. Today, a significant portion of the\nfinancial services sector employs various machine learning algorithms, such as\nXGBoost, Random Forest, and neural networks, to model transaction data. While\nthese techniques have proven more efficient than rule-based methods, they still\nfail to capture interactions between different transactions and their\ninterrelationships. Recently, graph-based techniques have been adopted for\nfinancial fraud detection, leveraging graph topology to aggregate neighborhood\ninformation of transaction data using Graph Neural Networks (GNNs). Despite\nshowing improvements over previous methods, these techniques still struggle to\nkeep pace with the evolving camouflaging tactics of fraudsters and suffer from\ninformation loss due to over-smoothing. In this paper, we propose a novel\nalgorithm that employs an efficient neighborhood sampling method, effective for\ncamouflage detection and preserving crucial feature information from\nnon-similar nodes. Additionally, we introduce a novel GNN architecture that\nutilizes attention mechanisms and preserves holistic neighborhood information\nto prevent information loss. We test our algorithm on financial data to show\nthat our method outperforms other state-of-the-art graph algorithms.",
    "categories": [
      "cs.LG",
      "cs.CR",
      "J.1"
    ],
    "published": "2024-11-07T05:12:51+00:00",
    "updated": "2024-11-22T18:34:58+00:00",
    "url": "http://arxiv.org/pdf/2411.05857v2"
  },
  {
    "id": "2411.02695v1",
    "title": "JEL: Applying End-to-End Neural Entity Linking in JPMorgan Chase",
    "authors": [
      "Wanying Ding",
      "Vinay K. Chaudhri",
      "Naren Chittar",
      "Krishna Konakanchi"
    ],
    "abstract": "Knowledge Graphs have emerged as a compelling abstraction for capturing key\nrelationship among the entities of interest to enterprises and for integrating\ndata from heterogeneous sources. JPMorgan Chase (JPMC) is leading this trend by\nleveraging knowledge graphs across the organization for multiple mission\ncritical applications such as risk assessment, fraud detection, investment\nadvice, etc. A core problem in leveraging a knowledge graph is to link mentions\n(e.g., company names) that are encountered in textual sources to entities in\nthe knowledge graph. Although several techniques exist for entity linking, they\nare tuned for entities that exist in Wikipedia, and fail to generalize for the\nentities that are of interest to an enterprise. In this paper, we propose a\nnovel end-to-end neural entity linking model (JEL) that uses minimal context\ninformation and a margin loss to generate entity embeddings, and a Wide & Deep\nLearning model to match character and semantic information respectively. We\nshow that JEL achieves the state-of-the-art performance to link mentions of\ncompany names in financial news with entities in our knowledge graph. We report\non our efforts to deploy this model in the company-wide system to generate\nalerts in response to financial news. The methodology used for JEL is directly\napplicable and usable by other enterprises who need entity linking solutions\nfor data that are unique to their respective situations.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2024-11-05T00:46:25+00:00",
    "updated": "2024-11-05T00:46:25+00:00",
    "url": "http://arxiv.org/pdf/2411.02695v1"
  },
  {
    "id": "2411.00431v1",
    "title": "Integrating Fuzzy Logic into Deep Symbolic Regression",
    "authors": [
      "Wout Gerdes",
      "Erman Acar"
    ],
    "abstract": "Credit card fraud detection is a critical concern for financial institutions,\nintensified by the rise of contactless payment technologies. While deep\nlearning models offer high accuracy, their lack of explainability poses\nsignificant challenges in financial settings. This paper explores the\nintegration of fuzzy logic into Deep Symbolic Regression (DSR) to enhance both\nperformance and explainability in fraud detection. We investigate the\neffectiveness of different fuzzy logic implications, specifically\n{\\L}ukasiewicz, G\\\"odel, and Product, in handling the complexity and\nuncertainty of fraud detection datasets. Our analysis suggest that the\n{\\L}ukasiewicz implication achieves the highest F1-score and overall accuracy,\nwhile the Product implication offers a favorable balance between performance\nand explainability. Despite having a performance lower than state-of-the-art\n(SOTA) models due to information loss in data transformation, our approach\nprovides novelty and insights into into integrating fuzzy logic into DSR for\nfraud detection, providing a comprehensive comparison between different\nimplications and methods.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "cs.SC"
    ],
    "published": "2024-11-01T07:55:17+00:00",
    "updated": "2024-11-01T07:55:17+00:00",
    "url": "http://arxiv.org/pdf/2411.00431v1"
  },
  {
    "id": "2411.00368v1",
    "title": "A Machine Learning Driven Website Platform and Browser Extension for Real-time Scoring and Fraud Detection for Website Legitimacy Verification and Consumer Protection",
    "authors": [
      "Md Kamrul Hasan Chy",
      "Obed Nana Buadi"
    ],
    "abstract": "This paper introduces a Machine Learning-Driven website Platform and Browser\nExtension designed to quickly enhance online security by providing real-time\nrisk scoring and fraud detection for website legitimacy verification and\nconsumer protection. The platform works seamlessly in the background to analyze\nwebsite behavior, network traffic, and user interactions, offering immediate\nfeedback and alerts when potential threats are detected. By integrating this\nsystem into a user-friendly browser extension, the platform empowers\nindividuals to navigate the web safely, reducing the risk of engaging with\nfraudulent websites. Its real-time functionality is crucial in e-commerce and\neveryday browsing, where quick, actionable insights can prevent financial\nlosses, identity theft, and exposure to malicious sites. This paper explores\nhow this solution offers a practical, fast-acting tool for enhancing online\nconsumer protection, underscoring its potential to play a critical role in\nsafeguarding users and maintaining trust in digital transactions. The\nplatform's focus on speed and efficiency makes it an essential asset for\npreventing fraud in today's increasingly digital world.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2024-11-01T05:13:18+00:00",
    "updated": "2024-11-01T05:13:18+00:00",
    "url": "http://arxiv.org/pdf/2411.00368v1"
  },
  {
    "id": "2411.05815v2",
    "title": "Graph Neural Networks for Financial Fraud Detection: A Review",
    "authors": [
      "Dawei Cheng",
      "Yao Zou",
      "Sheng Xiang",
      "Changjun Jiang"
    ],
    "abstract": "The landscape of financial transactions has grown increasingly complex due to\nthe expansion of global economic integration and advancements in information\ntechnology. This complexity poses greater challenges in detecting and managing\nfinancial fraud. This review explores the role of Graph Neural Networks (GNNs)\nin addressing these challenges by proposing a unified framework that\ncategorizes existing GNN methodologies applied to financial fraud detection.\nSpecifically, by examining a series of detailed research questions, this review\ndelves into the suitability of GNNs for financial fraud detection, their\ndeployment in real-world scenarios, and the design considerations that enhance\ntheir effectiveness. This review reveals that GNNs are exceptionally adept at\ncapturing complex relational patterns and dynamics within financial networks,\nsignificantly outperforming traditional fraud detection methods. Unlike\nprevious surveys that often overlook the specific potentials of GNNs or address\nthem only superficially, our review provides a comprehensive, structured\nanalysis, distinctly focusing on the multifaceted applications and deployments\nof GNNs in financial fraud detection. This review not only highlights the\npotential of GNNs to improve fraud detection mechanisms but also identifies\ncurrent gaps and outlines future research directions to enhance their\ndeployment in financial systems. Through a structured review of over 100\nstudies, this review paper contributes to the understanding of GNN applications\nin financial fraud detection, offering insights into their adaptability and\npotential integration strategies.",
    "categories": [
      "q-fin.ST",
      "cs.LG"
    ],
    "published": "2024-11-01T03:59:57+00:00",
    "updated": "2024-11-17T03:01:05+00:00",
    "url": "http://arxiv.org/pdf/2411.05815v2"
  },
  {
    "id": "2410.23563v1",
    "title": "Across-Platform Detection of Malicious Cryptocurrency Transactions via Account Interaction Learning",
    "authors": [
      "Zheng Che",
      "Meng Shen",
      "Zhehui Tan",
      "Hanbiao Du",
      "Liehuang Zhu",
      "Wei Wang",
      "Ting Chen",
      "Qinglin Zhao",
      "Yong Xie"
    ],
    "abstract": "With the rapid evolution of Web3.0, cryptocurrency has become a cornerstone\nof decentralized finance. While these digital assets enable efficient and\nborderless financial transactions, their pseudonymous nature has also attracted\nmalicious activities such as money laundering, fraud, and other financial\ncrimes. Effective detection of malicious transactions is crucial to maintaining\nthe security and integrity of the Web 3.0 ecosystem. Existing malicious\ntransaction detection methods rely on large amounts of labeled data and suffer\nfrom low generalization. Label-efficient and generalizable malicious\ntransaction detection remains a challenging task. In this paper, we propose\nShadowEyes, a novel malicious transaction detection method. Specifically, we\nfirst propose a generalized graph structure named TxGraph as a representation\nof malicious transaction, which captures the interaction features of each\nmalicious account and its neighbors. Then we carefully design a data\naugmentation method tailored to simulate the evolution of malicious\ntransactions to generate positive pairs. To alleviate account label scarcity,\nwe further design a graph contrastive mechanism, which enables ShadowEyes to\nlearn discriminative features effectively from unlabeled data, thereby\nenhancing its detection capabilities in real-world scenarios. We conduct\nextensive experiments using public datasets to evaluate the performance of\nShadowEyes. The results demonstrate that it outperforms state-of-the-art (SOTA)\nmethods in four typical scenarios. Specifically, in the zero-shot learning\nscenario, it can achieve an F1 score of 76.98% for identifying gambling\ntransactions, surpassing the SOTA method by12.05%. In the scenario of\nacross-platform malicious transaction detection, ShadowEyes maintains an F1\nscore of around 90%, which is 10% higher than the SOTA method.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-10-31T02:01:42+00:00",
    "updated": "2024-10-31T02:01:42+00:00",
    "url": "http://arxiv.org/pdf/2410.23563v1"
  },
  {
    "id": "2410.21928v1",
    "title": "Differentiable Inductive Logic Programming for Fraud Detection",
    "authors": [
      "Boris Wolfson",
      "Erman Acar"
    ],
    "abstract": "Current trends in Machine Learning prefer explainability even when it comes\nat the cost of performance. Therefore, explainable AI methods are particularly\nimportant in the field of Fraud Detection. This work investigates the\napplicability of Differentiable Inductive Logic Programming (DILP) as an\nexplainable AI approach to Fraud Detection. Although the scalability of DILP is\na well-known issue, we show that with some data curation such as cleaning and\nadjusting the tabular and numerical data to the expected format of background\nfacts statements, it becomes much more applicable. While in processing it does\nnot provide any significant advantage on rather more traditional methods such\nas Decision Trees, or more recent ones like Deep Symbolic Classification, it\nstill gives comparable results. We showcase its limitations and points to\nimprove, as well as potential use cases where it can be much more useful\ncompared to traditional methods, such as recursive rule learning.",
    "categories": [
      "q-fin.RM",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2024-10-29T10:43:06+00:00",
    "updated": "2024-10-29T10:43:06+00:00",
    "url": "http://arxiv.org/pdf/2410.21928v1"
  },
  {
    "id": "2410.21484v1",
    "title": "A Systematic Review of Machine Learning in Sports Betting: Techniques, Challenges, and Future Directions",
    "authors": [
      "René Manassé Galekwa",
      "Jean Marie Tshimula",
      "Etienne Gael Tajeuna",
      "Kyamakya Kyandoghere"
    ],
    "abstract": "The sports betting industry has experienced rapid growth, driven largely by\ntechnological advancements and the proliferation of online platforms. Machine\nlearning (ML) has played a pivotal role in the transformation of this sector by\nenabling more accurate predictions, dynamic odds-setting, and enhanced risk\nmanagement for both bookmakers and bettors. This systematic review explores\nvarious ML techniques, including support vector machines, random forests, and\nneural networks, as applied in different sports such as soccer, basketball,\ntennis, and cricket. These models utilize historical data, in-game statistics,\nand real-time information to optimize betting strategies and identify value\nbets, ultimately improving profitability. For bookmakers, ML facilitates\ndynamic odds adjustment and effective risk management, while bettors leverage\ndata-driven insights to exploit market inefficiencies. This review also\nunderscores the role of ML in fraud detection, where anomaly detection models\nare used to identify suspicious betting patterns. Despite these advancements,\nchallenges such as data quality, real-time decision-making, and the inherent\nunpredictability of sports outcomes remain. Ethical concerns related to\ntransparency and fairness are also of significant importance. Future research\nshould focus on developing adaptive models that integrate multimodal data and\nmanage risk in a manner akin to financial portfolios. This review provides a\ncomprehensive examination of the current applications of ML in sports betting,\nand highlights both the potential and the limitations of these technologies.",
    "categories": [
      "cs.LG",
      "cs.CE",
      "cs.ET",
      "cs.IR",
      "cs.SI"
    ],
    "published": "2024-10-28T19:49:53+00:00",
    "updated": "2024-10-28T19:49:53+00:00",
    "url": "http://arxiv.org/pdf/2410.21484v1"
  },
  {
    "id": "2411.00819v1",
    "title": "A Bellman-Ford algorithm for the path-length-weighted distance in graphs",
    "authors": [
      "R. Arnau",
      "J. M. Calabuig",
      "L. M. García Raffi",
      "E. A. Sánchez Pérez",
      "S. Sanjuan"
    ],
    "abstract": "Consider a finite directed graph without cycles in which the arrows are\nweighted. We present an algorithm for the computation of a new distance, called\npath-length-weighted distance, which has proven useful for graph analysis in\nthe context of fraud detection. The idea is that the new distance explicitly\ntakes into account the size of the paths in the calculations. Thus, although\nour algorithm is based on arguments similar to those at work for the\nBellman-Ford and Dijkstra methods, it is in fact essentially different. We lay\nout the appropriate framework for its computation, showing the constraints and\nrequirements for its use, along with some illustrative examples.",
    "categories": [
      "cs.DS",
      "cs.DM",
      "cs.MS",
      "05C38 (Primary) 90C35 (Secondary)"
    ],
    "published": "2024-10-28T15:31:34+00:00",
    "updated": "2024-10-28T15:31:34+00:00",
    "url": "http://arxiv.org/pdf/2411.00819v1"
  },
  {
    "id": "2410.20742v1",
    "title": "Mitigating Unauthorized Speech Synthesis for Voice Protection",
    "authors": [
      "Zhisheng Zhang",
      "Qianyi Yang",
      "Derui Wang",
      "Pengyang Huang",
      "Yuxin Cao",
      "Kai Ye",
      "Jie Hao"
    ],
    "abstract": "With just a few speech samples, it is possible to perfectly replicate a\nspeaker's voice in recent years, while malicious voice exploitation (e.g.,\ntelecom fraud for illegal financial gain) has brought huge hazards in our daily\nlives. Therefore, it is crucial to protect publicly accessible speech data that\ncontains sensitive information, such as personal voiceprints. Most previous\ndefense methods have focused on spoofing speaker verification systems in timbre\nsimilarity but the synthesized deepfake speech is still of high quality. In\nresponse to the rising hazards, we devise an effective, transferable, and\nrobust proactive protection technology named Pivotal Objective Perturbation\n(POP) that applies imperceptible error-minimizing noises on original speech\nsamples to prevent them from being effectively learned for text-to-speech (TTS)\nsynthesis models so that high-quality deepfake speeches cannot be generated. We\nconduct extensive experiments on state-of-the-art (SOTA) TTS models utilizing\nobjective and subjective metrics to comprehensively evaluate our proposed\nmethod. The experimental results demonstrate outstanding effectiveness and\ntransferability across various models. Compared to the speech unclarity score\nof 21.94% from voice synthesizers trained on samples without protection,\nPOP-protected samples significantly increase it to 127.31%. Moreover, our\nmethod shows robustness against noise reduction and data augmentation\ntechniques, thereby greatly reducing potential hazards.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "published": "2024-10-28T05:16:37+00:00",
    "updated": "2024-10-28T05:16:37+00:00",
    "url": "http://arxiv.org/pdf/2410.20742v1"
  },
  {
    "id": "2410.20605v2",
    "title": "Design, Implementation and Practical Energy-Efficiency Evaluation of a Blockchain Based Academic Credential Verification System for Low-Power Nodes",
    "authors": [
      "Gabriel Fernández-Blanco",
      "Iván Froiz-Míguez",
      "Paula Fraga-Lamas",
      "Tiago M. Fernández-Caramés"
    ],
    "abstract": "The educational system manages extensive documentation and paperwork, which\ncan lead to human errors and sometimes abuse or fraud, such as the\nfalsification of diplomas, certificates or other credentials. In fact, in the\nlast years, multiple cases of fraud have been detected, which have a\nsignificant cost to society, since they harm the trustworthiness of\ncertificates and academic institutions. To tackle such an issue, this article\nproposes a solution aimed at recording and verifying academic records through a\ndecentralized application that is supported by a smart contract deployed in the\nEthereum blockchain and by a decentralized storage system based on\nInter-Planetary File System (IPFS). The proposed solution is evaluated in terms\nof performance and energy-efficiency, comparing the results obtained with a\ntraditional Proof-of-Work (PoW) consensus protocol and the new\nProof-of-Authority (PoA) protocol. The results shown in this paper indicate\nthat the latter is clearly greener and demands less CPU load. Moreover, this\narticle compares the performance of a traditional computer and two SBCs (a\nRaspberry Pi 4 and an Orange Pi One), showing that is possible to make use of\nthe latter low-power devices to implement blockchain nodes but at the cost of\nhigher response latency. Furthermore, the impact of Ethereum gas limit is\nevaluated, demonstrating its significant influence on the blockchain network\nperformance. Thus, this article provides guidelines, useful practical\nevaluations and key findings that will help the next generation of green\nblockchain developers and researchers.",
    "categories": [
      "cs.DC",
      "cs.CR",
      "cs.CY",
      "cs.SY",
      "eess.SY"
    ],
    "published": "2024-10-27T21:32:20+00:00",
    "updated": "2025-04-01T16:18:58+00:00",
    "url": "http://arxiv.org/pdf/2410.20605v2"
  },
  {
    "id": "2410.20281v1",
    "title": "Proactive Fraud Defense: Machine Learning's Evolving Role in Protecting Against Online Fraud",
    "authors": [
      "Md Kamrul Hasan Chy"
    ],
    "abstract": "As online fraud becomes more sophisticated and pervasive, traditional fraud\ndetection methods are struggling to keep pace with the evolving tactics\nemployed by fraudsters. This paper explores the transformative role of machine\nlearning in addressing these challenges by offering more advanced, scalable,\nand adaptable solutions for fraud detection and prevention. By analyzing key\nmodels such as Random Forest, Neural Networks, and Gradient Boosting, this\npaper highlights the strengths of machine learning in processing vast datasets,\nidentifying intricate fraud patterns, and providing real-time predictions that\nenable a proactive approach to fraud prevention. Unlike rule-based systems that\nreact after fraud has occurred, machine learning models continuously learn from\nnew data, adapting to emerging fraud schemes and reducing false positives,\nwhich ultimately minimizes financial losses. This research emphasizes the\npotential of machine learning to revolutionize fraud detection frameworks by\nmaking them more dynamic, efficient, and capable of handling the growing\ncomplexity of fraud across various industries. Future developments in machine\nlearning, including deep learning and hybrid models, are expected to further\nenhance the predictive accuracy and applicability of these systems, ensuring\nthat organizations remain resilient in the face of new and emerging fraud\ntactics.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-10-26T21:34:28+00:00",
    "updated": "2024-10-26T21:34:28+00:00",
    "url": "http://arxiv.org/pdf/2410.20281v1"
  },
  {
    "id": "2410.21988v1",
    "title": "American Views About Election Fraud in 2024",
    "authors": [
      "Mitchell Linegar",
      "R. Michael Alvarez"
    ],
    "abstract": "What are the opinions of American registered voters about election fraud and\ntypes of election fraud as we head into the final stages of the 2024\nPresidential election? In this paper we use data from an online national survey\nof 2,211 U.S. registered voters interviewed between June 26 - July 3, 2024.\nRespondents were asked how common they thought that ten different types of\nelection fraud might be in the U.S. In our analysis, we show that substantial\nproportions of U.S. registered voters believe that these types of election\nfraud are common. Our multivariate analysis shows that partisanship correlates\nstrongly with endorsement of types of election fraud, with Republicans\nconsistently more likely to state that types of election fraud are common, even\nwhen we control for a wide variety of other factors. We also find that\nconspiratorial thinking is strongly correlated with belief in the occurrence of\ntypes of election fraud, even when we control for partisanship. Our results\nreported in this paper provide important data regarding how American registered\nvoters perceive the prevalence of types of election fraud, just months before\nthe 2024 Presidential election.",
    "categories": [
      "econ.GN",
      "q-fin.EC",
      "J.4.1; J.4.3"
    ],
    "published": "2024-10-25T00:11:05+00:00",
    "updated": "2024-10-25T00:11:05+00:00",
    "url": "http://arxiv.org/pdf/2410.21988v1"
  },
  {
    "id": "2410.17459v1",
    "title": "Data Obfuscation through Latent Space Projection (LSP) for Privacy-Preserving AI Governance: Case Studies in Medical Diagnosis and Finance Fraud Detection",
    "authors": [
      "Mahesh Vaijainthymala Krishnamoorthy"
    ],
    "abstract": "As AI systems increasingly integrate into critical societal sectors, the\ndemand for robust privacy-preserving methods has escalated. This paper\nintroduces Data Obfuscation through Latent Space Projection (LSP), a novel\ntechnique aimed at enhancing AI governance and ensuring Responsible AI\ncompliance. LSP uses machine learning to project sensitive data into a latent\nspace, effectively obfuscating it while preserving essential features for model\ntraining and inference. Unlike traditional privacy methods like differential\nprivacy or homomorphic encryption, LSP transforms data into an abstract,\nlower-dimensional form, achieving a delicate balance between data utility and\nprivacy. Leveraging autoencoders and adversarial training, LSP separates\nsensitive from non-sensitive information, allowing for precise control over\nprivacy-utility trade-offs. We validate LSP's effectiveness through experiments\non benchmark datasets and two real-world case studies: healthcare cancer\ndiagnosis and financial fraud analysis. Our results show LSP achieves high\nperformance (98.7% accuracy in image classification) while providing strong\nprivacy (97.3% protection against sensitive attribute inference), outperforming\ntraditional anonymization and privacy-preserving methods. The paper also\nexamines LSP's alignment with global AI governance frameworks, such as GDPR,\nCCPA, and HIPAA, highlighting its contribution to fairness, transparency, and\naccountability. By embedding privacy within the machine learning pipeline, LSP\noffers a promising approach to developing AI systems that respect privacy while\ndelivering valuable insights. We conclude by discussing future research\ndirections, including theoretical privacy guarantees, integration with\nfederated learning, and enhancing latent space interpretability, positioning\nLSP as a critical tool for ethical AI advancement.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CY",
      "F.2.1; E.3"
    ],
    "published": "2024-10-22T22:31:03+00:00",
    "updated": "2024-10-22T22:31:03+00:00",
    "url": "http://arxiv.org/pdf/2410.17459v1"
  },
  {
    "id": "2410.15951v1",
    "title": "Redefining Finance: The Influence of Artificial Intelligence (AI) and Machine Learning (ML)",
    "authors": [
      "Animesh Kumar"
    ],
    "abstract": "With rapid transformation of technologies, the fusion of Artificial\nIntelligence (AI) and Machine Learning (ML) in finance is disrupting the entire\necosystem and operations which were followed for decades. The current landscape\nis where decisions are increasingly data-driven by financial institutions with\nan appetite for automation while mitigating risks. The segments of financial\ninstitutions which are getting heavily influenced are retail banking, wealth\nmanagement, corporate banking & payment ecosystem. The solution ranges from\nonboarding the customers all the way fraud detection & prevention to enhancing\nthe customer services. Financial Institutes are leap frogging with integration\nof Artificial Intelligence and Machine Learning in mainstream applications and\nenhancing operational efficiency through advanced predictive analytics,\nextending personalized customer experiences, and automation to minimize risk\nwith fraud detection techniques. However, with Adoption of AI & ML, it is\nimperative that the financial institute also needs to address ethical and\nregulatory challenges, by putting in place robust governance frameworks and\nresponsible AI practices.",
    "categories": [
      "cs.AI",
      "68Txx - Artificial Intelligence",
      "I.2.7"
    ],
    "published": "2024-10-21T12:32:17+00:00",
    "updated": "2024-10-21T12:32:17+00:00",
    "url": "http://arxiv.org/pdf/2410.15951v1"
  },
  {
    "id": "2412.12370v5",
    "title": "Scam Detection for Ethereum Smart Contracts: Leveraging Graph Representation Learning for Secure Blockchain",
    "authors": [
      "Yihong Jin",
      "Ze Yang",
      "Xinhe Xu"
    ],
    "abstract": "As more and more attacks have been detected on Ethereum smart contracts, it\nhas seriously affected finance and credibility. Current anti-fraud detection\ntechniques, including code parsing or manual feature extraction, still have\nsome shortcomings, although some generalization or adaptability can be\nobtained. In the face of this situation, this paper proposes to use graphical\nrepresentation learning technology to find transaction patterns and distinguish\nmalicious transaction contracts, that is, to represent Ethereum transaction\ndata as graphs, and then use advanced ML technology to obtain reliable and\naccurate results. Taking into account the sample imbalance, we treated with\nSMOTE-ENN and tested several models, in which MLP performed better than GCN,\nbut the exact effect depends on its field trials. Our research opens up more\npossibilities for trust and security in the Ethereum ecosystem.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.DC",
      "cs.SI",
      "I.2.1"
    ],
    "published": "2024-12-16T21:56:01+00:00",
    "updated": "2025-03-19T05:38:58+00:00",
    "url": "http://arxiv.org/pdf/2412.12370v5"
  },
  {
    "id": "2412.11488v1",
    "title": "Counting Butterflies over Streaming Bipartite Graphs with Duplicate Edges",
    "authors": [
      "Lingkai Meng",
      "Long Yuan",
      "Xuemin Lin",
      "Chengjie Li",
      "Kai Wang",
      "Wenjie Zhang"
    ],
    "abstract": "Bipartite graphs are commonly used to model relationships between two\ndistinct entities in real-world applications, such as user-product\ninteractions, user-movie ratings and collaborations between authors and\npublications. A butterfly (a 2x2 bi-clique) is a critical substructure in\nbipartite graphs, playing a significant role in tasks like community detection,\nfraud detection, and link prediction. As more real-world data is presented in a\nstreaming format, efficiently counting butterflies in streaming bipartite\ngraphs has become increasingly important. However, most existing algorithms\ntypically assume that duplicate edges are absent, which is hard to hold in\nreal-world graph streams, as a result, they tend to sample edges that appear\nmultiple times, leading to inaccurate results. The only algorithm designed to\nhandle duplicate edges is FABLE, but it suffers from significant limitations,\nincluding high variance, substantial time complexity, and memory inefficiency\ndue to its reliance on a priority queue. To overcome these limitations, we\nintroduce DEABC (Duplicate-Edge-Aware Butterfly Counting), an innovative method\nthat uses bucket-based priority sampling to accurately estimate the number of\nbutterflies, accounting for duplicate edges. Compared to existing methods,\nDEABC significantly reduces memory usage by storing only the essential sampled\nedge data while maintaining high accuracy. We provide rigorous proofs of the\nunbiasedness and variance bounds for DEABC, ensuring they achieve high\naccuracy. We compare DEABC with state-of-the-art algorithms on real-world\nstreaming bipartite graphs. The results show that our DEABC outperforms\nexisting methods in memory efficiency and accuracy, while also achieving\nsignificantly higher throughput.",
    "categories": [
      "cs.DS"
    ],
    "published": "2024-12-16T07:04:54+00:00",
    "updated": "2024-12-16T07:04:54+00:00",
    "url": "http://arxiv.org/pdf/2412.11488v1"
  },
  {
    "id": "2412.11142v3",
    "title": "AD-LLM: Benchmarking Large Language Models for Anomaly Detection",
    "authors": [
      "Tiankai Yang",
      "Yi Nian",
      "Shawn Li",
      "Ruiyao Xu",
      "Yuangang Li",
      "Jiaqi Li",
      "Zhuo Xiao",
      "Xiyang Hu",
      "Ryan Rossi",
      "Kaize Ding",
      "Xia Hu",
      "Yue Zhao"
    ],
    "abstract": "Anomaly detection (AD) is an important machine learning task with many\nreal-world uses, including fraud detection, medical diagnosis, and industrial\nmonitoring. Within natural language processing (NLP), AD helps detect issues\nlike spam, misinformation, and unusual user activity. Although large language\nmodels (LLMs) have had a strong impact on tasks such as text generation and\nsummarization, their potential in AD has not been studied enough. This paper\nintroduces AD-LLM, the first benchmark that evaluates how LLMs can help with\nNLP anomaly detection. We examine three key tasks: (i) zero-shot detection,\nusing LLMs' pre-trained knowledge to perform AD without tasks-specific\ntraining; (ii) data augmentation, generating synthetic data and category\ndescriptions to improve AD models; and (iii) model selection, using LLMs to\nsuggest unsupervised AD models. Through experiments with different datasets, we\nfind that LLMs can work well in zero-shot AD, that carefully designed\naugmentation methods are useful, and that explaining model selection for\nspecific datasets remains challenging. Based on these results, we outline six\nfuture research directions on LLMs for AD.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2024-12-15T10:22:14+00:00",
    "updated": "2025-05-15T20:46:39+00:00",
    "url": "http://arxiv.org/pdf/2412.11142v3"
  },
  {
    "id": "2412.10258v1",
    "title": "Copy-Move Detection in Optical Microscopy: A Segmentation Network and A Dataset",
    "authors": [
      "Hao-Chiang Shao",
      "Yuan-Rong Liao",
      "Tse-Yu Tseng",
      "Yen-Liang Chuo",
      "Fong-Yi Lin"
    ],
    "abstract": "With increasing revelations of academic fraud, detecting forged experimental\nimages in the biomedical field has become a public concern. The challenge lies\nin the fact that copy-move targets can include background tissue, small\nforeground objects, or both, which may be out of the training domain and\nsubject to unseen attacks, rendering standard object-detection-based approaches\nless effective. To address this, we reformulate the problem of detecting\nbiomedical copy-move forgery regions as an intra-image co-saliency detection\ntask and propose CMSeg-Net, a copy-move forgery segmentation network capable of\nidentifying unseen duplicated areas. Built on a multi-resolution\nencoder-decoder architecture, CMSeg-Net incorporates self-correlation and\ncorrelation-assisted spatial-attention modules to detect intra-image regional\nsimilarities within feature tensors at each observation scale. This design\nhelps distinguish even small copy-move targets in complex microscopic images\nfrom other similar objects. Furthermore, we created a copy-move forgery dataset\nof optical microscopic images, named FakeParaEgg, using open data from the ICIP\n2022 Challenge to support CMSeg-Net's development and verify its performance.\nExtensive experiments demonstrate that our approach outperforms previous\nstate-of-the-art methods on the FakeParaEgg dataset and other open copy-move\ndetection datasets, including CASIA-CMFD, CoMoFoD, and CMF. The FakeParaEgg\ndataset, our source code, and the CMF dataset with our manually defined\nsegmentation ground truths available at\n``https://github.com/YoursEver/FakeParaEgg''.",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "published": "2024-12-13T16:29:00+00:00",
    "updated": "2024-12-13T16:29:00+00:00",
    "url": "http://arxiv.org/pdf/2412.10258v1"
  },
  {
    "id": "2412.08957v3",
    "title": "Registered Attribute-Based Encryption with Reliable Outsourced Decryption Based on Blockchain",
    "authors": [
      "Dongliang Cai",
      "Liang Zhang",
      "Borui Chen",
      "Haibin Kan"
    ],
    "abstract": "Decentralized data sovereignty and secure data exchange are regarded as\nfoundational pillars of the new era. Attribute-based encryption (ABE) is a\npromising solution that enables fine-grained access control in data sharing.\nRecently, Hohenberger et al. (Eurocrypt 2023) introduced registered ABE (RABE)\nto eliminate trusted authority and gain decentralization. Users generate their\nown public and secret keys and then register their keys and attributes with a\ntransparent key curator. However, RABE still suffers from heavy decryption\noverhead. A natural approach to address this issue is to outsource decryption\nto a decryption cloud server (DCS). In this work, we propose the first\nauditable RABE scheme with reliable outsourced decryption (ORABE) based on\nblockchain. First, we achieve verifiability of transform ciphertext via a\nverifiable tag mechanism. Then, the exemptibility, which ensures that the DCS\nescapes false accusations, is guaranteed by zero knowledge fraud proof under\nthe optimistic assumption. Additionally, our system achieves fairness and\nauditability to protect the interests of all parties through blockchain.\nFinally, we give concrete security and theoretical analysis and evaluate our\nscheme on Ethereum to demonstrate feasibility and efficiency.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-12-12T05:38:50+00:00",
    "updated": "2025-07-04T11:42:13+00:00",
    "url": "http://arxiv.org/pdf/2412.08957v3"
  },
  {
    "id": "2412.08680v1",
    "title": "Distinguishing Scams and Fraud with Ensemble Learning",
    "authors": [
      "Isha Chadalavada",
      "Tianhui Huang",
      "Jessica Staddon"
    ],
    "abstract": "Users increasingly query LLM-enabled web chatbots for help with scam defense.\nThe Consumer Financial Protection Bureau's complaints database is a rich data\nsource for evaluating LLM performance on user scam queries, but currently the\ncorpus does not distinguish between scam and non-scam fraud. We developed an\nLLM ensemble approach to distinguishing scam and fraud CFPB complaints and\ndescribe initial findings regarding the strengths and weaknesses of LLMs in the\nscam defense context.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "published": "2024-12-11T18:07:18+00:00",
    "updated": "2024-12-11T18:07:18+00:00",
    "url": "http://arxiv.org/pdf/2412.08680v1"
  },
  {
    "id": "2412.08366v1",
    "title": "Backdoor attacks on DNN and GBDT -- A Case Study from the insurance domain",
    "authors": [
      "Robin Kühlem",
      "Daniel Otten",
      "Daniel Ludwig",
      "Anselm Hudde",
      "Alexander Rosenbaum",
      "Andreas Mauthe"
    ],
    "abstract": "Machine learning (ML) will likely play a large role in many processes in the\nfuture, also for insurance companies. However, ML models are at risk of being\nattacked and manipulated. In this work, the robustness of Gradient Boosted\nDecision Tree (GBDT) models and Deep Neural Networks (DNN) within an insurance\ncontext will be evaluated. Therefore, two GBDT models and two DNNs are trained\non two different tabular datasets from an insurance context. Past research in\nthis domain mainly used homogenous data and there are comparably few insights\nregarding heterogenous tabular data. The ML tasks performed on the datasets are\nclaim prediction (regression) and fraud detection (binary classification). For\nthe backdoor attacks different samples containing a specific pattern were\ncrafted and added to the training data. It is shown, that this type of attack\ncan be highly successful, even with a few added samples. The backdoor attacks\nworked well on the models trained on one dataset but poorly on the models\ntrained on the other. In real-world scenarios the attacker will have to face\nseveral obstacles but as attacks can work with very few added samples this risk\nshould be evaluated.",
    "categories": [
      "cs.LG",
      "I.2.m"
    ],
    "published": "2024-12-11T13:15:06+00:00",
    "updated": "2024-12-11T13:15:06+00:00",
    "url": "http://arxiv.org/pdf/2412.08366v1"
  },
  {
    "id": "2412.12154v1",
    "title": "PyOD 2: A Python Library for Outlier Detection with LLM-powered Model Selection",
    "authors": [
      "Sihan Chen",
      "Zhuangzhuang Qian",
      "Wingchun Siu",
      "Xingcan Hu",
      "Jiaqi Li",
      "Shawn Li",
      "Yuehan Qin",
      "Tiankai Yang",
      "Zhuo Xiao",
      "Wanghao Ye",
      "Yichi Zhang",
      "Yushun Dong",
      "Yue Zhao"
    ],
    "abstract": "Outlier detection (OD), also known as anomaly detection, is a critical\nmachine learning (ML) task with applications in fraud detection, network\nintrusion detection, clickstream analysis, recommendation systems, and social\nnetwork moderation. Among open-source libraries for outlier detection, the\nPython Outlier Detection (PyOD) library is the most widely adopted, with over\n8,500 GitHub stars, 25 million downloads, and diverse industry usage. However,\nPyOD currently faces three limitations: (1) insufficient coverage of modern\ndeep learning algorithms, (2) fragmented implementations across PyTorch and\nTensorFlow, and (3) no automated model selection, making it hard for\nnon-experts.\n  To address these issues, we present PyOD Version 2 (PyOD 2), which integrates\n12 state-of-the-art deep learning models into a unified PyTorch framework and\nintroduces a large language model (LLM)-based pipeline for automated OD model\nselection. These improvements simplify OD workflows, provide access to 45\nalgorithms, and deliver robust performance on various datasets. In this paper,\nwe demonstrate how PyOD 2 streamlines the deployment and automation of OD\nmodels and sets a new standard in both research and industry. PyOD 2 is\naccessible at\n[https://github.com/yzhao062/pyod](https://github.com/yzhao062/pyod). This\nstudy aligns with the Web Mining and Content Analysis track, addressing topics\nsuch as the robustness of Web mining methods and the quality of\nalgorithmically-generated Web data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2024-12-11T07:53:20+00:00",
    "updated": "2024-12-11T07:53:20+00:00",
    "url": "http://arxiv.org/pdf/2412.12154v1"
  },
  {
    "id": "2412.08082v1",
    "title": "FaceTracer: Unveiling Source Identities from Swapped Face Images and Videos for Fraud Prevention",
    "authors": [
      "Zhongyi Zhang",
      "Jie Zhang",
      "Wenbo Zhou",
      "Xinghui Zhou",
      "Qing Guo",
      "Weiming Zhang",
      "Tianwei Zhang",
      "Nenghai Yu"
    ],
    "abstract": "Face-swapping techniques have advanced rapidly with the evolution of deep\nlearning, leading to widespread use and growing concerns about potential\nmisuse, especially in cases of fraud. While many efforts have focused on\ndetecting swapped face images or videos, these methods are insufficient for\ntracing the malicious users behind fraudulent activities. Intrusive\nwatermark-based approaches also fail to trace unmarked identities, limiting\ntheir practical utility. To address these challenges, we introduce FaceTracer,\nthe first non-intrusive framework specifically designed to trace the identity\nof the source person from swapped face images or videos. Specifically,\nFaceTracer leverages a disentanglement module that effectively suppresses\nidentity information related to the target person while isolating the identity\nfeatures of the source person. This allows us to extract robust identity\ninformation that can directly link the swapped face back to the original\nindividual, aiding in uncovering the actors behind fraudulent activities.\nExtensive experiments demonstrate FaceTracer's effectiveness across various\nface-swapping techniques, successfully identifying the source person in swapped\ncontent and enabling the tracing of malicious actors involved in fraudulent\nactivities. Additionally, FaceTracer shows strong transferability to unseen\nface-swapping methods including commercial applications and robustness against\ntransmission distortions and adaptive attacks.",
    "categories": [
      "cs.CV"
    ],
    "published": "2024-12-11T04:00:17+00:00",
    "updated": "2024-12-11T04:00:17+00:00",
    "url": "http://arxiv.org/pdf/2412.08082v1"
  },
  {
    "id": "2412.07437v1",
    "title": "Impact of Sampling Techniques and Data Leakage on XGBoost Performance in Credit Card Fraud Detection",
    "authors": [
      "Siyaxolisa Kabane"
    ],
    "abstract": "Credit card fraud detection remains a critical challenge in financial\nsecurity, with machine learning models like XGBoost(eXtreme gradient boosting)\nemerging as powerful tools for identifying fraudulent transactions. However,\nthe inherent class imbalance in credit card transaction datasets poses\nsignificant challenges for model performance. Although sampling techniques are\ncommonly used to address this imbalance, their implementation sometimes\nprecedes the train-test split, potentially introducing data leakage.\n  This study presents a comparative analysis of XGBoost's performance in credit\ncard fraud detection under three scenarios: Firstly without any imbalance\nhandling techniques, secondly with sampling techniques applied only to the\ntraining set after the train-test split, and third with sampling techniques\napplied before the train-test split. We utilized a dataset from Kaggle of\n284,807 credit card transactions, containing 0.172\\% fraudulent cases, to\nevaluate these approaches.\n  Our findings show that although sampling strategies enhance model\nperformance, the reliability of results is greatly impacted by when they are\napplied. Due to a data leakage issue that frequently occurs in machine learning\nmodels during the sampling phase, XGBoost models trained on data where sampling\nwas applied prior to the train-test split may have displayed artificially\ninflated performance metrics. Surprisingly, models trained with sampling\ntechniques applied solely to the training set demonstrated significantly lower\nresults than those with pre-split sampling, all the while preserving the\nintegrity of the evaluation process.",
    "categories": [
      "cs.LG",
      "62H30"
    ],
    "published": "2024-12-10T11:54:14+00:00",
    "updated": "2024-12-10T11:54:14+00:00",
    "url": "http://arxiv.org/pdf/2412.07437v1"
  },
  {
    "id": "2412.09640v1",
    "title": "Blockchain Data Analysis in the Era of Large-Language Models",
    "authors": [
      "Kentaroh Toyoda",
      "Xiao Wang",
      "Mingzhe Li",
      "Bo Gao",
      "Yuan Wang",
      "Qingsong Wei"
    ],
    "abstract": "Blockchain data analysis is essential for deriving insights, tracking\ntransactions, identifying patterns, and ensuring the integrity and security of\ndecentralized networks. It plays a key role in various areas, such as fraud\ndetection, regulatory compliance, smart contract auditing, and decentralized\nfinance (DeFi) risk management. However, existing blockchain data analysis\ntools face challenges, including data scarcity, the lack of generalizability,\nand the lack of reasoning capability.\n  We believe large language models (LLMs) can mitigate these challenges;\nhowever, we have not seen papers discussing LLM integration in blockchain data\nanalysis in a comprehensive and systematic way. This paper systematically\nexplores potential techniques and design patterns in LLM-integrated blockchain\ndata analysis. We also outline prospective research opportunities and\nchallenges, emphasizing the need for further exploration in this promising\nfield. This paper aims to benefit a diverse audience spanning academia,\nindustry, and policy-making, offering valuable insights into the integration of\nLLMs in blockchain data analysis.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2024-12-09T07:32:35+00:00",
    "updated": "2024-12-09T07:32:35+00:00",
    "url": "http://arxiv.org/pdf/2412.09640v1"
  },
  {
    "id": "2412.04784v1",
    "title": "NLP-ADBench: NLP Anomaly Detection Benchmark",
    "authors": [
      "Yuangang Li",
      "Jiaqi Li",
      "Zhuo Xiao",
      "Tiankai Yang",
      "Yi Nian",
      "Xiyang Hu",
      "Yue Zhao"
    ],
    "abstract": "Anomaly detection (AD) is a critical machine learning task with diverse\napplications in web systems, including fraud detection, content moderation, and\nuser behavior analysis. Despite its significance, AD in natural language\nprocessing (NLP) remains underexplored, limiting advancements in detecting\nanomalies in text data such as harmful content, phishing attempts, or spam\nreviews. In this paper, we introduce NLP-ADBench, the most comprehensive\nbenchmark for NLP anomaly detection (NLP-AD), comprising eight curated datasets\nand evaluations of nineteen state-of-the-art algorithms. These include three\nend-to-end methods and sixteen two-step algorithms that apply traditional\nanomaly detection techniques to language embeddings generated by\nbert-base-uncased and OpenAI's text-embedding-3-large models.\n  Our results reveal critical insights and future directions for NLP-AD.\nNotably, no single model excels across all datasets, highlighting the need for\nautomated model selection. Moreover, two-step methods leveraging\ntransformer-based embeddings consistently outperform specialized end-to-end\napproaches, with OpenAI embeddings demonstrating superior performance over BERT\nembeddings. By releasing NLP-ADBench at\nhttps://github.com/USC-FORTIS/NLP-ADBench, we provide a standardized framework\nfor evaluating NLP-AD methods, fostering the development of innovative\napproaches. This work fills a crucial gap in the field and establishes a\nfoundation for advancing NLP anomaly detection, particularly in the context of\nimproving the safety and reliability of web-based systems.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2024-12-06T05:30:41+00:00",
    "updated": "2024-12-06T05:30:41+00:00",
    "url": "http://arxiv.org/pdf/2412.04784v1"
  },
  {
    "id": "2412.04535v1",
    "title": "Dual approach to proving electoral fraud via statistics and forensics (Dvojnoe dokazatel'stvo falsifikazij na vyborah statistikoj i kriminalistikoj)",
    "authors": [
      "Andrey Podlazov",
      "Vadim Makarov"
    ],
    "abstract": "Electoral fraud often manifests itself as statistical anomalies in election\nresults, yet its extent can rarely be reliably confirmed by other evidence.\nHere we report complete results of municipal elections in Vlasikha town near\nMoscow, where we observe both statistical irregularities in the vote-counting\ntranscripts and forensic evidence of tampering with ballots during their\novernight storage. We evaluate two types of statistical signatures in the vote\nsequence that can prove batches of fraudulent ballots have been injected. We\nfind that pairs of factory-made security bags with identical serial numbers are\nused in this fraud scheme. At 8 out of our 9 polling stations, the statistical\nand forensic evidence agrees (identifying 7 as fraudulent and 1 as honest),\nwhile at the remaining station the statistical evidence detects the fraud while\nthe forensic one is insufficient. We also illustrate that the use of\ntamper-indicating seals at elections is inherently unreliable. -- --\n  Tezis po-russki est' v russkoj versii stat'i (normal'noj kirillicej, ne\ntranslitom)",
    "categories": [
      "stat.AP",
      "physics.soc-ph"
    ],
    "published": "2024-12-05T17:55:45+00:00",
    "updated": "2024-12-05T17:55:45+00:00",
    "url": "http://arxiv.org/pdf/2412.04535v1"
  },
  {
    "id": "2412.04014v1",
    "title": "(Blind) Users Really Do Heed Aural Telephone Scam Warnings",
    "authors": [
      "Filipo Sharevski",
      "Jennifer Vander Loop",
      "Bill Evans",
      "Alexander Ponticello"
    ],
    "abstract": "This paper reports on a study exploring how two groups of individuals,\nlegally blind (n=36) and sighted ones (n=36), react to aural telephone scam\nwarnings in naturalistic settings. As spoofing a CallerID is trivial,\ncommunicating the context of an incoming call instead offers a better\npossibility to warn a receiver about a potential scam. Usually, such warnings\nare visual in nature and fail to cater to users with visual disabilities. To\naddress this exclusion, we developed an aural variant of telephone scam\nwarnings and tested them in three conditions: baseline (no warning), short\nwarning, and contextual warning that preceded the scam's content. We tested the\ntwo most common scam scenarios: fraud (interest rate reduction) and identity\ntheft (social security number) by cold-calling participants and recording their\naction, and debriefing and obtaining consent afterward. Only two participants\n\"pressed one\" as the scam demanded, both from the legally blind group that\nheard the contextual warning for the social security scenario. Upon close\ninspection, we learned that one of them did so because of accessibility issues\nwith their screen reader and the other did so intentionally because the warning\nconvinced them to waste the scammer's time, so they don't scam vulnerable\npeople. Both the legally blind and the sighted participants found the\ncontextual warnings as powerful usable security cues that, together with\nSTIR/SHAKEN indicators like \"Scam Likely\", would provide robust protection\nagainst any type of scam. We also discussed the potential privacy implications\nof the contextual warnings and collected recommendations for usably accessible\nimplementation.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-12-05T09:47:38+00:00",
    "updated": "2024-12-05T09:47:38+00:00",
    "url": "http://arxiv.org/pdf/2412.04014v1"
  },
  {
    "id": "2412.03894v1",
    "title": "Machine Learning-based Android Intrusion Detection System",
    "authors": [
      "Madiha Tahreem",
      "Ifrah Andleeb",
      "Bilal Zahid Hussain",
      "Arsalan Hameed"
    ],
    "abstract": "The android operating system is being installed in most of the smart devices.\nThe introduction of intrusions in such operating systems is rising at a\ntremendous rate. With the introduction of such malicious data streams, the\nsmart devices are being subjected to various attacks like Phishing, Spyware,\nSMS Fraud, Bots and Banking-Trojans and many such. The application of machine\nlearning classification algorithms for the security of android APK files is\nused in this paper. Each apk data stream was marked to be either malicious or\nnon malicious on the basis of different parameters. The machine learning\nclassification techniques are then used to classify whether the newly installed\napplications' signature falls within the malicious or non-malicious domain. If\nit falls within the malicious category, appropriate action can be taken, and\nthe Android operating system can be shielded against illegal activities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2024-12-05T06:05:12+00:00",
    "updated": "2024-12-05T06:05:12+00:00",
    "url": "http://arxiv.org/pdf/2412.03894v1"
  },
  {
    "id": "2412.03864v1",
    "title": "Training MLPs on Graphs without Supervision",
    "authors": [
      "Zehong Wang",
      "Zheyuan Zhang",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "abstract": "Graph Neural Networks (GNNs) have demonstrated their effectiveness in various\ngraph learning tasks, yet their reliance on neighborhood aggregation during\ninference poses challenges for deployment in latency-sensitive applications,\nsuch as real-time financial fraud detection. To address this limitation, recent\nstudies have proposed distilling knowledge from teacher GNNs into student\nMulti-Layer Perceptrons (MLPs) trained on node content, aiming to accelerate\ninference. However, these approaches often inadequately explore structural\ninformation when inferring unseen nodes. To this end, we introduce SimMLP, a\nSelf-supervised framework for learning MLPs on graphs, designed to fully\nintegrate rich structural information into MLPs. Notably, SimMLP is the first\nMLP-learning method that can achieve equivalence to GNNs in the optimal case.\nThe key idea is to employ self-supervised learning to align the representations\nencoded by graph context-aware GNNs and neighborhood dependency-free MLPs,\nthereby fully integrating the structural information into MLPs. We provide a\ncomprehensive theoretical analysis, demonstrating the equivalence between\nSimMLP and GNNs based on mutual information and inductive bias, highlighting\nSimMLP's advanced structural learning capabilities. Additionally, we conduct\nextensive experiments on 20 benchmark datasets, covering node classification,\nlink prediction, and graph classification, to showcase SimMLP's superiority\nover state-of-the-art baselines, particularly in scenarios involving unseen\nnodes (e.g., inductive and cold-start node classification) where structural\ninsights are crucial. Our codes are available at:\nhttps://github.com/Zehong-Wang/SimMLP.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "published": "2024-12-05T04:20:54+00:00",
    "updated": "2024-12-05T04:20:54+00:00",
    "url": "http://arxiv.org/pdf/2412.03864v1"
  },
  {
    "id": "2411.19841v1",
    "title": "Parallel Stacked Aggregated Network for Voice Authentication in IoT-Enabled Smart Devices",
    "authors": [
      "Awais Khan",
      "Ijaz Ul Haq",
      "Khalid Mahmood Malik"
    ],
    "abstract": "Voice authentication on IoT-enabled smart devices has gained prominence in\nrecent years due to increasing concerns over user privacy and security. The\ncurrent authentication systems are vulnerable to different voice-spoofing\nattacks (e.g., replay, voice cloning, and audio deepfakes) that mimic\nlegitimate voices to deceive authentication systems and enable fraudulent\nactivities (e.g., impersonation, unauthorized access, financial fraud, etc.).\nExisting solutions are often designed to tackle a single type of attack,\nleading to compromised performance against unseen attacks. On the other hand,\nexisting unified voice anti-spoofing solutions, not designed specifically for\nIoT, possess complex architectures and thus cannot be deployed on IoT-enabled\nsmart devices. Additionally, most of these unified solutions exhibit\nsignificant performance issues, including higher equal error rates or lower\naccuracy for specific attacks. To overcome these issues, we present the\nparallel stacked aggregation network (PSA-Net), a lightweight framework\ndesigned as an anti-spoofing defense system for voice-controlled smart IoT\ndevices. The PSA-Net processes raw audios directly and eliminates the need for\ndataset-dependent handcrafted features or pre-computed spectrograms.\nFurthermore, PSA-Net employs a split-transform-aggregate approach, which\ninvolves the segmentation of utterances, the extraction of intrinsic\ndifferentiable embeddings through convolutions, and the aggregation of them to\ndistinguish legitimate from spoofed audios. In contrast to existing deep\nResnet-oriented solutions, we incorporate cardinality as an additional\ndimension in our network, which enhances the PSA-Net ability to generalize\nacross diverse attacks. The results show that the PSA-Net achieves more\nconsistent performance for different attacks that exist in current\nanti-spoofing solutions.",
    "categories": [
      "cs.SD",
      "cs.CR",
      "cs.NE",
      "eess.AS"
    ],
    "published": "2024-11-29T16:57:31+00:00",
    "updated": "2024-11-29T16:57:31+00:00",
    "url": "http://arxiv.org/pdf/2411.19841v1"
  },
  {
    "id": "2411.19457v1",
    "title": "Multi-task CNN Behavioral Embedding Model For Transaction Fraud Detection",
    "authors": [
      "Bo Qu",
      "Zhurong Wang",
      "Minghao Gu",
      "Daisuke Yagi",
      "Yang Zhao",
      "Yinan Shan",
      "Frank Zahradnik"
    ],
    "abstract": "The burgeoning e-Commerce sector requires advanced solutions for the\ndetection of transaction fraud. With an increasing risk of financial\ninformation theft and account takeovers, deep learning methods have become\nintegral to the embedding of behavior sequence data in fraud detection.\nHowever, these methods often struggle to balance modeling capabilities and\nefficiency and incorporate domain knowledge. To address these issues, we\nintroduce the multitask CNN behavioral Embedding Model for Transaction Fraud\nDetection. Our contributions include 1) introducing a single-layer CNN design\nfeaturing multirange kernels which outperform LSTM and Transformer models in\nterms of scalability and domain-focused inductive bias, and 2) the integration\nof positional encoding with CNN to introduce sequence-order signals enhancing\noverall performance, and 3) implementing multitask learning with randomly\nassigned label weights, thus removing the need for manual tuning. Testing on\nreal-world data reveals our model's enhanced performance of downstream\ntransaction models and comparable competitiveness with the Transformer Time\nSeries (TST) model.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-11-29T03:58:11+00:00",
    "updated": "2024-11-29T03:58:11+00:00",
    "url": "http://arxiv.org/pdf/2411.19457v1"
  },
  {
    "id": "2412.04495v1",
    "title": "Artificial intelligence and cybersecurity in banking sector: opportunities and risks",
    "authors": [
      "Ana Kovacevic",
      "Sonja D. Radenkovic",
      "Dragana Nikolic"
    ],
    "abstract": "The rapid advancements in artificial intelligence (AI) have presented new\nopportunities for enhancing efficiency and economic competitiveness across\nvarious industries, espcially in banking. Machine learning (ML), as a subset of\nartificial intelligence, enables systems to adapt and learn from vast datasets,\nrevolutionizing decision-making processes, fraud detection, and customer\nservice automation. However, these innovations also introduce new challenges,\nparticularly in the realm of cybersecurity. Adversarial attacks, such as data\npoisoning and evasion attacks, represent critical threats to machine learning\nmodels, exploiting vulnerabilities to manipulate outcomes or compromise\nsensitive information. Furthermore, this study highlights the dual-use nature\nof AI tools, which can be used by malicious users. To address these challenges,\nthe paper emphasizes the importance of developing machine learning models with\nkey characteristics such as security, trust, resilience and robustness. These\nfeatures are essential to mitigating risks and ensuring the secure deployment\nof AI technologies in banking sectors, where the protection of financial data\nis paramount. The findings underscore the urgent need for enhanced\ncybersecurity frameworks and continuous improvements in defensive mechanisms.\nBy exploring both opportunities and risks, this paper aims to guide the\nresponsible integration of AI in the banking sector, paving the way for\ninnovation while safeguarding against emerging threats.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-11-28T22:09:55+00:00",
    "updated": "2024-11-28T22:09:55+00:00",
    "url": "http://arxiv.org/pdf/2412.04495v1"
  },
  {
    "id": "2411.18875v2",
    "title": "Know Your Account: Double Graph Inference-based Account De-anonymization on Ethereum",
    "authors": [
      "Shuyi Miao",
      "Wangjie Qiu",
      "Hongwei Zheng",
      "Qinnan Zhang",
      "Xiaofan Tu",
      "Xunan Liu",
      "Yang Liu",
      "Jin Dong",
      "Zhiming Zheng"
    ],
    "abstract": "The scaled Web 3.0 digital economy, represented by decentralized finance\n(DeFi), has sparked increasing interest in the past few years, which usually\nrelies on blockchain for token transfer and diverse transaction logic. However,\nillegal behaviors, such as financial fraud, hacker attacks, and money\nlaundering, are rampant in the blockchain ecosystem and seriously threaten its\nintegrity and security. In this paper, we propose a novel double graph-based\nEthereum account de-anonymization inference method, dubbed DBG4ETH, which aims\nto capture the behavioral patterns of accounts comprehensively and has more\nrobust analytical and judgment capabilities for current complex and\ncontinuously generated transaction behaviors. Specifically, we first construct\na global static graph to build complex interactions between the various account\nnodes for all transaction data. Then, we also construct a local dynamic graph\nto learn about the gradual evolution of transactions over different periods.\nDifferent graphs focus on information from different perspectives, and features\nof global and local, static and dynamic transaction graphs are available\nthrough DBG4ETH. In addition, we propose an adaptive confidence calibration\nmethod to predict the results by feeding the calibrated weighted prediction\nvalues into the classifier. Experimental results show that DBG4ETH achieves\nstate-of-the-art results in the account identification task, improving the\nF1-score by at least 3.75% and up to 40.52% compared to processing each graph\ntype individually and outperforming similar account identity inference methods\nby 5.23% to 12.91%.",
    "categories": [
      "cs.SI"
    ],
    "published": "2024-11-28T03:00:27+00:00",
    "updated": "2025-01-14T03:46:32+00:00",
    "url": "http://arxiv.org/pdf/2411.18875v2"
  },
  {
    "id": "2411.17102v2",
    "title": "Scholar Name Disambiguation with Search-enhanced LLM Across Language",
    "authors": [
      "Renyu Zhao",
      "Yunxin Chen"
    ],
    "abstract": "The task of scholar name disambiguation is crucial in various real-world\nscenarios, including bibliometric-based candidate evaluation for awards,\napplication material anti-fraud measures, and more. Despite significant\nadvancements, current methods face limitations due to the complexity of\nheterogeneous data, often necessitating extensive human intervention. This\npaper proposes a novel approach by leveraging search-enhanced language models\nacross multiple languages to improve name disambiguation. By utilizing the\npowerful query rewriting, intent recognition, and data indexing capabilities of\nsearch engines, our method can gather richer information for distinguishing\nbetween entities and extracting profiles, resulting in a more comprehensive\ndata dimension. Given the strong cross-language capabilities of large language\nmodels(LLMs), optimizing enhanced retrieval methods with this technology offers\nsubstantial potential for high-efficiency information retrieval and\nutilization. Our experiments demonstrate that incorporating local languages\nsignificantly enhances disambiguation performance, particularly for scholars\nfrom diverse geographic regions. This multi-lingual, search-enhanced\nmethodology offers a promising direction for more efficient and accurate active\nscholar name disambiguation.",
    "categories": [
      "cs.IR"
    ],
    "published": "2024-11-26T04:39:46+00:00",
    "updated": "2025-03-04T07:04:59+00:00",
    "url": "http://arxiv.org/pdf/2411.17102v2"
  },
  {
    "id": "2411.14957v2",
    "title": "Information Extraction from Heterogeneous Documents without Ground Truth Labels using Synthetic Label Generation and Knowledge Distillation",
    "authors": [
      "Aniket Bhattacharyya",
      "Anurag Tripathi"
    ],
    "abstract": "Invoices and receipts submitted by employees are visually rich documents\n(VRDs) with textual, visual and layout information. To protect against the risk\nof fraud and abuse, it is crucial for organizations to efficiently extract\ndesired information from submitted receipts. This helps in the assessment of\nkey factors such as appropriateness of the expense claim, adherence to spending\nand transaction policies, the validity of the receipt, as well as downstream\nanomaly detection at various levels. These documents are heterogeneous, with\nmultiple formats and languages, uploaded with different image qualities, and\noften do not contain ground truth labels for the efficient training of models.\nIn this paper we propose Task Aware Instruction-based Labelling (TAIL), a\nmethod for synthetic label generation in VRD corpuses without labels, and\nfine-tune a multimodal Visually Rich Document Understanding Model (VRDU) on\nTAIL labels using response-based knowledge distillation without using the\nteacher model's weights or training dataset to conditionally generate\nannotations in the appropriate format. Using a benchmark external dataset where\nground truth labels are available, we demonstrate conditions under which our\napproach performs at par with Claude 3 Sonnet through empirical studies. We\nthen show that the resulting model performs at par or better on the internal\nexpense documents of a large multinational organization than state-of-the-art\nLMM (large multimodal model) Claude 3 Sonnet while being 85% less costly and\n~5X faster, and outperforms layout-aware baselines by more than 10% in Average\nNormalized Levenshtein Similarity (ANLS) scores due to its ability to reason\nand extract information from rare formats. Finally, we illustrate the usage of\nour approach in overpayment prevention.",
    "categories": [
      "cs.CL"
    ],
    "published": "2024-11-22T14:16:09+00:00",
    "updated": "2024-11-25T09:47:20+00:00",
    "url": "http://arxiv.org/pdf/2411.14957v2"
  },
  {
    "id": "2411.12556v4",
    "title": "UMGAD: Unsupervised Multiplex Graph Anomaly Detection",
    "authors": [
      "Xiang Li",
      "Jianpeng Qi",
      "Zhongying Zhao",
      "Guanjie Zheng",
      "Lei Cao",
      "Junyu Dong",
      "Yanwei Yu"
    ],
    "abstract": "Graph anomaly detection (GAD) is a critical task in graph machine learning,\nwith the primary objective of identifying anomalous nodes that deviate\nsignificantly from the majority. This task is widely applied in various\nreal-world scenarios, including fraud detection and social network analysis.\nHowever, existing GAD methods still face two major challenges: (1) They are\noften limited to detecting anomalies in single-type interaction graphs and\nstruggle with multiple interaction types in multiplex heterogeneous graphs. (2)\nIn unsupervised scenarios, selecting appropriate anomaly score thresholds\nremains a significant challenge for accurate anomaly detection. To address the\nabove challenges, we propose a novel Unsupervised Multiplex Graph Anomaly\nDetection method, named UMGAD. We first learn multi-relational correlations\namong nodes in multiplex heterogeneous graphs and capture anomaly information\nduring node attribute and structure reconstruction through graph-masked\nautoencoder (GMAE). Then, to further extract abnormal information, we generate\nattribute-level and subgraph-level augmented-view graphs, respectively, and\nperform attribute and structure reconstruction through GMAE. Finally, we learn\nto optimize node attributes and structural features through contrastive\nlearning between original-view and augmented-view graphs to improve the model's\nability to capture anomalies. Meanwhile, we propose a new anomaly score\nthreshold selection strategy, which allows the model to be independent of\nground truth information in real unsupervised scenarios. Extensive experiments\non six datasets show that our UMGAD significantly outperforms state-of-the-art\nmethods, achieving average improvements of 12.25% in AUC and 11.29% in Macro-F1\nacross all datasets.",
    "categories": [
      "cs.LG"
    ],
    "published": "2024-11-19T15:15:45+00:00",
    "updated": "2025-04-09T04:11:23+00:00",
    "url": "http://arxiv.org/pdf/2411.12556v4"
  },
  {
    "id": "2411.15190v1",
    "title": "Transforming Triple-Entry Accounting with Machine Learning: A Path to Enhanced Transparency Through Analytics",
    "authors": [
      "Abraham Itzhak Weinberg",
      "Alessio Faccia"
    ],
    "abstract": "Triple Entry (TE) is an accounting method that utilizes three accounts or\n'entries' to record each transaction, rather than the conventional double-entry\nbookkeeping system. Existing studies have found that TE accounting, with its\nadditional layer of verification and disclosure of inter-organizational\nrelationships, could help improve transparency in complex financial and supply\nchain transactions such as blockchain. Machine learning (ML) presents a\npromising avenue to augment the transparency advantages of TE accounting. By\nautomating some of the data collection and analysis needed for TE bookkeeping,\nML techniques have the potential to make this more transparent accounting\nmethod scalable for large organizations with complex international supply\nchains, further enhancing the visibility and trustworthiness of financial\nreporting. By leveraging ML algorithms, anomalies within distributed ledger\ndata can be swiftly identified, flagging potential instances of fraud or\nerrors. Furthermore, by delving into transaction relationships over time, ML\ncan untangle intricate webs of transactions, shedding light on obscured\ndealings and adding an investigative dimension. This paper aims to demonstrate\nthe interaction between TE and ML and how they can leverage transparency\nlevels.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2024-11-19T08:58:44+00:00",
    "updated": "2024-11-19T08:58:44+00:00",
    "url": "http://arxiv.org/pdf/2411.15190v1"
  },
  {
    "id": "2412.00020v1",
    "title": "Partitioning Message Passing for Graph Fraud Detection",
    "authors": [
      "Wei Zhuo",
      "Zemin Liu",
      "Bryan Hooi",
      "Bingsheng He",
      "Guang Tan",
      "Rizal Fathony",
      "Jia Chen"
    ],
    "abstract": "Label imbalance and homophily-heterophily mixture are the fundamental\nproblems encountered when applying Graph Neural Networks (GNNs) to Graph Fraud\nDetection (GFD) tasks. Existing GNN-based GFD models are designed to augment\ngraph structure to accommodate the inductive bias of GNNs towards homophily, by\nexcluding heterophilic neighbors during message passing. In our work, we argue\nthat the key to applying GNNs for GFD is not to exclude but to {\\em\ndistinguish} neighbors with different labels. Grounded in this perspective, we\nintroduce Partitioning Message Passing (PMP), an intuitive yet effective\nmessage passing paradigm expressly crafted for GFD. Specifically, in the\nneighbor aggregation stage of PMP, neighbors with different classes are\naggregated with distinct node-specific aggregation functions. By this means,\nthe center node can adaptively adjust the information aggregated from its\nheterophilic and homophilic neighbors, thus avoiding the model gradient being\ndominated by benign nodes which occupy the majority of the population. We\ntheoretically establish a connection between the spatial formulation of PMP and\nspectral analysis to characterize that PMP operates an adaptive node-specific\nspectral graph filter, which demonstrates the capability of PMP to handle\nheterophily-homophily mixed graphs. Extensive experimental results show that\nPMP can significantly boost the performance on GFD tasks.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "published": "2024-11-16T11:30:53+00:00",
    "updated": "2024-11-16T11:30:53+00:00",
    "url": "http://arxiv.org/pdf/2412.00020v1"
  },
  {
    "id": "2501.09166v1",
    "title": "Attention is All You Need Until You Need Retention",
    "authors": [
      "M. Murat Yaslioglu"
    ],
    "abstract": "This work introduces a novel Retention Layer mechanism for Transformer based\narchitectures, addressing their inherent lack of intrinsic retention\ncapabilities. Unlike human cognition, which can encode and dynamically recall\nsymbolic templates, Generative Pretrained Transformers rely solely on fixed\npretrained weights and ephemeral context windows, limiting their adaptability.\nThe proposed Retention Layer incorporates a persistent memory module capable of\nreal time data population, dynamic recall, and guided output generation. This\nenhancement allows models to store, update, and reuse observed patterns across\nsessions, enabling incremental learning and bridging the gap between static\npretraining and dynamic, context sensitive adaptation. The Retention Layer\ndesign parallels social learning processes, encompassing attention, retention,\nreproduction, and motivation stages. Technically, it integrates a memory\nattention mechanism and episodic buffers to manage memory scalability, mitigate\noverfitting, and ensure efficient recall. Applications span adaptive personal\nassistants, real time fraud detection, autonomous robotics, content moderation,\nand healthcare diagnostics. In each domain, the retention mechanism enables\nsystems to learn incrementally, personalize outputs, and respond to evolving\nreal world challenges effectively. By emulating key aspects of human learning,\nthis retention enhanced architecture fosters a more fluid and responsive AI\nparadigm, paving the way for dynamic, session aware models that extend the\ncapabilities of traditional Transformers into domains requiring continual\nadaptation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-01-15T21:33:53+00:00",
    "updated": "2025-01-15T21:33:53+00:00",
    "url": "http://arxiv.org/pdf/2501.09166v1"
  },
  {
    "id": "2501.07033v1",
    "title": "Detection of AI Deepfake and Fraud in Online Payments Using GAN-Based Models",
    "authors": [
      "Zong Ke",
      "Shicheng Zhou",
      "Yining Zhou",
      "Chia Hong Chang",
      "Rong Zhang"
    ],
    "abstract": "This study explores the use of Generative Adversarial Networks (GANs) to\ndetect AI deepfakes and fraudulent activities in online payment systems. With\nthe growing prevalence of deepfake technology, which can manipulate facial\nfeatures in images and videos, the potential for fraud in online transactions\nhas escalated. Traditional security systems struggle to identify these\nsophisticated forms of fraud. This research proposes a novel GAN-based model\nthat enhances online payment security by identifying subtle manipulations in\npayment images. The model is trained on a dataset consisting of real-world\nonline payment images and deepfake images generated using advanced GAN\narchitectures, such as StyleGAN and DeepFake. The results demonstrate that the\nproposed model can accurately distinguish between legitimate transactions and\ndeepfakes, achieving a high detection rate above 95%. This approach\nsignificantly improves the robustness of payment systems against AI-driven\nfraud. The paper contributes to the growing field of digital security, offering\ninsights into the application of GANs for fraud detection in financial\nservices. Keywords- Payment Security, Image Recognition, Generative Adversarial\nNetworks, AI Deepfake, Fraudulent Activities",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.CV"
    ],
    "published": "2025-01-13T03:10:54+00:00",
    "updated": "2025-01-13T03:10:54+00:00",
    "url": "http://arxiv.org/pdf/2501.07033v1"
  },
  {
    "id": "2501.05788v2",
    "title": "The Waters We Swim In: Replicability and the Evolution of Scientific Norms",
    "authors": [
      "Hope Bretscher",
      "Núria Muñoz Garganté"
    ],
    "abstract": "In recent years, a series of high-profile retractions and fraud cases have\narisen in physics, sparking a conversation about research integrity and\nreplicability. Here, we discuss how the practice of science is shaped by the\nsocial and political context in which it operates. Reflection on our norms and\nvalues could provide a route to create community-driven safeguards that respond\nto the changing demands in which our research occurs. We propose that\ncollaborations between physicists, philosophers, social scientists, and\nhistorians of science could facilitate these reflections and provide new ideas\nfor social science and humanities colleagues.",
    "categories": [
      "physics.soc-ph",
      "physics.hist-ph"
    ],
    "published": "2025-01-10T08:44:46+00:00",
    "updated": "2025-03-19T10:18:27+00:00",
    "url": "http://arxiv.org/pdf/2501.05788v2"
  },
  {
    "id": "2501.05601v1",
    "title": "Exploring Large Language Models for Translating Romanian Computational Problems into English",
    "authors": [
      "Adrian Marius Dumitran",
      "Adrian-Catalin Badea",
      "Stefan-Gabriel Muscalu",
      "Angela-Liliana Dumitran",
      "Stefan-Cosmin Dascalescu",
      "Radu-Sebastian Amarie"
    ],
    "abstract": "Recent studies have suggested that large language models (LLMs) underperform\non mathematical and computer science tasks when these problems are translated\nfrom Romanian into English, compared to their original Romanian format.\nAccurate translation is critical for applications ranging from automatic\ntranslations in programming competitions to the creation of high-quality\neducational materials, as well as minimizing errors or fraud in human\ntranslations. This study shows that robust large language models (LLMs) can\nmaintain or even enhance their performance in translating less common languages\nwhen given well-structured prompts. Our findings suggest that LLMs, with\nappropriate supervision, can be reliably used for the automatic translation of\nIOI (International Olympiad in Informatics)-style tasks. We evaluate several\ntranslation methods across multiple LLMs, including OpenRoLLM, Llama 3.1 8B,\nLlama 3.2 3B and GPT-4o, assessing their translation accuracy and performance\nstability through repeated runs. Additionally, we augment the OJI (Romanian\nCounty-Level Informatics Olympiad) Romanian dataset with accurate English\ntranslations, enhancing its utility for future LLM training and evaluation.\nThrough detailed syntactic and semantic analyses, we confirm that with human\noversight, LLMs can serve as a viable solution for multilingual\nproblem-solving. We also compare the translation quality of LLMs against human\ntranslators, as evaluated by a certified expert, underscoring the potential of\nLLMs in realworld scenarios.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-01-09T22:17:44+00:00",
    "updated": "2025-01-09T22:17:44+00:00",
    "url": "http://arxiv.org/pdf/2501.05601v1"
  },
  {
    "id": "2501.02032v1",
    "title": "Dynamic Feature Fusion: Combining Global Graph Structures and Local Semantics for Blockchain Fraud Detection",
    "authors": [
      "Zhang Sheng",
      "Liangliang Song",
      "Yanbin Wang"
    ],
    "abstract": "The advent of blockchain technology has facilitated the widespread adoption\nof smart contracts in the financial sector. However, current fraud detection\nmethodologies exhibit limitations in capturing both global structural patterns\nwithin transaction networks and local semantic relationships embedded in\ntransaction data. Most existing models focus on either structural information\nor semantic features individually, leading to suboptimal performance in\ndetecting complex fraud patterns.In this paper, we propose a dynamic feature\nfusion model that combines graph-based representation learning and semantic\nfeature extraction for blockchain fraud detection. Specifically, we construct\nglobal graph representations to model account relationships and extract local\ncontextual features from transaction data. A dynamic multimodal fusion\nmechanism is introduced to adaptively integrate these features, enabling the\nmodel to capture both structural and semantic fraud patterns effectively. We\nfurther develop a comprehensive data processing pipeline, including graph\nconstruction, temporal feature enhancement, and text preprocessing.\nExperimental results on large-scale real-world blockchain datasets demonstrate\nthat our method outperforms existing benchmarks across accuracy, F1 score, and\nrecall metrics. This work highlights the importance of integrating structural\nrelationships and semantic similarities for robust fraud detection and offers a\nscalable solution for securing blockchain systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "published": "2025-01-03T09:04:43+00:00",
    "updated": "2025-01-03T09:04:43+00:00",
    "url": "http://arxiv.org/pdf/2501.02032v1"
  },
  {
    "id": "2501.01061v1",
    "title": "An Efficient Outlier Detection Algorithm for Data Streaming",
    "authors": [
      "Rui Hu",
      "Luc",
      "Chen",
      "Yiwei Wang"
    ],
    "abstract": "The nature of modern data is increasingly real-time, making outlier detection\ncrucial in any data-related field, such as finance for fraud detection and\nhealthcare for monitoring patient vitals. Traditional outlier detection\nmethods, such as the Local Outlier Factor (LOF) algorithm, struggle with\nreal-time data due to the need for extensive recalculations with each new data\npoint, limiting their application in real-time environments. While the\nIncremental LOF (ILOF) algorithm has been developed to tackle the challenges of\nonline anomaly detection, it remains computationally expensive when processing\nlarge streams of data points, and its detection performance may degrade after a\ncertain threshold of points have streamed in. In this paper, we propose a novel\napproach to enhance the efficiency of LOF algorithms for online anomaly\ndetection, named the Efficient Incremental LOF (EILOF) algorithm. The EILOF\nalgorithm only computes the LOF scores of new points without altering the LOF\nscores of existing data points. Although exact LOF scores have not yet been\ncomputed for the existing points in the new algorithm, datasets often contain\nnoise, and minor deviations in LOF score calculations do not necessarily\ndegrade detection performance. In fact, such deviations can sometimes enhance\noutlier detection. We systematically tested this approach on both simulated and\nreal-world datasets, demonstrating that EILOF outperforms ILOF as the volume of\nstreaming data increases across various scenarios. The EILOF algorithm not only\nsignificantly reduces computational costs, but also systematically improves\ndetection accuracy when the number of additional points increases compared to\nthe ILOF algorithm.",
    "categories": [
      "stat.CO",
      "cs.LG",
      "stat.AP"
    ],
    "published": "2025-01-02T05:12:43+00:00",
    "updated": "2025-01-02T05:12:43+00:00",
    "url": "http://arxiv.org/pdf/2501.01061v1"
  },
  {
    "id": "2412.19441v2",
    "title": "Comparative Performance Analysis of Quantum Machine Learning Architectures for Credit Card Fraud Detection",
    "authors": [
      "Mansour El Alami",
      "Nouhaila Innan",
      "Muhammad Shafique",
      "Mohamed Bennai"
    ],
    "abstract": "As financial fraud becomes increasingly complex, effective detection methods\nare essential. Quantum Machine Learning (QML) introduces certain capabilities\nthat may enhance both accuracy and efficiency in this area. This study examines\nhow different quantum feature map and ansatz configurations affect the\nperformance of three QML-based classifiers-the Variational Quantum Classifier\n(VQC), the Sampler Quantum Neural Network (SQNN), and the Estimator Quantum\nNeural Network (EQNN)-when applied to two non-standardized financial fraud\ndatasets. Different quantum feature map and ansatz configurations are\nevaluated, revealing distinct performance patterns. The VQC consistently\ndemonstrates strong classification results, achieving an F1 score of 0.88,\nwhile the SQNN also delivers promising outcomes. In contrast, the EQNN\nstruggles to produce robust results, emphasizing the challenges presented by\nnon-standardized data. These findings highlight the importance of careful model\nconfiguration in QML-based financial fraud detection. By showing how specific\nfeature maps and ansatz choices influence predictive success, this work guides\nresearchers and practitioners in refining QML approaches for complex financial\napplications.",
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "published": "2024-12-27T04:17:34+00:00",
    "updated": "2025-01-03T03:36:44+00:00",
    "url": "http://arxiv.org/pdf/2412.19441v2"
  },
  {
    "id": "2412.19850v1",
    "title": "The Patterns of Digital Deception",
    "authors": [
      "Gregory M. Dickinson"
    ],
    "abstract": "Current consumer-protection debates focus on the powerful new data-analysis\ntechniques that have disrupted the balance of power between companies and their\ncustomers. Online tracking enables sellers to amass troves of historical data,\napply machine-learning tools to construct detailed customer profiles, and\ntarget those customers with tailored offers that best suit their interests. It\nis often a win-win. Sellers avoid pumping dud products and consumers see ads\nfor things they actually want to buy. But the same tools are also used for ill\n-- to target vulnerable members of the population with scams specially tailored\nto prey on their weaknesses. The result has been a dramatic rise in online\nfraud that disproportionately impacts those least able to bear the loss.\n  The law's response has been technology centric. Lawmakers race to identify\nthose technologies that drive consumer deception and target them for regulatory\nrestrictions. But that approach comes at a major cost. General-purpose\ndata-analysis and communications tools have both desirable and undesirable\nuses, and uniform restrictions on their use impede the good along with the bad.\nA superior approach would focus not on the technological tools of deception but\non what this Article identifies as the legal patterns of digital deception --\nthose aspects of digital technology that have outflanked the law's existing\nmechanisms for redressing consumer harm. This Article reorients the discussion\nfrom the power of new technologies to the shortcomings in existing regulatory\nstructures that have allowed for their abuse. Focus on these patterns of\ndeception will allow regulators to reallocate resources to offset those\nshortcomings and thereby enhance efforts to combat online fraud without\nimpeding technological innovation.",
    "categories": [
      "econ.GN",
      "cs.CY",
      "q-fin.EC"
    ],
    "published": "2024-12-25T15:55:17+00:00",
    "updated": "2024-12-25T15:55:17+00:00",
    "url": "http://arxiv.org/pdf/2412.19850v1"
  },
  {
    "id": "2412.18470v1",
    "title": "PonziLens+: Visualizing Bytecode Actions for Smart Ponzi Scheme Identification",
    "authors": [
      "Xiaolin Wen",
      "Tai D. Nguyen",
      "Shaolun Ruan",
      "Qiaomu Shen",
      "Jun Sun",
      "Feida Zhu",
      "Yong Wang"
    ],
    "abstract": "With the prevalence of smart contracts, smart Ponzi schemes have become a\ncommon fraud on blockchain and have caused significant financial loss to\ncryptocurrency investors in the past few years. Despite the critical importance\nof detecting smart Ponzi schemes, a reliable and transparent identification\napproach adaptive to various smart Ponzi schemes is still missing. To fill the\nresearch gap, we first extract semantic-meaningful actions to represent the\nexecution behaviors specified in smart contract bytecodes, which are derived\nfrom a literature review and in-depth interviews with domain experts. We then\npropose PonziLens+, a novel visual analytic approach that provides an intuitive\nand reliable analysis of Ponzi-scheme-related features within these execution\nbehaviors. PonziLens+ has three visualization modules that intuitively reveal\nall potential behaviors of a smart contract, highlighting fraudulent features\nacross three levels of detail. It can help smart contract investors and\nauditors achieve confident identification of any smart Ponzi schemes. We\nconducted two case studies and in-depth user interviews with 12 domain experts\nand common investors to evaluate PonziLens+. The results demonstrate the\neffectiveness and usability of PonziLens+ in achieving an effective\nidentification of smart Ponzi schemes.",
    "categories": [
      "cs.HC"
    ],
    "published": "2024-12-24T14:56:07+00:00",
    "updated": "2024-12-24T14:56:07+00:00",
    "url": "http://arxiv.org/pdf/2412.18470v1"
  },
  {
    "id": "2412.18370v3",
    "title": "Unveiling the Threat of Fraud Gangs to Graph Neural Networks: Multi-Target Graph Injection Attacks Against GNN-Based Fraud Detectors",
    "authors": [
      "Jinhyeok Choi",
      "Heehyeon Kim",
      "Joyce Jiyoung Whang"
    ],
    "abstract": "Graph neural networks (GNNs) have emerged as an effective tool for fraud\ndetection, identifying fraudulent users, and uncovering malicious behaviors.\nHowever, attacks against GNN-based fraud detectors and their risks have rarely\nbeen studied, thereby leaving potential threats unaddressed. Recent findings\nsuggest that frauds are increasingly organized as gangs or groups. In this\nwork, we design attack scenarios where fraud gangs aim to make their fraud\nnodes misclassified as benign by camouflaging their illicit activities in\ncollusion. Based on these scenarios, we study adversarial attacks against\nGNN-based fraud detectors by simulating attacks of fraud gangs in three\nreal-world fraud cases: spam reviews, fake news, and medical insurance frauds.\nWe define these attacks as multi-target graph injection attacks and propose\nMonTi, a transformer-based Multi-target one-Time graph injection attack model.\nMonTi simultaneously generates attributes and edges of all attack nodes with a\ntransformer encoder, capturing interdependencies between attributes and edges\nmore effectively than most existing graph injection attack methods that\ngenerate these elements sequentially. Additionally, MonTi adaptively allocates\nthe degree budget for each attack node to explore diverse injection structures\ninvolving target, candidate, and attack nodes, unlike existing methods that fix\nthe degree budget across all attack nodes. Experiments show that MonTi\noutperforms the state-of-the-art graph injection attack methods on five\nreal-world graphs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2024-12-24T11:53:24+00:00",
    "updated": "2025-04-15T11:43:49+00:00",
    "url": "http://arxiv.org/pdf/2412.18370v3"
  },
  {
    "id": "2412.18287v1",
    "title": "Semi-supervised Credit Card Fraud Detection via Attribute-Driven Graph Representation",
    "authors": [
      "Sheng Xiang",
      "Mingzhi Zhu",
      "Dawei Cheng",
      "Enxia Li",
      "Ruihui Zhao",
      "Yi Ouyang",
      "Ling Chen",
      "Yefeng Zheng"
    ],
    "abstract": "Credit card fraud incurs a considerable cost for both cardholders and issuing\nbanks. Contemporary methods apply machine learning-based classifiers to detect\nfraudulent behavior from labeled transaction records. But labeled data are\nusually a small proportion of billions of real transactions due to expensive\nlabeling costs, which implies that they do not well exploit many natural\nfeatures from unlabeled data. Therefore, we propose a semi-supervised graph\nneural network for fraud detection. Specifically, we leverage transaction\nrecords to construct a temporal transaction graph, which is composed of\ntemporal transactions (nodes) and interactions (edges) among them. Then we pass\nmessages among the nodes through a Gated Temporal Attention Network (GTAN) to\nlearn the transaction representation. We further model the fraud patterns\nthrough risk propagation among transactions. The extensive experiments are\nconducted on a real-world transaction dataset and two publicly available fraud\ndetection datasets. The result shows that our proposed method, namely GTAN,\noutperforms other state-of-the-art baselines on three fraud detection datasets.\nSemi-supervised experiments demonstrate the excellent fraud detection\nperformance of our model with only a tiny proportion of labeled data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "published": "2024-12-24T08:48:48+00:00",
    "updated": "2024-12-24T08:48:48+00:00",
    "url": "http://arxiv.org/pdf/2412.18287v1"
  },
  {
    "id": "2412.16788v2",
    "title": "DCOR: Anomaly Detection in Attributed Networks via Dual Contrastive Learning Reconstruction",
    "authors": [
      "Hossein Rafieizadeh",
      "Hadi Zare",
      "Mohsen Ghassemi Parsa",
      "Hadi Davardoust",
      "Meshkat Shariat Bagheri"
    ],
    "abstract": "Anomaly detection using a network-based approach is one of the most efficient\nways to identify abnormal events such as fraud, security breaches, and system\nfaults in a variety of applied domains. While most of the earlier works address\nthe complex nature of graph-structured data and predefined anomalies, the\nimpact of data attributes and emerging anomalies are often neglected. This\npaper introduces DCOR, a novel approach on attributed networks that integrates\nreconstruction-based anomaly detection with Contrastive Learning. Utilizing a\nGraph Neural Network (GNN) framework, DCOR contrasts the reconstructed\nadjacency and feature matrices from both the original and augmented graphs to\ndetect subtle anomalies. We employed comprehensive experimental studies on\nbenchmark datasets through standard evaluation measures. The results show that\nDCOR significantly outperforms state-of-the-art methods. Obtained results\ndemonstrate the efficacy of proposed approach in attributed networks with the\npotential of uncovering new patterns of anomalies.",
    "categories": [
      "cs.AI",
      "05C82 05C82 05C82 05C82",
      "I.2.6; G.2.2"
    ],
    "published": "2024-12-21T22:02:06+00:00",
    "updated": "2025-01-20T20:17:59+00:00",
    "url": "http://arxiv.org/pdf/2412.16788v2"
  },
  {
    "id": "2412.15621v1",
    "title": "Pirates of Charity: Exploring Donation-based Abuses in Social Media Platforms",
    "authors": [
      "Bhupendra Acharya",
      "Dario Lazzaro",
      "Antonio Emanuele Cinà",
      "Thorsten Holz"
    ],
    "abstract": "With the widespread use of social media, organizations, and individuals use\nthese platforms to raise funds and support causes. Unfortunately, this has led\nto the rise of scammers in soliciting fraudulent donations. In this study, we\nconduct a large-scale analysis of donation-based scams on social media\nplatforms. More specifically, we studied profile creation and scam operation\nfraudulent donation solicitation on X, Instagram, Facebook, YouTube, and\nTelegram. By collecting data from 151,966 accounts and their 3,053,333 posts\nrelated to donations between March 2024 and May 2024, we identified 832\nscammers using various techniques to deceive users into making fraudulent\ndonations. Analyzing the fraud communication channels such as phone number,\nemail, and external URL linked, we show that these scamming accounts perform\nvarious fraudulent donation schemes, including classic abuse such as fake\nfundraising website setup, crowdsourcing fundraising, and asking users to\ncommunicate via email, phone, and pay via various payment methods. Through\ncollaboration with industry partners PayPal and cryptocurrency abuse database\nChainabuse, we further validated the scams and measured the financial losses on\nthese platforms. Our study highlights significant weaknesses in social media\nplatforms' ability to protect users from fraudulent donations. Additionally, we\nrecommended social media platforms, and financial services for taking proactive\nsteps to block these fraudulent activities. Our study provides a foundation for\nthe security community and researchers to automate detecting and mitigating\nfraudulent donation solicitation on social media platforms.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-12-20T07:26:43+00:00",
    "updated": "2024-12-20T07:26:43+00:00",
    "url": "http://arxiv.org/pdf/2412.15621v1"
  },
  {
    "id": "2412.14985v1",
    "title": "Exploration of the Dynamics of Buy and Sale of Social Media Accounts",
    "authors": [
      "Mario Beluri",
      "Bhupendra Acharya",
      "Soheil Khodayari",
      "Giada Stivala",
      "Giancarlo Pellegrino",
      "Thorsten Holz"
    ],
    "abstract": "There has been a rise in online platforms facilitating the buying and selling\nof social media accounts. While the trade of social media profiles is not\ninherently illegal, social media platforms view such transactions as violations\nof their policies. They often take action against accounts involved in the\nmisuse of platforms for financial gain. This research conducts a comprehensive\nanalysis of marketplaces that enable the buying and selling of social media\naccounts.\n  We investigate the economic scale of account trading across five major\nplatforms: X, Instagram, Facebook, TikTok, and YouTube. From February to June\n2024, we identified 38,253 accounts advertising account sales across 11 online\nmarketplaces, covering 211 distinct categories. The total value of marketed\nsocial media accounts exceeded \\$64 million, with a median price of \\$157 per\naccount. Additionally, we analyzed the profiles of 11,457 visible advertised\naccounts, collecting their metadata and over 200,000 profile posts. By\nexamining their engagement patterns and account creation methods, we evaluated\nthe fraudulent activities commonly associated with these sold accounts. Our\nresearch reveals these marketplaces foster fraudulent activities such as bot\nfarming, harvesting accounts for future fraud, and fraudulent engagement. Such\npractices pose significant risks to social media users, who are often targeted\nby fraudulent accounts resembling legitimate profiles and employing social\nengineering tactics. We highlight social media platform weaknesses in the\nability to detect and mitigate such fraudulent accounts, thereby endangering\nusers. Alongside this, we conducted thorough disclosures with the respective\nplatforms and proposed actionable recommendations, including indicators to\nidentify and track these accounts. These measures aim to enhance proactive\ndetection and safeguard users from potential threats.",
    "categories": [
      "cs.CR"
    ],
    "published": "2024-12-19T15:58:37+00:00",
    "updated": "2024-12-19T15:58:37+00:00",
    "url": "http://arxiv.org/pdf/2412.14985v1"
  },
  {
    "id": "2412.13471v1",
    "title": "Gradual Vigilance and Interval Communication: Enhancing Value Alignment in Multi-Agent Debates",
    "authors": [
      "Rui Zou",
      "Mengqi Wei",
      "Jintian Feng",
      "Qian Wan",
      "Jianwen Sun",
      "Sannyuya Liu"
    ],
    "abstract": "In recent years, large language models have shown exceptional performance in\nfulfilling diverse human needs. However, their training data can introduce\nharmful content, underscoring the necessity for robust value alignment.\nMainstream methods, which depend on feedback learning and supervised training,\nare resource-intensive and may constrain the full potential of the models.\nMulti-Agent Debate (MAD) offers a more efficient and innovative solution by\nenabling the generation of reliable answers through agent interactions. To\napply MAD to value alignment, we examine the relationship between the\nhelpfulness and harmlessness of debate outcomes and individual responses, and\npropose a MAD based framework Gradual Vigilance and Interval Communication\n(GVIC). GVIC allows agents to assess risks with varying levels of vigilance and\nto exchange diverse information through interval communication. We\ntheoretically prove that GVIC optimizes debate efficiency while reducing\ncommunication overhead. Experimental results demonstrate that GVIC consistently\noutperforms baseline methods across various tasks and datasets, particularly\nexcelling in harmfulness mitigation and fraud prevention. Additionally, GVIC\nexhibits strong adaptability across different base model sizes, including both\nunaligned and aligned models, and across various task types.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2024-12-18T03:36:08+00:00",
    "updated": "2024-12-18T03:36:08+00:00",
    "url": "http://arxiv.org/pdf/2412.13471v1"
  },
  {
    "id": "2412.12370v5",
    "title": "Scam Detection for Ethereum Smart Contracts: Leveraging Graph Representation Learning for Secure Blockchain",
    "authors": [
      "Yihong Jin",
      "Ze Yang",
      "Xinhe Xu"
    ],
    "abstract": "As more and more attacks have been detected on Ethereum smart contracts, it\nhas seriously affected finance and credibility. Current anti-fraud detection\ntechniques, including code parsing or manual feature extraction, still have\nsome shortcomings, although some generalization or adaptability can be\nobtained. In the face of this situation, this paper proposes to use graphical\nrepresentation learning technology to find transaction patterns and distinguish\nmalicious transaction contracts, that is, to represent Ethereum transaction\ndata as graphs, and then use advanced ML technology to obtain reliable and\naccurate results. Taking into account the sample imbalance, we treated with\nSMOTE-ENN and tested several models, in which MLP performed better than GCN,\nbut the exact effect depends on its field trials. Our research opens up more\npossibilities for trust and security in the Ethereum ecosystem.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.DC",
      "cs.SI",
      "I.2.1"
    ],
    "published": "2024-12-16T21:56:01+00:00",
    "updated": "2025-03-19T05:38:58+00:00",
    "url": "http://arxiv.org/pdf/2412.12370v5"
  },
  {
    "id": "2412.11488v1",
    "title": "Counting Butterflies over Streaming Bipartite Graphs with Duplicate Edges",
    "authors": [
      "Lingkai Meng",
      "Long Yuan",
      "Xuemin Lin",
      "Chengjie Li",
      "Kai Wang",
      "Wenjie Zhang"
    ],
    "abstract": "Bipartite graphs are commonly used to model relationships between two\ndistinct entities in real-world applications, such as user-product\ninteractions, user-movie ratings and collaborations between authors and\npublications. A butterfly (a 2x2 bi-clique) is a critical substructure in\nbipartite graphs, playing a significant role in tasks like community detection,\nfraud detection, and link prediction. As more real-world data is presented in a\nstreaming format, efficiently counting butterflies in streaming bipartite\ngraphs has become increasingly important. However, most existing algorithms\ntypically assume that duplicate edges are absent, which is hard to hold in\nreal-world graph streams, as a result, they tend to sample edges that appear\nmultiple times, leading to inaccurate results. The only algorithm designed to\nhandle duplicate edges is FABLE, but it suffers from significant limitations,\nincluding high variance, substantial time complexity, and memory inefficiency\ndue to its reliance on a priority queue. To overcome these limitations, we\nintroduce DEABC (Duplicate-Edge-Aware Butterfly Counting), an innovative method\nthat uses bucket-based priority sampling to accurately estimate the number of\nbutterflies, accounting for duplicate edges. Compared to existing methods,\nDEABC significantly reduces memory usage by storing only the essential sampled\nedge data while maintaining high accuracy. We provide rigorous proofs of the\nunbiasedness and variance bounds for DEABC, ensuring they achieve high\naccuracy. We compare DEABC with state-of-the-art algorithms on real-world\nstreaming bipartite graphs. The results show that our DEABC outperforms\nexisting methods in memory efficiency and accuracy, while also achieving\nsignificantly higher throughput.",
    "categories": [
      "cs.DS"
    ],
    "published": "2024-12-16T07:04:54+00:00",
    "updated": "2024-12-16T07:04:54+00:00",
    "url": "http://arxiv.org/pdf/2412.11488v1"
  },
  {
    "id": "2502.10321v1",
    "title": "Dynamic Fraud Proof",
    "authors": [
      "Gabriele Picco",
      "Andrea Fortugno"
    ],
    "abstract": "In this paper, we present a novel fraud-proof mechanism that achieves fast\nfinality and, when combined with optimistic execution, enables real-time\ntransaction processing. State-of-the-art optimistic rollups typically adopt a\n7-day challenge window, during which any honest party can raise a challenge in\ncase of fraud. We propose a new assert/challenge construction called \"Dynamic\nFraud Proofs\" that achieves sub-second finality in ideal scenarios, while\ndynamically delaying settlement in the event of fraud detection and challenge\nresolution. The system relies on 1) a dynamic challenge period and 2) a\nconfigurable number of randomly selected verifier nodes who must interactively\napprove a state commitment without raising a challenge. If these conditions are\nnot met, the state is not finalized, and the challenge period and approval\ncriteria are dynamically adjusted. We provide a detailed analysis of the\nsystem's design, explaining how it maintains the assumption of a single honest\nnode and addresses censorship attacks by inverting the traditional challenge\nprocess. Additionally, we formalize the system's probabilistic security model\nand discuss how bonding, incentives, and slashing mechanisms can encourage\nhonest behavior, thereby increasing the likelihood of fast settlement in ideal\nscenarios.",
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "published": "2025-02-14T17:27:40+00:00",
    "updated": "2025-02-14T17:27:40+00:00",
    "url": "http://arxiv.org/pdf/2502.10321v1"
  },
  {
    "id": "2502.08077v1",
    "title": "Cascading Bandits Robust to Adversarial Corruptions",
    "authors": [
      "Jize Xie",
      "Cheng Chen",
      "Zhiyong Wang",
      "Shuai Li"
    ],
    "abstract": "Online learning to rank sequentially recommends a small list of items to\nusers from a large candidate set and receives the users' click feedback. In\nmany real-world scenarios, users browse the recommended list in order and click\nthe first attractive item without checking the rest. Such behaviors are usually\nformulated as the cascade model. Many recent works study algorithms for\ncascading bandits, an online learning to rank framework in the cascade model.\nHowever, the performance of existing methods may drop significantly if part of\nthe user feedback is adversarially corrupted (e.g., click fraud). In this work,\nwe study how to resist adversarial corruptions in cascading bandits. We first\nformulate the ``\\textit{Cascading Bandits with Adversarial Corruptions}\" (CBAC)\nproblem, which assumes that there is an adaptive adversary that may manipulate\nthe user feedback. Then we propose two robust algorithms for this problem,\nwhich assume the corruption level is known and agnostic, respectively. We show\nthat both algorithms can achieve logarithmic regret when the algorithm is not\nunder attack, and the regret increases linearly with the corruption level. The\nexperimental results also verify the robustness of our methods.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-02-12T02:44:41+00:00",
    "updated": "2025-02-12T02:44:41+00:00",
    "url": "http://arxiv.org/pdf/2502.08077v1"
  },
  {
    "id": "2502.07694v1",
    "title": "Methodology for Identifying Social Groups within a Transactional Graph",
    "authors": [
      "Maxence Morin",
      "Baptiste Hemery",
      "Fabrice Jeanne",
      "Estelle Pawlowski-Cherrier"
    ],
    "abstract": "Social network analysis is pivotal for organizations aiming to leverage the\nvast amounts of data generated from user interactions on social media and other\ndigital platforms. These interactions often reveal complex social structures,\nsuch as tightly-knit groups based on common interests, which are crucial for\nenhancing service personalization or fraud detection. Traditional methods like\ncommunity detection and graph matching, while useful, often fall short of\naccurately identifying specific groups of users. This paper introduces a novel\nframework specifically designed to identify groups of users within\ntransactional graphs by focusing on the contextual and structural nuances that\ndefine these groups.",
    "categories": [
      "cs.SI"
    ],
    "published": "2025-02-11T16:48:48+00:00",
    "updated": "2025-02-11T16:48:48+00:00",
    "url": "http://arxiv.org/pdf/2502.07694v1"
  },
  {
    "id": "2503.22681v1",
    "title": "detectGNN: Harnessing Graph Neural Networks for Enhanced Fraud Detection in Credit Card Transactions",
    "authors": [
      "Irin Sultana",
      "Syed Mustavi Maheen",
      "Naresh Kshetri",
      "Md Nasim Fardous Zim"
    ],
    "abstract": "Credit card fraud is a major issue nowadays, costing huge money and affecting\ntrust in financial systems. Traditional fraud detection methods often fail to\ndetect advanced and growing fraud techniques. This study focuses on using Graph\nNeural Networks (GNNs) to improve fraud detection by analyzing transactions as\na network of connected data points, such as accounts, traders, and devices. The\nproposed \"detectGNN\" model uses advanced features like time-based patterns and\ndynamic updates to expose hidden fraud and improve detection accuracy. Tests\nshow that GNNs perform better than traditional methods in finding complex and\nmulti-layered fraud. The model also addresses real-time processing, data\nimbalance, and privacy concerns, making it practical for real-world use. This\nresearch shows that GNNs can provide a powerful, accurate, and a scalable\nsolution for detecting fraud. Future work will focus on making the models\neasier to understand, privacy-friendly, and adaptable to new types of fraud,\nensuring safer financial transactions in the digital world.",
    "categories": [
      "cs.CR"
    ],
    "published": "2025-02-09T00:01:36+00:00",
    "updated": "2025-02-09T00:01:36+00:00",
    "url": "http://arxiv.org/pdf/2503.22681v1"
  },
  {
    "id": "2502.05439v2",
    "title": "Agentic AI Systems Applied to tasks in Financial Services: Modeling and model risk management crews",
    "authors": [
      "Izunna Okpala",
      "Ashkan Golgoon",
      "Arjun Ravi Kannan"
    ],
    "abstract": "The advent of large language models has ushered in a new era of agentic\nsystems, where artificial intelligence programs exhibit remarkable autonomous\ndecision-making capabilities across diverse domains. This paper explores\nagentic system workflows in the financial services industry. In particular, we\nbuild agentic crews with human-in-the-loop module that can effectively\ncollaborate to perform complex modeling and model risk management (MRM) tasks.\nThe modeling crew consists of a judge agent and multiple agents who perform\nspecific tasks such as exploratory data analysis, feature engineering, model\nselection/hyperparameter tuning, model training, model evaluation, and writing\ndocumentation. The MRM crew consists of a judge agent along with specialized\nagents who perform tasks such as checking compliance of modeling documentation,\nmodel replication, conceptual soundness, analysis of outcomes, and writing\ndocumentation. We demonstrate the effectiveness and robustness of modeling and\nMRM crews by presenting a series of numerical examples applied to credit card\nfraud detection, credit card approval, and portfolio credit risk modeling\ndatasets.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.CL",
      "cs.LG",
      "68T01 (Primary) 68T05, 68N99, 68T05, 68T20, 68T50, 62H30, 65C20,\n  68P20 (Secondary)",
      "I.2.0; I.2.1; I.2.2; I.2.6; I.2.7; I.5.1; I.6.0; I.7.1"
    ],
    "published": "2025-02-08T04:03:47+00:00",
    "updated": "2025-04-29T18:39:35+00:00",
    "url": "http://arxiv.org/pdf/2502.05439v2"
  },
  {
    "id": "2502.03386v1",
    "title": "A Structured Reasoning Framework for Unbalanced Data Classification Using Probabilistic Models",
    "authors": [
      "Junliang Du",
      "Shiyu Dou",
      "Bohuan Yang",
      "Jiacheng Hu",
      "Tai An"
    ],
    "abstract": "This paper studies a Markov network model for unbalanced data, aiming to\nsolve the problems of classification bias and insufficient minority class\nrecognition ability of traditional machine learning models in environments with\nuneven class distribution. By constructing joint probability distribution and\nconditional dependency, the model can achieve global modeling and reasoning\noptimization of sample categories. The study introduced marginal probability\nestimation and weighted loss optimization strategies, combined with\nregularization constraints and structured reasoning methods, effectively\nimproving the generalization ability and robustness of the model. In the\nexperimental stage, a real credit card fraud detection dataset was selected and\ncompared with models such as logistic regression, support vector machine,\nrandom forest and XGBoost. The experimental results show that the Markov\nnetwork performs well in indicators such as weighted accuracy, F1 score, and\nAUC-ROC, significantly outperforming traditional classification models,\ndemonstrating its strong decision-making ability and applicability in\nunbalanced data scenarios. Future research can focus on efficient model\ntraining, structural optimization, and deep learning integration in large-scale\nunbalanced data environments and promote its wide application in practical\napplications such as financial risk control, medical diagnosis, and intelligent\nmonitoring.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-02-05T17:20:47+00:00",
    "updated": "2025-02-05T17:20:47+00:00",
    "url": "http://arxiv.org/pdf/2502.03386v1"
  },
  {
    "id": "2502.02767v2",
    "title": "When Anti-Fraud Laws Become a Barrier to Computer Science Research",
    "authors": [
      "Madelyne Xiao",
      "Andrew Sellars",
      "Sarah Scheffler"
    ],
    "abstract": "Computer science research sometimes brushes with the law, from red-team\nexercises that probe the boundaries of authentication mechanisms, to AI\nresearch processing copyrighted material, to platform research measuring the\nbehavior of algorithms and users. U.S.-based computer security research is no\nstranger to the Computer Fraud and Abuse Act (CFAA) and the Digital Millennium\nCopyright Act (DMCA) in a relationship that is still evolving through case law,\nresearch practices, changing policies, and legislation.\n  Amid the landscape computer scientists, lawyers, and policymakers have\nlearned to navigate, anti-fraud laws are a surprisingly under-examined\nchallenge for computer science research. Fraud brings separate issues that are\nnot addressed by the methods for navigating CFAA, DMCA, and Terms of Service\nthat are more familiar in the computer security literature. Although anti-fraud\nlaws have been discussed to a limited extent in older research on phishing\nattacks, modern computer science researchers are left with little guidance when\nit comes to navigating issues of deception outside the context of pure\nlaboratory research.\n  In this paper, we analyze and taxonomize the anti-fraud and deception issues\nthat arise in several areas of computer science research. We find that, despite\nthe lack of attention to these issues in the legal and computer science\nliterature, issues of misrepresented identity or false information that could\nimplicate anti-fraud laws are actually relevant to many methodologies used in\ncomputer science research, including penetration testing, web scraping, user\nstudies, sock puppets, social engineering, auditing AI or socio-technical\nsystems, and attacks on artificial intelligence. We especially highlight the\nimportance of anti-fraud laws in two research fields of great policy\nimportance: attacking or auditing AI systems, and research involving legal\nidentification.",
    "categories": [
      "cs.CY"
    ],
    "published": "2025-02-04T23:14:09+00:00",
    "updated": "2025-02-06T02:43:44+00:00",
    "url": "http://arxiv.org/pdf/2502.02767v2"
  },
  {
    "id": "2502.02290v1",
    "title": "FRAUD-RLA: A new reinforcement learning adversarial attack against credit card fraud detection",
    "authors": [
      "Daniele Lunghi",
      "Yannick Molinghen",
      "Alkis Simitsis",
      "Tom Lenaerts",
      "Gianluca Bontempi"
    ],
    "abstract": "Adversarial attacks pose a significant threat to data-driven systems, and\nresearchers have spent considerable resources studying them. Despite its\neconomic relevance, this trend largely overlooked the issue of credit card\nfraud detection. To address this gap, we propose a new threat model that\ndemonstrates the limitations of existing attacks and highlights the necessity\nto investigate new approaches. We then design a new adversarial attack for\ncredit card fraud detection, employing reinforcement learning to bypass\nclassifiers. This attack, called FRAUD-RLA, is designed to maximize the\nattacker's reward by optimizing the exploration-exploitation tradeoff and\nworking with significantly less required knowledge than competitors. Our\nexperiments, conducted on three different heterogeneous datasets and against\ntwo fraud detection systems, indicate that FRAUD-RLA is effective, even\nconsidering the severe limitations imposed by our threat model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-02-04T12:59:35+00:00",
    "updated": "2025-02-04T12:59:35+00:00",
    "url": "http://arxiv.org/pdf/2502.02290v1"
  },
  {
    "id": "2502.01193v1",
    "title": "SigN: SIMBox Activity Detection Through Latency Anomalies at the Cellular Edge",
    "authors": [
      "Anne Josiane Kouam",
      "Aline Carneiro Viana",
      "Philippe Martins",
      "Cedric Adjih",
      "Alain Tchana"
    ],
    "abstract": "Despite their widespread adoption, cellular networks face growing\nvulnerabilities due to their inherent complexity and the integration of\nadvanced technologies. One of the major threats in this landscape is Voice over\nIP (VoIP) to GSM gateways, known as SIMBox devices. These devices use multiple\nSIM cards to route VoIP traffic through cellular networks, enabling\ninternational bypass fraud with losses of up to $3.11 billion annually. Beyond\nfinancial impact, SIMBox activity degrades network performance, threatens\nnational security, and facilitates eavesdropping on communications. Existing\ndetection methods for SIMBox activity are hindered by evolving fraud techniques\nand implementation complexities, limiting their practical adoption in operator\nnetworks.This paper addresses the limitations of current detection methods by\nintroducing SigN , a novel approach to identifying SIMBox activity at the\ncellular edge. The proposed method focuses on detecting remote SIM card\nassociation, a technique used by SIMBox appliances to mimic human mobility\npatterns. The method detects latency anomalies between SIMBox and standard\ndevices by analyzing cellular signaling during network attachment. Extensive\nindoor and outdoor experiments demonstrate that SIMBox devices generate\nsignificantly higher attachment latencies, particularly during the\nauthentication phase, where latency is up to 23 times greater than that of\nstandard devices. We attribute part of this overhead to immutable factors such\nas LTE authentication standards and Internet-based communication protocols.\nTherefore, our approach offers a robust, scalable, and practical solution to\nmitigate SIMBox activity risks at the network edge.",
    "categories": [
      "cs.NI"
    ],
    "published": "2025-02-03T09:32:00+00:00",
    "updated": "2025-02-03T09:32:00+00:00",
    "url": "http://arxiv.org/pdf/2502.01193v1"
  },
  {
    "id": "2502.00837v2",
    "title": "Explainability in Practice: A Survey of Explainable NLP Across Various Domains",
    "authors": [
      "Hadi Mohammadi",
      "Ayoub Bagheri",
      "Anastasia Giachanou",
      "Daniel L. Oberski"
    ],
    "abstract": "Natural Language Processing (NLP) has become a cornerstone in many critical\nsectors, including healthcare, finance, and customer relationship management.\nThis is especially true with the development and use of advanced models such as\nGPT-based architectures and BERT, which are widely used in decision-making\nprocesses. However, the black-box nature of these advanced NLP models has\ncreated an urgent need for transparency and explainability. This review\nexplores explainable NLP (XNLP) with a focus on its practical deployment and\nreal-world applications, examining its implementation and the challenges faced\nin domain-specific contexts. The paper underscores the importance of\nexplainability in NLP and provides a comprehensive perspective on how XNLP can\nbe designed to meet the unique demands of various sectors, from healthcare's\nneed for clear insights to finance's emphasis on fraud detection and risk\nassessment. Additionally, this review aims to bridge the knowledge gap in XNLP\nliterature by offering a domain-specific exploration and discussing\nunderrepresented areas such as real-world applicability, metric evaluation, and\nthe role of human interaction in model assessment. The paper concludes by\nsuggesting future research directions that could enhance the understanding and\nbroader application of XNLP.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-02-02T16:18:44+00:00",
    "updated": "2025-06-05T15:41:25+00:00",
    "url": "http://arxiv.org/pdf/2502.00837v2"
  },
  {
    "id": "2502.00612v2",
    "title": "Using Causality for Enhanced Prediction of Web Traffic Time Series",
    "authors": [
      "Chang Tian",
      "Mingzhe Xing",
      "Zenglin Shi",
      "Matthew B. Blaschko",
      "Yinliang Yue",
      "Marie-Francine Moens"
    ],
    "abstract": "Predicting web service traffic has significant social value, as it can be\napplied to various practical scenarios, including but not limited to dynamic\nresource scaling, load balancing, system anomaly detection, service-level\nagreement compliance, and fraud detection. Web service traffic is characterized\nby frequent and drastic fluctuations over time and are influenced by\nheterogeneous web user behaviors, making accurate prediction a challenging\ntask. Previous research has extensively explored statistical approaches, and\nneural networks to mine features from preceding service traffic time series for\nprediction. However, these methods have largely overlooked the causal\nrelationships between services. Drawing inspiration from causality in\necological systems, we empirically recognize the causal relationships between\nweb services. To leverage these relationships for improved web service traffic\nprediction, we propose an effective neural network module, CCMPlus, designed to\nextract causal relationship features across services. This module can be\nseamlessly integrated with existing time series models to consistently enhance\nthe performance of web service traffic predictions. We theoretically justify\nthat the causal correlation matrix generated by the CCMPlus module captures\ncausal relationships among services. Empirical results on real-world datasets\nfrom Microsoft Azure, Alibaba Group, and Ant Group confirm that our method\nsurpasses state-of-the-art approaches in Mean Squared Error (MSE) and Mean\nAbsolute Error (MAE) for predicting service traffic time series. These findings\nhighlight the efficacy of leveraging causal relationships for improved\npredictions.",
    "categories": [
      "cs.LG",
      "cs.NI"
    ],
    "published": "2025-02-02T00:36:40+00:00",
    "updated": "2025-09-05T16:00:06+00:00",
    "url": "http://arxiv.org/pdf/2502.00612v2"
  },
  {
    "id": "2502.00529v1",
    "title": "Graph Data Management and Graph Machine Learning: Synergies and Opportunities",
    "authors": [
      "Arijit Khan",
      "Xiangyu Ke",
      "Yinghui Wu"
    ],
    "abstract": "The ubiquity of machine learning, particularly deep learning, applied to\ngraphs is evident in applications ranging from cheminformatics (drug discovery)\nand bioinformatics (protein interaction prediction) to knowledge graph-based\nquery answering, fraud detection, and social network analysis. Concurrently,\ngraph data management deals with the research and development of effective,\nefficient, scalable, robust, and user-friendly systems and algorithms for\nstoring, processing, and analyzing vast quantities of heterogeneous and complex\ngraph data. Our survey provides a comprehensive overview of the synergies\nbetween graph data management and graph machine learning, illustrating how they\nintertwine and mutually reinforce each other across the entire spectrum of the\ngraph data science and machine learning pipeline. Specifically, the survey\nhighlights two crucial aspects: (1) How graph data management enhances graph\nmachine learning, including contributions such as improved graph neural network\nperformance through graph data cleaning, scalable graph embedding, efficient\ngraph-based vector data management, robust graph neural networks, user-friendly\nexplainability methods; and (2) how graph machine learning, in turn, aids in\ngraph data management, with a focus on applications like query answering over\nknowledge graphs and various data science tasks. We discuss pertinent open\nproblems and delineate crucial research directions.",
    "categories": [
      "cs.DB"
    ],
    "published": "2025-02-01T19:04:25+00:00",
    "updated": "2025-02-01T19:04:25+00:00",
    "url": "http://arxiv.org/pdf/2502.00529v1"
  },
  {
    "id": "2502.00201v2",
    "title": "Year-over-Year Developments in Financial Fraud Detection via Deep Learning: A Systematic Literature Review",
    "authors": [
      "Yisong Chen",
      "Chuqing Zhao",
      "Yixin Xu",
      "Chuanhao Nie",
      "Yixin Zhang"
    ],
    "abstract": "This paper systematically reviews advancements in deep learning (DL)\ntechniques for financial fraud detection, a critical issue in the financial\nsector. Using the Kitchenham systematic literature review approach, 57 studies\npublished between 2019 and 2024 were analyzed. The review highlights the\neffectiveness of various deep learning models such as Convolutional Neural\nNetworks, Long Short-Term Memory, and transformers across domains such as\ncredit card transactions, insurance claims, and financial statement audits.\nPerformance metrics such as precision, recall, F1-score, and AUC-ROC were\nevaluated. Key themes explored include the impact of data privacy frameworks\nand advancements in feature engineering and data preprocessing. The study\nemphasizes challenges such as imbalanced datasets, model interpretability, and\nethical considerations, alongside opportunities for automation and\nprivacy-preserving techniques such as blockchain integration and Principal\nComponent Analysis. By examining trends over the past five years, this review\nidentifies critical gaps and promising directions for advancing DL applications\nin financial fraud detection, offering actionable insights for researchers and\npractitioners.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.ST"
    ],
    "published": "2025-01-31T22:31:50+00:00",
    "updated": "2025-07-30T04:32:58+00:00",
    "url": "http://arxiv.org/pdf/2502.00201v2"
  },
  {
    "id": "2501.19267v1",
    "title": "Transformer-Based Financial Fraud Detection with Cloud-Optimized Real-Time Streaming",
    "authors": [
      "Tingting Deng",
      "Shuochen Bi",
      "Jue Xiao"
    ],
    "abstract": "As the financial industry becomes more interconnected and reliant on digital\nsystems, fraud detection systems must evolve to meet growing threats.\nCloud-enabled Transformer models present a transformative opportunity to\naddress these challenges. By leveraging the scalability, flexibility, and\nadvanced AI capabilities of cloud platforms, companies can deploy fraud\ndetection solutions that adapt to real-time data patterns and proactively\nrespond to evolving threats. Using the Graph self-attention Transformer neural\nnetwork module, we can directly excavate gang fraud features from the\ntransaction network without constructing complicated feature engineering.\nFinally, the fraud prediction network is combined to optimize the topological\npattern and the temporal transaction pattern to realize the high-precision\ndetection of fraudulent transactions. The results of antifraud experiments on\ncredit card transaction data show that the proposed model outperforms the 7\nbaseline models on all evaluation indicators: In the transaction fraud\ndetection task, the average accuracy (AP) increased by 20% and the area under\nthe ROC curve (AUC) increased by 2.7% on average compared with the benchmark\ngraph attention neural network (GAT), which verified the effectiveness of the\nproposed model in the detection of credit card fraud transactions.",
    "categories": [
      "cs.CE"
    ],
    "published": "2025-01-31T16:27:58+00:00",
    "updated": "2025-01-31T16:27:58+00:00",
    "url": "http://arxiv.org/pdf/2501.19267v1"
  },
  {
    "id": "2501.18417v2",
    "title": "Real-Time Anomaly Detection with Synthetic Anomaly Monitoring (SAM)",
    "authors": [
      "Emanuele Luzio",
      "Moacir Antonelli Ponti"
    ],
    "abstract": "Anomaly detection is essential for identifying rare and significant events\nacross diverse domains such as finance, cybersecurity, and network monitoring.\nThis paper presents Synthetic Anomaly Monitoring (SAM), an innovative approach\nthat applies synthetic control methods from causal inference to improve both\nthe accuracy and interpretability of anomaly detection processes. By modeling\nnormal behavior through the treatment of each feature as a control unit, SAM\nidentifies anomalies as deviations within this causal framework. We conducted\nextensive experiments comparing SAM with established benchmark models,\nincluding Isolation Forest, Local Outlier Factor (LOF), k-Nearest Neighbors\n(kNN), and One-Class Support Vector Machine (SVM), across five diverse\ndatasets, including Credit Card Fraud, HTTP Dataset CSIC 2010, and KDD Cup\n1999, among others. Our results demonstrate that SAM consistently delivers\nrobust performance, highlighting its potential as a powerful tool for real-time\nanomaly detection in dynamic and complex environments.",
    "categories": [
      "cs.LG",
      "62H30, 68T05, 62G99, 91G80, 68M10",
      "I.5.4; K.6.5; I.2.6; H.4.2"
    ],
    "published": "2025-01-30T15:15:17+00:00",
    "updated": "2025-02-03T12:12:21+00:00",
    "url": "http://arxiv.org/pdf/2501.18417v2"
  },
  {
    "id": "2501.17834v1",
    "title": "Hierarchical Fallback Architecture for High Risk Online Machine Learning Inference",
    "authors": [
      "Gustavo Polleti",
      "Marlesson Santana",
      "Felipe Sassi Del Sant",
      "Eduardo Fontes"
    ],
    "abstract": "Open Banking powered machine learning applications require novel robustness\napproaches to deal with challenging stress and failure scenarios. In this paper\nwe propose an hierarchical fallback architecture for improving robustness in\nhigh risk machine learning applications with a focus in the financial domain.\nWe define generic failure scenarios often found in online inference that depend\non external data providers and we describe in detail how to apply the\nhierarchical fallback architecture to address them. Finally, we offer a real\nworld example of its applicability in the industry for near-real time\ntransactional fraud risk evaluation using Open Banking data and under extreme\nstress scenarios.",
    "categories": [
      "cs.LG",
      "cs.CE",
      "cs.SE",
      "I.2.m"
    ],
    "published": "2025-01-29T18:30:18+00:00",
    "updated": "2025-01-29T18:30:18+00:00",
    "url": "http://arxiv.org/pdf/2501.17834v1"
  },
  {
    "id": "2501.17903v2",
    "title": "Free Agent in Agent-Based Mixture-of-Experts Generative AI Framework",
    "authors": [
      "Jung-Hua Liu"
    ],
    "abstract": "Multi-agent systems commonly distribute tasks among specialized, autonomous\nagents, yet they often lack mechanisms to replace or reassign underperforming\nagents in real time. Inspired by the free-agency model of Major League\nBaseball, the Reinforcement Learning Free Agent (RLFA) algorithm introduces a\nreward-based mechanism to detect and remove agents exhibiting persistent\nunderperformance and seamlessly insert more capable ones. Each agent internally\nuses a mixture-of-experts (MoE) approach, delegating incoming tasks to\nspecialized sub-models under the guidance of a gating function. A primary use\ncase is fraud detection, where RLFA promptly swaps out an agent whose detection\naccuracy dips below a preset threshold. A new agent is tested in a probationary\nmode, and upon demonstrating superior performance, fully replaces the\nunderperformer. This dynamic, free-agency cycle ensures sustained accuracy,\nquicker adaptation to emerging threats, and minimal disruption to ongoing\noperations. By continually refreshing its roster of agents, the system fosters\nongoing improvements and more resilient collaboration in multi-agent Generative\nAI environments.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "published": "2025-01-29T13:00:22+00:00",
    "updated": "2025-02-10T16:13:08+00:00",
    "url": "http://arxiv.org/pdf/2501.17903v2"
  },
  {
    "id": "2501.15290v1",
    "title": "Advanced Real-Time Fraud Detection Using RAG-Based LLMs",
    "authors": [
      "Gurjot Singh",
      "Prabhjot Singh",
      "Maninder Singh"
    ],
    "abstract": "Artificial Intelligence has become a double edged sword in modern society\nbeing both a boon and a bane. While it empowers individuals it also enables\nmalicious actors to perpetrate scams such as fraudulent phone calls and user\nimpersonations. This growing threat necessitates a robust system to protect\nindividuals In this paper we introduce a novel real time fraud detection\nmechanism using Retrieval Augmented Generation technology to address this\nchallenge on two fronts. First our system incorporates a continuously updating\npolicy checking feature that transcribes phone calls in real time and uses RAG\nbased models to verify that the caller is not soliciting private information\nthus ensuring transparency and the authenticity of the conversation. Second we\nimplement a real time user impersonation check with a two step verification\nprocess to confirm the callers identity ensuring accountability. A key\ninnovation of our system is the ability to update policies without retraining\nthe entire model enhancing its adaptability. We validated our RAG based\napproach using synthetic call recordings achieving an accuracy of 97.98 percent\nand an F1score of 97.44 percent with 100 calls outperforming state of the art\nmethods. This robust and flexible fraud detection system is well suited for\nreal world deployment.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-01-25T17:58:05+00:00",
    "updated": "2025-01-25T17:58:05+00:00",
    "url": "http://arxiv.org/pdf/2501.15290v1"
  },
  {
    "id": "2506.07363v2",
    "title": "Deepfake Technology Unveiled: The Commoditization of AI and Its Impact on Digital Trust",
    "authors": [
      "Claudiu Popa",
      "Rex Pallath",
      "Liam Cunningham",
      "Hewad Tahiri",
      "Abiram Kesavarajah",
      "Tao Wu"
    ],
    "abstract": "Deepfake Technology Unveiled: The Commoditization of AI and Its Impact on\nDigital Trust. With the increasing accessibility of generative AI, tools for\nvoice cloning, face-swapping, and synthetic media creation have advanced\nsignificantly, lowering both financial and technical barriers for their use.\nWhile these technologies present innovative opportunities, their rapid growth\nraises concerns about trust, privacy, and security. This white paper explores\nthe implications of deepfake technology, analyzing its role in enabling fraud,\nmisinformation, and the erosion of authenticity in multimedia. Using\ncost-effective, easy to use tools such as Runway, Rope, and ElevenLabs, we\nexplore how realistic deepfakes can be created with limited resources,\ndemonstrating the risks posed to individuals and organizations alike. By\nanalyzing the technical and ethical challenges of deepfake mitigation and\ndetection, we emphasize the urgent need for regulatory frameworks, public\nawareness, and collaborative efforts to maintain trust in digital media.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2.m"
    ],
    "published": "2025-01-24T18:02:49+00:00",
    "updated": "2025-07-15T14:07:07+00:00",
    "url": "http://arxiv.org/pdf/2506.07363v2"
  },
  {
    "id": "2501.12560v1",
    "title": "Improved Detection and Diagnosis of Faults in Deep Neural Networks Using Hierarchical and Explainable Classification",
    "authors": [
      "Sigma Jahan",
      "Mehil B Shah",
      "Parvez Mahbub",
      "Mohammad Masudur Rahman"
    ],
    "abstract": "Deep Neural Networks (DNN) have found numerous applications in various\ndomains, including fraud detection, medical diagnosis, facial recognition, and\nautonomous driving. However, DNN-based systems often suffer from reliability\nissues due to their inherent complexity and the stochastic nature of their\nunderlying models. Unfortunately, existing techniques to detect faults in DNN\nprograms are either limited by the types of faults (e.g., hyperparameter or\nlayer) they support or the kind of information (e.g., dynamic or static) they\nuse. As a result, they might fall short of comprehensively detecting and\ndiagnosing the faults. In this paper, we present DEFault (Detect and Explain\nFault) -- a novel technique to detect and diagnose faults in DNN programs. It\nfirst captures dynamic (i.e., runtime) features during model training and\nleverages a hierarchical classification approach to detect all major fault\ncategories from the literature. Then, it captures static features (e.g., layer\ntypes) from DNN programs and leverages explainable AI methods (e.g., SHAP) to\nnarrow down the root cause of the fault. We train and evaluate DEFault on a\nlarge, diverse dataset of ~14.5K DNN programs and further validate our\ntechnique using a benchmark dataset of 52 real-life faulty DNN programs. Our\napproach achieves ~94% recall in detecting real-world faulty DNN programs and\n~63% recall in diagnosing the root causes of the faults, demonstrating 3.92% -\n11.54% higher performance than that of state-of-the-art techniques. Thus,\nDEFault has the potential to significantly improve the reliability of DNN\nprograms by effectively detecting and diagnosing the faults.",
    "categories": [
      "cs.SE"
    ],
    "published": "2025-01-22T00:55:09+00:00",
    "updated": "2025-01-22T00:55:09+00:00",
    "url": "http://arxiv.org/pdf/2501.12560v1"
  },
  {
    "id": "2501.12491v1",
    "title": "Optimizing Blockchain Analysis: Tackling Temporality and Scalability with an Incremental Approach with Metropolis-Hastings Random Walks",
    "authors": [
      "Junliang Luo",
      "Xue Liu"
    ],
    "abstract": "Blockchain technology, with implications in the financial domain, offers data\nin the form of large-scale transaction networks. Analyzing transaction networks\nfacilitates fraud detection, market analysis, and supports government\nregulation. Despite many graph representation learning methods for transaction\nnetwork analysis, we pinpoint two salient limitations that merit more\ninvestigation. Existing methods predominantly focus on the snapshots of\ntransaction networks, sidelining the evolving nature of blockchain transaction\nnetworks. Existing methodologies may not sufficiently emphasize efficient,\nincremental learning capabilities, which are essential for addressing the\nscalability challenges in ever-expanding large-scale transaction networks. To\naddress these challenges, we employed an incremental approach for random\nwalk-based node representation learning in transaction networks. Further, we\nproposed a Metropolis-Hastings-based random walk mechanism for improved\nefficiency. The empirical evaluation conducted on blockchain transaction\ndatasets reveals comparable performance in node classification tasks while\nreducing computational overhead. Potential applications include transaction\nnetwork monitoring, the efficient classification of blockchain addresses for\nfraud detection or the identification of specialized address types within the\nnetwork.",
    "categories": [
      "cs.CE",
      "stat.ML"
    ],
    "published": "2025-01-21T20:34:38+00:00",
    "updated": "2025-01-21T20:34:38+00:00",
    "url": "http://arxiv.org/pdf/2501.12491v1"
  },
  {
    "id": "2501.12430v1",
    "title": "SCFCRC: Simultaneously Counteract Feature Camouflage and Relation Camouflage for Fraud Detection",
    "authors": [
      "Xiaocheng Zhang",
      "Zhuangzhuang Ye",
      "GuoPing Zhao",
      "Jianing Wang",
      "Xiaohong Su"
    ],
    "abstract": "In fraud detection, fraudsters often interact with many benign users,\ncamouflaging their features or relations to hide themselves. Most existing work\nconcentrates solely on either feature camouflage or relation camouflage, or\ndecoupling feature learning and relation learning to avoid the two camouflage\nfrom affecting each other. However, this inadvertently neglects the valuable\ninformation derived from features or relations, which could mutually enhance\ntheir adversarial camouflage strategies. In response to this gap, we propose\nSCFCRC, a Transformer-based fraud detector that Simultaneously Counteract\nFeature Camouflage and Relation Camouflage. SCFCRC consists of two components:\nFeature Camouflage Filter and Relation Camouflage Refiner. The feature\ncamouflage filter utilizes pseudo labels generated through label propagation to\ntrain the filter and uses contrastive learning that combines instance-wise and\nprototype-wise to improve the quality of features. The relation camouflage\nrefiner uses Mixture-of-Experts(MoE) network to disassemble the multi-relations\ngraph into multiple substructures and divide and conquer them to mitigate the\ndegradation of detection performance caused by relation camouflage.\nFurthermore, we introduce a regularization method for MoE to enhance the\nrobustness of the model. Extensive experiments on two fraud detection benchmark\ndatasets demonstrate that our method outperforms state-of-the-art baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-01-21T15:50:51+00:00",
    "updated": "2025-01-21T15:50:51+00:00",
    "url": "http://arxiv.org/pdf/2501.12430v1"
  },
  {
    "id": "2501.11902v1",
    "title": "Transferable Adversarial Attacks on Audio Deepfake Detection",
    "authors": [
      "Muhammad Umar Farooq",
      "Awais Khan",
      "Kutub Uddin",
      "Khalid Mahmood Malik"
    ],
    "abstract": "Audio deepfakes pose significant threats, including impersonation, fraud, and\nreputation damage. To address these risks, audio deepfake detection (ADD)\ntechniques have been developed, demonstrating success on benchmarks like\nASVspoof2019. However, their resilience against transferable adversarial\nattacks remains largely unexplored. In this paper, we introduce a transferable\nGAN-based adversarial attack framework to evaluate the effectiveness of\nstate-of-the-art (SOTA) ADD systems. By leveraging an ensemble of surrogate ADD\nmodels and a discriminator, the proposed approach generates transferable\nadversarial attacks that better reflect real-world scenarios. Unlike previous\nmethods, the proposed framework incorporates a self-supervised audio model to\nensure transcription and perceptual integrity, resulting in high-quality\nadversarial attacks. Experimental results on benchmark dataset reveal that SOTA\nADD systems exhibit significant vulnerabilities, with accuracies dropping from\n98% to 26%, 92% to 54%, and 94% to 84% in white-box, gray-box, and black-box\nscenarios, respectively. When tested in other data sets, performance drops of\n91% to 46%, and 94% to 67% were observed against the In-the-Wild and WaveFake\ndata sets, respectively. These results highlight the significant\nvulnerabilities of existing ADD systems and emphasize the need to enhance their\nrobustness against advanced adversarial threats to ensure security and\nreliability.",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "published": "2025-01-21T05:46:47+00:00",
    "updated": "2025-01-21T05:46:47+00:00",
    "url": "http://arxiv.org/pdf/2501.11902v1"
  },
  {
    "id": "2501.11430v5",
    "title": "A Survey on Diffusion Models for Anomaly Detection",
    "authors": [
      "Jing Liu",
      "Zhenchao Ma",
      "Zepu Wang",
      "Chenxuanyin Zou",
      "Jiayang Ren",
      "Zehua Wang",
      "Liang Song",
      "Bo Hu",
      "Yang Liu",
      "Victor C. M. Leung"
    ],
    "abstract": "Diffusion models (DMs) have emerged as a powerful class of generative AI\nmodels, showing remarkable potential in anomaly detection (AD) tasks across\nvarious domains, such as cybersecurity, fraud detection, healthcare, and\nmanufacturing. The intersection of these two fields, termed diffusion models\nfor anomaly detection (DMAD), offers promising solutions for identifying\ndeviations in increasingly complex and high-dimensional data. In this survey,\nwe review recent advances in DMAD research. We begin by presenting the\nfundamental concepts of AD and DMs, followed by a comprehensive analysis of\nclassic DM architectures including DDPMs, DDIMs, and Score SDEs. We further\ncategorize existing DMAD methods into reconstruction-based, density-based, and\nhybrid approaches, providing detailed examinations of their methodological\ninnovations. We also explore the diverse tasks across different data\nmodalities, encompassing image, time series, video, and multimodal data\nanalysis. Furthermore, we discuss critical challenges and emerging research\ndirections, including computational efficiency, model interpretability,\nrobustness enhancement, edge-cloud collaboration, and integration with large\nlanguage models. The collection of DMAD research papers and resources is\navailable at https://github.com/fdjingliu/DMAD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-01-20T12:06:54+00:00",
    "updated": "2025-02-27T02:05:55+00:00",
    "url": "http://arxiv.org/pdf/2501.11430v5"
  },
  {
    "id": "2501.10803v1",
    "title": "\"Auntie, Please Don't Fall for Those Smooth Talkers\": How Chinese Younger Family Members Safeguard Seniors from Online Fraud",
    "authors": [
      "Yue Deng",
      "Changyang He",
      "Yixin Zou",
      "Bo Li"
    ],
    "abstract": "Online fraud substantially harms individuals and seniors are\ndisproportionately targeted. While family is crucial for seniors, little\nresearch has empirically examined how they protect seniors against fraud. To\naddress this gap, we employed an inductive thematic analysis of 124 posts and\n16,872 comments on RedNote (Xiaohongshu), exploring the family support\necosystem for senior-targeted online fraud in China. We develop a taxonomy of\nsenior-targeted online fraud from a familial perspective, revealing younger\nmembers often spot frauds hard for seniors to detect, such as unusual charges.\nYounger family members fulfill multiple safeguarding roles, including\npreventative measures, fraud identification, fraud persuasion, loss recovery,\nand education. They also encounter numerous challenges, such as seniors'\nrefusal of help and considerable mental and financial stress. Drawing on these,\nwe develop a conceptual framework to characterize family support in\nsenior-targeted fraud, and outline implications for researchers and\npractitioners to consider the broader stakeholder ecosystem and cultural\naspects.",
    "categories": [
      "cs.HC"
    ],
    "published": "2025-01-18T15:55:31+00:00",
    "updated": "2025-01-18T15:55:31+00:00",
    "url": "http://arxiv.org/pdf/2501.10803v1"
  },
  {
    "id": "2501.10111v1",
    "title": "AI-Generated Music Detection and its Challenges",
    "authors": [
      "Darius Afchar",
      "Gabriel Meseguer-Brocal",
      "Romain Hennequin"
    ],
    "abstract": "In the face of a new era of generative models, the detection of artificially\ngenerated content has become a matter of utmost importance. In particular, the\nability to create credible minute-long synthetic music in a few seconds on\nuser-friendly platforms poses a real threat of fraud on streaming services and\nunfair competition to human artists. This paper demonstrates the possibility\n(and surprising ease) of training classifiers on datasets comprising real audio\nand artificial reconstructions, achieving a convincing accuracy of 99.8%. To\nour knowledge, this marks the first publication of a AI-music detector, a tool\nthat will help in the regulation of synthetic media. Nevertheless, informed by\ndecades of literature on forgery detection in other fields, we stress that\ngetting a good test score is not the end of the story. We expose and discuss\nseveral facets that could be problematic with such a deployed detector:\nrobustness to audio manipulation, generalisation to unseen models. This second\npart acts as a position for future research steps in the field and a caveat to\na flourishing market of artificial content checkers.",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "published": "2025-01-17T10:53:07+00:00",
    "updated": "2025-01-17T10:53:07+00:00",
    "url": "http://arxiv.org/pdf/2501.10111v1"
  },
  {
    "id": "2501.09239v1",
    "title": "AI-based Identity Fraud Detection: A Systematic Review",
    "authors": [
      "Chuo Jun Zhang",
      "Asif Q. Gill",
      "Bo Liu",
      "Memoona J. Anwar"
    ],
    "abstract": "With the rapid development of digital services, a large volume of personally\nidentifiable information (PII) is stored online and is subject to cyberattacks\nsuch as Identity fraud. Most recently, the use of Artificial Intelligence (AI)\nenabled deep fake technologies has significantly increased the complexity of\nidentity fraud. Fraudsters may use these technologies to create highly\nsophisticated counterfeit personal identification documents, photos and videos.\nThese advancements in the identity fraud landscape pose challenges for identity\nfraud detection and society at large. There is a pressing need to review and\nunderstand identity fraud detection methods, their limitations and potential\nsolutions. This research aims to address this important need by using the\nwell-known systematic literature review method. This paper reviewed a selected\nset of 43 papers across 4 major academic literature databases. In particular,\nthe review results highlight the two types of identity fraud prevention and\ndetection methods, in-depth and open challenges. The results were also\nconsolidated into a taxonomy of AI-based identity fraud detection and\nprevention methods including key insights and trends. Overall, this paper\nprovides a foundational knowledge base to researchers and practitioners for\nfurther research and development in this important area of digital identity\nfraud.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-01-16T01:52:30+00:00",
    "updated": "2025-01-16T01:52:30+00:00",
    "url": "http://arxiv.org/pdf/2501.09239v1"
  },
  {
    "id": "2501.09166v1",
    "title": "Attention is All You Need Until You Need Retention",
    "authors": [
      "M. Murat Yaslioglu"
    ],
    "abstract": "This work introduces a novel Retention Layer mechanism for Transformer based\narchitectures, addressing their inherent lack of intrinsic retention\ncapabilities. Unlike human cognition, which can encode and dynamically recall\nsymbolic templates, Generative Pretrained Transformers rely solely on fixed\npretrained weights and ephemeral context windows, limiting their adaptability.\nThe proposed Retention Layer incorporates a persistent memory module capable of\nreal time data population, dynamic recall, and guided output generation. This\nenhancement allows models to store, update, and reuse observed patterns across\nsessions, enabling incremental learning and bridging the gap between static\npretraining and dynamic, context sensitive adaptation. The Retention Layer\ndesign parallels social learning processes, encompassing attention, retention,\nreproduction, and motivation stages. Technically, it integrates a memory\nattention mechanism and episodic buffers to manage memory scalability, mitigate\noverfitting, and ensure efficient recall. Applications span adaptive personal\nassistants, real time fraud detection, autonomous robotics, content moderation,\nand healthcare diagnostics. In each domain, the retention mechanism enables\nsystems to learn incrementally, personalize outputs, and respond to evolving\nreal world challenges effectively. By emulating key aspects of human learning,\nthis retention enhanced architecture fosters a more fluid and responsive AI\nparadigm, paving the way for dynamic, session aware models that extend the\ncapabilities of traditional Transformers into domains requiring continual\nadaptation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-01-15T21:33:53+00:00",
    "updated": "2025-01-15T21:33:53+00:00",
    "url": "http://arxiv.org/pdf/2501.09166v1"
  },
  {
    "id": "2503.12163v1",
    "title": "AgentDroid: A Multi-Agent Framework for Detecting Fraudulent Android Applications",
    "authors": [
      "Ruwei Pan",
      "Hongyu Zhang",
      "Zhonghao Jiang",
      "Ran Hou"
    ],
    "abstract": "With the increasing prevalence of fraudulent Android applications such as\nfake and malicious applications, it is crucial to detect them with high\naccuracy and adaptability. This paper introduces AgentDroid, a novel framework\nfor Android fraudulent application detection based on multi-modal analysis and\nmulti-agent systems. AgentDroid overcomes the limitations of traditional\ndetection methods such as the inability to handle multimodal data and high\nfalse alarm rates. It processes Android applications and extracts a series of\nmulti-modal data for analysis. Multiple LLM-based agents with specialized roles\nanalyze the relevant data and collaborate to detect complex fraud effectively.\nWe constructed a dataset containing various categories of fraudulent\napplications and legitimate applications and validated our framework on this\ndataset. Experimental results indicate that our multi-agent framework based on\nGPT-4o achieves an accuracy of 91.7% and an F1-Score of 91.68%, showing\nimproved detection accuracy over the baseline methods.",
    "categories": [
      "cs.SE"
    ],
    "published": "2025-03-15T15:07:43+00:00",
    "updated": "2025-03-15T15:07:43+00:00",
    "url": "http://arxiv.org/pdf/2503.12163v1"
  },
  {
    "id": "2503.12037v1",
    "title": "Unsupervised Graph Anomaly Detection via Multi-Hypersphere Heterophilic Graph Learning",
    "authors": [
      "Hang Ni",
      "Jindong Han",
      "Nengjun Zhu",
      "Hao Liu"
    ],
    "abstract": "Graph Anomaly Detection (GAD) plays a vital role in various data mining\napplications such as e-commerce fraud prevention and malicious user detection.\nRecently, Graph Neural Network (GNN) based approach has demonstrated great\neffectiveness in GAD by first encoding graph data into low-dimensional\nrepresentations and then identifying anomalies under the guidance of supervised\nor unsupervised signals. However, existing GNN-based approaches implicitly\nfollow the homophily principle (i.e., the \"like attracts like\" phenomenon) and\nfail to learn discriminative embedding for anomalies that connect vast normal\nnodes. Moreover, such approaches identify anomalies in a unified global\nperspective but overlook diversified abnormal patterns conditioned on local\ngraph context, leading to suboptimal performance. To overcome the\naforementioned limitations, in this paper, we propose a Multi-hypersphere\nHeterophilic Graph Learning (MHetGL) framework for unsupervised GAD.\nSpecifically, we first devise a Heterophilic Graph Encoding (HGE) module to\nlearn distinguishable representations for potential anomalies by purifying and\naugmenting their neighborhood in a fully unsupervised manner. Then, we propose\na Multi-Hypersphere Learning (MHL) module to enhance the detection capability\nfor context-dependent anomalies by jointly incorporating critical patterns from\nboth global and local perspectives. Extensive experiments on ten real-world\ndatasets show that MHetGL outperforms 14 baselines. Our code is publicly\navailable at https://github.com/KennyNH/MHetGL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-03-15T08:08:13+00:00",
    "updated": "2025-03-15T08:08:13+00:00",
    "url": "http://arxiv.org/pdf/2503.12037v1"
  },
  {
    "id": "2503.11273v1",
    "title": "Financial Fraud Detection with Entropy Computing",
    "authors": [
      "Babak Emami",
      "Wesley Dyk",
      "David Haycraft",
      "Carrie Spear",
      "Lac Nguyen",
      "Nicholas Chancellor"
    ],
    "abstract": "We introduce CVQBoost, a novel classification algorithm that leverages early\nhardware implementing Quantum Computing Inc's Entropy Quantum Computing (EQC)\nparadigm, Dirac-3 [Nguyen et. al. arXiv:2407.04512]. We apply CVQBoost to a\nfraud detection test case and benchmark its performance against XGBoost, a\nwidely utilized ML method. Running on Dirac-3, CVQBoost demonstrates a\nsignificant runtime advantage over XGBoost, which we evaluate on\nhigh-performance hardware comprising up to 48 CPUs and four NVIDIA L4 GPUs\nusing the RAPIDS AI framework. Our results show that CVQBoost maintains\ncompetitive accuracy (measured by AUC) while significantly reducing training\ntime, particularly as dataset size and feature complexity increase. To assess\nscalability, we extend our study to large synthetic datasets ranging from 1M to\n70M samples, demonstrating that CVQBoost on Dirac-3 is well-suited for\nlarge-scale classification tasks. These findings position CVQBoost as a\npromising alternative to gradient boosting methods, offering superior\nscalability and efficiency for high-dimensional ML applications such as fraud\ndetection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.optics",
      "quant-ph"
    ],
    "published": "2025-03-14T10:30:43+00:00",
    "updated": "2025-03-14T10:30:43+00:00",
    "url": "http://arxiv.org/pdf/2503.11273v1"
  },
  {
    "id": "2503.10058v1",
    "title": "Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions",
    "authors": [
      "Jiani Fan",
      "Lwin Khin Shar",
      "Ruichen Zhang",
      "Ziyao Liu",
      "Wenzhuo Yang",
      "Dusit Niyato",
      "Bomin Mao",
      "Kwok-Yan Lam"
    ],
    "abstract": "Money laundering is a financial crime that obscures the origin of illicit\nfunds, necessitating the development and enforcement of anti-money laundering\n(AML) policies by governments and organizations. The proliferation of mobile\npayment platforms and smart IoT devices has significantly complicated AML\ninvestigations. As payment networks become more interconnected, there is an\nincreasing need for efficient real-time detection to process large volumes of\ntransaction data on heterogeneous payment systems by different operators such\nas digital currencies, cryptocurrencies and account-based payments. Most of\nthese mobile payment networks are supported by connected devices, many of which\nare considered loT devices in the FinTech space that constantly generate data.\nFurthermore, the growing complexity and unpredictability of transaction\npatterns across these networks contribute to a higher incidence of false\npositives. While machine learning solutions have the potential to enhance\ndetection efficiency, their application in AML faces unique challenges, such as\naddressing privacy concerns tied to sensitive financial data and managing the\nreal-world constraint of limited data availability due to data regulations.\nExisting surveys in the AML literature broadly review machine learning\napproaches for money laundering detection, but they often lack an in-depth\nexploration of advanced deep learning techniques - an emerging field with\nsignificant potential. To address this gap, this paper conducts a comprehensive\nreview of deep learning solutions and the challenges associated with their use\nin AML. Additionally, we propose a novel framework that applies the\nleast-privilege principle by integrating machine learning techniques, codifying\nAML red flags, and employing account profiling to provide context for\npredictions and enable effective fraud detection under limited data\navailability....",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2025-03-13T05:19:44+00:00",
    "updated": "2025-03-13T05:19:44+00:00",
    "url": "http://arxiv.org/pdf/2503.10058v1"
  },
  {
    "id": "2503.09302v1",
    "title": "Detecting and Preventing Data Poisoning Attacks on AI Models",
    "authors": [
      "Halima I. Kure",
      "Pradipta Sarkar",
      "Ahmed B. Ndanusa",
      "Augustine O. Nwajana"
    ],
    "abstract": "This paper investigates the critical issue of data poisoning attacks on AI\nmodels, a growing concern in the ever-evolving landscape of artificial\nintelligence and cybersecurity. As advanced technology systems become\nincreasingly prevalent across various sectors, the need for robust defence\nmechanisms against adversarial attacks becomes paramount. The study aims to\ndevelop and evaluate novel techniques for detecting and preventing data\npoisoning attacks, focusing on both theoretical frameworks and practical\napplications. Through a comprehensive literature review, experimental\nvalidation using the CIFAR-10 and Insurance Claims datasets, and the\ndevelopment of innovative algorithms, this paper seeks to enhance the\nresilience of AI models against malicious data manipulation. The study explores\nvarious methods, including anomaly detection, robust optimization strategies,\nand ensemble learning, to identify and mitigate the effects of poisoned data\nduring model training. Experimental results indicate that data poisoning\nsignificantly degrades model performance, reducing classification accuracy by\nup to 27% in image recognition tasks (CIFAR-10) and 22% in fraud detection\nmodels (Insurance Claims dataset). The proposed defence mechanisms, including\nstatistical anomaly detection and adversarial training, successfully mitigated\npoisoning effects, improving model robustness and restoring accuracy levels by\nan average of 15-20%. The findings further demonstrate that ensemble learning\ntechniques provide an additional layer of resilience, reducing false positives\nand false negatives caused by adversarial data injections.",
    "categories": [
      "cs.CR",
      "eess.IV"
    ],
    "published": "2025-03-12T11:55:01+00:00",
    "updated": "2025-03-12T11:55:01+00:00",
    "url": "http://arxiv.org/pdf/2503.09302v1"
  },
  {
    "id": "2503.09289v1",
    "title": "Unmask It! AI-Generated Product Review Detection in Dravidian Languages",
    "authors": [
      "Somsubhra De",
      "Advait Vats"
    ],
    "abstract": "The rise of Generative AI has led to a surge in AI-generated reviews, often\nposing a serious threat to the credibility of online platforms. Reviews serve\nas the primary source of information about products and services. Authentic\nreviews play a vital role in consumer decision-making. The presence of\nfabricated content misleads consumers, undermines trust and facilitates\npotential fraud in digital marketplaces. This study focuses on detecting\nAI-generated product reviews in Tamil and Malayalam, two low-resource languages\nwhere research in this domain is relatively under-explored. We worked on a\nrange of approaches - from traditional machine learning methods to advanced\ntransformer-based models such as Indic-BERT, IndicSBERT, MuRIL, XLM-RoBERTa and\nMalayalamBERT. Our findings highlight the effectiveness of leveraging the\nstate-of-the-art transformers in accurately identifying AI-generated content,\ndemonstrating the potential in enhancing the detection of fake reviews in\nlow-resource language settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-03-12T11:35:04+00:00",
    "updated": "2025-03-12T11:35:04+00:00",
    "url": "http://arxiv.org/pdf/2503.09289v1"
  },
  {
    "id": "2503.08346v2",
    "title": "Pathology-Aware Adaptive Watermarking for Text-Driven Medical Image Synthesis",
    "authors": [
      "Chanyoung Kim",
      "Dayun Ju",
      "Jinyeong Kim",
      "Woojung Han",
      "Roberto Alcover-Couso",
      "Seong Jae Hwang"
    ],
    "abstract": "As recent text-conditioned diffusion models have enabled the generation of\nhigh-quality images, concerns over their potential misuse have also grown. This\nissue is critical in the medical domain, where text-conditioned generated\nmedical images could enable insurance fraud or falsified records, highlighting\nthe urgent need for reliable safeguards against unethical use. While\nwatermarking techniques have emerged as a promising solution in general image\ndomains, their direct application to medical imaging presents significant\nchallenges. A key challenge is preserving fine-grained disease manifestations,\nas even minor distortions from a watermark may lead to clinical\nmisinterpretation, which compromises diagnostic integrity. To overcome this\ngap, we present MedSign, a deep learning-based watermarking framework\nspecifically designed for text-to-medical image synthesis, which preserves\npathologically significant regions by adaptively adjusting watermark strength.\nSpecifically, we generate a pathology localization map using cross-attention\nbetween medical text tokens and the diffusion denoising network, aggregating\ntoken-wise attention across layers, heads, and time steps. Leveraging this map,\nwe optimize the LDM decoder to incorporate watermarking during image synthesis,\nensuring cohesive integration while minimizing interference in diagnostically\ncritical regions. Experimental results show that our MedSign preserves\ndiagnostic integrity while ensuring watermark robustness, achieving\nstate-of-the-art performance in image quality and detection accuracy on\nMIMIC-CXR and OIA-ODIR datasets.",
    "categories": [
      "cs.CV"
    ],
    "published": "2025-03-11T11:55:14+00:00",
    "updated": "2025-09-02T01:30:25+00:00",
    "url": "http://arxiv.org/pdf/2503.08346v2"
  },
  {
    "id": "2503.08097v1",
    "title": "Evidential Uncertainty Probes for Graph Neural Networks",
    "authors": [
      "Linlin Yu",
      "Kangshuo Li",
      "Pritom Kumar Saha",
      "Yifei Lou",
      "Feng Chen"
    ],
    "abstract": "Accurate quantification of both aleatoric and epistemic uncertainties is\nessential when deploying Graph Neural Networks (GNNs) in high-stakes\napplications such as drug discovery and financial fraud detection, where\nreliable predictions are critical. Although Evidential Deep Learning (EDL)\nefficiently quantifies uncertainty using a Dirichlet distribution over\npredictive probabilities, existing EDL-based GNN (EGNN) models require\nmodifications to the network architecture and retraining, failing to take\nadvantage of pre-trained models. We propose a plug-and-play framework for\nuncertainty quantification in GNNs that works with pre-trained models without\nthe need for retraining. Our Evidential Probing Network (EPN) uses a\nlightweight Multi-Layer-Perceptron (MLP) head to extract evidence from learned\nrepresentations, allowing efficient integration with various GNN architectures.\nWe further introduce evidence-based regularization techniques, referred to as\nEPN-reg, to enhance the estimation of epistemic uncertainty with theoretical\njustifications. Extensive experiments demonstrate that the proposed EPN-reg\nachieves state-of-the-art performance in accurate and efficient uncertainty\nquantification, making it suitable for real-world deployment.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-03-11T07:00:54+00:00",
    "updated": "2025-03-11T07:00:54+00:00",
    "url": "http://arxiv.org/pdf/2503.08097v1"
  },
  {
    "id": "2503.08734v1",
    "title": "Zero-to-One IDV: A Conceptual Model for AI-Powered Identity Verification",
    "authors": [
      "Aniket Vaidya",
      "Anurag Awasthi"
    ],
    "abstract": "In today's increasingly digital interactions, robust Identity Verification\n(IDV) is crucial for security and trust. Artificial Intelligence (AI) is\ntransforming IDV, enhancing accuracy and fraud detection. This paper introduces\n``Zero to One,'' a holistic conceptual framework for developing AI-powered IDV\nproducts. This paper outlines the foundational problem and research objectives\nthat necessitate a new framework for IDV in the age of AI. It details the\nevolution of identity verification and the current regulatory landscape to\ncontextualize the need for a robust conceptual model. The core of the paper is\nthe presentation of the ``Zero to One'' framework itself, dissecting its four\nessential components: Document Verification, Biometric Verification, Risk\nAssessment, and Orchestration. The paper concludes by discussing the\nimplications of this conceptual model and suggesting future research directions\nfocused on the framework's further development and application. The framework\naddresses security, privacy, UX, and regulatory compliance, offering a\nstructured approach to building effective IDV solutions. Successful IDV\nplatforms require a balanced conceptual understanding of verification methods,\nrisk management, and operational scalability, with AI as a key enabler. This\npaper presents the ``Zero to One'' framework as a refined conceptual model,\ndetailing verification layers, and AI's transformative role in shaping\nnext-generation IDV products.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-03-11T04:20:02+00:00",
    "updated": "2025-03-11T04:20:02+00:00",
    "url": "http://arxiv.org/pdf/2503.08734v1"
  },
  {
    "id": "2503.06500v1",
    "title": "StructVizor: Interactive Profiling of Semi-Structured Textual Data",
    "authors": [
      "Yanwei Huang",
      "Yan Miao",
      "Di Weng",
      "Adam Perer",
      "Yingcai Wu"
    ],
    "abstract": "Data profiling plays a critical role in understanding the structure of\ncomplex datasets and supporting numerous downstream tasks, such as social media\nanalytics and financial fraud detection. While existing research predominantly\nfocuses on structured data formats, a substantial portion of semi-structured\ntextual data still requires ad-hoc and arduous manual profiling to extract and\ncomprehend its internal structures. In this work, we propose StructVizor, an\ninteractive profiling system that facilitates sensemaking and transformation of\nsemi-structured textual data. Our tool mainly addresses two challenges: a)\nextracting and visualizing the diverse structural patterns within data, such as\nhow information is organized or related, and b) enabling users to efficiently\nperform various wrangling operations on textual data. Through automatic data\nparsing and structure mining, StructVizor enables visual analytics of\nstructural patterns, while incorporating novel interactions to enable\nprofile-based data wrangling. A comparative user study involving 12\nparticipants demonstrates the system's usability and its effectiveness in\nsupporting exploratory data analysis and transformation tasks.",
    "categories": [
      "cs.HC"
    ],
    "published": "2025-03-09T08:03:32+00:00",
    "updated": "2025-03-09T08:03:32+00:00",
    "url": "http://arxiv.org/pdf/2503.06500v1"
  },
  {
    "id": "2503.04549v1",
    "title": "Lite-PoT: Practical Powers-of-Tau Setup Ceremony",
    "authors": [
      "Lucien K. L. Ng",
      "Pedro Moreno-Sanchez",
      "Mohsen Minaei",
      "Panagiotis Chatzigiannis",
      "Adithya Bhat",
      "Duc V. Le"
    ],
    "abstract": "Zero-Knowledge Succinct Non-Interactive Argument of Knowledge (zk-SNARK)\nschemes have gained significant adoption in privacy-preserving applications,\ndecentralized systems (e.g., blockchain), and verifiable computation due to\ntheir efficiency. However, the most efficient zk-SNARKs often rely on a\none-time trusted setup to generate a public parameter, often known as the\n``Powers of Tau\" (PoT) string. The leakage of the secret parameter, $\\tau$, in\nthe string would allow attackers to generate false proofs, compromising the\nsoundness of all zk-SNARK systems built on it.\n  Prior proposals for decentralized setup ceremonies have utilized\nblockchain-based smart contracts to allow any party to contribute randomness to\n$\\tau$ while also preventing censorship of contributions. For a PoT string of\n$d$-degree generated by the randomness of $m$ contributors, these solutions\nrequired a total of $O(md)$ on-chain operations (i.e., in terms of both storage\nand cryptographic operations). These operations primarily consisted of costly\ngroup operations, particularly scalar multiplication on pairing curves, which\ndiscouraged participation and limited the impact of decentralization\n  In this work, we present Lite-PoT, which includes two key protocols designed\nto reduce participation costs: \\emph{(i)} a fraud-proof protocol to reduce the\nnumber of expensive on-chain cryptographic group operations to $O(1)$ per\ncontributor. Our experimental results show that (with one transaction per\nupdate) our protocol enables decentralized ceremonies for PoT strings up to a\n$2^{15}$ degree, an $\\approx 16x$ improvement over existing on-chain solutions;\n\\emph{(ii)} a proof aggregation technique that batches $m$ randomness\ncontributions into one on-chain update with only $O(d)$ on-chain operations,\nindependent of $m$. This significantly reduces the monetary cost of on-chain\nupdates by $m$-fold via amortization.",
    "categories": [
      "cs.CR"
    ],
    "published": "2025-03-06T15:34:50+00:00",
    "updated": "2025-03-06T15:34:50+00:00",
    "url": "http://arxiv.org/pdf/2503.04549v1"
  },
  {
    "id": "2503.04292v1",
    "title": "A Study on Malicious Browser Extensions in 2025",
    "authors": [
      "Shreya Singh",
      "Gaurav Varshney",
      "Tarun Kumar Singh",
      "Vidhi Mishra"
    ],
    "abstract": "Browser extensions are additional tools developed by third parties that\nintegrate with web browsers to extend their functionality beyond standard\ncapabilities. However, the browser extension platform is increasingly being\nexploited by hackers to launch sophisticated cyber threats. These threats\nencompass a wide range of malicious activities, including but not limited to\nphishing, spying, Distributed Denial of Service (DDoS) attacks, email spamming,\naffiliate fraud, malvertising, and payment fraud. This paper examines the\nevolving threat landscape of malicious browser extensions in 2025, focusing on\nMozilla Firefox and Chrome. Our research successfully bypassed security\nmechanisms of Firefox and Chrome, demonstrating that malicious extensions can\nstill be developed, published, and executed within the Mozilla Add-ons Store\nand Chrome Web Store. These findings highlight the persisting weaknesses in\nbrowser's vetting process and security framework. It provides insights into the\nrisks associated with browser extensions, helping users understand these\nthreats while aiding the industry in developing controls and countermeasures to\ndefend against such attacks. All experiments discussed in this paper were\nconducted in a controlled laboratory environment by the researchers, adhering\nto proper ethical guidelines. The sole purpose of these experiments is to raise\nsecurity awareness among the industry, research community, and the general\npublic.",
    "categories": [
      "cs.CR"
    ],
    "published": "2025-03-06T10:24:27+00:00",
    "updated": "2025-03-06T10:24:27+00:00",
    "url": "http://arxiv.org/pdf/2503.04292v1"
  },
  {
    "id": "2503.02857v4",
    "title": "Deepfake-Eval-2024: A Multi-Modal In-the-Wild Benchmark of Deepfakes Circulated in 2024",
    "authors": [
      "Nuria Alina Chandra",
      "Ryan Murtfeldt",
      "Lin Qiu",
      "Arnab Karmakar",
      "Hannah Lee",
      "Emmanuel Tanumihardja",
      "Kevin Farhat",
      "Ben Caffee",
      "Sejin Paik",
      "Changyeon Lee",
      "Jongwook Choi",
      "Aerin Kim",
      "Oren Etzioni"
    ],
    "abstract": "In the age of increasingly realistic generative AI, robust deepfake detection\nis essential for mitigating fraud and disinformation. While many deepfake\ndetectors report high accuracy on academic datasets, we show that these\nacademic benchmarks are out of date and not representative of real-world\ndeepfakes. We introduce Deepfake-Eval-2024, a new deepfake detection benchmark\nconsisting of in-the-wild deepfakes collected from social media and deepfake\ndetection platform users in 2024. Deepfake-Eval-2024 consists of 45 hours of\nvideos, 56.5 hours of audio, and 1,975 images, encompassing the latest\nmanipulation technologies. The benchmark contains diverse media content from 88\ndifferent websites in 52 different languages. We find that the performance of\nopen-source state-of-the-art deepfake detection models drops precipitously when\nevaluated on Deepfake-Eval-2024, with AUC decreasing by 50% for video, 48% for\naudio, and 45% for image models compared to previous benchmarks. We also\nevaluate commercial deepfake detection models and models finetuned on\nDeepfake-Eval-2024, and find that they have superior performance to\noff-the-shelf open-source models, but do not yet reach the accuracy of deepfake\nforensic analysts. The dataset is available at\nhttps://github.com/nuriachandra/Deepfake-Eval-2024.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-03-04T18:33:22+00:00",
    "updated": "2025-05-27T16:27:56+00:00",
    "url": "http://arxiv.org/pdf/2503.02857v4"
  },
  {
    "id": "2503.02772v2",
    "title": "ESSPI: ECDSA/Schnorr Signed Program Input for BitVMX",
    "authors": [
      "Sergio Demian Lerner",
      "Martin Jonas",
      "Ariel Futoransky"
    ],
    "abstract": "The BitVM and BitVMX protocols have long relied on inefficient one-time\nsignature (OTS) schemes like Lamport and Winternitz for signing program inputs.\nThese schemes exhibit significant storage overheads, hindering their practical\napplication. This paper introduces ESSPI, an optimized method leveraging\nECDSA/Schnorr signatures to sign the BitVMX program input. With Schnorr\nsignatures we achieve an optimal 1:1 data expansion, compared to the current\nknown best ratio of 1:200 based on Winternitz signatures. To accomplish this we\nintroduce 4 innovations to BitVMX: (1) a modification of the BitVMX CPU, adding\na challengeable hashing core to it, (2) a new partition-based search to detect\nfraud during hashing, (3) a new enhanced transaction DAG with added\ndata-carrying transactions with a fraud-verifying smart-contract and (4) a\nnovel timelock-based method for proving data availability to Bitcoin smart\ncontracts. The enhanced BitVMX protocol enables the verification of\nuncompressed inputs such as SPV proofs, NiPoPoWs, or longer computation\nintegrity proofs, such as STARKs.",
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "published": "2025-03-04T16:40:55+00:00",
    "updated": "2025-03-07T01:09:23+00:00",
    "url": "http://arxiv.org/pdf/2503.02772v2"
  },
  {
    "id": "2503.01686v1",
    "title": "\\textsc{Perseus}: Tracing the Masterminds Behind Cryptocurrency Pump-and-Dump Schemes",
    "authors": [
      "Honglin Fu",
      "Yebo Feng",
      "Cong Wu",
      "Jiahua Xu"
    ],
    "abstract": "Masterminds are entities organizing, coordinating, and orchestrating\ncryptocurrency pump-and-dump schemes, a form of trade-based manipulation\nundermining market integrity and causing financial losses for unwitting\ninvestors. Previous research detects pump-and-dump activities in the market,\npredicts the target cryptocurrency, and examines investors and \\ac{osn}\nentities. However, these solutions do not address the root cause of the\nproblem. There is a critical gap in identifying and tracing the masterminds\ninvolved in these schemes. In this research, we develop a detection system\n\\textsc{Perseus}, which collects real-time data from the \\acs{osn} and\ncryptocurrency markets. \\textsc{Perseus} then constructs temporal attributed\ngraphs that preserve the direction of information diffusion and the structure\nof the community while leveraging \\ac{gnn} to identify the masterminds behind\npump-and-dump activities. Our design of \\textsc{Perseus} leads to higher F1\nscores and precision than the \\ac{sota} fraud detection method, achieving fast\ntraining and inferring speeds. Deployed in the real world from February 16 to\nOctober 9 2024, \\textsc{Perseus} successfully detects $438$ masterminds who are\nefficient in the pump-and-dump information diffusion networks. \\textsc{Perseus}\nprovides regulators with an explanation of the risks of masterminds and\noversight capabilities to mitigate the pump-and-dump schemes of cryptocurrency.",
    "categories": [
      "cs.CY",
      "cs.LG",
      "q-fin.TR"
    ],
    "published": "2025-03-03T15:59:40+00:00",
    "updated": "2025-03-03T15:59:40+00:00",
    "url": "http://arxiv.org/pdf/2503.01686v1"
  },
  {
    "id": "2503.01556v1",
    "title": "Effective High-order Graph Representation Learning for Credit Card Fraud Detection",
    "authors": [
      "Yao Zou",
      "Dawei Cheng"
    ],
    "abstract": "Credit card fraud imposes significant costs on both cardholders and issuing\nbanks. Fraudsters often disguise their crimes, such as using legitimate\ntransactions through several benign users to bypass anti-fraud detection.\nExisting graph neural network (GNN) models struggle with learning features of\ncamouflaged, indirect multi-hop transactions due to their inherent\nover-smoothing issues in deep multi-layer aggregation, presenting a major\nchallenge in detecting disguised relationships. Therefore, in this paper, we\npropose a novel High-order Graph Representation Learning model (HOGRL) to avoid\nincorporating excessive noise during the multi-layer aggregation process. In\nparticular, HOGRL learns different orders of \\emph{pure} representations\ndirectly from high-order transaction graphs. We realize this goal by\neffectively constructing high-order transaction graphs first and then learning\nthe \\emph{pure} representations of each order so that the model could identify\nfraudsters' multi-hop indirect transactions via multi-layer \\emph{pure} feature\nlearning. In addition, we introduce a mixture-of-expert attention mechanism to\nautomatically determine the importance of different orders for jointly\noptimizing fraud detection performance. We conduct extensive experiments in\nboth the open source and real-world datasets, the result demonstrates the\nsignificant improvements of our proposed HOGRL compared with state-of-the-art\nfraud detection baselines. HOGRL's superior performance also proves its\neffectiveness in addressing high-order fraud camouflage criminals.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07, 91B06",
      "I.2.6; H.2.8"
    ],
    "published": "2025-03-03T13:59:46+00:00",
    "updated": "2025-03-03T13:59:46+00:00",
    "url": "http://arxiv.org/pdf/2503.01556v1"
  },
  {
    "id": "2502.20334v1",
    "title": "Economic Censorship Games in Fraud Proofs",
    "authors": [
      "Ben Berger",
      "Edward W. Felten",
      "Akaki Mamageishvili",
      "Benny Sudakov"
    ],
    "abstract": "Optimistic rollups rely on fraud proofs -- interactive protocols executed on\nEthereum to resolve conflicting claims about the rollup's state -- to scale\nEthereum securely.\n  To mitigate against potential censorship of protocol moves, fraud proofs\ngrant participants a significant time window, known as the challenge period, to\nensure their moves are processed on chain. Major optimistic rollups today set\nthis period at roughly one week, mainly to guard against strong censorship that\nundermines Ethereum's own crypto-economic security. However, other forms of\ncensorship are possible, and their implication on optimistic rollup security is\nnot well understood.\n  This paper considers economic censorship attacks, where an attacker censors\nthe defender's transactions by bribing block proposers. At each step, the\nattacker can either censor the defender -- depleting the defender's time\nallowance at the cost of the bribe -- or allow the current transaction through\nwhile conserving funds for future censorship.\n  We analyze three game theoretic models of these dynamics and determine the\nchallenge period length required to ensure the defender's success, as a\nfunction of the number of required protocol moves and the players' available\nbudgets.",
    "categories": [
      "cs.GT"
    ],
    "published": "2025-02-27T18:02:42+00:00",
    "updated": "2025-02-27T18:02:42+00:00",
    "url": "http://arxiv.org/pdf/2502.20334v1"
  },
  {
    "id": "2502.19305v2",
    "title": "Corporate Fraud Detection in Rich-yet-Noisy Financial Graph",
    "authors": [
      "Shiqi Wang",
      "Zhibo Zhang",
      "Libing Fang",
      "Cam-Tu Nguyen",
      "Wenzhong Li"
    ],
    "abstract": "Corporate fraud detection aims to automatically recognize companies that\nconduct wrongful activities such as fraudulent financial statements or illegal\ninsider trading. Previous learning-based methods fail to effectively integrate\nrich interactions in the company network. To close this gap, we collect 18-year\nfinancial records in China to form three graph datasets with fraud labels. We\nanalyze the characteristics of the financial graphs, highlighting two\npronounced issues: (1) information overload: the dominance of (noisy)\nnon-company nodes over company nodes hinders the message-passing process in\nGraph Convolution Networks (GCN); and (2) hidden fraud: there exists a large\npercentage of possible undetected violations in the collected data. The hidden\nfraud problem will introduce noisy labels in the training dataset and\ncompromise fraud detection results. To handle such challenges, we propose a\nnovel graph-based method, namely, Knowledge-enhanced GCN with Robust Two-stage\nLearning (${\\rm KeGCN}_{R}$), which leverages Knowledge Graph Embeddings to\nmitigate the information overload and effectively learns rich representations.\nThe proposed model adopts a two-stage learning method to enhance robustness\nagainst hidden frauds. Extensive experimental results not only confirm the\nimportance of interactions but also show the superiority of ${\\rm KeGCN}_{R}$\nover a number of strong baselines in terms of fraud detection effectiveness and\nrobustness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.RM",
      "q-fin.ST"
    ],
    "published": "2025-02-26T17:05:54+00:00",
    "updated": "2025-05-29T19:46:08+00:00",
    "url": "http://arxiv.org/pdf/2502.19305v2"
  },
  {
    "id": "2502.18334v3",
    "title": "Structural Alignment Improves Graph Test-Time Adaptation",
    "authors": [
      "Hans Hao-Hsun Hsu",
      "Shikun Liu",
      "Han Zhao",
      "Pan Li"
    ],
    "abstract": "Graph-based learning excels at capturing interaction patterns in diverse\ndomains like recommendation, fraud detection, and particle physics. However,\nits performance often degrades under distribution shifts, especially those\naltering network connectivity. Current methods to address these shifts\ntypically require retraining with the source dataset, which is often infeasible\ndue to computational or privacy limitations. We introduce Test-Time Structural\nAlignment (TSA), a novel algorithm for Graph Test-Time Adaptation (GTTA) that\naligns graph structures during inference without accessing the source data.\nGrounded in a theoretical understanding of graph data distribution shifts, TSA\nemploys three synergistic strategies: uncertainty-aware neighborhood weighting\nto accommodate neighbor label distribution shifts, adaptive balancing of\nself-node and aggregated neighborhood representations based on their\nsignal-to-noise ratio, and decision boundary refinement to correct residual\nlabel and feature shifts. Extensive experiments on synthetic and real-world\ndatasets demonstrate TSA's consistent outperformance of both non-graph TTA\nmethods and state-of-the-art GTTA baselines.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-02-25T16:26:25+00:00",
    "updated": "2025-06-05T14:44:56+00:00",
    "url": "http://arxiv.org/pdf/2502.18334v3"
  },
  {
    "id": "2502.16947v1",
    "title": "Using Machine Learning to Detect Fraudulent SMSs in Chichewa",
    "authors": [
      "Amelia Taylor",
      "Amoss Robert"
    ],
    "abstract": "SMS enabled fraud is of great concern globally. Building classifiers based on\nmachine learning for SMS fraud requires the use of suitable datasets for model\ntraining and validation. Most research has centred on the use of datasets of\nSMSs in English. This paper introduces a first dataset for SMS fraud detection\nin Chichewa, a major language in Africa, and reports on experiments with\nmachine learning algorithms for classifying SMSs in Chichewa as fraud or\nnon-fraud. We answer the broader research question of how feasible it is to\ndevelop machine learning classification models for Chichewa SMSs. To do that,\nwe created three datasets. A small dataset of SMS in Chichewa was collected\nthrough primary research from a segment of the young population. We applied a\nlabel-preserving text transformations to increase its size. The enlarged\ndataset was translated into English using two approaches: human translation and\nmachine translation. The Chichewa and the translated datasets were subjected to\nmachine classification using random forest and logistic regression. Our\nfindings indicate that both models achieved a promising accuracy of over 96% on\nthe Chichewa dataset. There was a drop in performance when moving from the\nChichewa to the translated dataset. This highlights the importance of data\npreprocessing, especially in multilingual or cross-lingual NLP tasks, and shows\nthe challenges of relying on machine-translated text for training machine\nlearning models. Our results underscore the importance of developing language\nspecific models for SMS fraud detection to optimise accuracy and performance.\nSince most machine learning models require data preprocessing, it is essential\nto investigate the impact of the reliance on English-specific tools for data\npreprocessing.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-02-24T08:17:54+00:00",
    "updated": "2025-02-24T08:17:54+00:00",
    "url": "http://arxiv.org/pdf/2502.16947v1"
  },
  {
    "id": "2502.15898v1",
    "title": "ML-Driven Approaches to Combat Medicare Fraud: Advances in Class Imbalance Solutions, Feature Engineering, Adaptive Learning, and Business Impact",
    "authors": [
      "Dorsa Farahmandazad",
      "Kasra Danesh"
    ],
    "abstract": "Medicare fraud poses a substantial challenge to healthcare systems, resulting\nin significant financial losses and undermining the quality of care provided to\nlegitimate beneficiaries. This study investigates the use of machine learning\n(ML) to enhance Medicare fraud detection, addressing key challenges such as\nclass imbalance, high-dimensional data, and evolving fraud patterns. A dataset\ncomprising inpatient claims, outpatient claims, and beneficiary details was\nused to train and evaluate five ML models: Random Forest, KNN, LDA, Decision\nTree, and AdaBoost. Data preprocessing techniques included resampling SMOTE\nmethod to address the class imbalance, feature selection for dimensionality\nreduction, and aggregation of diagnostic and procedural codes. Random Forest\nemerged as the best-performing model, achieving a training accuracy of 99.2%\nand validation accuracy of 98.8%, and F1-score (98.4%). The Decision Tree also\nperformed well, achieving a validation accuracy of 96.3%. KNN and AdaBoost\ndemonstrated moderate performance, with validation accuracies of 79.2% and\n81.1%, respectively, while LDA struggled with a validation accuracy of 63.3%\nand a low recall of 16.6%. The results highlight the importance of advanced\nresampling techniques, feature engineering, and adaptive learning in detecting\nMedicare fraud effectively. This study underscores the potential of machine\nlearning in addressing the complexities of fraud detection. Future work should\nexplore explainable AI and hybrid models to improve interpretability and\nperformance, ensuring scalable and reliable fraud detection systems that\nprotect healthcare resources and beneficiaries.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-02-21T19:34:12+00:00",
    "updated": "2025-02-21T19:34:12+00:00",
    "url": "http://arxiv.org/pdf/2502.15898v1"
  },
  {
    "id": "2502.15429v5",
    "title": "Pub-Guard-LLM: Detecting Retracted Biomedical Articles with Reliable Explanations",
    "authors": [
      "Lihu Chen",
      "Shuojie Fu",
      "Gabriel Freedman",
      "Cemre Zor",
      "Guy Martin",
      "James Kinross",
      "Uddhav Vaghela",
      "Ovidiu Serban",
      "Francesca Toni"
    ],
    "abstract": "A significant and growing number of published scientific articles is found to\ninvolve fraudulent practices, posing a serious threat to the credibility and\nsafety of research in fields such as medicine. We propose Pub-Guard-LLM, the\nfirst large language model-based system tailored to fraud detection of\nbiomedical scientific articles. We provide three application modes for\ndeploying Pub-Guard-LLM: vanilla reasoning, retrieval-augmented generation, and\nmulti-agent debate. Each mode allows for textual explanations of predictions.\nTo assess the performance of our system, we introduce an open-source benchmark,\nPubMed Retraction, comprising over 11K real-world biomedical articles,\nincluding metadata and retraction labels. We show that, across all modes,\nPub-Guard-LLM consistently surpasses the performance of various baselines and\nprovides more reliable explanations, namely explanations which are deemed more\nrelevant and coherent than those generated by the baselines when evaluated by\nmultiple assessment methods. By enhancing both detection performance and\nexplainability in scientific fraud detection, Pub-Guard-LLM contributes to\nsafeguarding research integrity with a novel, effective, open-source tool.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-02-21T12:54:56+00:00",
    "updated": "2025-08-21T12:27:18+00:00",
    "url": "http://arxiv.org/pdf/2502.15429v5"
  },
  {
    "id": "2502.15822v1",
    "title": "Financial fraud detection system based on improved random forest and gradient boosting machine (GBM)",
    "authors": [
      "Tianzuo Hu"
    ],
    "abstract": "This paper proposes a financial fraud detection system based on improved\nRandom Forest (RF) and Gradient Boosting Machine (GBM). Specifically, the\nsystem introduces a novel model architecture called GBM-SSRF (Gradient Boosting\nMachine with Simplified and Strengthened Random Forest), which cleverly\ncombines the powerful optimization capabilities of the gradient boosting\nmachine (GBM) with improved randomization. The computational efficiency and\nfeature extraction capabilities of the Simplified and Strengthened Random\nForest (SSRF) forest significantly improve the performance of financial fraud\ndetection. Although the traditional random forest model has good classification\ncapabilities, it has high computational complexity when faced with large-scale\ndata and has certain limitations in feature selection. As a commonly used\nensemble learning method, the GBM model has significant advantages in\noptimizing performance and handling nonlinear problems. However, GBM takes a\nlong time to train and is prone to overfitting problems when data samples are\nunbalanced. In response to these limitations, this paper optimizes the random\nforest based on the structure, reducing the computational complexity and\nimproving the feature selection ability through the structural simplification\nand enhancement of the random forest. In addition, the optimized random forest\nis embedded into the GBM framework, and the model can maintain efficiency and\nstability with the help of GBM's gradient optimization capability. Experiments\nshow that the GBM-SSRF model not only has good performance, but also has good\nrobustness and generalization capabilities, providing an efficient and reliable\nsolution for financial fraud detection.",
    "categories": [
      "q-fin.ST",
      "cs.LG",
      "q-fin.GN",
      "stat.AP",
      "stat.ML"
    ],
    "published": "2025-02-20T03:27:57+00:00",
    "updated": "2025-02-20T03:27:57+00:00",
    "url": "http://arxiv.org/pdf/2502.15822v1"
  },
  {
    "id": "2502.13308v3",
    "title": "A Label-Free Heterophily-Guided Approach for Unsupervised Graph Fraud Detection",
    "authors": [
      "Junjun Pan",
      "Yixin Liu",
      "Xin Zheng",
      "Yizhen Zheng",
      "Alan Wee-Chung Liew",
      "Fuyi Li",
      "Shirui Pan"
    ],
    "abstract": "Graph fraud detection (GFD) has rapidly advanced in protecting online\nservices by identifying malicious fraudsters. Recent supervised GFD research\nhighlights that heterophilic connections between fraudsters and users can\ngreatly impact detection performance, since fraudsters tend to camouflage\nthemselves by building more connections to benign users. Despite the promising\nperformance of supervised GFD methods, the reliance on labels limits their\napplications to unsupervised scenarios; Additionally, accurately capturing\ncomplex and diverse heterophily patterns without labels poses a further\nchallenge. To fill the gap, we propose a Heterophily-guided Unsupervised Graph\nfraud dEtection approach (HUGE) for unsupervised GFD, which contains two\nessential components: a heterophily estimation module and an alignment-based\nfraud detection module. In the heterophily estimation module, we design a novel\nlabel-free heterophily metric called HALO, which captures the critical graph\nproperties for GFD, enabling its outstanding ability to estimate heterophily\nfrom node attributes. In the alignment-based fraud detection module, we develop\na joint MLP-GNN architecture with ranking loss and asymmetric alignment loss.\nThe ranking loss aligns the predicted fraud score with the relative order of\nHALO, providing an extra robustness guarantee by comparing heterophily among\nnon-adjacent nodes. Moreover, the asymmetric alignment loss effectively\nutilizes structural information while alleviating the feature-smooth effects of\nGNNs. Extensive experiments on 6 datasets demonstrate that HUGE significantly\noutperforms competitors, showcasing its effectiveness and robustness.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-02-18T22:07:36+00:00",
    "updated": "2025-03-20T03:59:44+00:00",
    "url": "http://arxiv.org/pdf/2502.13308v3"
  },
  {
    "id": "2502.12904v2",
    "title": "Fraud-R1 : A Multi-Round Benchmark for Assessing the Robustness of LLM Against Augmented Fraud and Phishing Inducements",
    "authors": [
      "Shu Yang",
      "Shenzhe Zhu",
      "Zeyu Wu",
      "Keyu Wang",
      "Junchi Yao",
      "Junchao Wu",
      "Lijie Hu",
      "Mengdi Li",
      "Derek F. Wong",
      "Di Wang"
    ],
    "abstract": "We introduce Fraud-R1, a benchmark designed to evaluate LLMs' ability to\ndefend against internet fraud and phishing in dynamic, real-world scenarios.\nFraud-R1 comprises 8,564 fraud cases sourced from phishing scams, fake job\npostings, social media, and news, categorized into 5 major fraud types. Unlike\nprevious benchmarks, Fraud-R1 introduces a multi-round evaluation pipeline to\nassess LLMs' resistance to fraud at different stages, including credibility\nbuilding, urgency creation, and emotional manipulation. Furthermore, we\nevaluate 15 LLMs under two settings: 1. Helpful-Assistant, where the LLM\nprovides general decision-making assistance, and 2. Role-play, where the model\nassumes a specific persona, widely used in real-world agent-based interactions.\nOur evaluation reveals the significant challenges in defending against fraud\nand phishing inducement, especially in role-play settings and fake job\npostings. Additionally, we observe a substantial performance gap between\nChinese and English, underscoring the need for improved multilingual fraud\ndetection capabilities.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-02-18T14:47:02+00:00",
    "updated": "2025-05-26T06:03:03+00:00",
    "url": "http://arxiv.org/pdf/2502.12904v2"
  },
  {
    "id": "2502.12099v1",
    "title": "Crime in Proportions: Applying Compositional Data Analysis to European Crime Trends for 2022",
    "authors": [
      "Onur Batın Doğan",
      "Fatma Sevinç Kurnaz"
    ],
    "abstract": "This article investigates crime patterns across European countries in 2022\nusing Compositional Data Analysis (CoDA) to address limitations of traditional\nstatistical approaches in dealing with the relative nature of crime data.\nRecognizing crime types as components of a whole, we employ CoDA to explore\nrelationships between different crime categories while respecting their\ninherent interdependencies. The study utilizes k-means clustering to group\ncountries based on their crime profiles, identifying three distinct clusters\nlargely aligning with geographical locations. This clustering is visualized\nthrough t-SNE and geographic mapping, revealing regional similarities. Further\nanalysis using Robust Principal Component Analysis on identified crime clusters\nreveals insightful relationships between specific crime types, such as\nhomicide, smuggling, and financial crimes, and how their prevalence varies\nacross countries. The findings reveals distinct crime patterns across Europe,\nhighlighting regional commonalities while also highlighting divergences like\nNorway and Latvia that deviate from their expected geographical\nclassifications. Moreover, the study identifies specific crime groups; for\nexample, it pairs countries high in corruption and smuggling, such as Austria,\nwith those countries that exhibit a higher relevance to homicide and smuggling,\nsuch as Luxembourg. It also points to the presence of financial crimes like\nfraud in countries such as Romania and Estonia.",
    "categories": [
      "stat.AP"
    ],
    "published": "2025-02-17T18:18:43+00:00",
    "updated": "2025-02-17T18:18:43+00:00",
    "url": "http://arxiv.org/pdf/2502.12099v1"
  },
  {
    "id": "2502.10771v1",
    "title": "Assessing the Trustworthiness of Electronic Identity Management Systems: Framework and Insights from Inception to Deployment",
    "authors": [
      "Mirko Bottarelli",
      "Gregory Epiphaniou",
      "Shah Mahmood",
      "Mark Hooper",
      "Carsten Maple"
    ],
    "abstract": "The growing dependence on Electronic Identity Management Systems (EIDS) and\nrecent advancements, such as non-human ID management, require a thorough\nevaluation of their trustworthiness. Assessing EIDS's trustworthiness ensures\nsecurity, privacy, and reliability in managing sensitive user information. It\nsafeguards against fraud, unauthorised access, and data breaches, fostering\nuser confidence. Existing frameworks primarily focus on specific dimensions\nsuch as security and privacy, often neglecting critical dimensions such as\nethics, resilience, robustness, and reliability. This paper introduces an\nintegrated Digital Identity Systems Trustworthiness Assessment Framework\n(DISTAF) encapsulating these six pillars. It is supported by over 65 mechanisms\nand over 400 metrics derived from international standards and technical\nguidelines. By addressing the lifecycle of DIMS from design to deployment, our\nDISTAF evaluates trustworthiness at granular levels while remaining accessible\nto diverse stakeholders. We demonstrate the application of DISTAF through a\nreal-world implementation using a Modular Open Source Identity Platform (MOSIP)\ninstance, refining its metrics to simplify trustworthiness assessment. Our\napproach introduces clustering mechanisms for metrics, hierarchical scoring,\nand mandatory criteria to ensure robust and consistent evaluations across an\nEIDS in both the design and operation stages. Furthermore, DISTAF is adaptable\nto emerging technologies like Self-Sovereign Identity (SSI), integrating\nprivacy-enhancing techniques and ethical considerations to meet modern\nchallenges. The assessment tool developed alongside DISTAF provides a\nuser-centric methodology and a simplified yet effective self-assessment\nprocess, enabling system designers and assessors to identify system gaps,\nimprove configurations, and enhance public trust.",
    "categories": [
      "cs.CR"
    ],
    "published": "2025-02-15T11:26:30+00:00",
    "updated": "2025-02-15T11:26:30+00:00",
    "url": "http://arxiv.org/pdf/2502.10771v1"
  },
  {
    "id": "2502.10624v1",
    "title": "Network evasion detection with Bi-LSTM model",
    "authors": [
      "Kehua Chen",
      "Jingping Jia"
    ],
    "abstract": "Network evasion detection aims to distinguish whether the network flow comes\nfrom link layer exists network evasion threat, which is a means to disguise the\ndata traffic on detection system by confusing the signature. Since the previous\nresearch works has all sorts of frauds, we propose a architecture with deep\nlearning network to handle this problem. In this paper, we extract the critical\ninformation as key features from data frame and also specifically propose to\nuse bidirectional long short-term memory (Bi-LSTM) neural network which shows\nan outstanding performance to trace the serial information, to encode both the\npast and future trait on the network flows. Furthermore we introduce a\nclassifier named Softmax at the bottom of Bi-LSTM, holding a character to\nselect the correct class. All experiments results shows that we can achieve a\nsignificant performance with a deep Bi-LSTM in network evasion detection and\nit's average accuracy reaches 96.1%.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-02-15T01:25:13+00:00",
    "updated": "2025-02-15T01:25:13+00:00",
    "url": "http://arxiv.org/pdf/2502.10624v1"
  },
  {
    "id": "2502.10321v1",
    "title": "Dynamic Fraud Proof",
    "authors": [
      "Gabriele Picco",
      "Andrea Fortugno"
    ],
    "abstract": "In this paper, we present a novel fraud-proof mechanism that achieves fast\nfinality and, when combined with optimistic execution, enables real-time\ntransaction processing. State-of-the-art optimistic rollups typically adopt a\n7-day challenge window, during which any honest party can raise a challenge in\ncase of fraud. We propose a new assert/challenge construction called \"Dynamic\nFraud Proofs\" that achieves sub-second finality in ideal scenarios, while\ndynamically delaying settlement in the event of fraud detection and challenge\nresolution. The system relies on 1) a dynamic challenge period and 2) a\nconfigurable number of randomly selected verifier nodes who must interactively\napprove a state commitment without raising a challenge. If these conditions are\nnot met, the state is not finalized, and the challenge period and approval\ncriteria are dynamically adjusted. We provide a detailed analysis of the\nsystem's design, explaining how it maintains the assumption of a single honest\nnode and addresses censorship attacks by inverting the traditional challenge\nprocess. Additionally, we formalize the system's probabilistic security model\nand discuss how bonding, incentives, and slashing mechanisms can encourage\nhonest behavior, thereby increasing the likelihood of fast settlement in ideal\nscenarios.",
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "published": "2025-02-14T17:27:40+00:00",
    "updated": "2025-02-14T17:27:40+00:00",
    "url": "http://arxiv.org/pdf/2502.10321v1"
  },
  {
    "id": "2504.10229v1",
    "title": "ROSFD: Robust Online Streaming Fraud Detection with Resilience to Concept Drift in Data Streams",
    "authors": [
      "Vivek Yelleti"
    ],
    "abstract": "Continuous generation of streaming data from diverse sources, such as online\ntransactions and digital interactions, necessitates timely fraud detection.\nTraditional batch processing methods often struggle to capture the rapidly\nevolving patterns of fraudulent activities. This paper highlights the critical\nimportance of processing streaming data for effective fraud detection. To\naddress the inherent challenges of latency, scalability, and concept drift in\nstreaming environments, we propose a robust online streaming fraud detection\n(ROSFD) framework. Our proposed framework comprises two key stages: (i) Stage\nOne: Offline Model Initialization. In this initial stage, a model is built in\noffline settings using incremental learning principles to overcome the\n\"cold-start\" problem. (ii) Stage Two: Real-time Model Adaptation. In this\ndynamic stage, drift detection algorithms (viz.,, DDM, EDDM, and ADWIN) are\nemployed to identify concept drift in the incoming data stream and\nincrementally train the model accordingly. This \"train-only-when-required\"\nstrategy drastically reduces the number of retrains needed without\nsignificantly impacting the area under the receiver operating characteristic\ncurve (AUC). Overall, ROSFD utilizing ADWIN as the drift detection method\ndemonstrated the best performance among the employed methods. In terms of model\nefficacy, Adaptive Random Forest consistently outperformed other models,\nachieving the highest AUC in four out of five datasets.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-04-14T13:50:23+00:00",
    "updated": "2025-04-14T13:50:23+00:00",
    "url": "http://arxiv.org/pdf/2504.10229v1"
  },
  {
    "id": "2504.09839v1",
    "title": "SafeSpeech: Robust and Universal Voice Protection Against Malicious Speech Synthesis",
    "authors": [
      "Zhisheng Zhang",
      "Derui Wang",
      "Qianyi Yang",
      "Pengyang Huang",
      "Junhan Pu",
      "Yuxin Cao",
      "Kai Ye",
      "Jie Hao",
      "Yixian Yang"
    ],
    "abstract": "Speech synthesis technology has brought great convenience, while the\nwidespread usage of realistic deepfake audio has triggered hazards. Malicious\nadversaries may unauthorizedly collect victims' speeches and clone a similar\nvoice for illegal exploitation (\\textit{e.g.}, telecom fraud). However, the\nexisting defense methods cannot effectively prevent deepfake exploitation and\nare vulnerable to robust training techniques. Therefore, a more effective and\nrobust data protection method is urgently needed. In response, we propose a\ndefensive framework, \\textit{\\textbf{SafeSpeech}}, which protects the users'\naudio before uploading by embedding imperceptible perturbations on original\nspeeches to prevent high-quality synthetic speech. In SafeSpeech, we devise a\nrobust and universal proactive protection technique, \\textbf{S}peech\n\\textbf{PE}rturbative \\textbf{C}oncealment (\\textbf{SPEC}), that leverages a\nsurrogate model to generate universally applicable perturbation for generative\nsynthetic models. Moreover, we optimize the human perception of embedded\nperturbation in terms of time and frequency domains. To evaluate our method\ncomprehensively, we conduct extensive experiments across advanced models and\ndatasets, both subjectively and objectively. Our experimental results\ndemonstrate that SafeSpeech achieves state-of-the-art (SOTA) voice protection\neffectiveness and transferability and is highly robust against advanced\nadaptive adversaries. Moreover, SafeSpeech has real-time capability in\nreal-world tests. The source code is available at\n\\href{https://github.com/wxzyd123/SafeSpeech}{https://github.com/wxzyd123/SafeSpeech}.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-04-14T03:21:23+00:00",
    "updated": "2025-04-14T03:21:23+00:00",
    "url": "http://arxiv.org/pdf/2504.09839v1"
  },
  {
    "id": "2504.09311v1",
    "title": "Dupin: A Parallel Framework for Densest Subgraph Discovery in Fraud Detection on Massive Graphs (Technical Report)",
    "authors": [
      "Jiaxin Jiang",
      "Siyuan Yao",
      "Yuchen Li",
      "Qiange Wang",
      "Bingsheng He",
      "Min Chen"
    ],
    "abstract": "Detecting fraudulent activities in financial and e-commerce transaction\nnetworks is crucial. One effective method for this is Densest Subgraph\nDiscovery (DSD). However, deploying DSD methods in production systems faces\nsubstantial scalability challenges due to the predominantly sequential nature\nof existing methods, which impedes their ability to handle large-scale\ntransaction networks and results in significant detection delays. To address\nthese challenges, we introduce Dupin, a novel parallel processing framework\ndesigned for efficient DSD processing in billion-scale graphs. Dupin is powered\nby a processing engine that exploits the unique properties of the peeling\nprocess, with theoretical guarantees on detection quality and efficiency. Dupin\nprovides userfriendly APIs for flexible customization of DSD objectives and\nensures robust adaptability to diverse fraud detection scenarios. Empirical\nevaluations demonstrate that Dupin consistently outperforms several existing\nDSD methods, achieving performance improvements of up to 100 times compared to\ntraditional approaches. On billion-scale graphs, Dupin demonstrates the\npotential to enhance the prevention of fraudulent transactions from 45% to\n94.5% and reduces density error from 30% to below 5%, as supported by our\nexperimental results. These findings highlight the effectiveness of Dupin in\nreal-world applications, ensuring both speed and accuracy in fraud detection.",
    "categories": [
      "cs.DB"
    ],
    "published": "2025-04-12T19:14:54+00:00",
    "updated": "2025-04-12T19:14:54+00:00",
    "url": "http://arxiv.org/pdf/2504.09311v1"
  },
  {
    "id": "2504.08183v1",
    "title": "Detecting Credit Card Fraud via Heterogeneous Graph Neural Networks with Graph Attention",
    "authors": [
      "Qiuwu Sha",
      "Tengda Tang",
      "Xinyu Du",
      "Jie Liu",
      "Yixian Wang",
      "Yuan Sheng"
    ],
    "abstract": "This study proposes a credit card fraud detection method based on\nHeterogeneous Graph Neural Network (HGNN) to address fraud in complex\ntransaction networks. Unlike traditional machine learning methods that rely\nsolely on numerical features of transaction records, this approach constructs\nheterogeneous transaction graphs. These graphs incorporate multiple node types,\nincluding users, merchants, and transactions. By leveraging graph neural\nnetworks, the model captures higher-order transaction relationships. A Graph\nAttention Mechanism is employed to dynamically assign weights to different\ntransaction relationships. Additionally, a Temporal Decay Mechanism is\nintegrated to enhance the model's sensitivity to time-related fraud patterns.\nTo address the scarcity of fraudulent transaction samples, this study applies\nSMOTE oversampling and Cost-sensitive Learning. These techniques strengthen the\nmodel's ability to identify fraudulent transactions. Experimental results\ndemonstrate that the proposed method outperforms existing GNN models, including\nGCN, GAT, and GraphSAGE, on the IEEE-CIS Fraud Detection dataset. The model\nachieves notable improvements in both accuracy and OC-ROC. Future research may\nexplore the integration of dynamic graph neural networks and reinforcement\nlearning. Such advancements could enhance the real-time adaptability of fraud\ndetection systems and provide more intelligent solutions for financial risk\ncontrol.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2025-04-11T00:53:53+00:00",
    "updated": "2025-04-11T00:53:53+00:00",
    "url": "http://arxiv.org/pdf/2504.08183v1"
  },
  {
    "id": "2504.12319v1",
    "title": "Specialized text classification: an approach to classifying Open Banking transactions",
    "authors": [
      "Duc Tuyen TA",
      "Wajdi Ben Saad",
      "Ji Young Oh"
    ],
    "abstract": "With the introduction of the PSD2 regulation in the EU which established the\nOpen Banking framework, a new window of opportunities has opened for banks and\nfintechs to explore and enrich Bank transaction descriptions with the aim of\nbuilding a better understanding of customer behavior, while using this\nunderstanding to prevent fraud, reduce risks and offer more competitive and\ntailored services.\n  And although the usage of natural language processing models and techniques\nhas seen an incredible progress in various applications and domains over the\npast few years, custom applications based on domain-specific text corpus remain\nunaddressed especially in the banking sector.\n  In this paper, we introduce a language-based Open Banking transaction\nclassification system with a focus on the french market and french language\ntext. The system encompasses data collection, labeling, preprocessing,\nmodeling, and evaluation stages. Unlike previous studies that focus on general\nclassification approaches, this system is specifically tailored to address the\nchallenges posed by training a language model with a specialized text corpus\n(Banking data in the French context). By incorporating language-specific\ntechniques and domain knowledge, the proposed system demonstrates enhanced\nperformance and efficiency compared to generic approaches.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "q-fin.CP"
    ],
    "published": "2025-04-10T17:14:43+00:00",
    "updated": "2025-04-10T17:14:43+00:00",
    "url": "http://arxiv.org/pdf/2504.12319v1"
  },
  {
    "id": "2504.05758v1",
    "title": "Addressing Class Imbalance with Probabilistic Graphical Models and Variational Inference",
    "authors": [
      "Yujia Lou",
      "Jie Liu",
      "Yuan Sheng",
      "Jiawei Wang",
      "Yiwei Zhang",
      "Yaokun Ren"
    ],
    "abstract": "This study proposes a method for imbalanced data classification based on deep\nprobabilistic graphical models (DPGMs) to solve the problem that traditional\nmethods have insufficient learning ability for minority class samples. To\naddress the classification bias caused by class imbalance, we introduce\nvariational inference optimization probability modeling, which enables the\nmodel to adaptively adjust the representation ability of minority classes and\ncombines the class-aware weight adjustment strategy to enhance the classifier's\nsensitivity to minority classes. In addition, we combine the adversarial\nlearning mechanism to generate minority class samples in the latent space so\nthat the model can better characterize the category boundary in the\nhigh-dimensional feature space. The experiment is evaluated on the Kaggle\n\"Credit Card Fraud Detection\" dataset and compared with a variety of advanced\nimbalanced classification methods (such as GAN-based sampling, BRF,\nXGBoost-Cost Sensitive, SAAD, HAN). The results show that the method in this\nstudy has achieved the best performance in AUC, Precision, Recall and F1-score\nindicators, effectively improving the recognition rate of minority classes and\nreducing the false alarm rate. This method can be widely used in imbalanced\nclassification tasks such as financial fraud detection, medical diagnosis, and\nanomaly detection, providing a new solution for related research.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-04-08T07:38:30+00:00",
    "updated": "2025-04-08T07:38:30+00:00",
    "url": "http://arxiv.org/pdf/2504.05758v1"
  },
  {
    "id": "2504.05504v1",
    "title": "SelfMAD: Enhancing Generalization and Robustness in Morphing Attack Detection via Self-Supervised Learning",
    "authors": [
      "Marija Ivanovska",
      "Leon Todorov",
      "Naser Damer",
      "Deepak Kumar Jain",
      "Peter Peer",
      "Vitomir Štruc"
    ],
    "abstract": "With the continuous advancement of generative models, face morphing attacks\nhave become a significant challenge for existing face verification systems due\nto their potential use in identity fraud and other malicious activities.\nContemporary Morphing Attack Detection (MAD) approaches frequently rely on\nsupervised, discriminative models trained on examples of bona fide and morphed\nimages. These models typically perform well with morphs generated with\ntechniques seen during training, but often lead to sub-optimal performance when\nsubjected to novel unseen morphing techniques. While unsupervised models have\nbeen shown to perform better in terms of generalizability, they typically\nresult in higher error rates, as they struggle to effectively capture features\nof subtle artifacts. To address these shortcomings, we present SelfMAD, a novel\nself-supervised approach that simulates general morphing attack artifacts,\nallowing classifiers to learn generic and robust decision boundaries without\noverfitting to the specific artifacts induced by particular face morphing\nmethods. Through extensive experiments on widely used datasets, we demonstrate\nthat SelfMAD significantly outperforms current state-of-the-art MADs, reducing\nthe detection error by more than 64% in terms of EER when compared to the\nstrongest unsupervised competitor, and by more than 66%, when compared to the\nbest performing discriminative MAD model, tested in cross-morph settings. The\nsource code for SelfMAD is available at https://github.com/LeonTodorov/SelfMAD.",
    "categories": [
      "cs.CV"
    ],
    "published": "2025-04-07T21:03:00+00:00",
    "updated": "2025-04-07T21:03:00+00:00",
    "url": "http://arxiv.org/pdf/2504.05504v1"
  },
  {
    "id": "2504.03615v1",
    "title": "Autonomous and Self-Adapting System for Synthetic Media Detection and Attribution",
    "authors": [
      "Aref Azizpour",
      "Tai D. Nguyen",
      "Matthew C. Stamm"
    ],
    "abstract": "Rapid advances in generative AI have enabled the creation of highly realistic\nsynthetic images, which, while beneficial in many domains, also pose serious\nrisks in terms of disinformation, fraud, and other malicious applications.\nCurrent synthetic image identification systems are typically static, relying on\nfeature representations learned from known generators; as new generative models\nemerge, these systems suffer from severe performance degradation. In this\npaper, we introduce the concept of an autonomous self-adaptive synthetic media\nidentification system -- one that not only detects synthetic images and\nattributes them to known sources but also autonomously identifies and\nincorporates novel generators without human intervention. Our approach\nleverages an open-set identification strategy with an evolvable embedding space\nthat distinguishes between known and unknown sources. By employing an\nunsupervised clustering method to aggregate unknown samples into\nhigh-confidence clusters and continuously refining its decision boundaries, our\nsystem maintains robust detection and attribution performance even as the\ngenerative landscape evolves. Extensive experiments demonstrate that our method\nsignificantly outperforms existing approaches, marking a crucial step toward\nuniversal, adaptable forensic systems in the era of rapidly advancing\ngenerative models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-04-04T17:33:59+00:00",
    "updated": "2025-04-04T17:33:59+00:00",
    "url": "http://arxiv.org/pdf/2504.03615v1"
  },
  {
    "id": "2504.02275v1",
    "title": "Enhancing Customer Contact Efficiency with Graph Neural Networks in Credit Card Fraud Detection Workflow",
    "authors": [
      "Menghao Huo",
      "Kuan Lu",
      "Qiang Zhu",
      "Zhenrui Chen"
    ],
    "abstract": "Credit card fraud has been a persistent issue since the last century, causing\nsignificant financial losses to the industry. The most effective way to prevent\nfraud is by contacting customers to verify suspicious transactions. However,\nwhile these systems are designed to detect fraudulent activity, they often\nmistakenly flag legitimate transactions, leading to unnecessary declines that\ndisrupt the user experience and erode customer trust. Frequent false positives\ncan frustrate customers, resulting in dissatisfaction, increased complaints,\nand a diminished sense of security. To address these limitations, we propose a\nfraud detection framework incorporating Relational Graph Convolutional Networks\n(RGCN) to enhance the accuracy and efficiency of identifying fraudulent\ntransactions. By leveraging the relational structure of transaction data, our\nmodel reduces the need for direct customer confirmation while maintaining high\ndetection performance. Our experiments are conducted using the IBM credit card\ntransaction dataset to evaluate the effectiveness of this approach.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-04-03T04:50:45+00:00",
    "updated": "2025-04-03T04:50:45+00:00",
    "url": "http://arxiv.org/pdf/2504.02275v1"
  },
  {
    "id": "2504.03765v1",
    "title": "Watermarking for AI Content Detection: A Review on Text, Visual, and Audio Modalities",
    "authors": [
      "Lele Cao"
    ],
    "abstract": "The rapid advancement of generative artificial intelligence (GenAI) has\nrevolutionized content creation across text, visual, and audio domains,\nsimultaneously introducing significant risks such as misinformation, identity\nfraud, and content manipulation. This paper presents a practical survey of\nwatermarking techniques designed to proactively detect GenAI content. We\ndevelop a structured taxonomy categorizing watermarking methods for text,\nvisual, and audio modalities and critically evaluate existing approaches based\non their effectiveness, robustness, and practicality. Additionally, we identify\nkey challenges, including resistance to adversarial attacks, lack of\nstandardization across different content types, and ethical considerations\nrelated to privacy and content ownership. Finally, we discuss potential future\nresearch directions aimed at enhancing watermarking strategies to ensure\ncontent authenticity and trustworthiness. This survey serves as a foundational\nresource for researchers and practitioners seeking to understand and advance\nwatermarking techniques for AI-generated content detection.",
    "categories": [
      "cs.CR",
      "68T45, 94A60, 68U10, 68P25",
      "I.2.7; I.4.9; H.2.8; K.4.1; K.6.5"
    ],
    "published": "2025-04-02T15:18:10+00:00",
    "updated": "2025-04-02T15:18:10+00:00",
    "url": "http://arxiv.org/pdf/2504.03765v1"
  },
  {
    "id": "2504.03750v1",
    "title": "Detecting Financial Fraud with Hybrid Deep Learning: A Mix-of-Experts Approach to Sequential and Anomalous Patterns",
    "authors": [
      "Diego Vallarino"
    ],
    "abstract": "Financial fraud detection remains a critical challenge due to the dynamic and\nadversarial nature of fraudulent behavior. As fraudsters evolve their tactics,\ndetection systems must combine robustness, adaptability, and precision. This\nstudy presents a hybrid architecture for credit card fraud detection that\nintegrates a Mixture of Experts (MoE) framework with Recurrent Neural Networks\n(RNNs), Transformer encoders, and Autoencoders. Each expert module contributes\na specialized capability: RNNs capture sequential behavior, Transformers\nextract high-order feature interactions, and Autoencoders detect anomalies\nthrough reconstruction loss. The MoE framework dynamically assigns predictive\nresponsibility among the experts, enabling adaptive and context-sensitive\ndecision-making.\n  Trained on a high-fidelity synthetic dataset that simulates real-world\ntransaction patterns and fraud typologies, the hybrid model achieved 98.7\npercent accuracy, 94.3 percent precision, and 91.5 percent recall,\noutperforming standalone models and classical machine learning baselines. The\nAutoencoder component significantly enhanced the system's ability to identify\nemerging fraud strategies and atypical behaviors.\n  Beyond technical performance, the model contributes to broader efforts in\nfinancial governance and crime prevention. It supports regulatory compliance\nwith Anti-Money Laundering (AML) and Know Your Customer (KYC) protocols and\naligns with routine activity theory by operationalizing AI as a capable\nguardian within financial ecosystems. The proposed hybrid system offers a\nscalable, modular, and regulation-aware approach to detecting increasingly\nsophisticated fraud patterns, contributing both to the advancement of\nintelligent systems and to the strengthening of institutional fraud defense\ninfrastructures.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-04-01T20:47:18+00:00",
    "updated": "2025-04-01T20:47:18+00:00",
    "url": "http://arxiv.org/pdf/2504.03750v1"
  },
  {
    "id": "2504.00786v1",
    "title": "FeatInsight: An Online ML Feature Management System on 4Paradigm Sage-Studio Platform",
    "authors": [
      "Xin Tong",
      "Xuanhe Zhou",
      "Bingsheng He",
      "Guoliang Li",
      "Zirui Tang",
      "Wei Zhou",
      "Fan Wu",
      "Mian Lu",
      "Yuqiang Chen"
    ],
    "abstract": "Feature management is essential for many online machine learning applications\nand can often become the performance bottleneck (e.g., taking up to 70% of the\noverall latency in sales prediction service). Improper feature configurations\n(e.g., introducing too many irrelevant features) can severely undermine the\nmodel's generalization capabilities. However, managing online ML features is\nchallenging due to (1) large-scale, complex raw data (e.g., the 2018 PHM\ndataset contains 17 tables and dozens to hundreds of columns), (2) the need for\nhigh-performance, consistent computation of interdependent features with\ncomplex patterns, and (3) the requirement for rapid updates and deployments to\naccommodate real-time data changes. In this demo, we present FeatInsight, a\nsystem that supports the entire feature lifecycle, including feature design,\nstorage, visualization, computation, verification, and lineage management.\nFeatInsight (with OpenMLDB as the execution engine) has been deployed in over\n100 real-world scenarios on 4Paradigm's Sage Studio platform, handling up to a\ntrillion-dimensional feature space and enabling millisecond-level feature\nupdates. We demonstrate how FeatInsight enhances feature design efficiency\n(e.g., for online product recommendation) and improve feature computation\nperformance (e.g., for online fraud detection). The code is available at\nhttps://github.com/4paradigm/FeatInsight.",
    "categories": [
      "cs.DB",
      "cs.LG"
    ],
    "published": "2025-04-01T13:39:45+00:00",
    "updated": "2025-04-01T13:39:45+00:00",
    "url": "http://arxiv.org/pdf/2504.00786v1"
  },
  {
    "id": "2503.24259v1",
    "title": "Advances in Continual Graph Learning for Anti-Money Laundering Systems: A Comprehensive Review",
    "authors": [
      "Bruno Deprez",
      "Wei Wei",
      "Wouter Verbeke",
      "Bart Baesens",
      "Kevin Mets",
      "Tim Verdonck"
    ],
    "abstract": "Financial institutions are required by regulation to report suspicious\nfinancial transactions related to money laundering. Therefore, they need to\nconstantly monitor vast amounts of incoming and outgoing transactions. A\nparticular challenge in detecting money laundering is that money launderers\ncontinuously adapt their tactics to evade detection. Hence, detection methods\nneed constant fine-tuning. Traditional machine learning models suffer from\ncatastrophic forgetting when fine-tuning the model on new data, thereby\nlimiting their effectiveness in dynamic environments. Continual learning\nmethods may address this issue and enhance current anti-money laundering (AML)\npractices, by allowing models to incorporate new information while retaining\nprior knowledge. Research on continual graph learning for AML, however, is\nstill scarce. In this review, we critically evaluate state-of-the-art continual\ngraph learning approaches for AML applications. We categorise methods into\nreplay-based, regularization-based, and architecture-based strategies within\nthe graph neural network (GNN) framework, and we provide in-depth experimental\nevaluations on both synthetic and real-world AML data sets that showcase the\neffect of the different hyperparameters. Our analysis demonstrates that\ncontinual learning improves model adaptability and robustness in the face of\nextreme class imbalances and evolving fraud patterns. Finally, we outline key\nchallenges and propose directions for future research.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-03-31T16:06:47+00:00",
    "updated": "2025-03-31T16:06:47+00:00",
    "url": "http://arxiv.org/pdf/2503.24259v1"
  },
  {
    "id": "2503.24115v4",
    "title": "TeleAntiFraud-28k: An Audio-Text Slow-Thinking Dataset for Telecom Fraud Detection",
    "authors": [
      "Zhiming Ma",
      "Peidong Wang",
      "Minhua Huang",
      "Jingpeng Wang",
      "Kai Wu",
      "Xiangzhao Lv",
      "Yachun Pang",
      "Yin Yang",
      "Wenjie Tang",
      "Yuchen Kang"
    ],
    "abstract": "The detection of telecom fraud faces significant challenges due to the lack\nof high-quality multimodal training data that integrates audio signals with\nreasoning-oriented textual analysis. To address this gap, we present\nTeleAntiFraud-28k, the first open-source audio-text slow-thinking dataset\nspecifically designed for automated telecom fraud analysis. Our dataset is\nconstructed through three strategies: (1) Privacy-preserved text-truth sample\ngeneration using automatically speech recognition (ASR)-transcribed call\nrecordings (with anonymized original audio), ensuring real-world consistency\nthrough text-to-speech (TTS) model regeneration; (2) Semantic enhancement via\nlarge language model (LLM)-based self-instruction sampling on authentic ASR\noutputs to expand scenario coverage; (3) Multi-agent adversarial synthesis that\nsimulates emerging fraud tactics through predefined communication scenarios and\nfraud typologies. The generated dataset contains 28,511 rigorously processed\nspeech-text pairs, complete with detailed annotations for fraud reasoning. The\ndataset is divided into three tasks: scenario classification, fraud detection,\nfraud type classification. Furthermore, we construct TeleAntiFraud-Bench, a\nstandardized evaluation benchmark comprising proportionally sampled instances\nfrom the dataset, to facilitate systematic testing of model performance on\ntelecom fraud detection tasks. We also contribute a production-optimized\nsupervised fine-tuning (SFT) model trained on hybrid real/synthetic data, while\nopen-sourcing the data processing framework to enable community-driven dataset\nexpansion. This work establishes a foundational framework for multimodal\nanti-fraud research while addressing critical challenges in data privacy and\nscenario diversity. The project will be released at\nhttps://github.com/JimmyMa99/TeleAntiFraud.",
    "categories": [
      "cs.CL",
      "cs.MM"
    ],
    "published": "2025-03-31T14:06:17+00:00",
    "updated": "2025-08-18T17:18:06+00:00",
    "url": "http://arxiv.org/pdf/2503.24115v4"
  },
  {
    "id": "2503.21463v1",
    "title": "Unveiling Latent Information in Transaction Hashes: Hypergraph Learning for Ethereum Ponzi Scheme Detection",
    "authors": [
      "Junhao Wu",
      "Yixin Yang",
      "Chengxiang Jin",
      "Silu Mu",
      "Xiaolei Qian",
      "Jiajun Zhou",
      "Shanqing Yu",
      "Qi Xuan"
    ],
    "abstract": "With the widespread adoption of Ethereum, financial frauds such as Ponzi\nschemes have become increasingly rampant in the blockchain ecosystem, posing\nsignificant threats to the security of account assets. Existing Ethereum fraud\ndetection methods typically model account transactions as graphs, but this\napproach primarily focuses on binary transactional relationships between\naccounts, failing to adequately capture the complex multi-party interaction\npatterns inherent in Ethereum. To address this, we propose a hypergraph\nmodeling method for the Ponzi scheme detection method in Ethereum, called\nHyperDet. Specifically, we treat transaction hashes as hyperedges that connect\nall the relevant accounts involved in a transaction. Additionally, we design a\ntwo-step hypergraph sampling strategy to significantly reduce computational\ncomplexity. Furthermore, we introduce a dual-channel detection module,\nincluding the hypergraph detection channel and the hyper-homo graph detection\nchannel, to be compatible with existing detection methods. Experimental results\nshow that, compared to traditional homogeneous graph-based methods, the\nhyper-homo graph detection channel achieves significant performance\nimprovements, demonstrating the superiority of hypergraph in Ponzi scheme\ndetection. This research offers innovations for modeling complex relationships\nin blockchain data.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-03-27T12:52:47+00:00",
    "updated": "2025-03-27T12:52:47+00:00",
    "url": "http://arxiv.org/pdf/2503.21463v1"
  },
  {
    "id": "2503.21175v1",
    "title": "Doing Less for More: Consumer Search and Undertreatment in Credence Service Markets",
    "authors": [
      "Xiaoyan Xu",
      "Weishi Lim",
      "Xing Zhang",
      "Jeff Cai"
    ],
    "abstract": "In many service markets, expert providers possess an information advantage\nover consumers regarding the necessary services, creating opportunities for\nfraudulent practices. These may involve overtreatment through unnecessary\nservices or undertreatment with ineffective solutions that fail to address\nconsumers' problems. When issues are resolved, consumers exit the market; when\nunresolved, they must decide whether to revisit the initial provider or seek a\nnew one. Little is known about how repeated interactions and the consumer\nsearch process influence expert fraud and consumer welfare in such markets. We\ndevelop a dynamic game-theoretic model to examine the role of consumer search\nbehavior and repeated interactions between consumers and service providers. We\nfind that overtreatment and undertreatment can arise simultaneously in\nequilibrium. Interestingly, undertreatment-being less costly for the\nconsumer-can initially act as a \"hook\" to induce acceptance of a minor\ntreatment recommendation. When this minor treatment fails to resolve the issue,\nit can generate additional demand for a more expensive and serious treatment.\nThis would arise when the cost of revisiting the initial provider is lower than\nthat of searching for a new one. The extent of undertreatment exhibits a\nnon-monotonic relationship with consumers' ex ante belief about the nature of\ntheir problems and the market's ethical level. Our results can shed light on\nhow market ethical levels, provider capabilities and capacities, and consumer\nprivacy protection policies interact with undertreatment and affect consumer\nwelfare. Specifically, consumer welfare can decrease as the market becomes more\nethical. Enhancing providers' diagnostic capabilities and capacities can\nexacerbate undertreatment. Providing access to consumers' diagnosis histories\ncan help mitigate the undertreatment issue and improve consumer welfare.",
    "categories": [
      "econ.TH"
    ],
    "published": "2025-03-27T05:53:26+00:00",
    "updated": "2025-03-27T05:53:26+00:00",
    "url": "http://arxiv.org/pdf/2503.21175v1"
  },
  {
    "id": "2503.21160v1",
    "title": "A Data Balancing and Ensemble Learning Approach for Credit Card Fraud Detection",
    "authors": [
      "Yuhan Wang"
    ],
    "abstract": "This research introduces an innovative method for identifying credit card\nfraud by combining the SMOTE-KMEANS technique with an ensemble machine learning\nmodel. The proposed model was benchmarked against traditional models such as\nlogistic regression, decision trees, random forests, and support vector\nmachines. Performance was evaluated using metrics, including accuracy, recall,\nand area under the curve (AUC). The results demonstrated that the proposed\nmodel achieved superior performance, with an AUC of 0.96 when combined with the\nSMOTE-KMEANS algorithm. This indicates a significant improvement in detecting\nfraudulent transactions while maintaining high precision and recall. The study\nalso explores the application of different oversampling techniques to enhance\nthe performance of various classifiers. The findings suggest that the proposed\nmethod is robust and effective for classification tasks on balanced datasets.\nFuture research directions include further optimization of the SMOTE-KMEANS\napproach and its integration into existing fraud detection systems to enhance\nfinancial security and consumer protection.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-03-27T04:59:45+00:00",
    "updated": "2025-03-27T04:59:45+00:00",
    "url": "http://arxiv.org/pdf/2503.21160v1"
  },
  {
    "id": "2503.20477v1",
    "title": "Development of New Methods for Detection and Control of Credit Card Fraud Attacks",
    "authors": [
      "Alexander Stotsky"
    ],
    "abstract": "Credit card fraud causes significant financial losses and frequently occurs\nas fraud attack, defined as short-term sequence of fraudulent transactions\nassociated with high transaction rates and amounts, business areas historically\ntied to fraud, unusual transaction times and locations and different types of\nerrors. Confidence interval method in the moving window with exponential\nforgetting is proposed in this report which allows to capture recent changes in\nthe shopping behaviour of the cardholder, detect fraudulent amounts and\nmitigate the attack. Fraud risk scoring method is used for estimation of the\nintensity of the fraudulent activity via monitoring of the transaction rates,\nmerchant category codes, times and some other factors for detection of the\nstart of the attack. The development and verification are based on detailed\nanalysis of the transaction patterns from the dataset, which represents an\nextensive collection of around 24.4 million credit card transactions from IBM\nfinancial database. Recommendations for further development of the detection\ntechniques are also presented.",
    "categories": [
      "math.OC",
      "math.DS"
    ],
    "published": "2025-03-26T12:06:27+00:00",
    "updated": "2025-03-26T12:06:27+00:00",
    "url": "http://arxiv.org/pdf/2503.20477v1"
  },
  {
    "id": "2503.20821v2",
    "title": "\"Hello, is this Anna?\": Unpacking the Lifecycle of Pig-Butchering Scams",
    "authors": [
      "Rajvardhan Oak",
      "Zubair Shafiq"
    ],
    "abstract": "Pig-butchering scams have emerged as a complex form of fraud that combines\nelements of romance, investment fraud, and advanced social engineering tactics\nto systematically exploit victims. In this paper, we present the first\nqualitative analysis of pig-butchering scams, informed by in-depth\nsemi-structured interviews with $N=26$ victims. We capture nuanced, first-hand\naccounts from victims, providing insight into the lifecycle of pig-butchering\nscams and the complex emotional and financial manipulation involved. We\nsystematically analyze each phase of the scam, revealing that perpetrators\nemploy tactics such as staged trust-building, fraudulent financial platforms,\nfabricated investment returns, and repeated high-pressure tactics, all designed\nto exploit victims' trust and financial resources over extended periods. Our\nfindings reveal an organized scam lifecycle characterized by emotional\nmanipulation, staged financial exploitation, and persistent re-engagement\nefforts that amplify victim losses. We also find complex psychological and\nfinancial impacts on victims, including heightened vulnerability to secondary\nscams. Finally, we propose actionable intervention points for social media and\nfinancial platforms to curb the prevalence of these scams and highlight the\nneed for non-stigmatizing terminology to encourage victims to report and seek\nassistance.",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "published": "2025-03-25T23:15:48+00:00",
    "updated": "2025-05-24T07:36:41+00:00",
    "url": "http://arxiv.org/pdf/2503.20821v2"
  },
  {
    "id": "2503.18841v1",
    "title": "Unsupervised Detection of Fraudulent Transactions in E-commerce Using Contrastive Learning",
    "authors": [
      "Xuan Li",
      "Yuting Peng",
      "Xiaoxuan Sun",
      "Yifei Duan",
      "Zhou Fang",
      "Tengda Tang"
    ],
    "abstract": "With the rapid development of e-commerce, e-commerce platforms are facing an\nincreasing number of fraud threats. Effectively identifying and preventing\nthese fraudulent activities has become a critical research problem. Traditional\nfraud detection methods typically rely on supervised learning, which requires\nlarge amounts of labeled data. However, such data is often difficult to obtain,\nand the continuous evolution of fraudulent activities further reduces the\nadaptability and effectiveness of traditional methods. To address this issue,\nthis study proposes an unsupervised e-commerce fraud detection algorithm based\non SimCLR. The algorithm leverages the contrastive learning framework to\neffectively detect fraud by learning the underlying representations of\ntransaction data in an unlabeled setting. Experimental results on the eBay\nplatform dataset show that the proposed algorithm outperforms traditional\nunsupervised methods such as K-means, Isolation Forest, and Autoencoders in\nterms of accuracy, precision, recall, and F1 score, demonstrating strong fraud\ndetection capabilities. The results confirm that the SimCLR-based unsupervised\nfraud detection method has broad application prospects in e-commerce platform\nsecurity, improving both detection accuracy and robustness. In the future, with\nthe increasing scale and diversity of datasets, the model's performance will\ncontinue to improve, and it could be integrated with real-time monitoring\nsystems to provide more efficient security for e-commerce platforms.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-03-24T16:14:16+00:00",
    "updated": "2025-03-24T16:14:16+00:00",
    "url": "http://arxiv.org/pdf/2503.18841v1"
  },
  {
    "id": "2503.18235v1",
    "title": "Enhance GNNs with Reliable Confidence Estimation via Adversarial Calibration Learning",
    "authors": [
      "Yilong Wang",
      "Jiahao Zhang",
      "Tianxiang Zhao",
      "Suhang Wang"
    ],
    "abstract": "Despite their impressive predictive performance, GNNs often exhibit poor\nconfidence calibration, i.e., their predicted confidence scores do not\naccurately reflect true correctness likelihood. This issue raises concerns\nabout their reliability in high-stakes domains such as fraud detection, and\nrisk assessment, where well-calibrated predictions are essential for\ndecision-making. To ensure trustworthy predictions, several GNN calibration\nmethods are proposed. Though they can improve global calibration, our\nexperiments reveal that they often fail to generalize across different node\ngroups, leading to inaccurate confidence in node groups with different degree\nlevels, classes, and local structures. In certain cases, they even degrade\ncalibration compared to the original uncalibrated GNN. To address this\nchallenge, we propose a novel AdvCali framework that adaptively enhances\ncalibration across different node groups. Our method leverages adversarial\ntraining to automatically identify mis-calibrated node groups and applies a\ndifferentiable Group Expected Calibration Error (ECE) loss term to refine\nconfidence estimation within these groups. This allows the model to dynamically\nadjust its calibration strategy without relying on dataset-specific prior\nknowledge about miscalibrated subgroups. Extensive experiments on real-world\ndatasets demonstrate that our approach not only improves global calibration but\nalso significantly enhances calibration within groups defined by feature\nsimilarity, topology, and connectivity, outperforming previous methods and\ndemonstrating its effectiveness in practical scenarios.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-03-23T23:04:41+00:00",
    "updated": "2025-03-23T23:04:41+00:00",
    "url": "http://arxiv.org/pdf/2503.18235v1"
  },
  {
    "id": "2503.22710v1",
    "title": "Assessing the influence of cybersecurity threats and risks on the adoption and growth of digital banking: a systematic literature review",
    "authors": [
      "Md. Waliullah",
      "Md Zahin Hossain George",
      "Md Tarek Hasan",
      "Md Khorshed Alam",
      "Mosa Sumaiya Khatun Munira",
      "Noor Alam Siddiqui"
    ],
    "abstract": "The rapid digitalization of banking services has significantly transformed\nfinancial transactions, offering enhanced convenience and efficiency for\nconsumers. However, the increasing reliance on digital banking has also exposed\nfinancial institutions and users to a wide range of cybersecurity threats,\nincluding phishing, malware, ransomware, data breaches, and unauthorized\naccess. This study systematically examines the influence of cybersecurity\nthreats on digital banking security, adoption, and regulatory compliance by\nconducting a comprehensive review of 78 peer-reviewed articles published\nbetween 2015 and 2024. Using the Preferred Reporting Items for Systematic\nReviews and Meta-Analyses (PRISMA) methodology, this research critically\nevaluates the most prevalent cyber threats targeting digital banking platforms,\nthe effectiveness of modern security measures, and the role of regulatory\nframeworks in mitigating financial cybersecurity risks. The findings reveal\nthat phishing and malware attacks remain the most commonly exploited cyber\nthreats, leading to significant financial losses and consumer distrust.\nMulti-factor authentication (MFA) and biometric security have been widely\nadopted to combat unauthorized access, while AI-driven fraud detection and\nblockchain technology offer promising solutions for securing financial\ntransactions. However, the integration of third-party FinTech solutions\nintroduces additional security risks, necessitating stringent regulatory\noversight and cybersecurity protocols. The study also highlights that\ncompliance with global cybersecurity regulations, such as GDPR, PSD2, and GLBA,\nenhances digital banking security by enforcing strict authentication measures,\nencryption protocols, and real-time fraud monitoring.",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "published": "2025-03-23T03:14:45+00:00",
    "updated": "2025-03-23T03:14:45+00:00",
    "url": "http://arxiv.org/pdf/2503.22710v1"
  },
  {
    "id": "2503.16901v1",
    "title": "TeMP-TraG: Edge-based Temporal Message Passing in Transaction Graphs",
    "authors": [
      "Steve Gounoue",
      "Ashutosh Sao",
      "Simon Gottschalk"
    ],
    "abstract": "Transaction graphs, which represent financial and trade transactions between\nentities such as bank accounts and companies, can reveal patterns indicative of\nfinancial crimes like money laundering and fraud. However, effective detection\nof such cases requires node and edge classification methods capable of\naddressing the unique challenges of transaction graphs, including rich edge\nfeatures, multigraph structures and temporal dynamics. To tackle these\nchallenges, we propose TeMP-TraG, a novel graph neural network mechanism that\nincorporates temporal dynamics into message passing. TeMP-TraG prioritises more\nrecent transactions when aggregating node messages, enabling better detection\nof time-sensitive patterns. We demonstrate that TeMP-TraG improves four\nstate-of-the-art graph neural networks by 6.19% on average. Our results\nhighlight TeMP-TraG as an advancement in leveraging transaction graphs to\ncombat financial crime.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-03-21T07:10:27+00:00",
    "updated": "2025-03-21T07:10:27+00:00",
    "url": "http://arxiv.org/pdf/2503.16901v1"
  },
  {
    "id": "2503.16847v1",
    "title": "Early-MFC: Enhanced Flow Correlation Attacks on Tor via Multi-view Triplet Networks with Early Network Traffic",
    "authors": [
      "Yali Yuan",
      "Qianqi Niu",
      "Yachao Yuan"
    ],
    "abstract": "Flow correlation attacks is an efficient network attacks, aiming to expose\nthose who use anonymous network services, such as Tor. Conducting such attacks\nduring the early stages of network communication is particularly critical for\nscenarios demanding rapid decision-making, such as cybercrime detection or\nfinancial fraud prevention. Although recent studies have made progress in flow\ncorrelation attacks techniques, research specifically addressing flow\ncorrelation with early network traffic flow remains limited. Moreover, due to\nfactors such as model complexity, training costs, and real-time requirements,\nexisting technologies cannot be directly applied to flow correlation with early\nnetwork traffic flow. In this paper, we propose flow correlation attack with\nearly network traffic, named Early-MFC, based on multi-view triplet networks.\nThe proposed approach extracts multi-view traffic features from the payload at\nthe transport layer and the Inter-Packet Delay. It then integrates multi-view\nflow information, converting the extracted features into shared embeddings. By\nleveraging techniques such as metric learning and contrastive learning, the\nmethod optimizes the embeddings space by ensuring that similar flows are mapped\ncloser together while dissimilar flows are positioned farther apart. Finally,\nBayesian decision theory is applied to determine flow correlation, enabling\nhigh-accuracy flow correlation with early network traffic flow. Furthermore, we\ninvestigate flow correlation attacks under extra-early network traffic flow\nconditions. To address this challenge, we propose Early-MFC+, which utilizes\npayload data to construct embedded feature representations, ensuring robust\nperformance even with minimal packet availability.",
    "categories": [
      "cs.CR"
    ],
    "published": "2025-03-21T04:36:51+00:00",
    "updated": "2025-03-21T04:36:51+00:00",
    "url": "http://arxiv.org/pdf/2503.16847v1"
  },
  {
    "id": "2503.16233v2",
    "title": "Empirical Analysis of Privacy-Fairness-Accuracy Trade-offs in Federated Learning: A Step Towards Responsible AI",
    "authors": [
      "Dawood Wasif",
      "Dian Chen",
      "Sindhuja Madabushi",
      "Nithin Alluru",
      "Terrence J. Moore",
      "Jin-Hee Cho"
    ],
    "abstract": "Federated Learning (FL) enables collaborative model training while preserving\ndata privacy; however, balancing privacy preservation (PP) and fairness poses\nsignificant challenges. In this paper, we present the first unified large-scale\nempirical study of privacy-fairness-utility trade-offs in FL, advancing toward\nresponsible AI deployment. Specifically, we systematically compare Differential\nPrivacy (DP), Homomorphic Encryption (HE), and Secure Multi-Party Computation\n(SMC) with fairness-aware optimizers including q-FedAvg, q-MAML, Ditto,\nevaluating their performance under IID and non-IID scenarios using benchmark\n(MNIST, Fashion-MNIST) and real-world datasets (Alzheimer's MRI, credit-card\nfraud detection). Our analysis reveals HE and SMC significantly outperform DP\nin achieving equitable outcomes under data skew, although at higher\ncomputational costs. Remarkably, we uncover unexpected interactions: DP\nmechanisms can negatively impact fairness, and fairness-aware optimizers can\ninadvertently reduce privacy effectiveness. We conclude with practical\nguidelines for designing robust FL systems that deliver equitable,\nprivacy-preserving, and accurate outcomes.",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.DC",
      "cs.ET"
    ],
    "published": "2025-03-20T15:31:01+00:00",
    "updated": "2025-08-09T23:41:23+00:00",
    "url": "http://arxiv.org/pdf/2503.16233v2"
  },
  {
    "id": "2503.15896v2",
    "title": "FlowSeries: Anomaly Detection in Financial Transaction Flows",
    "authors": [
      "Arthur Capozzi",
      "Salvatore Vilella",
      "Dario Moncalvo",
      "Marco Fornasiero",
      "Valeria Ricci",
      "Silvia Ronchiadin",
      "Giancarlo Ruffo"
    ],
    "abstract": "In recent years, the digitization and automation of anti-financial crime\n(AFC) investigative processes have faced significant challenges, particularly\nthe need for interpretability of AI model results and the lack of labeled data\nfor training. Network analysis has emerged as a valuable approach in this\ncontext.\n  In this paper, we present WeirdFlows, a top-down search pipeline for\ndetecting potentially fraudulent transactions and non-compliant agents. In a\ntransaction network, fraud attempts are often based on complex transaction\npatterns that change over time to avoid detection. The WeirdFlows pipeline\nrequires neither an a priori set of patterns nor a training set. In addition,\nby providing elements to explain the anomalies found, it facilitates and\nsupports the work of an AFC analyst.\n  We evaluate WeirdFlows on a dataset from Intesa Sanpaolo (ISP) bank,\ncomprising 80 million cross-country transactions over 15 months, benchmarking\nour implementation of the algorithm. The results, corroborated by ISP AFC\nexperts, highlight its effectiveness in identifying suspicious transactions and\nactors, particularly in the context of the economic sanctions imposed in the EU\nafter February 2022. This demonstrates \\textit{WeirdFlows}' capability to\nhandle large datasets, detect complex transaction patterns, and provide the\nnecessary interpretability for formal AFC investigations.",
    "categories": [
      "cs.CY",
      "cs.CE",
      "I.2.1; H.3.3"
    ],
    "published": "2025-03-20T06:49:33+00:00",
    "updated": "2025-04-01T16:23:27+00:00",
    "url": "http://arxiv.org/pdf/2503.15896v2"
  },
  {
    "id": "2503.14421v1",
    "title": "ExDDV: A New Dataset for Explainable Deepfake Detection in Video",
    "authors": [
      "Vlad Hondru",
      "Eduard Hogea",
      "Darian Onchis",
      "Radu Tudor Ionescu"
    ],
    "abstract": "The ever growing realism and quality of generated videos makes it\nincreasingly harder for humans to spot deepfake content, who need to rely more\nand more on automatic deepfake detectors. However, deepfake detectors are also\nprone to errors, and their decisions are not explainable, leaving humans\nvulnerable to deepfake-based fraud and misinformation. To this end, we\nintroduce ExDDV, the first dataset and benchmark for Explainable Deepfake\nDetection in Video. ExDDV comprises around 5.4K real and deepfake videos that\nare manually annotated with text descriptions (to explain the artifacts) and\nclicks (to point out the artifacts). We evaluate a number of vision-language\nmodels on ExDDV, performing experiments with various fine-tuning and in-context\nlearning strategies. Our results show that text and click supervision are both\nrequired to develop robust explainable models for deepfake videos, which are\nable to localize and describe the observed artifacts. Our novel dataset and\ncode to reproduce the results are available at\nhttps://github.com/vladhondru25/ExDDV.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM"
    ],
    "published": "2025-03-18T16:55:07+00:00",
    "updated": "2025-03-18T16:55:07+00:00",
    "url": "http://arxiv.org/pdf/2503.14421v1"
  },
  {
    "id": "2503.13923v1",
    "title": "ConSCompF: Consistency-focused Similarity Comparison Framework for Generative Large Language Models",
    "authors": [
      "Alexey Karev",
      "Dong Xu"
    ],
    "abstract": "Large language models (LLMs) have been one of the most important discoveries\nin machine learning in recent years. LLM-based artificial intelligence (AI)\nassistants, such as ChatGPT, have consistently attracted the attention from\nresearchers, investors, and the general public, driving the rapid growth of\nthis industry. With the frequent introduction of new LLMs to the market, it\nbecomes increasingly difficult to differentiate between them, creating a demand\nfor new LLM comparison methods.\n  In this research, the Consistency-focused Similarity Comparison Framework\n(ConSCompF) for generative large language models is proposed. It compares texts\ngenerated by two LLMs and produces a similarity score, indicating the overall\ndegree of similarity between their responses. The main advantage of this\nframework is that it can operate on a small number of unlabeled data, such as\nchatbot instruction prompts, and does not require LLM developers to disclose\nany information about their product.\n  To evaluate the efficacy of ConSCompF, two experiments aimed at identifying\nsimilarities between multiple LLMs are conducted. Additionally, these\nexperiments examine the correlation between the similarity scores generated by\nConSCompF and the differences in the outputs produced by other benchmarking\ntechniques, such as ROUGE-L. Finally, a series of few-shot LLM comparison\nexperiments is conducted to evaluate the performance of ConSCompF in a few-shot\nLLM comparison scenario.\n  The proposed framework can be used for calculating similarity matrices of\nmultiple LLMs, which can be effectively visualized using principal component\nanalysis (PCA). The ConSCompF output may provide useful insights into data that\nmight have been used during LLM training and help detect possible investment\nfraud attempts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-03-18T05:38:04+00:00",
    "updated": "2025-03-18T05:38:04+00:00",
    "url": "http://arxiv.org/pdf/2503.13923v1"
  },
  {
    "id": "2503.14541v1",
    "title": "Regulating Ai In Financial Services: Legal Frameworks And Compliance Challenges",
    "authors": [
      "Shahmar Mirishli"
    ],
    "abstract": "This article examines the evolving landscape of artificial intelligence (AI)\nregulation in financial services, detailing the legal frameworks and compliance\nchallenges posed by rapid technological adoption. By reviewing current\nlegislation, industry guidelines, and real-world use cases, it highlights how\nAI-driven processes, from fraud detection to algorithmic trading, offer\nefficiency gains yet introduce significant risks, including algorithmic bias,\ndata privacy breaches, and lack of transparency in automated decision-making.\nThe study compares regulatory approaches across major jurisdictions such as the\nEuropean Union, United States, and United Kingdom, identifying both universal\nconcerns, like the need for explainability and robust data protection, and\nregion-specific compliance requirements that impact the implementation of\nhigh-risk AI applications. Additionally, it underscores emerging areas of\nfocus, such as liability for AI-driven errors, systemic risks posed by\ninterlinked AI systems, and the ethical considerations of technology-driven\nfinancial exclusion. The findings reveal gaps in existing rules and emphasize\nthe necessity for adaptive, technology-neutral policies capable of fostering\ninnovation while safeguarding consumer rights and market integrity. The article\nconcludes by proposing a principled regulatory model that balances flexibility\nwith enforceable standards, advocating closer collaboration between\npolicymakers, financial institutions, and AI developers to ensure a secure,\nfair, and forward-looking framework for AI in finance.",
    "categories": [
      "cs.CY",
      "q-fin.GN"
    ],
    "published": "2025-03-17T14:29:09+00:00",
    "updated": "2025-03-17T14:29:09+00:00",
    "url": "http://arxiv.org/pdf/2503.14541v1"
  },
  {
    "id": "2503.13195v1",
    "title": "Deep Learning Advancements in Anomaly Detection: A Comprehensive Survey",
    "authors": [
      "Haoqi Huang",
      "Ping Wang",
      "Jianhua Pei",
      "Jiacheng Wang",
      "Shahen Alexanian",
      "Dusit Niyato"
    ],
    "abstract": "The rapid expansion of data from diverse sources has made anomaly detection\n(AD) increasingly essential for identifying unexpected observations that may\nsignal system failures, security breaches, or fraud. As datasets become more\ncomplex and high-dimensional, traditional detection methods struggle to\neffectively capture intricate patterns. Advances in deep learning have made AD\nmethods more powerful and adaptable, improving their ability to handle\nhigh-dimensional and unstructured data. This survey provides a comprehensive\nreview of over 180 recent studies, focusing on deep learning-based AD\ntechniques. We categorize and analyze these methods into reconstruction-based\nand prediction-based approaches, highlighting their effectiveness in modeling\ncomplex data distributions. Additionally, we explore the integration of\ntraditional and deep learning methods, highlighting how hybrid approaches\ncombine the interpretability of traditional techniques with the flexibility of\ndeep learning to enhance detection accuracy and model transparency. Finally, we\nidentify open issues and propose future research directions to advance the\nfield of AD. This review bridges gaps in existing literature and serves as a\nvaluable resource for researchers and practitioners seeking to enhance AD\ntechniques using deep learning.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-03-17T14:04:48+00:00",
    "updated": "2025-03-17T14:04:48+00:00",
    "url": "http://arxiv.org/pdf/2503.13195v1"
  },
  {
    "id": "2503.15546v1",
    "title": "Enforcing Cybersecurity Constraints for LLM-driven Robot Agents for Online Transactions",
    "authors": [
      "Shraddha Pradipbhai Shah",
      "Aditya Vilas Deshpande"
    ],
    "abstract": "The integration of Large Language Models (LLMs) into autonomous robotic\nagents for conducting online transactions poses significant cybersecurity\nchallenges. This study aims to enforce robust cybersecurity constraints to\nmitigate the risks associated with data breaches, transaction fraud, and system\nmanipulation. The background focuses on the rise of LLM-driven robotic systems\nin e-commerce, finance, and service industries, alongside the vulnerabilities\nthey introduce. A novel security architecture combining blockchain technology\nwith multi-factor authentication (MFA) and real-time anomaly detection was\nimplemented to safeguard transactions. Key performance metrics such as\ntransaction integrity, response time, and breach detection accuracy were\nevaluated, showing improved security and system performance. The results\nhighlight that the proposed architecture reduced fraudulent transactions by\n90%, improved breach detection accuracy to 98%, and ensured secure transaction\nvalidation within a latency of 0.05 seconds. These findings emphasize the\nimportance of cybersecurity in the deployment of LLM-driven robotic systems and\nsuggest a framework adaptable to various online platforms.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-03-17T01:01:10+00:00",
    "updated": "2025-03-17T01:01:10+00:00",
    "url": "http://arxiv.org/pdf/2503.15546v1"
  },
  {
    "id": "2505.10050v1",
    "title": "Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods",
    "authors": [
      "Fahad Almalki",
      "Mehedi Masud"
    ],
    "abstract": "Traditional machine learning models often prioritize predictive accuracy,\noften at the expense of model transparency and interpretability. The lack of\ntransparency makes it difficult for organizations to comply with regulatory\nrequirements and gain stakeholders trust. In this research, we propose a fraud\ndetection framework that combines a stacking ensemble of well-known gradient\nboosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable\nartificial intelligence (XAI) techniques are used to enhance the transparency\nand interpretability of the model's decisions. We used SHAP (SHapley Additive\nExplanations) for feature selection to identify the most important features.\nFurther efforts were made to explain the model's predictions using Local\nInterpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots\n(PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection\ndataset, which includes more than 590,000 real transaction records, was used to\nevaluate the proposed model. The model achieved a high performance with an\naccuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent\nrelated approaches. These results indicate that combining high prediction\naccuracy with transparent interpretability is possible and could lead to a more\nethical and trustworthy solution in financial fraud detection.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-05-15T07:53:02+00:00",
    "updated": "2025-05-15T07:53:02+00:00",
    "url": "http://arxiv.org/pdf/2505.10050v1"
  },
  {
    "id": "2505.09593v1",
    "title": "Online Isolation Forest",
    "authors": [
      "Filippo Leveni",
      "Guilherme Weigert Cassales",
      "Bernhard Pfahringer",
      "Albert Bifet",
      "Giacomo Boracchi"
    ],
    "abstract": "The anomaly detection literature is abundant with offline methods, which\nrequire repeated access to data in memory, and impose impractical assumptions\nwhen applied to a streaming context. Existing online anomaly detection methods\nalso generally fail to address these constraints, resorting to periodic\nretraining to adapt to the online context. We propose Online-iForest, a novel\nmethod explicitly designed for streaming conditions that seamlessly tracks the\ndata generating process as it evolves over time. Experimental validation on\nreal-world datasets demonstrated that Online-iForest is on par with online\nalternatives and closely rivals state-of-the-art offline anomaly detection\ntechniques that undergo periodic retraining. Notably, Online-iForest\nconsistently outperforms all competitors in terms of efficiency, making it a\npromising solution in applications where fast identification of anomalies is of\nprimary importance such as cybersecurity, fraud and fault detection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-05-14T17:42:50+00:00",
    "updated": "2025-05-14T17:42:50+00:00",
    "url": "http://arxiv.org/pdf/2505.09593v1"
  },
  {
    "id": "2505.06766v1",
    "title": "Beyond Identity: A Generalizable Approach for Deepfake Audio Detection",
    "authors": [
      "Yasaman Ahmadiadli",
      "Xiao-Ping Zhang",
      "Naimul Khan"
    ],
    "abstract": "Deepfake audio presents a growing threat to digital security, due to its\npotential for social engineering, fraud, and identity misuse. However, existing\ndetection models suffer from poor generalization across datasets, due to\nimplicit identity leakage, where models inadvertently learn speaker-specific\nfeatures instead of manipulation artifacts. To the best of our knowledge, this\nis the first study to explicitly analyze and address identity leakage in the\naudio deepfake detection domain. This work proposes an identity-independent\naudio deepfake detection framework that mitigates identity leakage by\nencouraging the model to focus on forgery-specific artifacts instead of\noverfitting to speaker traits. Our approach leverages Artifact Detection\nModules (ADMs) to isolate synthetic artifacts in both time and frequency\ndomains, enhancing cross-dataset generalization. We introduce novel dynamic\nartifact generation techniques, including frequency domain swaps, time domain\nmanipulations, and background noise augmentation, to enforce learning of\ndataset-invariant features. Extensive experiments conducted on ASVspoof2019,\nADD 2022, FoR, and In-The-Wild datasets demonstrate that the proposed\nADM-enhanced models achieve F1 scores of 0.230 (ADD 2022), 0.604 (FoR), and\n0.813 (In-The-Wild), consistently outperforming the baseline. Dynamic Frequency\nSwap proves to be the most effective strategy across diverse conditions. These\nfindings emphasize the value of artifact-based learning in mitigating implicit\nidentity leakage for more generalizable audio deepfake detection.",
    "categories": [
      "cs.SD",
      "eess.AS",
      "eess.SP"
    ],
    "published": "2025-05-10T22:03:07+00:00",
    "updated": "2025-05-10T22:03:07+00:00",
    "url": "http://arxiv.org/pdf/2505.06766v1"
  },
  {
    "id": "2505.05897v1",
    "title": "Exploring the Susceptibility to Fraud of Monetary Incentive Mechanisms for Strengthening FOSS Projects",
    "authors": [
      "Ben Swierzy",
      "Timo Pohl",
      "Marc Ohm",
      "Michael Meier"
    ],
    "abstract": "Free and open source software (FOSS) is ubiquitous on modern IT systems,\naccelerating the speed of software engineering over the past decades. With its\nincreasing importance and historical reliance on uncompensated contributions,\nquestions have been raised regarding the continuous maintenance of FOSS and its\nimplications from a security perspective. In recent years, different funding\nprograms have emerged to provide external incentives to reinforce community\nFOSS' sustainability. Past research primarily focused on analyses what type of\nprojects have been funded and for what reasons. However, it has neither been\nconsidered whether there is a need for such external incentives, nor whether\nthe incentive mechanisms, especially with the development of decentralized\napproaches, are susceptible to fraud. In this study, we explore the need for\nfunding through a literature review and compare the susceptibility to fraud of\ncentralized and decentralized incentive programs by performing case studies on\nthe Sovereign Tech Fund (STF) and the tea project. We find non-commercial\nincentives to fill an important gap, ensuring longevity and sustainability of\nprojects. Furthermore, we find the STF to be able to achieve a high resilience\nagainst fraud attempts, while tea is highly susceptible to fraud, as evidenced\nby revelation of an associated sybil attack on npm. Our results imply that\nspecial considerations must be taken into account when utilizing quantitative\nrepository metrics regardless whether spoofing is expected.",
    "categories": [
      "cs.CR",
      "cs.SE"
    ],
    "published": "2025-05-09T09:05:38+00:00",
    "updated": "2025-05-09T09:05:38+00:00",
    "url": "http://arxiv.org/pdf/2505.05897v1"
  },
  {
    "id": "2505.07852v1",
    "title": "Joint Detection of Fraud and Concept Drift inOnline Conversations with LLM-Assisted Judgment",
    "authors": [
      "Ali Senol",
      "Garima Agrawal",
      "Huan Liu"
    ],
    "abstract": "Detecting fake interactions in digital communication platforms remains a\nchallenging and insufficiently addressed problem. These interactions may appear\nas harmless spam or escalate into sophisticated scam attempts, making it\ndifficult to flag malicious intent early. Traditional detection methods often\nrely on static anomaly detection techniques that fail to adapt to dynamic\nconversational shifts. One key limitation is the misinterpretation of benign\ntopic transitions referred to as concept drift as fraudulent behavior, leading\nto either false alarms or missed threats. We propose a two stage detection\nframework that first identifies suspicious conversations using a tailored\nensemble classification model. To improve the reliability of detection, we\nincorporate a concept drift analysis step using a One Class Drift Detector\n(OCDD) to isolate conversational shifts within flagged dialogues. When drift is\ndetected, a large language model (LLM) assesses whether the shift indicates\nfraudulent manipulation or a legitimate topic change. In cases where no drift\nis found, the behavior is inferred to be spam like. We validate our framework\nusing a dataset of social engineering chat scenarios and demonstrate its\npractical advantages in improving both accuracy and interpretability for real\ntime fraud detection. To contextualize the trade offs, we compare our modular\napproach against a Dual LLM baseline that performs detection and judgment using\ndifferent language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-05-07T22:30:53+00:00",
    "updated": "2025-05-07T22:30:53+00:00",
    "url": "http://arxiv.org/pdf/2505.07852v1"
  },
  {
    "id": "2505.04403v1",
    "title": "Blockchain Data Analytics: A Scoping Literature Review and Directions for Future Research",
    "authors": [
      "Marcel Bühlmann",
      "Hans-Georg Fill",
      "Simon Curty"
    ],
    "abstract": "Blockchain technology has rapidly expanded beyond its original use in\ncryptocurrencies to a broad range of applications, creating vast amounts of\nimmutable, decentralized data. As blockchain adoption grows, so does the need\nfor advanced data analytics techniques to extract insights for business\nintelligence, fraud detection, financial analysis and many more. While previous\nresearch has examined specific aspects of blockchain data analytics, such as\ntransaction patterns, illegal activity detection, and data management, there\nremains a lack of comprehensive reviews that explore the full scope of\nblockchain data analytics. This study addresses this gap through a scoping\nliterature review, systematically mapping the existing research landscape,\nidentifying key topics, and highlighting emerging trends. Using established\nmethodologies for literature reviews, we analyze 466 publications, clustering\nthem into six major research themes: illegal activity detection, data\nmanagement, financial analysis, user analysis, community detection, and mining\nanalysis. Our findings reveal a strong focus on detecting illicit activities\nand financial applications, while holistic business intelligence use cases\nremain underexplored. This review provides a structured overview of blockchain\ndata analytics, identifying research gaps and proposing future directions to\nenhance the fields impact.",
    "categories": [
      "cs.ET"
    ],
    "published": "2025-05-07T13:36:43+00:00",
    "updated": "2025-05-07T13:36:43+00:00",
    "url": "http://arxiv.org/pdf/2505.04403v1"
  },
  {
    "id": "2505.04204v1",
    "title": "Cyber Security Data Science: Machine Learning Methods and their Performance on Imbalanced Datasets",
    "authors": [
      "Mateo Lopez-Ledezma",
      "Gissel Velarde"
    ],
    "abstract": "Cybersecurity has become essential worldwide and at all levels, concerning\nindividuals, institutions, and governments. A basic principle in cybersecurity\nis to be always alert. Therefore, automation is imperative in processes where\nthe volume of daily operations is large. Several cybersecurity applications can\nbe addressed as binary classification problems, including anomaly detection,\nfraud detection, intrusion detection, spam detection, or malware detection. We\npresent three experiments. In the first experiment, we evaluate single\nclassifiers including Random Forests, Light Gradient Boosting Machine, eXtreme\nGradient Boosting, Logistic Regression, Decision Tree, and Gradient Boosting\nDecision Tree. In the second experiment, we test different sampling techniques\nincluding over-sampling, under-sampling, Synthetic Minority Over-sampling\nTechnique, and Self-Paced Ensembling. In the last experiment, we evaluate\nSelf-Paced Ensembling and its number of base classifiers. We found that\nimbalance learning techniques had positive and negative effects, as reported in\nrelated studies. Thus, these techniques should be applied with caution.\nBesides, we found different best performers for each dataset. Therefore, we\nrecommend testing single classifiers and imbalance learning techniques for each\nnew dataset and application involving imbalanced datasets as is the case in\nseveral cyber security applications.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-05-07T07:57:33+00:00",
    "updated": "2025-05-07T07:57:33+00:00",
    "url": "http://arxiv.org/pdf/2505.04204v1"
  },
  {
    "id": "2505.02791v1",
    "title": "Scoring the European Citizen in the AI Era",
    "authors": [
      "Nathan Genicot"
    ],
    "abstract": "Social scoring is one of the AI practices banned by the AI Act. This ban is\nexplicitly inspired by China, which in 2014 announced its intention to set up a\nlarge-scale government project - the Social Credit System - aiming to rate\nevery Chinese citizen according to their good behaviour, using digital\ntechnologies and AI. But in Europe, individuals are also scored by public and\nprivate bodies in a variety of contexts, such as assessing creditworthiness,\nmonitoring employee productivity, detecting social fraud or terrorist risks,\nand so on. However, the AI Act does not intend to prohibit these types of\nscoring, as they would qualify as 'high-risk AI systems', which are authorised\nwhile subject to various requirements. One might therefore think that the ban\non social scoring will have no practical effect on the scoring practices\nalready in use in Europe, and that it is merely a vague safeguard in case an\nauthoritarian power is tempted to set up such a system on European territory.\nContrary to this view, this article argues that the ban has been drafted in a\nway that is flexible and therefore likely to make it a useful tool, similar and\ncomplementary to Article 22 of the General Data Protection Regulation, to\nprotect individuals against certain forms of disproportionate use of AI-based\nscoring.",
    "categories": [
      "cs.CY"
    ],
    "published": "2025-05-05T17:04:25+00:00",
    "updated": "2025-05-05T17:04:25+00:00",
    "url": "http://arxiv.org/pdf/2505.02791v1"
  },
  {
    "id": "2505.01735v1",
    "title": "Brain-Inspired Quantum Neural Architectures for Pattern Recognition: Integrating QSNN and QLSTM",
    "authors": [
      "Eva Andrés",
      "Manuel Pegalajar Cuéllar",
      "Gabriel Navarro"
    ],
    "abstract": "Recent advances in the fields of deep learning and quantum computing have\npaved the way for innovative developments in artificial intelligence. In this\nmanuscript, we leverage these cutting-edge technologies to introduce a novel\nmodel that emulates the intricate functioning of the human brain, designed\nspecifically for the detection of anomalies such as fraud in credit card\ntransactions. Leveraging the synergies of Quantum Spiking Neural Networks\n(QSNN) and Quantum Long Short-Term Memory (QLSTM) architectures, our approach\nis developed in two distinct stages, closely mirroring the information\nprocessing mechanisms found in the brain's sensory and memory systems. In the\ninitial stage, similar to the brain's hypothalamus, we extract low-level\ninformation from the data, emulating sensory data processing patterns. In the\nsubsequent stage, resembling the hippocampus, we process this information at a\nhigher level, capturing and memorizing correlated patterns. We will compare\nthis model with other quantum models such as Quantum Neural Networks among\nothers and their corresponding classical models.",
    "categories": [
      "cs.ET"
    ],
    "published": "2025-05-03T08:18:05+00:00",
    "updated": "2025-05-03T08:18:05+00:00",
    "url": "http://arxiv.org/pdf/2505.01735v1"
  },
  {
    "id": "2505.01008v2",
    "title": "Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content",
    "authors": [
      "Haoyue Bai",
      "Yiyou Sun",
      "Wei Cheng",
      "Haifeng Chen"
    ],
    "abstract": "The recent proliferation of photorealistic images created by generative\nmodels has sparked both excitement and concern, as these images are\nincreasingly indistinguishable from real ones to the human eye. While offering\nnew creative and commercial possibilities, the potential for misuse, such as in\nmisinformation and fraud, highlights the need for effective detection methods.\nCurrent detection approaches often rely on access to model weights or require\nextensive collections of real image datasets, limiting their scalability and\npractical application in real world scenarios. In this work, we introduce a\nnovel black box detection framework that requires only API access, sidestepping\nthe need for model weights or large auxiliary datasets. Our approach leverages\na corrupt and recover strategy: by masking part of an image and assessing the\nmodel ability to reconstruct it, we measure the likelihood that the image was\ngenerated by the model itself. For black-box models that do not support masked\nimage inputs, we incorporate a cost efficient surrogate model trained to align\nwith the target model distribution, enhancing detection capability. Our\nframework demonstrates strong performance, outperforming baseline methods by\n4.31% in mean average precision across eight diffusion model variant datasets.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-05-02T05:11:35+00:00",
    "updated": "2025-08-25T07:18:26+00:00",
    "url": "http://arxiv.org/pdf/2505.01008v2"
  },
  {
    "id": "2505.00946v1",
    "title": "Addressing Noise and Stochasticity in Fraud Detection for Service Networks",
    "authors": [
      "Wenxin Zhang",
      "Ding Xu",
      "Xi Xuan",
      "Lei Jiang",
      "Guangzhen Yao",
      "Renda Han",
      "Xiangxiang Lang",
      "Cuicui Luo"
    ],
    "abstract": "Fraud detection is crucial in social service networks to maintain user trust\nand improve service network security. Existing spectral graph-based methods\naddress this challenge by leveraging different graph filters to capture signals\nwith different frequencies in service networks. However, most graph\nfilter-based methods struggle with deriving clean and discriminative graph\nsignals. On the one hand, they overlook the noise in the information\npropagation process, resulting in degradation of filtering ability. On the\nother hand, they fail to discriminate the frequency-specific characteristics of\ngraph signals, leading to distortion of signals fusion. To address these\nissues, we develop a novel spectral graph network based on information\nbottleneck theory (SGNN-IB) for fraud detection in service networks. SGNN-IB\nsplits the original graph into homophilic and heterophilic subgraphs to better\ncapture the signals at different frequencies. For the first limitation, SGNN-IB\napplies information bottleneck theory to extract key characteristics of encoded\nrepresentations. For the second limitation, SGNN-IB introduces prototype\nlearning to implement signal fusion, preserving the frequency-specific\ncharacteristics of signals. Extensive experiments on three real-world datasets\ndemonstrate that SGNN-IB outperforms state-of-the-art fraud detection methods.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2025-05-02T01:17:03+00:00",
    "updated": "2025-05-02T01:17:03+00:00",
    "url": "http://arxiv.org/pdf/2505.00946v1"
  },
  {
    "id": "2505.00137v1",
    "title": "Toward Practical Quantum Machine Learning: A Novel Hybrid Quantum LSTM for Fraud Detection",
    "authors": [
      "Rushikesh Ubale",
      "Sujan K. K.",
      "Sangram Deshpande",
      "Gregory T. Byrd"
    ],
    "abstract": "We present a novel hybrid quantum-classical neural network architecture for\nfraud detection that integrates a classical Long Short-Term Memory (LSTM)\nnetwork with a variational quantum circuit. By leveraging quantum phenomena\nsuch as superposition and entanglement, our model enhances the feature\nrepresentation of sequential transaction data, capturing complex non-linear\npatterns that are challenging for purely classical models. A comprehensive data\npreprocessing pipeline is employed to clean, encode, balance, and normalize a\ncredit card fraud dataset, ensuring a fair comparison with baseline models.\nNotably, our hybrid approach achieves per-epoch training times in the range of\n45-65 seconds, which is significantly faster than similar architectures\nreported in the literature, where training typically requires several minutes\nper epoch. Both classical and quantum gradients are jointly optimized via a\nunified backpropagation procedure employing the parameter-shift rule for the\nquantum parameters. Experimental evaluations demonstrate competitive\nimprovements in accuracy, precision, recall, and F1 score relative to a\nconventional LSTM baseline. These results underscore the promise of hybrid\nquantum-classical techniques in advancing the efficiency and performance of\nfraud detection systems.\n  Keywords: Hybrid Quantum-Classical Neural Networks, Quantum Computing, Fraud\nDetection, Hybrid Quantum LSTM, Variational Quantum Circuit, Parameter-Shift\nRule, Financial Risk Analysis",
    "categories": [
      "quant-ph",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "published": "2025-04-30T19:09:12+00:00",
    "updated": "2025-04-30T19:09:12+00:00",
    "url": "http://arxiv.org/pdf/2505.00137v1"
  },
  {
    "id": "2504.21574v1",
    "title": "Generative AI in Financial Institution: A Global Survey of Opportunities, Threats, and Regulation",
    "authors": [
      "Bikash Saha",
      "Nanda Rani",
      "Sandeep Kumar Shukla"
    ],
    "abstract": "Generative Artificial Intelligence (GenAI) is rapidly reshaping the global\nfinancial landscape, offering unprecedented opportunities to enhance customer\nengagement, automate complex workflows, and extract actionable insights from\nvast financial data. This survey provides an overview of GenAI adoption across\nthe financial ecosystem, examining how banks, insurers, asset managers, and\nfintech startups worldwide are integrating large language models and other\ngenerative tools into their operations. From AI-powered virtual assistants and\npersonalized financial advisory to fraud detection and compliance automation,\nGenAI is driving innovation across functions. However, this transformation\ncomes with significant cybersecurity and ethical risks. We discuss emerging\nthreats such as AI-generated phishing, deepfake-enabled fraud, and adversarial\nattacks on AI systems, as well as concerns around bias, opacity, and data\nmisuse. The evolving global regulatory landscape is explored in depth,\nincluding initiatives by major financial regulators and international efforts\nto develop risk-based AI governance. Finally, we propose best practices for\nsecure and responsible adoption - including explainability techniques,\nadversarial testing, auditability, and human oversight. Drawing from academic\nliterature, industry case studies, and policy frameworks, this chapter offers a\nperspective on how the financial sector can harness GenAI's transformative\npotential while navigating the complex risks it introduces.",
    "categories": [
      "cs.CR",
      "cs.CE"
    ],
    "published": "2025-04-30T12:25:30+00:00",
    "updated": "2025-04-30T12:25:30+00:00",
    "url": "http://arxiv.org/pdf/2504.21574v1"
  },
  {
    "id": "2504.19632v1",
    "title": "QFDNN: A Resource-Efficient Variational Quantum Feature Deep Neural Networks for Fraud Detection and Loan Prediction",
    "authors": [
      "Subham Das",
      "Ashtakala Meghanath",
      "Bikash K. Behera",
      "Shahid Mumtaz",
      "Saif Al-Kuwari",
      "Ahmed Farouk"
    ],
    "abstract": "Social financial technology focuses on trust, sustainability, and social\nresponsibility, which require advanced technologies to address complex\nfinancial tasks in the digital era. With the rapid growth in online\ntransactions, automating credit card fraud detection and loan eligibility\nprediction has become increasingly challenging. Classical machine learning (ML)\nmodels have been used to solve these challenges; however, these approaches\noften encounter scalability, overfitting, and high computational costs due to\ncomplexity and high-dimensional financial data. Quantum computing (QC) and\nquantum machine learning (QML) provide a promising solution to efficiently\nprocessing high-dimensional datasets and enabling real-time identification of\nsubtle fraud patterns. However, existing quantum algorithms lack robustness in\nnoisy environments and fail to optimize performance with reduced feature sets.\nTo address these limitations, we propose a quantum feature deep neural network\n(QFDNN), a novel, resource efficient, and noise-resilient quantum model that\noptimizes feature representation while requiring fewer qubits and simpler\nvariational circuits. The model is evaluated using credit card fraud detection\nand loan eligibility prediction datasets, achieving competitive accuracies of\n82.2% and 74.4%, respectively, with reduced computational overhead.\nFurthermore, we test QFDNN against six noise models, demonstrating its\nrobustness across various error conditions. Our findings highlight QFDNN\npotential to enhance trust and security in social financial technology by\naccurately detecting fraudulent transactions while supporting sustainability\nthrough its resource-efficient design and minimal computational overhead.",
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "published": "2025-04-28T09:47:28+00:00",
    "updated": "2025-04-28T09:47:28+00:00",
    "url": "http://arxiv.org/pdf/2504.19632v1"
  },
  {
    "id": "2504.18785v2",
    "title": "ALF: Advertiser Large Foundation Model for Multi-Modal Advertiser Understanding",
    "authors": [
      "Santosh Rajagopalan",
      "Jonathan Vronsky",
      "Songbai Yan",
      "S. Alireza Golestaneh",
      "Shubhra Chandra",
      "Min Zhou"
    ],
    "abstract": "We present ALF (Advertiser Large Foundation model), a multi-modal transformer\narchitecture for understanding advertiser behavior and intent across text,\nimage, video, and structured data modalities. Through contrastive learning and\nmulti-task optimization, ALF creates unified advertiser representations that\ncapture both content and behavioral patterns. Our model achieves\nstate-of-the-art performance on critical tasks including fraud detection,\npolicy violation identification, and advertiser similarity matching. In\nproduction deployment, ALF demonstrates significant real-world impact by\ndelivering simultaneous gains in both precision and recall, for instance\nboosting recall by over 40 percentage points on one critical policy and\nincreasing precision to 99.8% on another. The architecture's effectiveness\nstems from its novel combination of multi-modal transformations, inter-sample\nattention mechanism, spectrally normalized projections, and calibrated\nprobabilistic outputs.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-04-26T03:33:42+00:00",
    "updated": "2025-09-05T00:45:08+00:00",
    "url": "http://arxiv.org/pdf/2504.18785v2"
  },
  {
    "id": "2504.18771v1",
    "title": "Performance of Machine Learning Classifiers for Anomaly Detection in Cyber Security Applications",
    "authors": [
      "Markus Haug",
      "Gissel Velarde"
    ],
    "abstract": "This work empirically evaluates machine learning models on two imbalanced\npublic datasets (KDDCUP99 and Credit Card Fraud 2013). The method includes data\npreparation, model training, and evaluation, using an 80/20 (train/test) split.\nModels tested include eXtreme Gradient Boosting (XGB), Multi Layer Perceptron\n(MLP), Generative Adversarial Network (GAN), Variational Autoencoder (VAE), and\nMultiple-Objective Generative Adversarial Active Learning (MO-GAAL), with XGB\nand MLP further combined with Random-Over-Sampling (ROS) and\nSelf-Paced-Ensemble (SPE). Evaluation involves 5-fold cross-validation and\nimputation techniques (mean, median, and IterativeImputer) with 10, 20, 30, and\n50 % missing data. Findings show XGB and MLP outperform generative models.\nIterativeImputer results are comparable to mean and median, but not recommended\nfor large datasets due to increased complexity and execution time. The code\nused is publicly available on GitHub (github.com/markushaug/acr-25).",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2025-04-26T02:43:27+00:00",
    "updated": "2025-04-26T02:43:27+00:00",
    "url": "http://arxiv.org/pdf/2504.18771v1"
  },
  {
    "id": "2504.17641v2",
    "title": "PTCL: Pseudo-Label Temporal Curriculum Learning for Label-Limited Dynamic Graph",
    "authors": [
      "Shengtao Zhang",
      "Haokai Zhang",
      "Shiqi Lou",
      "Zicheng Wang",
      "Zinan Zeng",
      "Yilin Wang",
      "Minnan Luo"
    ],
    "abstract": "Dynamic node classification is critical for modeling evolving systems like\nfinancial transactions and academic collaborations. In such systems,\ndynamically capturing node information changes is critical for dynamic node\nclassification, which usually requires all labels at every timestamp. However,\nit is difficult to collect all dynamic labels in real-world scenarios due to\nhigh annotation costs and label uncertainty (e.g., ambiguous or delayed labels\nin fraud detection). In contrast, final timestamp labels are easier to obtain\nas they rely on complete temporal patterns and are usually maintained as a\nunique label for each user in many open platforms, without tracking the history\ndata. To bridge this gap, we propose PTCL(Pseudo-label Temporal Curriculum\nLearning), a pioneering method addressing label-limited dynamic node\nclassification where only final labels are available. PTCL introduces: (1) a\ntemporal decoupling architecture separating the backbone (learning time-aware\nrepresentations) and decoder (strictly aligned with final labels), which\ngenerate pseudo-labels, and (2) a Temporal Curriculum Learning strategy that\nprioritizes pseudo-labels closer to the final timestamp by assigning them\nhigher weights using an exponentially decaying function. We contribute a new\nacademic dataset (CoOAG), capturing long-range research interest in dynamic\ngraph. Experiments across real-world scenarios demonstrate PTCL's consistent\nsuperiority over other methods adapted to this task. Beyond methodology, we\npropose a unified framework FLiD (Framework for Label-Limited Dynamic Node\nClassification), consisting of a complete preparation workflow, training\npipeline, and evaluation standards, and supporting various models and datasets.\nThe code can be found at https://github.com/3205914485/FLiD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-04-24T15:11:41+00:00",
    "updated": "2025-04-25T03:38:56+00:00",
    "url": "http://arxiv.org/pdf/2504.17641v2"
  },
  {
    "id": "2504.15491v1",
    "title": "Application of Deep Generative Models for Anomaly Detection in Complex Financial Transactions",
    "authors": [
      "Tengda Tang",
      "Jianhua Yao",
      "Yixian Wang",
      "Qiuwu Sha",
      "Hanrui Feng",
      "Zhen Xu"
    ],
    "abstract": "This study proposes an algorithm for detecting suspicious behaviors in large\npayment flows based on deep generative models. By combining Generative\nAdversarial Networks (GAN) and Variational Autoencoders (VAE), the algorithm is\ndesigned to detect abnormal behaviors in financial transactions. First, the GAN\nis used to generate simulated data that approximates normal payment flows. The\ndiscriminator identifies anomalous patterns in transactions, enabling the\ndetection of potential fraud and money laundering behaviors. Second, a VAE is\nintroduced to model the latent distribution of payment flows, ensuring that the\ngenerated data more closely resembles real transaction features, thus improving\nthe model's detection accuracy. The method optimizes the generative\ncapabilities of both GAN and VAE, ensuring that the model can effectively\ncapture suspicious behaviors even in sparse data conditions. Experimental\nresults show that the proposed method significantly outperforms traditional\nmachine learning algorithms and other deep learning models across various\nevaluation metrics, especially in detecting rare fraudulent behaviors.\nFurthermore, this study provides a detailed comparison of performance in\nrecognizing different transaction patterns (such as normal, money laundering,\nand fraud) in large payment flows, validating the advantages of generative\nmodels in handling complex financial data.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-04-21T23:49:10+00:00",
    "updated": "2025-04-21T23:49:10+00:00",
    "url": "http://arxiv.org/pdf/2504.15491v1"
  },
  {
    "id": "2505.23770v1",
    "title": "A comprehensive survey of cybercrimes in India over the last decade",
    "authors": [
      "Sudhanshu Sekhar Tripathy"
    ],
    "abstract": "Since the 1990s, the integration of technology into daily life has led to the\ncreation of an extensive network of interconnected devices, transforming how\nindividuals and organizations operate. However, this digital transformation has\nalso spurred the rise of cybercrime, criminal activities perpetrated through\nnetworks or computer systems. Cybercrime has become a global concern,\npresenting significant challenges to security systems. Although advancements in\ndigital technology have enhanced efficiency, they have also opened new avenues\nfor exploitation by cybercriminals, highlighting the urgent need for advanced\ncybersecurity measures. The escalating number of cyberattacks and associated\nrisks in the past decade highlights the critical importance of protecting\nsensitive data and safeguarding information systems. Cybercrimes range from\nfinancial fraud and phishing scams to identity theft and online harassment,\nposing substantial risks to both individuals and organizations. In response,\ngovernments, law enforcement agencies, and cybersecurity units have intensified\ntheir efforts to address these threats. In recent years, India has experienced\na significant surge in cybercrime incidents, with a notable increase in cases\ninvolving ransomware, data breaches, and social engineering attacks. The\ngrowing penetration of internet services, the expansion of e-commerce, and the\nrapid adoption of digital payment systems have made individuals and\norganizations more vulnerable to cyber threats. Key areas affected include\nbanking, healthcare, and government sectors, which are frequently targeted due\nto the sensitive nature of the data they handle. To combat these risks, there\nis an increasing focus on public awareness, cybersecurity education, and robust\nregulatory frameworks. This paper examines cybercrime, prevention strategies,\nsecurity protocols, and terminology to safeguard digital infrastructure.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-04-21T04:42:46+00:00",
    "updated": "2025-04-21T04:42:46+00:00",
    "url": "http://arxiv.org/pdf/2505.23770v1"
  },
  {
    "id": "2504.14205v2",
    "title": "Dual-channel Heterophilic Message Passing for Graph Fraud Detection",
    "authors": [
      "Wenxin Zhang",
      "Jingxing Zhong",
      "Guangzhen Yao",
      "Renda Han",
      "Xiaojian Lin",
      "Zeyu Zhang",
      "Cuicui Luo"
    ],
    "abstract": "Fraudulent activities have significantly increased across various domains,\nsuch as e-commerce, online review platforms, and social networks, making fraud\ndetection a critical task. Spatial Graph Neural Networks (GNNs) have been\nsuccessfully applied to fraud detection tasks due to their strong inductive\nlearning capabilities. However, existing spatial GNN-based methods often\nenhance the graph structure by excluding heterophilic neighbors during message\npassing to align with the homophilic bias of GNNs. Unfortunately, this approach\ncan disrupt the original graph topology and increase uncertainty in\npredictions. To address these limitations, this paper proposes a novel\nframework, Dual-channel Heterophilic Message Passing (DHMP), for fraud\ndetection. DHMP leverages a heterophily separation module to divide the graph\ninto homophilic and heterophilic subgraphs, mitigating the low-pass inductive\nbias of traditional GNNs. It then applies shared weights to capture signals at\ndifferent frequencies independently and incorporates a customized sampling\nstrategy for training. This allows nodes to adaptively balance the\ncontributions of various signals based on their labels. Extensive experiments\non three real-world datasets demonstrate that DHMP outperforms existing\nmethods, highlighting the importance of separating signals with different\nfrequencies for improved fraud detection. The code is available at\nhttps://github.com/shaieesss/DHMP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-04-19T06:41:24+00:00",
    "updated": "2025-04-26T08:03:12+00:00",
    "url": "http://arxiv.org/pdf/2504.14205v2"
  },
  {
    "id": "2504.11808v1",
    "title": "Federated Spectral Graph Transformers Meet Neural Ordinary Differential Equations for Non-IID Graphs",
    "authors": [
      "Kishan Gurumurthy",
      "Himanshu Pal",
      "Charu Sharma"
    ],
    "abstract": "Graph Neural Network (GNN) research is rapidly advancing due to GNNs'\ncapacity to learn distributed representations from graph-structured data.\nHowever, centralizing large volumes of real-world graph data for GNN training\nis often impractical due to privacy concerns, regulatory restrictions, and\ncommercial competition. Federated learning (FL), a distributed learning\nparadigm, offers a solution by preserving data privacy with collaborative model\ntraining. Despite progress in training huge vision and language models,\nfederated learning for GNNs remains underexplored. To address this challenge,\nwe present a novel method for federated learning on GNNs based on spectral GNNs\nequipped with neural ordinary differential equations (ODE) for better\ninformation capture, showing promising results across both homophilic and\nheterophilic graphs. Our approach effectively handles non-Independent and\nIdentically Distributed (non-IID) data, while also achieving performance\ncomparable to existing methods that only operate on IID data. It is designed to\nbe privacy-preserving and bandwidth-optimized, making it suitable for\nreal-world applications such as social network analysis, recommendation\nsystems, and fraud detection, which often involve complex, non-IID, and\nheterophilic graph structures. Our results in the area of federated learning on\nnon-IID heterophilic graphs demonstrate significant improvements, while also\nachieving better performance on homophilic graphs. This work highlights the\npotential of federated learning in diverse and challenging graph settings.\nOpen-source code available on GitHub\n(https://github.com/SpringWiz11/Fed-GNODEFormer).",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-04-16T06:43:20+00:00",
    "updated": "2025-04-16T06:43:20+00:00",
    "url": "http://arxiv.org/pdf/2504.11808v1"
  },
  {
    "id": "2506.11635v1",
    "title": "FAA Framework: A Large Language Model-Based Approach for Credit Card Fraud Investigations",
    "authors": [
      "Shaun Shuster",
      "Eyal Zaloof",
      "Asaf Shabtai",
      "Rami Puzis"
    ],
    "abstract": "The continuous growth of the e-commerce industry attracts fraudsters who\nexploit stolen credit card details. Companies often investigate suspicious\ntransactions in order to retain customer trust and address gaps in their fraud\ndetection systems. However, analysts are overwhelmed with an enormous number of\nalerts from credit card transaction monitoring systems. Each alert\ninvestigation requires from the fraud analysts careful attention, specialized\nknowledge, and precise documentation of the outcomes, leading to alert fatigue.\nTo address this, we propose a fraud analyst assistant (FAA) framework, which\nemploys multi-modal large language models (LLMs) to automate credit card fraud\ninvestigations and generate explanatory reports. The FAA framework leverages\nthe reasoning, code execution, and vision capabilities of LLMs to conduct\nplanning, evidence collection, and analysis in each investigation step. A\ncomprehensive empirical evaluation of 500 credit card fraud investigations\ndemonstrates that the FAA framework produces reliable and efficient\ninvestigations comprising seven steps on average. Thus we found that the FAA\nframework can automate large parts of the workload and help reduce the\nchallenges faced by fraud analysts.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-06-13T10:05:43+00:00",
    "updated": "2025-06-13T10:05:43+00:00",
    "url": "http://arxiv.org/pdf/2506.11635v1"
  },
  {
    "id": "2506.10842v1",
    "title": "Advanced fraud detection using machine learning models: enhancing financial transaction security",
    "authors": [
      "Nudrat Fariha",
      "Md Nazmuddin Moin Khan",
      "Md Iqbal Hossain",
      "Syed Ali Reza",
      "Joy Chakra Bortty",
      "Kazi Sharmin Sultana",
      "Md Shadidur Islam Jawad",
      "Saniah Safat",
      "Md Abdul Ahad",
      "Maksuda Begum"
    ],
    "abstract": "The rise of digital payments has accelerated the need for intelligent and\nscalable systems to detect fraud. This research presents an end-to-end,\nfeature-rich machine learning framework for detecting credit card transaction\nanomalies and fraud using real-world data. The study begins by merging\ntransactional, cardholder, merchant, and merchant category datasets from a\nrelational database to create a unified analytical view. Through the feature\nengineering process, we extract behavioural signals such as average spending,\ndeviation from historical patterns, transaction timing irregularities, and\ncategory frequency metrics. These features are enriched with temporal markers\nsuch as hour, day of week, and weekend indicators to expose all latent patterns\nthat indicate fraudulent behaviours. Exploratory data analysis reveals\ncontextual transaction trends across all the dataset features. Using the\ntransactional data, we train and evaluate a range of unsupervised models:\nIsolation Forest, One Class SVM, and a deep autoencoder trained to reconstruct\nnormal behavior. These models flag the top 1% of reconstruction errors as\noutliers. PCA visualizations illustrate each models ability to separate\nanomalies into a two-dimensional latent space. We further segment the\ntransaction landscape using K-Means clustering and DBSCAN to identify dense\nclusters of normal activity and isolate sparse, suspicious regions.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-06-12T15:59:25+00:00",
    "updated": "2025-06-12T15:59:25+00:00",
    "url": "http://arxiv.org/pdf/2506.10842v1"
  },
  {
    "id": "2506.09938v1",
    "title": "Microservices and Real-Time Processing in Retail IT: A Review of Open-Source Toolchains and Deployment Strategies",
    "authors": [
      "Aaditaa Vashisht",
      "Rekha B S"
    ],
    "abstract": "With the rapid pace of digital transformation, the retail industry is\nincreasingly depending on real-time, scalable, and resilient systems to manage\nfinancial transactions, analyze customer behavior, and streamline order\nprocessing. This literature review explores how modern event-driven and\nmicroservices-based architectures, particularly those leveraging Apache Kafka,\nSpring Boot, MongoDB, and Kubernetes are transforming retail and financial\nsystems. By systematically reviewing academic publications, technical white\npapers, and industry reports from recent years, this study synthesizes key\nthemes and implementation strategies. The analysis reveals that technologies\nlike Kafka and Spring Boot are instrumental in building low-latency,\nevent-driven applications that support real-time analytics and fraud detection,\nwhile MongoDB, when deployed on Kubernetes, ensures fault tolerance and high\navailability in inventory and transaction systems. Kubernetes itself plays a\ncrucial role in automating deployment and scaling of microservices. These\nfindings provide valuable insights for industry practitioners aiming to design\nscalable infrastructures, identify research opportunities in hybrid deployment\nmodels, and offer educators a foundation to integrate modern system\narchitectures into professional and technical communication training.",
    "categories": [
      "cs.SE",
      "cs.DB"
    ],
    "published": "2025-06-11T17:02:12+00:00",
    "updated": "2025-06-11T17:02:12+00:00",
    "url": "http://arxiv.org/pdf/2506.09938v1"
  },
  {
    "id": "2506.12088v2",
    "title": "Risks & Benefits of LLMs & GenAI for Platform Integrity, Healthcare Diagnostics, Financial Trust and Compliance, Cybersecurity, Privacy & AI Safety: A Comprehensive Survey, Roadmap & Implementation Blueprint",
    "authors": [
      "Kiarash Ahi"
    ],
    "abstract": "Large Language Models (LLMs) and generative AI (GenAI) systems, such as\nChatGPT, Claude, Gemini, LLaMA, and Copilot (by OpenAI, Anthropic, Google,\nMeta, and Microsoft, respectively), are reshaping digital platforms and app\necosystems while introducing critical challenges in cybersecurity, privacy, and\nplatform integrity. Our analysis reveals alarming trends: LLM-assisted malware\nis projected to rise from 2% (2021) to 50% (2025); AI-generated Google reviews\ngrew nearly tenfold (1.2% in 2021 to 12.21% in 2023, expected to reach 30% by\n2025); AI scam reports surged 456%; misinformation sites increased over 1500%;\nand deepfake attacks are projected to rise over 900% in 2025. In finance,\nLLM-driven threats like synthetic identity fraud and AI-generated scams are\naccelerating. Platforms such as JPMorgan Chase, Stripe, and Plaid deploy LLMs\nfor fraud detection, regulation parsing, and KYC/AML automation, reducing fraud\nloss by up to 21% and accelerating onboarding by 40-60%. LLM-facilitated code\ndevelopment has driven mobile app submissions from 1.8 million (2020) to 3.0\nmillion (2024), projected to reach 3.6 million (2025). To address AI threats,\nplatforms like Google Play, Apple App Store, GitHub Copilot, TikTok, Facebook,\nand Amazon deploy LLM-based defenses, highlighting their dual nature as both\nthreat sources and mitigation tools. In clinical diagnostics, LLMs raise\nconcerns about accuracy, bias, and safety, necessitating strong governance.\nDrawing on 445 references, this paper surveys LLM/GenAI and proposes a\nstrategic roadmap and operational blueprint integrating policy auditing (such\nas CCPA and GDPR compliance), fraud detection, and demonstrates an advanced\nLLM-DA stack with modular components, multi-LLM routing, agentic memory, and\ngovernance layers. We provide actionable insights, best practices, and\nreal-world case studies for scalable trust and responsible innovation.",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "published": "2025-06-10T18:03:19+00:00",
    "updated": "2025-07-26T23:50:09+00:00",
    "url": "http://arxiv.org/pdf/2506.12088v2"
  },
  {
    "id": "2506.08762v1",
    "title": "EDINET-Bench: Evaluating LLMs on Complex Financial Tasks using Japanese Financial Statements",
    "authors": [
      "Issa Sugiura",
      "Takashi Ishida",
      "Taro Makino",
      "Chieko Tazuke",
      "Takanori Nakagawa",
      "Kosuke Nakago",
      "David Ha"
    ],
    "abstract": "Financial analysis presents complex challenges that could leverage large\nlanguage model (LLM) capabilities. However, the scarcity of challenging\nfinancial datasets, particularly for Japanese financial data, impedes academic\ninnovation in financial analytics. As LLMs advance, this lack of accessible\nresearch resources increasingly hinders their development and evaluation in\nthis specialized domain. To address this gap, we introduce EDINET-Bench, an\nopen-source Japanese financial benchmark designed to evaluate the performance\nof LLMs on challenging financial tasks including accounting fraud detection,\nearnings forecasting, and industry prediction. EDINET-Bench is constructed by\ndownloading annual reports from the past 10 years from Japan's Electronic\nDisclosure for Investors' NETwork (EDINET) and automatically assigning labels\ncorresponding to each evaluation task. Our experiments reveal that even\nstate-of-the-art LLMs struggle, performing only slightly better than logistic\nregression in binary classification for fraud detection and earnings\nforecasting. These results highlight significant challenges in applying LLMs to\nreal-world financial applications and underscore the need for domain-specific\nadaptation. Our dataset, benchmark construction code, and evaluation code is\npublicly available to facilitate future research in finance with LLMs.",
    "categories": [
      "q-fin.ST",
      "cs.CE",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-06-10T13:03:36+00:00",
    "updated": "2025-06-10T13:03:36+00:00",
    "url": "http://arxiv.org/pdf/2506.08762v1"
  },
  {
    "id": "2506.05740v1",
    "title": "FIST: A Structured Threat Modeling Framework for Fraud Incidents",
    "authors": [
      "Yu-Chen Dai",
      "Lu-An Chen",
      "Sy-Jye Her",
      "Yu-Xian Jiang"
    ],
    "abstract": "Fraudulent activities are rapidly evolving, employing increasingly diverse\nand sophisticated methods that pose serious threats to individuals,\norganizations, and society. This paper proposes the FIST Framework (Fraud\nIncident Structured Threat Framework), an innovative structured threat modeling\nmethodology specifically designed for fraud scenarios. Inspired by MITRE\nATT\\&CK and DISARM, FIST systematically incorporates social engineering\ntactics, stage-based behavioral decomposition, and detailed attack technique\nmapping into a reusable knowledge base. FIST aims to enhance the efficiency of\nfraud detection and the standardization of threat intelligence sharing,\npromoting collaboration and a unified language across organizations and\nsectors. The framework integrates interdisciplinary insights from\ncybersecurity, criminology, and behavioral science, addressing both technical\nvectors and psychological manipulation mechanisms in fraud. This approach\nenables fine-grained analysis of fraud incidents, supporting automated\ndetection, quantitative risk assessment, and standardized incident reporting.\nThe effectiveness of the framework is further validated through real-world case\nstudies, demonstrating its value in bridging academic research and practical\napplications, and laying the foundation for an intelligence-driven anti-fraud\necosystem. To the best of our knowledge, FIST is the first systematic,\nopen-source fraud threat modeling framework that unifies both technical and\npsychological aspects, and is made freely available to foster collaboration\nbetween academia and industry.",
    "categories": [
      "cs.CR"
    ],
    "published": "2025-06-06T04:54:49+00:00",
    "updated": "2025-06-06T04:54:49+00:00",
    "url": "http://arxiv.org/pdf/2506.05740v1"
  },
  {
    "id": "2506.03988v3",
    "title": "RAID: A Dataset for Testing the Adversarial Robustness of AI-Generated Image Detectors",
    "authors": [
      "Hicham Eddoubi",
      "Jonas Ricker",
      "Federico Cocchi",
      "Lorenzo Baraldi",
      "Angelo Sotgiu",
      "Maura Pintor",
      "Marcella Cornia",
      "Lorenzo Baraldi",
      "Asja Fischer",
      "Rita Cucchiara",
      "Battista Biggio"
    ],
    "abstract": "AI-generated images have reached a quality level at which humans are\nincapable of reliably distinguishing them from real images. To counteract the\ninherent risk of fraud and disinformation, the detection of AI-generated images\nis a pressing challenge and an active research topic. While many of the\npresented methods claim to achieve high detection accuracy, they are usually\nevaluated under idealized conditions. In particular, the adversarial robustness\nis often neglected, potentially due to a lack of awareness or the substantial\neffort required to conduct a comprehensive robustness analysis. In this work,\nwe tackle this problem by providing a simpler means to assess the robustness of\nAI-generated image detectors. We present RAID (Robust evaluation of\nAI-generated image Detectors), a dataset of 72k diverse and highly transferable\nadversarial examples. The dataset is created by running attacks against an\nensemble of seven state-of-the-art detectors and images generated by four\ndifferent text-to-image models. Extensive experiments show that our methodology\ngenerates adversarial images that transfer with a high success rate to unseen\ndetectors, which can be used to quickly provide an approximate yet still\nreliable estimate of a detector's adversarial robustness. Our findings indicate\nthat current state-of-the-art AI-generated image detectors can be easily\ndeceived by adversarial examples, highlighting the critical need for the\ndevelopment of more robust methods. We release our dataset at\nhttps://huggingface.co/datasets/aimagelab/RAID and evaluation code at\nhttps://github.com/pralab/RAID.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-06-04T14:16:00+00:00",
    "updated": "2025-06-09T10:46:28+00:00",
    "url": "http://arxiv.org/pdf/2506.03988v3"
  },
  {
    "id": "2506.03940v2",
    "title": "Depermissioning Web3: a Permissionless Accountable RPC Protocol for Blockchain Networks",
    "authors": [
      "Weihong Wang",
      "Tom Van Cutsem"
    ],
    "abstract": "In blockchain networks, so-called \"full nodes\" serve data to and relay\ntransactions from clients through an RPC interface. This serving layer enables\nintegration of \"Web3\" data, stored on blockchains, with \"Web2\" mobile or web\napplications that cannot directly participate as peers in a blockchain network.\nIn practice, the serving layer is dominated by a small number of centralized\nservices (\"node providers\") that offer permissioned access to RPC endpoints.\nClients register with these providers because they offer reliable and\nconvenient access to blockchain data: operating a full node themselves requires\nsignificant computational and storage resources, and public (permissionless)\nRPC nodes lack financial incentives to serve large numbers of clients with\nconsistent performance.\n  Permissioned access to an otherwise permissionless blockchain network raises\nconcerns regarding the privacy, integrity, and availability of data access. To\naddress this, we propose a Permissionless Accountable RPC Protocol (PARP). It\nenables clients and full nodes to interact pseudonymously while keeping both\nparties accountable. PARP leverages \"light client\" schemes for essential data\nintegrity checks, combined with fraud proofs, to keep full nodes honest and\naccountable. It integrates payment channels to facilitate micro-payments,\nholding clients accountable for the resources they consume and providing an\neconomic incentive for full nodes to serve. Our prototype implementation for\nEthereum demonstrates the feasibility of PARP, and we quantify its overhead\ncompared to the base RPC protocol.",
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "published": "2025-06-04T13:31:32+00:00",
    "updated": "2025-06-06T22:27:31+00:00",
    "url": "http://arxiv.org/pdf/2506.03940v2"
  },
  {
    "id": "2506.04292v1",
    "title": "GARG-AML against Smurfing: A Scalable and Interpretable Graph-Based Framework for Anti-Money Laundering",
    "authors": [
      "Bruno Deprez",
      "Bart Baesens",
      "Tim Verdonck",
      "Wouter Verbeke"
    ],
    "abstract": "Money laundering poses a significant challenge as it is estimated to account\nfor 2%-5% of the global GDP. This has compelled regulators to impose stringent\ncontrols on financial institutions. One prominent laundering method for evading\nthese controls, called smurfing, involves breaking up large transactions into\nsmaller amounts. Given the complexity of smurfing schemes, which involve\nmultiple transactions distributed among diverse parties, network analytics has\nbecome an important anti-money laundering tool. However, recent advances have\nfocused predominantly on black-box network embedding methods, which has\nhindered their adoption in businesses. In this paper, we introduce GARG-AML, a\nnovel graph-based method that quantifies smurfing risk through a single\ninterpretable metric derived from the structure of the second-order transaction\nnetwork of each individual node in the network. Unlike traditional methods,\nGARG-AML strikes an effective balance among computational efficiency, detection\npower and transparency, which enables its integration into existing AML\nworkflows. To enhance its capabilities, we combine the GARG-AML score\ncalculation with different tree-based methods and also incorporate the scores\nof the node's neighbours. An experimental evaluation on large-scale synthetic\nand open-source networks demonstrate that the GARG-AML outperforms the current\nstate-of-the-art smurfing detection methods. By leveraging only the adjacency\nmatrix of the second-order neighbourhood and basic network features, this work\nhighlights the potential of fundamental network properties towards advancing\nfraud detection.",
    "categories": [
      "cs.SI",
      "cs.LG",
      "stat.AP"
    ],
    "published": "2025-06-04T11:30:37+00:00",
    "updated": "2025-06-04T11:30:37+00:00",
    "url": "http://arxiv.org/pdf/2506.04292v1"
  },
  {
    "id": "2506.02757v1",
    "title": "Investigating Mask-aware Prototype Learning for Tabular Anomaly Detection",
    "authors": [
      "Ruiying Lu",
      "Jinhan Liu",
      "Chuan Du",
      "Dandan Guo"
    ],
    "abstract": "Tabular anomaly detection, which aims at identifying deviant samples, has\nbeen crucial in a variety of real-world applications, such as medical disease\nidentification, financial fraud detection, intrusion monitoring, etc. Although\nrecent deep learning-based methods have achieved competitive performances,\nthese methods suffer from representation entanglement and the lack of global\ncorrelation modeling, which hinders anomaly detection performance. To tackle\nthe problem, we incorporate mask modeling and prototype learning into tabular\nanomaly detection. The core idea is to design learnable masks by disentangled\nrepresentation learning within a projection space and extracting normal\ndependencies as explicit global prototypes. Specifically, the overall model\ninvolves two parts: (i) During encoding, we perform mask modeling in both the\ndata space and projection space with orthogonal basis vectors for learning\nshared disentangled normal patterns; (ii) During decoding, we decode multiple\nmasked representations in parallel for reconstruction and learn association\nprototypes to extract normal characteristic correlations. Our proposal derives\nfrom a distribution-matching perspective, where both projection space learning\nand association prototype learning are formulated as optimal transport\nproblems, and the calibration distances are utilized to refine the anomaly\nscores. Quantitative and qualitative experiments on 20 tabular benchmarks\ndemonstrate the effectiveness and interpretability of our model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-06-03T11:22:44+00:00",
    "updated": "2025-06-03T11:22:44+00:00",
    "url": "http://arxiv.org/pdf/2506.02757v1"
  },
  {
    "id": "2506.02703v1",
    "title": "Data Leakage and Deceptive Performance: A Critical Examination of Credit Card Fraud Detection Methodologies",
    "authors": [
      "Khizar Hayat",
      "Baptiste Magnier"
    ],
    "abstract": "This study critically examines the methodological rigor in credit card fraud\ndetection research, revealing how fundamental evaluation flaws can overshadow\nalgorithmic sophistication. Through deliberate experimentation with improper\nevaluation protocols, we demonstrate that even simple models can achieve\ndeceptively impressive results when basic methodological principles are\nviolated. Our analysis identifies four critical issues plaguing current\napproaches: (1) pervasive data leakage from improper preprocessing sequences,\n(2) intentional vagueness in methodological reporting, (3) inadequate temporal\nvalidation for transaction data, and (4) metric manipulation through recall\noptimization at precision's expense. We present a case study showing how a\nminimal neural network architecture with data leakage outperforms many\nsophisticated methods reported in literature, achieving 99.9\\% recall despite\nfundamental evaluation flaws. These findings underscore that proper evaluation\nmethodology matters more than model complexity in fraud detection research. The\nstudy serves as a cautionary example of how methodological rigor must precede\narchitectural sophistication, with implications for improving research\npractices across machine learning applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-06-03T09:56:43+00:00",
    "updated": "2025-06-03T09:56:43+00:00",
    "url": "http://arxiv.org/pdf/2506.02703v1"
  },
  {
    "id": "2506.02068v1",
    "title": "Enhancing Interpretability of Quantum-Assisted Blockchain Clustering via AI Agent-Based Qualitative Analysis",
    "authors": [
      "Yun-Cheng Tsai",
      "Yen-Ku Liu",
      "Samuel Yen-Chi Chen"
    ],
    "abstract": "Blockchain transaction data is inherently high dimensional, noisy, and\nentangled, posing substantial challenges for traditional clustering algorithms.\nWhile quantum enhanced clustering models have demonstrated promising\nperformance gains, their interpretability remains limited, restricting their\napplication in sensitive domains such as financial fraud detection and\nblockchain governance. To address this gap, we propose a two stage analysis\nframework that synergistically combines quantitative clustering evaluation with\nAI Agent assisted qualitative interpretation. In the first stage, we employ\nclassical clustering methods and evaluation metrics including the Silhouette\nScore, Davies Bouldin Index, and Calinski Harabasz Index to determine the\noptimal cluster count and baseline partition quality. In the second stage, we\nintegrate an AI Agent to generate human readable, semantic explanations of\nclustering results, identifying intra cluster characteristics and inter cluster\nrelationships. Our experiments reveal that while fully trained Quantum Neural\nNetworks (QNN) outperform random Quantum Features (QF) in quantitative metrics,\nthe AI Agent further uncovers nuanced differences between these methods,\nnotably exposing the singleton cluster phenomenon in QNN driven models. The\nconsolidated insights from both stages consistently endorse the three cluster\nconfiguration, demonstrating the practical value of our hybrid approach. This\nwork advances the interpretability frontier in quantum assisted blockchain\nanalytics and lays the groundwork for future autonomous AI orchestrated\nclustering frameworks.",
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "published": "2025-06-02T02:15:48+00:00",
    "updated": "2025-06-02T02:15:48+00:00",
    "url": "http://arxiv.org/pdf/2506.02068v1"
  },
  {
    "id": "2506.00719v1",
    "title": "Browser Fingerprinting Using WebAssembly",
    "authors": [
      "Mordechai Guri",
      "Dor Fibert"
    ],
    "abstract": "Web client fingerprinting has become a widely used technique for uniquely\nidentifying users, browsers, operating systems, and devices with high accuracy.\nWhile it is beneficial for applications such as fraud detection and\npersonalized experiences, it also raises privacy concerns by enabling\npersistent tracking and detailed user profiling. This paper introduces an\nadvanced fingerprinting method using WebAssembly (Wasm) - a low-level\nprogramming language that offers near-native execution speed in modern web\nbrowsers. With broad support across major browsers and growing adoption,\nWebAssembly provides a strong foundation for developing more effective\nfingerprinting methods.\n  In this work, we present a new approach that leverages WebAssembly's\ncomputational capabilities to identify returning devices-such as smartphones,\ntablets, laptops, and desktops across different browsing sessions. Our method\nuses subtle differences in the WebAssembly JavaScript API implementation to\ndistinguish between Chromium-based browsers like Google Chrome and Microsoft\nEdge, even when identifiers such as the User-Agent are completely spoofed,\nachieving a false-positive rate of less than 1%. The fingerprint is generated\nusing a combination of CPU-bound operations, memory tasks, and I/O activities\nto capture unique browser behaviors. We validate this approach on a variety of\nplatforms, including Intel, AMD, and ARM CPUs, operating systems such as\nWindows, macOS, Android, and iOS, and in environments like VMWare, KVM, and\nVirtualBox. Extensive evaluation shows that WebAssembly-based fingerprinting\nsignificantly improves identification accuracy. We also propose mitigation\nstrategies to reduce the privacy risks associated with this method, which could\nbe integrated into future browser designs to better protect user privacy.",
    "categories": [
      "cs.CR"
    ],
    "published": "2025-05-31T21:39:17+00:00",
    "updated": "2025-05-31T21:39:17+00:00",
    "url": "http://arxiv.org/pdf/2506.00719v1"
  },
  {
    "id": "2506.00282v1",
    "title": "Shill Bidding Prevention in Decentralized Auctions Using Smart Contracts",
    "authors": [
      "M. A. Bouaicha",
      "G. Destefanis",
      "T. Montanaro",
      "N. Lasla",
      "L. Patrono"
    ],
    "abstract": "In online auctions, fraudulent behaviors such as shill bidding pose\nsignificant risks. This paper presents a conceptual framework that applies\ndynamic, behavior-based penalties to deter auction fraud using blockchain smart\ncontracts. Unlike traditional post-auction detection methods, this approach\nprevents manipulation in real-time by introducing an economic disincentive\nsystem where penalty severity scales with suspicious bidding patterns. The\nframework employs the proposed Bid Shill Score (BSS) to evaluate nine distinct\nbidding behaviors, dynamically adjusting the penalty fees to make fraudulent\nactivity financially unaffordable while providing fair competition.\n  The system is implemented within a decentralized English auction on the\nEthereum blockchain, demonstrating how smart contracts enforce transparent\nauction rules without trusted intermediaries. Simulations confirm the\neffectiveness of the proposed model: the dynamic penalty mechanism reduces the\nprofitability of shill bidding while keeping penalties low for honest bidders.\nPerformance evaluation shows that the system introduces only moderate gas and\nlatency overhead, keeping transaction costs and response times within practical\nbounds for real-world use. The approach provides a practical method for\nbehaviour-based fraud prevention in decentralised systems where trust cannot be\nassumed.",
    "categories": [
      "cs.GT",
      "cs.CR",
      "cs.SE"
    ],
    "published": "2025-05-30T22:23:29+00:00",
    "updated": "2025-05-30T22:23:29+00:00",
    "url": "http://arxiv.org/pdf/2506.00282v1"
  },
  {
    "id": "2505.24284v1",
    "title": "Transaction Proximity: A Graph-Based Approach to Blockchain Fraud Prevention",
    "authors": [
      "Gordon Y. Liao",
      "Ziming Zeng",
      "Mira Belenkiy",
      "Jacob Hirshman"
    ],
    "abstract": "This paper introduces a fraud-deterrent access validation system for public\nblockchains, leveraging two complementary concepts: \"Transaction Proximity\",\nwhich measures the distance between wallets in the transaction graph, and\n\"Easily Attainable Identities (EAIs)\", wallets with direct transaction\nconnections to centralized exchanges. Recognizing the limitations of\ntraditional approaches like blocklisting (reactive, slow) and strict allow\nlisting (privacy-invasive, adoption barriers), we propose a system that\nanalyzes transaction patterns to identify wallets with close connections to\ncentralized exchanges.\n  Our directed graph analysis of the Ethereum blockchain reveals that 56% of\nlarge USDC wallets (with a lifetime maximum balance greater than \\$10,000) are\nEAI and 88% are within one transaction hop of an EAI. For transactions\nexceeding \\$2,000, 91% involve at least one EAI. Crucially, an analysis of past\nexploits shows that 83% of the known exploiter addresses are not EAIs, with 21%\nbeing more than five hops away from any regulated exchange. We present three\nimplementation approaches with varying gas cost and privacy tradeoffs,\ndemonstrating that EAI-based access control can potentially prevent most of\nthese incidents while preserving blockchain openness. Importantly, our approach\ndoes not restrict access or share personally identifiable information, but it\nprovides information for protocols to implement their own validation or risk\nscoring systems based on specific needs. This middle-ground solution enables\nprogrammatic compliance while maintaining the core values of open blockchain.",
    "categories": [
      "cs.CR",
      "cs.CE",
      "econ.GN",
      "q-fin.EC",
      "H.3.5; K.4.4; H.2.8"
    ],
    "published": "2025-05-30T07:00:07+00:00",
    "updated": "2025-05-30T07:00:07+00:00",
    "url": "http://arxiv.org/pdf/2505.24284v1"
  },
  {
    "id": "2505.22521v1",
    "title": "Evaluating Supervised Learning Models for Fraud Detection: A Comparative Study of Classical and Deep Architectures on Imbalanced Transaction Data",
    "authors": [
      "Chao Wang",
      "Chuanhao Nie",
      "Yunbo Liu"
    ],
    "abstract": "Fraud detection remains a critical task in high-stakes domains such as\nfinance and e-commerce, where undetected fraudulent transactions can lead to\nsignificant economic losses. In this study, we systematically compare the\nperformance of four supervised learning models - Logistic Regression, Random\nForest, Light Gradient Boosting Machine (LightGBM), and a Gated Recurrent Unit\n(GRU) network - on a large-scale, highly imbalanced online transaction dataset.\nWhile ensemble methods such as Random Forest and LightGBM demonstrated superior\nperformance in both overall and class-specific metrics, Logistic Regression\noffered a reliable and interpretable baseline. The GRU model showed strong\nrecall for the minority fraud class, though at the cost of precision,\nhighlighting a trade-off relevant for real-world deployment. Our evaluation\nemphasizes not only weighted averages but also per-class precision, recall, and\nF1-scores, providing a nuanced view of each model's effectiveness in detecting\nrare but consequential fraudulent activity. The findings underscore the\nimportance of choosing models based on the specific risk tolerance and\noperational needs of fraud detection systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-05-28T16:08:04+00:00",
    "updated": "2025-05-28T16:08:04+00:00",
    "url": "http://arxiv.org/pdf/2505.22521v1"
  },
  {
    "id": "2506.02008v1",
    "title": "Big Data-Driven Fraud Detection Using Machine Learning and Real-Time Stream Processing",
    "authors": [
      "Chen Liu",
      "Hengyu Tang",
      "Zhixiao Yang",
      "Ke Zhou",
      "Sangwhan Cha"
    ],
    "abstract": "In the age of digital finance, detecting fraudulent transactions and money\nlaundering is critical for financial institutions. This paper presents a\nscalable and efficient solution using Big Data tools and machine learning\nmodels. We utilize realtime data streaming platforms like Apache Kafka and\nFlink, distributed processing frameworks such as Apache Spark, and cloud\nstorage services AWS S3 and RDS. A synthetic dataset representing real-world\nAnti-Money Laundering (AML) challenges is employed to build a binary\nclassification model. Logistic Regression, Decision Tree, and Random Forest are\ntrained and evaluated using engineered features. Our system demonstrates over\n99% classification accuracy, illustrating the power of combining Big Data\narchitectures with machine learning to tackle fraud.",
    "categories": [
      "cs.DC"
    ],
    "published": "2025-05-27T14:45:16+00:00",
    "updated": "2025-05-27T14:45:16+00:00",
    "url": "http://arxiv.org/pdf/2506.02008v1"
  },
  {
    "id": "2505.19338v1",
    "title": "Co-evolutionary Dynamics of Attack and Defence in Cybersecurity",
    "authors": [
      "Adeela Bashir",
      "Zia Ush Shamszaman",
      "Zhao Song",
      "The Anh Han"
    ],
    "abstract": "In the evolving digital landscape, it is crucial to study the dynamics of\ncyberattacks and defences. This study uses an Evolutionary Game Theory (EGT)\nframework to investigate the evolutionary dynamics of attacks and defences in\ncyberspace. We develop a two-population asymmetric game between attacker and\ndefender to capture the essential factors of costs, potential benefits, and the\nprobability of successful defences. Through mathematical analysis and numerical\nsimulations, we find that systems with high defence intensities show stability\nwith minimal attack frequencies, whereas low-defence environments show\ninstability, and are vulnerable to attacks. Furthermore, we find five\nequilibria, where the strategy pair always defend and attack emerged as the\nmost likely stable state as cyber domain is characterised by a continuous\nbattle between defenders and attackers. Our theoretical findings align with\nreal-world data from past cyber incidents, demonstrating the interdisciplinary\nimpact, such as fraud detection, risk management and cybersecurity\ndecision-making. Overall, our analysis suggests that adaptive cybersecurity\nstrategies based on EGT can improve resource allocation, enhance system\nresilience, and reduce the overall risk of cyberattacks. By incorporating\nreal-world data, this study demonstrates the applicability of EGT in addressing\nthe evolving nature of cyber threats and the need for secure digital ecosystems\nthrough strategic planning and proactive defence measures.",
    "categories": [
      "cs.GT",
      "cs.CR",
      "nlin.AO"
    ],
    "published": "2025-05-25T22:11:24+00:00",
    "updated": "2025-05-25T22:11:24+00:00",
    "url": "http://arxiv.org/pdf/2505.19338v1"
  },
  {
    "id": "2505.18002v1",
    "title": "Rethinking Contrastive Learning in Graph Anomaly Detection: A Clean-View Perspective",
    "authors": [
      "Di Jin",
      "Jingyi Cao",
      "Xiaobao Wang",
      "Bingdao Feng",
      "Dongxiao He",
      "Longbiao Wang",
      "Jianwu Dang"
    ],
    "abstract": "Graph anomaly detection aims to identify unusual patterns in graph-based\ndata, with wide applications in fields such as web security and financial fraud\ndetection. Existing methods typically rely on contrastive learning, assuming\nthat a lower similarity between a node and its local subgraph indicates\nabnormality. However, these approaches overlook a crucial limitation: the\npresence of interfering edges invalidates this assumption, since it introduces\ndisruptive noise that compromises the contrastive learning process.\nConsequently, this limitation impairs the ability to effectively learn\nmeaningful representations of normal patterns, leading to suboptimal detection\nperformance. To address this issue, we propose a Clean-View Enhanced Graph\nAnomaly Detection framework (CVGAD), which includes a multi-scale anomaly\nawareness module to identify key sources of interference in the contrastive\nlearning process. Moreover, to mitigate bias from the one-step edge removal\nprocess, we introduce a novel progressive purification module. This module\nincrementally refines the graph by iteratively identifying and removing\ninterfering edges, thereby enhancing model performance. Extensive experiments\non five benchmark datasets validate the effectiveness of our approach.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-05-23T15:05:56+00:00",
    "updated": "2025-05-23T15:05:56+00:00",
    "url": "http://arxiv.org/pdf/2505.18002v1"
  },
  {
    "id": "2505.17513v1",
    "title": "What You Read Isn't What You Hear: Linguistic Sensitivity in Deepfake Speech Detection",
    "authors": [
      "Binh Nguyen",
      "Shuji Shi",
      "Ryan Ofman",
      "Thai Le"
    ],
    "abstract": "Recent advances in text-to-speech technologies have enabled realistic voice\ngeneration, fueling audio-based deepfake attacks such as fraud and\nimpersonation. While audio anti-spoofing systems are critical for detecting\nsuch threats, prior work has predominantly focused on acoustic-level\nperturbations, leaving the impact of linguistic variation largely unexplored.\nIn this paper, we investigate the linguistic sensitivity of both open-source\nand commercial anti-spoofing detectors by introducing transcript-level\nadversarial attacks. Our extensive evaluation reveals that even minor\nlinguistic perturbations can significantly degrade detection accuracy: attack\nsuccess rates surpass 60% on several open-source detector-voice pairs, and\nnotably one commercial detection accuracy drops from 100% on synthetic audio to\njust 32%. Through a comprehensive feature attribution analysis, we identify\nthat both linguistic complexity and model-level audio embedding similarity\ncontribute strongly to detector vulnerability. We further demonstrate the\nreal-world risk via a case study replicating the Brad Pitt audio deepfake scam,\nusing transcript adversarial attacks to completely bypass commercial detectors.\nThese results highlight the need to move beyond purely acoustic defenses and\naccount for linguistic variation in the design of robust anti-spoofing systems.\nAll source code will be publicly available.",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.SD",
      "eess.AS",
      "53-04"
    ],
    "published": "2025-05-23T06:06:37+00:00",
    "updated": "2025-05-23T06:06:37+00:00",
    "url": "http://arxiv.org/pdf/2505.17513v1"
  },
  {
    "id": "2505.16557v2",
    "title": "Is Your LLM-Based Multi-Agent a Reliable Real-World Planner? Exploring Fraud Detection in Travel Planning",
    "authors": [
      "Junchi Yao",
      "Jianhua Xu",
      "Tianyu Xin",
      "Ziyi Wang",
      "Shenzhe Zhu",
      "Shu Yang",
      "Di Wang"
    ],
    "abstract": "The rise of Large Language Model-based Multi-Agent Planning has leveraged\nadvanced frameworks to enable autonomous and collaborative task execution. Some\nsystems rely on platforms like review sites and social media, which are prone\nto fraudulent information, such as fake reviews or misleading descriptions.\nThis reliance poses risks, potentially causing financial losses and harming\nuser experiences. To evaluate the risk of planning systems in real-world\napplications, we introduce \\textbf{WandaPlan}, an evaluation environment\nmirroring real-world data and injected with deceptive content. We assess system\nperformance across three fraud cases: Misinformation Fraud, Team-Coordinated\nMulti-Person Fraud, and Level-Escalating Multi-Round Fraud. We reveal\nsignificant weaknesses in existing frameworks that prioritize task efficiency\nover data authenticity. At the same time, we validate WandaPlan's\ngeneralizability, capable of assessing the risks of real-world open-source\nplanning frameworks. To mitigate the risk of fraud, we propose integrating an\nanti-fraud agent, providing a solution for reliable planning.",
    "categories": [
      "cs.MA"
    ],
    "published": "2025-05-22T11:46:46+00:00",
    "updated": "2025-06-13T11:41:42+00:00",
    "url": "http://arxiv.org/pdf/2505.16557v2"
  },
  {
    "id": "2505.12594v1",
    "title": "AD-AGENT: A Multi-agent Framework for End-to-end Anomaly Detection",
    "authors": [
      "Tiankai Yang",
      "Junjun Liu",
      "Wingchun Siu",
      "Jiahang Wang",
      "Zhuangzhuang Qian",
      "Chanjuan Song",
      "Cheng Cheng",
      "Xiyang Hu",
      "Yue Zhao"
    ],
    "abstract": "Anomaly detection (AD) is essential in areas such as fraud detection, network\nmonitoring, and scientific research. However, the diversity of data modalities\nand the increasing number of specialized AD libraries pose challenges for\nnon-expert users who lack in-depth library-specific knowledge and advanced\nprogramming skills. To tackle this, we present AD-AGENT, an LLM-driven\nmulti-agent framework that turns natural-language instructions into fully\nexecutable AD pipelines. AD-AGENT coordinates specialized agents for intent\nparsing, data preparation, library and model selection, documentation mining,\nand iterative code generation and debugging. Using a shared short-term\nworkspace and a long-term cache, the agents integrate popular AD libraries like\nPyOD, PyGOD, and TSLib into a unified workflow. Experiments demonstrate that\nAD-AGENT produces reliable scripts and recommends competitive models across\nlibraries. The system is open-sourced to support further research and practical\napplications in AD.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-05-19T01:14:57+00:00",
    "updated": "2025-05-19T01:14:57+00:00",
    "url": "http://arxiv.org/pdf/2505.12594v1"
  },
  {
    "id": "2505.11094v1",
    "title": "Blockchain-Enabled Decentralized Privacy-Preserving Group Purchasing for Energy Plans",
    "authors": [
      "Sid Chi-Kin Chau",
      "Yue Zhou"
    ],
    "abstract": "Retail energy markets are increasingly consumer-oriented, thanks to a growing\nnumber of energy plans offered by a plethora of energy suppliers, retailers and\nintermediaries. To maximize the benefits of competitive retail energy markets,\ngroup purchasing is an emerging paradigm that aggregates consumers' purchasing\npower by coordinating switch decisions to specific energy providers for\ndiscounted energy plans. Traditionally, group purchasing is mediated by a\ntrusted third-party, which suffers from the lack of privacy and transparency.\nIn this paper, we introduce a novel paradigm of decentralized\nprivacy-preserving group purchasing, empowered by privacy-preserving blockchain\nand secure multi-party computation, to enable users to form a coalition for\ncoordinated switch decisions in a decentralized manner, without a trusted\nthird-party. The coordinated switch decisions are determined by a competitive\nonline algorithm, based on users' private consumption data and current energy\nplan tariffs. Remarkably, no private user consumption data will be revealed to\nothers in the online decision-making process, which is carried out in a\ntransparently verifiable manner to eliminate frauds from dishonest users and\nsupports fair mutual compensations by sharing the switching costs to\nincentivize group purchasing. We implemented our decentralized group purchasing\nsolution as a smart contract on Solidity-supported blockchain platform (e.g.,\nEthereum), and provide extensive empirical evaluation.",
    "categories": [
      "cs.CR"
    ],
    "published": "2025-05-16T10:26:15+00:00",
    "updated": "2025-05-16T10:26:15+00:00",
    "url": "http://arxiv.org/pdf/2505.11094v1"
  },
  {
    "id": "2505.10050v1",
    "title": "Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods",
    "authors": [
      "Fahad Almalki",
      "Mehedi Masud"
    ],
    "abstract": "Traditional machine learning models often prioritize predictive accuracy,\noften at the expense of model transparency and interpretability. The lack of\ntransparency makes it difficult for organizations to comply with regulatory\nrequirements and gain stakeholders trust. In this research, we propose a fraud\ndetection framework that combines a stacking ensemble of well-known gradient\nboosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable\nartificial intelligence (XAI) techniques are used to enhance the transparency\nand interpretability of the model's decisions. We used SHAP (SHapley Additive\nExplanations) for feature selection to identify the most important features.\nFurther efforts were made to explain the model's predictions using Local\nInterpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots\n(PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection\ndataset, which includes more than 590,000 real transaction records, was used to\nevaluate the proposed model. The model achieved a high performance with an\naccuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent\nrelated approaches. These results indicate that combining high prediction\naccuracy with transparent interpretability is possible and could lead to a more\nethical and trustworthy solution in financial fraud detection.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-05-15T07:53:02+00:00",
    "updated": "2025-05-15T07:53:02+00:00",
    "url": "http://arxiv.org/pdf/2505.10050v1"
  },
  {
    "id": "2507.10743v1",
    "title": "Language Models for Adult Service Website Text Analysis",
    "authors": [
      "Nickolas Freeman",
      "Thanh Nguyen",
      "Gregory Bott",
      "Jason Parton",
      "Collin Francel"
    ],
    "abstract": "Sex trafficking refers to the use of force, fraud, or coercion to compel an\nindividual to perform in commercial sex acts against their will. Adult service\nwebsites (ASWs) have and continue to be linked to sex trafficking, offering a\nplatform for traffickers to advertise their victims. Thus, organizations\ninvolved in the fight against sex trafficking often use ASW data when\nattempting to identify potential sex trafficking victims. A critical challenge\nin transforming ASW data into actionable insight is text analysis. Previous\nresearch using ASW data has shown that ASW ad text is important for linking\nads. However, working with this text is challenging due to its extensive use of\nemojis, poor grammar, and deliberate obfuscation to evade law enforcement\nscrutiny. We conduct a comprehensive study of language modeling approaches for\nthis application area, including simple information retrieval methods,\npre-trained transformers, and custom transformer models. We demonstrate that\ncharacteristics of ASW text data allow efficient custom transformer models to\nbe trained with relatively small GPU resources and used efficiently for\ninference on consumer hardware. Our custom models outperform fine-tuned\nvariants of well-known encoder-only transformer models, including BERT-base,\nRoBERTa, and ModernBERT, on accuracy, recall, F1 score, and ROC AUC. We\ndemonstrate the use of our best-performing custom configuration on three tasks\nrelated to ASW data analysis: (i) decomposing the giant component in a graph\nrepresentation of ASW data, (ii) clustering ASW ad text, and (iii) using the\nlearned token embeddings to understand the use of emojis in the illicit context\nwe study. The models we develop represent a significant advancement in ASW text\nanalysis, which can be leveraged in a variety of downstream applications and\nresearch.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-07-14T19:08:07+00:00",
    "updated": "2025-07-14T19:08:07+00:00",
    "url": "http://arxiv.org/pdf/2507.10743v1"
  },
  {
    "id": "2507.09385v1",
    "title": "Credit Card Fraud Detection Using RoFormer Model With Relative Distance Rotating Encoding",
    "authors": [
      "Kevin Reyes",
      "Vasco Cortez"
    ],
    "abstract": "Fraud detection is one of the most important challenges that financial\nsystems must address. Detecting fraudulent transactions is critical for payment\ngateway companies like Flow Payment, which process millions of transactions\nmonthly and require robust security measures to mitigate financial risks.\nIncreasing transaction authorization rates while reducing fraud is essential\nfor providing a good user experience and building a sustainable business. For\nthis reason, discovering novel and improved methods to detect fraud requires\ncontinuous research and investment for any company that wants to succeed in\nthis industry. In this work, we introduced a novel method for detecting\ntransactional fraud by incorporating the Relative Distance Rotating Encoding\n(ReDRE) in the RoFormer model. The incorporation of angle rotation using ReDRE\nenhances the characterization of time series data within a Transformer, leading\nto improved fraud detection by better capturing temporal dependencies and event\nrelationships.",
    "categories": [
      "cs.NE",
      "cs.LG"
    ],
    "published": "2025-07-12T20:02:02+00:00",
    "updated": "2025-07-12T20:02:02+00:00",
    "url": "http://arxiv.org/pdf/2507.09385v1"
  },
  {
    "id": "2507.08917v1",
    "title": "Detecting Deepfake Talking Heads from Facial Biometric Anomalies",
    "authors": [
      "Justin D. Norman",
      "Hany Farid"
    ],
    "abstract": "The combination of highly realistic voice cloning, along with visually\ncompelling avatar, face-swap, or lip-sync deepfake video generation, makes it\nrelatively easy to create a video of anyone saying anything. Today, such\ndeepfake impersonations are often used to power frauds, scams, and political\ndisinformation. We propose a novel forensic machine learning technique for the\ndetection of deepfake video impersonations that leverages unnatural patterns in\nfacial biometrics. We evaluate this technique across a large dataset of\ndeepfake techniques and impersonations, as well as assess its reliability to\nvideo laundering and its generalization to previously unseen video deepfake\ngenerators.",
    "categories": [
      "cs.CV"
    ],
    "published": "2025-07-11T16:29:25+00:00",
    "updated": "2025-07-11T16:29:25+00:00",
    "url": "http://arxiv.org/pdf/2507.08917v1"
  },
  {
    "id": "2507.08193v2",
    "title": "Entity-Specific Cyber Risk Assessment using InsurTech Empowered Risk Factors",
    "authors": [
      "Jiayi Guo",
      "Zhiyu Quan",
      "Linfeng Zhang"
    ],
    "abstract": "The lack of high-quality public cyber incident data limits empirical research\nand predictive modeling for cyber risk assessment. This challenge persists due\nto the reluctance of companies to disclose incidents that could damage their\nreputation or investor confidence. Therefore, from an actuarial perspective,\npotential resolutions conclude two aspects: the enhancement of existing cyber\nincident datasets and the implementation of advanced modeling techniques to\noptimize the use of the available data. A review of existing data-driven\nmethods highlights a significant lack of entity-specific organizational\nfeatures in publicly available datasets. To address this gap, we propose a\nnovel InsurTech framework that enriches cyber incident data with\nentity-specific attributes. We develop various machine learning (ML) models: a\nmultilabel classification model to predict the occurrence of cyber incident\ntypes (e.g., Privacy Violation, Data Breach, Fraud and Extortion, IT Error, and\nOthers) and a multioutput regression model to estimate their annual\nfrequencies. While classifier and regressor chains are implemented to explore\ndependencies among cyber incident types as well, no significant correlations\nare observed in our datasets. Besides, we apply multiple interpretable ML\ntechniques to identify and cross-validate potential risk factors developed by\nInsurTech across ML models. We find that InsurTech empowered features enhance\nprediction occurrence and frequency estimation robustness compared to only\nusing conventional risk factors. The framework generates transparent,\nentity-specific cyber risk profiles, supporting customized underwriting and\nproactive cyber risk mitigation. It provides insurers and organizations with\ndata-driven insights to support decision-making and compliance planning.",
    "categories": [
      "q-fin.RM",
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-07-10T22:04:00+00:00",
    "updated": "2025-07-14T22:21:11+00:00",
    "url": "http://arxiv.org/pdf/2507.08193v2"
  },
  {
    "id": "2507.06469v3",
    "title": "Mitigating Message Imbalance in Fraud Detection with Dual-View Graph Representation Learning",
    "authors": [
      "Yudan Song",
      "Yuecen Wei",
      "Yuhang Lu",
      "Qingyun Sun",
      "Minglai Shao",
      "Li-e Wang",
      "Chunming Hu",
      "Xianxian Li",
      "Xingcheng Fu"
    ],
    "abstract": "Graph representation learning has become a mainstream method for fraud\ndetection due to its strong expressive power, which focuses on enhancing node\nrepresentations through improved neighborhood knowledge capture. However, the\nfocus on local interactions leads to imbalanced transmission of global\ntopological information and increased risk of node-specific information being\noverwhelmed during aggregation due to the imbalance between fraud and benign\nnodes. In this paper, we first summarize the impact of topology and class\nimbalance on downstream tasks in GNN-based fraud detection, as the problem of\nimbalanced supervisory messages is caused by fraudsters' topological behavior\nobfuscation and identity feature concealment. Based on statistical validation,\nwe propose a novel dual-view graph representation learning method to mitigate\nMessage imbalance in Fraud Detection (MimbFD). Specifically, we design a\ntopological message reachability module for high-quality node representation\nlearning to penetrate fraudsters' camouflage and alleviate insufficient\npropagation. Then, we introduce a local confounding debiasing module to adjust\nnode representations, enhancing the stable association between node\nrepresentations and labels to balance the influence of different classes.\nFinally, we conducted experiments on three public fraud datasets, and the\nresults demonstrate that MimbFD exhibits outstanding performance in fraud\ndetection.",
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "published": "2025-07-09T01:00:55+00:00",
    "updated": "2025-09-04T15:01:28+00:00",
    "url": "http://arxiv.org/pdf/2507.06469v3"
  },
  {
    "id": "2507.08844v1",
    "title": "Immutability Does Not Guarantee Trust: A Formal and Logical Refutation",
    "authors": [
      "Craig S Wright"
    ],
    "abstract": "It is frequently claimed in blockchain discourse that immutability guarantees\ntrust. This paper rigorously refutes that assertion. We define immutability as\nthe cryptographic persistence of historical states in an append-only data\nstructure and contrast it with trust, understood as a rational epistemic\nexpectation under uncertainty. Employing predicate logic, automata-theoretic\nmodels, and epistemic game-theoretic analysis, we demonstrate that immutability\nneither entails nor implies correctness, fairness, or credibility. Through\nformal constructions and counterexamples--including predictive fraud schemes\nand the phenomenon of garbage permanence--we show that the belief conflates\nstructural and epistemic domains. Immutability preserves all data equally,\nregardless of veracity. Therefore, the assertion that immutability guarantees\ntrust collapses under the weight of formal scrutiny.",
    "categories": [
      "cs.CR",
      "cs.CC",
      "03B70, 68M10, 91A80",
      "F.4.1; D.4.6; C.2.2"
    ],
    "published": "2025-07-08T09:35:52+00:00",
    "updated": "2025-07-08T09:35:52+00:00",
    "url": "http://arxiv.org/pdf/2507.08844v1"
  },
  {
    "id": "2507.05636v1",
    "title": "Graph Learning",
    "authors": [
      "Feng Xia",
      "Ciyuan Peng",
      "Jing Ren",
      "Falih Gozi Febrinanto",
      "Renqiang Luo",
      "Vidya Saikrishna",
      "Shuo Yu",
      "Xiangjie Kong"
    ],
    "abstract": "Graph learning has rapidly evolved into a critical subfield of machine\nlearning and artificial intelligence (AI). Its development began with early\ngraph-theoretic methods, gaining significant momentum with the advent of graph\nneural networks (GNNs). Over the past decade, progress in scalable\narchitectures, dynamic graph modeling, multimodal learning, generative AI,\nexplainable AI (XAI), and responsible AI has broadened the applicability of\ngraph learning to various challenging environments. Graph learning is\nsignificant due to its ability to model complex, non-Euclidean relationships\nthat traditional machine learning struggles to capture, thus better supporting\nreal-world applications ranging from drug discovery and fraud detection to\nrecommender systems and scientific reasoning. However, challenges like\nscalability, generalization, heterogeneity, interpretability, and\ntrustworthiness must be addressed to unlock its full potential. This survey\nprovides a comprehensive introduction to graph learning, focusing on key\ndimensions including scalable, temporal, multimodal, generative, explainable,\nand responsible graph learning. We review state-of-the-art techniques for\nefficiently handling large-scale graphs, capturing dynamic temporal\ndependencies, integrating heterogeneous data modalities, generating novel graph\nsamples, and enhancing interpretability to foster trust and transparency. We\nalso explore ethical considerations, such as privacy and fairness, to ensure\nresponsible deployment of graph learning models. Additionally, we identify and\ndiscuss emerging topics, highlighting recent integration of graph learning and\nother AI paradigms and offering insights into future directions. This survey\nserves as a valuable resource for researchers and practitioners seeking to\nnavigate the rapidly evolving landscape of graph learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T09, 68R10",
      "I.2.6; G.2.2; E.1"
    ],
    "published": "2025-07-08T03:29:27+00:00",
    "updated": "2025-07-08T03:29:27+00:00",
    "url": "http://arxiv.org/pdf/2507.05636v1"
  },
  {
    "id": "2507.06266v1",
    "title": "Machine Learning based Enterprise Financial Audit Framework and High Risk Identification",
    "authors": [
      "Tingyu Yuan",
      "Xi Zhang",
      "Xuanjing Chen"
    ],
    "abstract": "In the face of global economic uncertainty, financial auditing has become\nessential for regulatory compliance and risk mitigation. Traditional manual\nauditing methods are increasingly limited by large data volumes, complex\nbusiness structures, and evolving fraud tactics. This study proposes an\nAI-driven framework for enterprise financial audits and high-risk\nidentification, leveraging machine learning to improve efficiency and accuracy.\nUsing a dataset from the Big Four accounting firms (EY, PwC, Deloitte, KPMG)\nfrom 2020 to 2025, the research examines trends in risk assessment, compliance\nviolations, and fraud detection. The dataset includes key indicators such as\naudit project counts, high-risk cases, fraud instances, compliance breaches,\nemployee workload, and client satisfaction, capturing both audit behaviors and\nAI's impact on operations. To build a robust risk prediction model, three\nalgorithms - Support Vector Machine (SVM), Random Forest (RF), and K-Nearest\nNeighbors (KNN) - are evaluated. SVM uses hyperplane optimization for complex\nclassification, RF combines decision trees to manage high-dimensional,\nnonlinear data with resistance to overfitting, and KNN applies distance-based\nlearning for flexible performance. Through hierarchical K-fold cross-validation\nand evaluation using F1-score, accuracy, and recall, Random Forest achieves the\nbest performance, with an F1-score of 0.9012, excelling in identifying fraud\nand compliance anomalies. Feature importance analysis reveals audit frequency,\npast violations, employee workload, and client ratings as key predictors. The\nstudy recommends adopting Random Forest as a core model, enhancing features via\nengineering, and implementing real-time risk monitoring. This research\ncontributes valuable insights into using machine learning for intelligent\nauditing and risk management in modern enterprises.",
    "categories": [
      "q-fin.RM",
      "cs.AI",
      "cs.LG",
      "stat.AP"
    ],
    "published": "2025-07-08T00:22:49+00:00",
    "updated": "2025-07-08T00:22:49+00:00",
    "url": "http://arxiv.org/pdf/2507.06266v1"
  },
  {
    "id": "2507.05441v1",
    "title": "Adversarial Machine Learning Attacks on Financial Reporting via Maximum Violated Multi-Objective Attack",
    "authors": [
      "Edward Raff",
      "Karen Kukla",
      "Michel Benaroch",
      "Joseph Comprix"
    ],
    "abstract": "Bad actors, primarily distressed firms, have the incentive and desire to\nmanipulate their financial reports to hide their distress and derive personal\ngains. As attackers, these firms are motivated by potentially millions of\ndollars and the availability of many publicly disclosed and used financial\nmodeling frameworks. Existing attack methods do not work on this data due to\nanti-correlated objectives that must both be satisfied for the attacker to\nsucceed. We introduce Maximum Violated Multi-Objective (MVMO) attacks that\nadapt the attacker's search direction to find $20\\times$ more satisfying\nattacks compared to standard attacks. The result is that in $\\approx50\\%$ of\ncases, a company could inflate their earnings by 100-200%, while simultaneously\nreducing their fraud scores by 15%. By working with lawyers and professional\naccountants, we ensure our threat model is realistic to how such frauds are\nperformed in practice.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-07-07T19:45:46+00:00",
    "updated": "2025-07-07T19:45:46+00:00",
    "url": "http://arxiv.org/pdf/2507.05441v1"
  },
  {
    "id": "2507.04061v3",
    "title": "Consistent and Invariant Generalization Learning for Short-video Misinformation Detection",
    "authors": [
      "Hanghui Guo",
      "Weijie Shi",
      "Mengze Li",
      "Juncheng Li",
      "Hao Chen",
      "Yue Cui",
      "Jiajie Xu",
      "Jia Zhu",
      "Jiawei Shen",
      "Zhangze Chen",
      "Sirui Han"
    ],
    "abstract": "Short-video misinformation detection has attracted wide attention in the\nmulti-modal domain, aiming to accurately identify the misinformation in the\nvideo format accompanied by the corresponding audio. Despite significant\nadvancements, current models in this field, trained on particular domains\n(source domains), often exhibit unsatisfactory performance on unseen domains\n(target domains) due to domain gaps. To effectively realize such domain\ngeneralization on the short-video misinformation detection task, we propose\ndeep insights into the characteristics of different domains: (1) The detection\non various domains may mainly rely on different modalities (i.e., mainly\nfocusing on videos or audios). To enhance domain generalization, it is crucial\nto achieve optimal model performance on all modalities simultaneously. (2) For\nsome domains focusing on cross-modal joint fraud, a comprehensive analysis\nrelying on cross-modal fusion is necessary. However, domain biases located in\neach modality (especially in each frame of videos) will be accumulated in this\nfusion process, which may seriously damage the final identification of\nmisinformation. To address these issues, we propose a new DOmain generalization\nmodel via ConsisTency and invariance learning for shORt-video misinformation\ndetection (named DOCTOR), which contains two characteristic modules: (1) We\ninvolve the cross-modal feature interpolation to map multiple modalities into a\nshared space and the interpolation distillation to synchronize multi-modal\nlearning; (2) We design the diffusion model to add noise to retain core\nfeatures of multi modal and enhance domain invariant features through\ncross-modal guided denoising. Extensive experiments demonstrate the\neffectiveness of our proposed DOCTOR model. Our code is public available at\nhttps://github.com/ghh1125/DOCTOR.",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "published": "2025-07-05T14:53:32+00:00",
    "updated": "2025-08-29T15:39:37+00:00",
    "url": "http://arxiv.org/pdf/2507.04061v3"
  },
  {
    "id": "2507.03457v1",
    "title": "Deepfakes in Criminal Investigations: Interdisciplinary Research Directions for CMC Research",
    "authors": [
      "Lorenz Meinen",
      "Astrid Schomäcker",
      "Stefanie Wiedemann",
      "Markus Hartmann",
      "Timo Speith",
      "Lena Kästner",
      "Niklas Kühl",
      "Christian Rückert"
    ],
    "abstract": "The emergence of deepfake technologies offers both opportunities and\nsignificant challenges. While commonly associated with deception,\nmisinformation, and fraud, deepfakes may also enable novel applications in\nhigh-stakes contexts such as criminal investigations. However, these\napplications raise complex technological, ethical, and legal questions. We\nadopt an interdisciplinary approach, drawing on computer science, philosophy,\nand law, to examine what it takes to responsibly use deepfakes in criminal\ninvestigations and argue that computer-mediated communication (CMC) research,\nespecially based on social media corpora, can provide crucial insights for\nunderstanding the potential harms and benefits of deepfakes. Our analysis\noutlines key research directions for the CMC community and underscores the need\nfor interdisciplinary collaboration in this evolving domain.",
    "categories": [
      "cs.CY"
    ],
    "published": "2025-07-04T10:22:50+00:00",
    "updated": "2025-07-04T10:22:50+00:00",
    "url": "http://arxiv.org/pdf/2507.03457v1"
  },
  {
    "id": "2507.01924v1",
    "title": "Exploring a Hybrid Deep Learning Approach for Anomaly Detection in Mental Healthcare Provider Billing: Addressing Label Scarcity through Semi-Supervised Anomaly Detection",
    "authors": [
      "Samirah Bakker",
      "Yao Ma",
      "Seyed Sahand Mohammadi Ziabari"
    ],
    "abstract": "The complexity of mental healthcare billing enables anomalies, including\nfraud. While machine learning methods have been applied to anomaly detection,\nthey often struggle with class imbalance, label scarcity, and complex\nsequential patterns. This study explores a hybrid deep learning approach\ncombining Long Short-Term Memory (LSTM) networks and Transformers, with\npseudo-labeling via Isolation Forests (iForest) and Autoencoders (AE). Prior\nwork has not evaluated such hybrid models trained on pseudo-labeled data in the\ncontext of healthcare billing. The approach is evaluated on two real-world\nbilling datasets related to mental healthcare. The iForest LSTM baseline\nachieves the highest recall (0.963) on declaration-level data. On the\noperation-level data, the hybrid iForest-based model achieves the highest\nrecall (0.744), though at the cost of lower precision. These findings highlight\nthe potential of combining pseudo-labeling with hybrid deep learning in\ncomplex, imbalanced anomaly detection settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-07-02T17:33:47+00:00",
    "updated": "2025-07-02T17:33:47+00:00",
    "url": "http://arxiv.org/pdf/2507.01924v1"
  },
  {
    "id": "2507.00907v1",
    "title": "The Age of Sensorial Zero Trust: Why We Can No Longer Trust Our Senses",
    "authors": [
      "Fabio Correa Xavier"
    ],
    "abstract": "In a world where deepfakes and cloned voices are emerging as sophisticated\nattack vectors, organizations require a new security mindset: Sensorial Zero\nTrust [9]. This article presents a scientific analysis of the need to\nsystematically doubt information perceived through the senses, establishing\nrigorous verification protocols to mitigate the risks of fraud based on\ngenerative artificial intelligence. Key concepts, such as Out-of-Band\nverification, Vision-Language Models (VLMs) as forensic collaborators,\ncryptographic provenance, and human training, are integrated into a framework\nthat extends Zero Trust principles to human sensory information. The approach\nis grounded in empirical findings and academic research, emphasizing that in an\nera of AI-generated realities, even our eyes and ears can no longer be\nimplicitly trusted without verification. Leaders are called to foster a culture\nof methodological skepticism to protect organizational integrity in this new\nthreat landscape.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "68T07, 68T45, 94A60",
      "K.6.5; D.4.6; I.2.6"
    ],
    "published": "2025-07-01T16:11:41+00:00",
    "updated": "2025-07-01T16:11:41+00:00",
    "url": "http://arxiv.org/pdf/2507.00907v1"
  },
  {
    "id": "2507.00827v1",
    "title": "A Technique for the Detection of PDF Tampering or Forgery",
    "authors": [
      "Gabriel Grobler",
      "Sheunesu Makura",
      "Hein Venter"
    ],
    "abstract": "Tampering or forgery of digital documents has become widespread, most\ncommonly through altering images without any malicious intent such as enhancing\nthe overall appearance of the image. However, there are occasions when\ntampering of digital documents can have negative consequences, such as\nfinancial fraud and reputational damage. Tampering can occur through altering a\ndigital document's text or editing an image's pixels. Many techniques have been\ndeveloped to detect whether changes have been made to a document. Most of these\ntechniques rely on generating hashes or watermarking the document. These\ntechniques, however, have limitations in that they cannot detect alterations to\nportable document format (PDF) signatures or other non-visual aspects, such as\nmetadata. This paper presents a new technique that can be used to detect\ntampering within a PDF document by utilizing the PDF document's file page\nobjects. The technique employs a prototype that can detect changes to a PDF\ndocument, such as changes made to the text, images, or metadata of the said\nfile.",
    "categories": [
      "cs.CR"
    ],
    "published": "2025-07-01T14:59:05+00:00",
    "updated": "2025-07-01T14:59:05+00:00",
    "url": "http://arxiv.org/pdf/2507.00827v1"
  },
  {
    "id": "2507.00096v1",
    "title": "AI-Governed Agent Architecture for Web-Trustworthy Tokenization of Alternative Assets",
    "authors": [
      "Ailiya Borjigin",
      "Wei Zhou",
      "Cong He"
    ],
    "abstract": "Alternative Assets tokenization is transforming non-traditional financial\ninstruments are represented and traded on the web. However, ensuring\ntrustworthiness in web-based tokenized ecosystems poses significant challenges,\nfrom verifying off-chain asset data to enforcing regulatory compliance. This\npaper proposes an AI-governed agent architecture that integrates intelligent\nagents with blockchain to achieve web-trustworthy tokenization of alternative\nassets. In the proposed architecture, autonomous agents orchestrate the\ntokenization process (asset verification, valuation, compliance checking, and\nlifecycle management), while an AI-driven governance layer monitors agent\nbehavior and enforces trust through adaptive policies and cryptoeconomic\nincentives. We demonstrate that this approach enhances transparency, security,\nand compliance in asset tokenization, addressing key concerns around data\nauthenticity and fraud. A case study on tokenizing real estate assets\nillustrates how the architecture mitigates risks (e.g., fraudulent listings and\nmoney laundering) through real-time AI anomaly detection and on-chain\nenforcement. Our evaluation and analysis suggest that combining AI governance\nwith multi-agent systems and blockchain can significantly bolster trust in\ntokenized asset ecosystems. This work offers a novel framework for trustworthy\nasset tokenization on the web and provides insights for practitioners aiming to\ndeploy secure, compliant tokenization platforms.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-06-30T11:28:51+00:00",
    "updated": "2025-06-30T11:28:51+00:00",
    "url": "http://arxiv.org/pdf/2507.00096v1"
  },
  {
    "id": "2506.22171v1",
    "title": "Proof-of-Behavior: Behavior-Driven Consensus for Trustworthy Decentralized Finance",
    "authors": [
      "Ailiya Borjigin",
      "Wei Zhou",
      "Cong He"
    ],
    "abstract": "Current blockchain protocols (e.g., Proof-of-Work and Proof-of-Stake) secure\nthe ledger yet cannot measure validator trustworthiness, allowing subtle\nmisconduct that is especially damaging in decentralized-finance (DeFi)\nsettings. We introduce Proof-of-Behavior (PoB), a consensus model that (i)\ngives each action a layered utility score -- covering motivation and outcome,\n(ii) adapts validator weights using recent scores, and (iii) applies\ndecentralized verification with proportional slashing. The reward design is\nincentive-compatible, yielding a Nash equilibrium in which honest behavior\nmaximizes long-run pay-offs. Simulated DeFi experiments (loan-fraud detection,\nreputation-weighted validation) show that PoB cuts fraud acceptance by more\nthan 90%, demotes malicious validators within two rounds, and improves proposer\nfairness versus standard PoS, all with no more than a 5% throughput overhead.\nBy linking consensus influence to verifiably trustworthy conduct, PoB offers a\nscalable, regulation-friendly foundation for secure and fair blockchain\ngovernance in financial applications.",
    "categories": [
      "cs.DC"
    ],
    "published": "2025-06-27T12:35:27+00:00",
    "updated": "2025-06-27T12:35:27+00:00",
    "url": "http://arxiv.org/pdf/2506.22171v1"
  },
  {
    "id": "2506.21443v1",
    "title": "Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection",
    "authors": [
      "Ali Şenol",
      "Garima Agrawal",
      "Huan Liu"
    ],
    "abstract": "Detecting deceptive conversations on dynamic platforms is increasingly\ndifficult due to evolving language patterns and Concept Drift (CD)-i.e.,\nsemantic or topical shifts that alter the context or intent of interactions\nover time. These shifts can obscure malicious intent or mimic normal dialogue,\nmaking accurate classification challenging. While Large Language Models (LLMs)\nshow strong performance in natural language tasks, they often struggle with\ncontextual ambiguity and hallucinations in risk-sensitive scenarios. To address\nthese challenges, we present a Domain Knowledge (DK)-Enhanced LLM framework\nthat integrates pretrained LLMs with structured, task-specific insights to\nperform fraud and concept drift detection. The proposed architecture consists\nof three main components: (1) a DK-LLM module to detect fake or deceptive\nconversations; (2) a drift detection unit (OCDD) to determine whether a\nsemantic shift has occurred; and (3) a second DK-LLM module to classify the\ndrift as either benign or fraudulent. We first validate the value of domain\nknowledge using a fake review dataset and then apply our full framework to\nSEConvo, a multiturn dialogue dataset that includes various types of fraud and\nspam attacks. Results show that our system detects fake conversations with high\naccuracy and effectively classifies the nature of drift. Guided by structured\nprompts, the LLaMA-based implementation achieves 98% classification accuracy.\nComparative studies against zero-shot baselines demonstrate that incorporating\ndomain knowledge and drift awareness significantly improves performance,\ninterpretability, and robustness in high-stakes NLP applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-06-26T16:29:45+00:00",
    "updated": "2025-06-26T16:29:45+00:00",
    "url": "http://arxiv.org/pdf/2506.21443v1"
  },
  {
    "id": "2506.21382v1",
    "title": "Temporal-Aware Graph Attention Network for Cryptocurrency Transaction Fraud Detection",
    "authors": [
      "Zhi Zheng",
      "Bochuan Zhou",
      "Yuping Song"
    ],
    "abstract": "Cryptocurrency transaction fraud detection faces the dual challenges of\nincreasingly complex transaction patterns and severe class imbalance.\nTraditional methods rely on manual feature engineering and struggle to capture\ntemporal and structural dependencies in transaction networks. This paper\nproposes an Augmented Temporal-aware Graph Attention Network (ATGAT) that\nenhances detection performance through three modules: (1) designing an advanced\ntemporal embedding module that fuses multi-scale time difference features with\nperiodic position encoding; (2) constructing a temporal-aware triple attention\nmechanism that jointly optimizes structural, temporal, and global context\nattention; (3) employing weighted BCE loss to address class imbalance.\nExperiments on the Elliptic++ cryptocurrency dataset demonstrate that ATGAT\nachieves an AUC of 0.9130, representing a 9.2% improvement over the best\ntraditional method XGBoost, 12.0% over GCN, and 10.0% over standard GAT. This\nmethod not only validates the enhancement effect of temporal awareness and\ntriple attention mechanisms on graph neural networks, but also provides\nfinancial institutions with more reliable fraud detection tools, with its\ndesign principles generalizable to other temporal graph anomaly detection\ntasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-06-26T15:34:06+00:00",
    "updated": "2025-06-26T15:34:06+00:00",
    "url": "http://arxiv.org/pdf/2506.21382v1"
  },
  {
    "id": "2506.20511v1",
    "title": "Collaborative Batch Size Optimization for Federated Learning",
    "authors": [
      "Arno Geimer",
      "Karthick Panner Selvam",
      "Beltran Fiz Pontiveros"
    ],
    "abstract": "Federated Learning (FL) is a decentralized collaborative Machine Learning\nframework for training models without collecting data in a centralized\nlocation. It has seen application across various disciplines, from helping\nmedical diagnoses in hospitals to detecting fraud in financial transactions. In\nthis paper, we focus on improving the local training process through hardware\nusage optimization. While participants in a federation might share the hardware\nthey are training on, since there is no information exchange between them,\ntheir training process can be hindered by an improper training configuration.\nTaking advantage of the parallel processing inherent to Federated Learning, we\nuse a greedy randomized search to optimize local batch sizes for the best\ntraining settings across all participants. Our results show that against\ndefault parameter settings, our method improves convergence speed while staying\nnearly on par with the case where local parameters are optimized.",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "published": "2025-06-25T14:57:23+00:00",
    "updated": "2025-06-25T14:57:23+00:00",
    "url": "http://arxiv.org/pdf/2506.20511v1"
  },
  {
    "id": "2507.01980v1",
    "title": "Detecting Fraud in Financial Networks: A Semi-Supervised GNN Approach with Granger-Causal Explanations",
    "authors": [
      "Linh Nguyen",
      "Marcel Boersma",
      "Erman Acar"
    ],
    "abstract": "Fraudulent activity in the financial industry costs billions annually.\nDetecting fraud, therefore, is an essential yet technically challenging task\nthat requires carefully analyzing large volumes of data. While machine learning\n(ML) approaches seem like a viable solution, applying them successfully is not\nso easy due to two main challenges: (1) the sparsely labeled data, which makes\nthe training of such approaches challenging (with inherent labeling costs), and\n(2) lack of explainability for the flagged items posed by the opacity of ML\nmodels, that is often required by business regulations. This article proposes\nSAGE-FIN, a semi-supervised graph neural network (GNN) based approach with\nGranger causal explanations for Financial Interaction Networks. SAGE-FIN learns\nto flag fraudulent items based on weakly labeled (or unlabelled) data points.\nTo adhere to regulatory requirements, the flagged items are explained by\nhighlighting related items in the network using Granger causality. We\nempirically validate the favorable performance of SAGE-FIN on a real-world\ndataset, Bipartite Edge-And-Node Attributed financial network (Elliptic++),\nwith Granger-causal explanations for the identified fraudulent items without\nany prior assumption on the network structure.",
    "categories": [
      "q-fin.ST",
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-06-25T12:04:40+00:00",
    "updated": "2025-06-25T12:04:40+00:00",
    "url": "http://arxiv.org/pdf/2507.01980v1"
  },
  {
    "id": "2507.02903v2",
    "title": "Harnessing Near-Infrared Spectroscopy and Machine Learning for Traceable Classification of Hanwoo and Holstein Beef",
    "authors": [
      "AMM Nurul Alam",
      "Abdul Samad",
      "AMM Shamsul Alam",
      "Jahan Ara Monti",
      "Ayesha Muazzam"
    ],
    "abstract": "This study evaluates the use of Near-Infrared spectroscopy (NIRS) combined\nwith advanced machine learning (ML) techniques to differentiate Hanwoo beef\n(HNB) and Holstein beef (HLB) to address food authenticity, mislabeling, and\nadulteration. Rapid and non-invasive spectral data were attained by a portable\nNIRS, recording absorbance data within the wavelength range of 700 to 1100 nm.\nA total of 40 Longissimus lumborum samples, evenly split between HNB and HLB,\nwere obtained from a local hypermarket. Data analysis using Principal Component\nAnalysis (PCA) demonstrated distinct spectral patterns associated with chemical\nchanges, clearly separating the two beef varieties and accounting for 93.72% of\nthe total variance. ML models, including Linear Discriminant Analysis (LDA),\nSupport Vector Machine (SVM), Logistic Regression (LR), Random Forest, Gradient\nBoosting (GB), K-Nearest Neighbors, Decision Tree (DT), Naive Bayes (NB), and\nNeural Networks (NN), were implemented, optimized through hyperparameter\ntuning, and validated by 5-fold cross-validation techniques to enhance model\nrobustness and prevent overfitting. Random Forest provided the highest\npredictive accuracy with a Receiver Operating Characteristic (ROC) Area Under\nthe Curve (AUC) of 0.8826, closely followed by the SVM model at 0.8747.\nFurthermore, GB and NN algorithms exhibited satisfactory performances, with\ncross-validation scores of 0.752. Notably, the NN model achieved the highest\nrecall rate of 0.7804, highlighting its suitability in scenarios requiring\nheightened sensitivity. DT and NB exhibited comparatively lower predictive\nperformance. The LR and SVM models emerged as optimal choices by effectively\nbalancing high accuracy, precision, and recall. This study confirms that\nintegrating NIRS with ML techniques offers a powerful and reliable method for\nmeat authenticity, significantly contributing to detecting food fraud.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-06-24T02:41:51+00:00",
    "updated": "2025-07-10T01:03:14+00:00",
    "url": "http://arxiv.org/pdf/2507.02903v2"
  },
  {
    "id": "2506.18787v1",
    "title": "3D Arena: An Open Platform for Generative 3D Evaluation",
    "authors": [
      "Dylan Ebert"
    ],
    "abstract": "Evaluating Generative 3D models remains challenging due to misalignment\nbetween automated metrics and human perception of quality. Current benchmarks\nrely on image-based metrics that ignore 3D structure or geometric measures that\nfail to capture perceptual appeal and real-world utility. To address this gap,\nwe present 3D Arena, an open platform for evaluating image-to-3D generation\nmodels through large-scale human preference collection using pairwise\ncomparisons.\n  Since launching in June 2024, the platform has collected 123,243 votes from\n8,096 users across 19 state-of-the-art models, establishing the largest human\npreference evaluation for Generative 3D. We contribute the iso3d dataset of 100\nevaluation prompts and demonstrate quality control achieving 99.75% user\nauthenticity through statistical fraud detection. Our ELO-based ranking system\nprovides reliable model assessment, with the platform becoming an established\nevaluation resource.\n  Through analysis of this preference data, we present insights into human\npreference patterns. Our findings reveal preferences for visual presentation\nfeatures, with Gaussian splat outputs achieving a 16.6 ELO advantage over\nmeshes and textured models receiving a 144.1 ELO advantage over untextured\nmodels. We provide recommendations for improving evaluation methods, including\nmulti-criteria assessment, task-oriented evaluation, and format-aware\ncomparison. The platform's community engagement establishes 3D Arena as a\nbenchmark for the field while advancing understanding of human-centered\nevaluation in Generative 3D.",
    "categories": [
      "cs.CV"
    ],
    "published": "2025-06-23T15:57:10+00:00",
    "updated": "2025-06-23T15:57:10+00:00",
    "url": "http://arxiv.org/pdf/2506.18787v1"
  },
  {
    "id": "2506.18942v1",
    "title": "Advanced Applications of Generative AI in Actuarial Science: Case Studies Beyond ChatGPT",
    "authors": [
      "Simon Hatzesberger",
      "Iris Nonneman"
    ],
    "abstract": "This article demonstrates the transformative impact of Generative AI (GenAI)\non actuarial science, illustrated by four implemented case studies. It begins\nwith a historical overview of AI, tracing its evolution from early neural\nnetworks to modern GenAI technologies. The first case study shows how Large\nLanguage Models (LLMs) improve claims cost prediction by deriving significant\nfeatures from unstructured textual data, significantly reducing prediction\nerrors in the underlying machine learning task. In the second case study, we\nexplore the automation of market comparisons using the GenAI concept of\nRetrieval-Augmented Generation to identify and process relevant information\nfrom documents. A third case study highlights the capabilities of fine-tuned\nvision-enabled LLMs in classifying car damage types and extracting contextual\ninformation. The fourth case study presents a multi-agent system that\nautonomously analyzes data from a given dataset and generates a corresponding\nreport detailing the key findings. In addition to these case studies, we\noutline further potential applications of GenAI in the insurance industry, such\nas the automation of claims processing and fraud detection, and the\nverification of document compliance with internal or external policies.\nFinally, we discuss challenges and considerations associated with the use of\nGenAI, covering regulatory issues, ethical concerns, and technical limitations,\namong others.",
    "categories": [
      "cs.CY",
      "q-fin.RM"
    ],
    "published": "2025-06-22T19:36:03+00:00",
    "updated": "2025-06-22T19:36:03+00:00",
    "url": "http://arxiv.org/pdf/2506.18942v1"
  },
  {
    "id": "2506.19871v1",
    "title": "An Attack Method for Medical Insurance Claim Fraud Detection based on Generative Adversarial Network",
    "authors": [
      "Yining Pang",
      "Chenghan Li"
    ],
    "abstract": "Insurance fraud detection represents a pivotal advancement in modern\ninsurance service, providing intelligent and digitalized monitoring to enhance\nmanagement and prevent fraud. It is crucial for ensuring the security and\nefficiency of insurance systems. Although AI and machine learning algorithms\nhave demonstrated strong performance in detecting fraudulent claims, the\nabsence of standardized defense mechanisms renders current systems vulnerable\nto emerging adversarial threats. In this paper, we propose a GAN-based approach\nto conduct adversarial attacks on fraud detection systems. Our results indicate\nthat an attacker, without knowledge of the training data or internal model\ndetails, can generate fraudulent cases that are classified as legitimate with a\n99\\% attack success rate (ASR). By subtly modifying real insurance records and\nclaims, adversaries can significantly increase the fraud risk, potentially\nbypassing compromised detection systems. These findings underscore the urgent\nneed to enhance the robustness of insurance fraud detection models against\nadversarial manipulation, thereby ensuring the stability and reliability of\ndifferent insurance systems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-06-22T05:02:45+00:00",
    "updated": "2025-06-22T05:02:45+00:00",
    "url": "http://arxiv.org/pdf/2506.19871v1"
  },
  {
    "id": "2506.19870v1",
    "title": "Secure Energy Transactions Using Blockchain Leveraging AI for Fraud Detection and Energy Market Stability",
    "authors": [
      "Md Asif Ul Hoq Khan",
      "MD Zahedul Islam",
      "Istiaq Ahmed",
      "Md Masud Karim Rabbi",
      "Farhana Rahman Anonna",
      "MD Abdul Fahim Zeeshan",
      "Mehedi Hasan Ridoy",
      "Bivash Ranjan Chowdhury",
      "Md Nazmul Shakir Rabbi",
      "GM Alamin Sadnan"
    ],
    "abstract": "Peer-to-peer trading and the move to decentralized grids have reshaped the\nenergy markets in the United States. Notwithstanding, such developments lead to\nnew challenges, mainly regarding the safety and authenticity of energy trade.\nThis study aimed to develop and build a secure, intelligent, and efficient\nenergy transaction system for the decentralized US energy market. This research\ninterlinks the technological prowess of blockchain and artificial intelligence\n(AI) in a novel way to solve long-standing challenges in the distributed energy\nmarket, specifically those of security, fraudulent behavior detection, and\nmarket reliability. The dataset for this research is comprised of more than 1.2\nmillion anonymized energy transaction records from a simulated peer-to-peer\n(P2P) energy exchange network emulating real-life blockchain-based American\nmicrogrids, including those tested by LO3 Energy and Grid+ Labs. Each record\ncontains detailed fields of transaction identifier, timestamp, energy volume\n(kWh), transaction type (buy/sell), unit price, prosumer/consumer identifier\n(hashed for privacy), smart meter readings, geolocation regions, and settlement\nconfirmation status. The dataset also includes system-calculated behavior\nmetrics of transaction rate, variability of energy production, and historical\npricing patterns. The system architecture proposed involves the integration of\ntwo layers, namely a blockchain layer and artificial intelligence (AI) layer,\neach playing a unique but complementary function in energy transaction securing\nand market intelligence improvement. The machine learning models used in this\nresearch were specifically chosen for their established high performance in\nclassification tasks, specifically in the identification of energy transaction\nfraud in decentralized markets.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-06-21T21:09:29+00:00",
    "updated": "2025-06-21T21:09:29+00:00",
    "url": "http://arxiv.org/pdf/2506.19870v1"
  },
  {
    "id": "2506.16121v1",
    "title": "On the Efficient Discovery of Maximum $k$-Defective Biclique",
    "authors": [
      "Donghang Cui",
      "Ronghua Li",
      "Qiangqiang Dai",
      "Hongchao Qin",
      "Guoren Wang"
    ],
    "abstract": "The problem of identifying the maximum edge biclique in bipartite graphs has\nattracted considerable attention in bipartite graph analysis, with numerous\nreal-world applications such as fraud detection, community detection, and\nonline recommendation systems. However, real-world graphs may contain noise or\nincomplete information, leading to overly restrictive conditions when employing\nthe biclique model. To mitigate this, we focus on a new relaxed subgraph model,\ncalled the $k$-defective biclique, which allows for up to $k$ missing edges\ncompared to the biclique model. We investigate the problem of finding the\nmaximum edge $k$-defective biclique in a bipartite graph, and prove that the\nproblem is NP-hard. To tackle this computation challenge, we propose a novel\nalgorithm based on a new branch-and-bound framework, which achieves a\nworst-case time complexity of $O(m\\alpha_k^n)$, where $\\alpha_k < 2$. We\nfurther enhance this framework by incorporating a novel pivoting technique,\nreducing the worst-case time complexity to $O(m\\beta_k^n)$, where $\\beta_k <\n\\alpha_k$. To improve the efficiency, we develop a series of optimization\ntechniques, including graph reduction methods, novel upper bounds, and a\nheuristic approach. Extensive experiments on 10 large real-world datasets\nvalidate the efficiency and effectiveness of the proposed approaches. The\nresults indicate that our algorithms consistently outperform state-of-the-art\nalgorithms, offering up to $1000\\times$ speedups across various parameter\nsettings.",
    "categories": [
      "cs.DS"
    ],
    "published": "2025-06-19T08:12:09+00:00",
    "updated": "2025-06-19T08:12:09+00:00",
    "url": "http://arxiv.org/pdf/2506.16121v1"
  },
  {
    "id": "2506.15325v1",
    "title": "Human-Centred AI in FinTech: Developing a User Experience (UX) Research Point of View (PoV) Playbook",
    "authors": [
      "Festus Adedoyin",
      "Huseyin Dogan"
    ],
    "abstract": "Advancements in Artificial Intelligence (AI) have significantly transformed\nthe financial industry, enabling the development of more personalised and\nadaptable financial products and services. This research paper explores various\ninstances where Human-Centred AI (HCAI) has facilitated these advancements,\ndrawing from contemporary studies and industry progress. The paper examines how\nthe application of HCAI-powered data analytics, machine learning, and natural\nlanguage processing enables financial institutions to gain a deeper\nunderstanding of their customers' unique needs, preferences, and behavioural\npatterns. This, in turn, allows for the creation of tailored financial\nsolutions that address individual consumer requirements, ultimately enhancing\noverall user experience and satisfaction. Additionally, the study highlights\nthe integration of AI-powered robo-advisory services, which offer customised\ninvestment recommendations and portfolio management tailored to diverse risk\nprofiles and investment goals. Moreover, the paper underscores the role of AI\nin strengthening fraud detection, risk assessment, and regulatory compliance,\nleading to a more secure and adaptable financial landscape. The findings of\nthis research demonstrate the substantial impact of Human-Centred AI on the\nfinancial industry, offering a strategic framework for financial institutions\nto leverage these technologies. By incorporating a User Experience Research\n(UXR) Point of View (PoV), financial institutions can ensure that AI-driven\nsolutions align with user needs and business objectives.",
    "categories": [
      "cs.HC"
    ],
    "published": "2025-06-18T09:53:51+00:00",
    "updated": "2025-06-18T09:53:51+00:00",
    "url": "http://arxiv.org/pdf/2506.15325v1"
  },
  {
    "id": "2506.13313v1",
    "title": "Large Language Models as 'Hidden Persuaders': Fake Product Reviews are Indistinguishable to Humans and Machines",
    "authors": [
      "Weiyao Meng",
      "John Harvey",
      "James Goulding",
      "Chris James Carter",
      "Evgeniya Lukinova",
      "Andrew Smith",
      "Paul Frobisher",
      "Mina Forrest",
      "Georgiana Nica-Avram"
    ],
    "abstract": "Reading and evaluating product reviews is central to how most people decide\nwhat to buy and consume online. However, the recent emergence of Large Language\nModels and Generative Artificial Intelligence now means writing fraudulent or\nfake reviews is potentially easier than ever. Through three studies we\ndemonstrate that (1) humans are no longer able to distinguish between real and\nfake product reviews generated by machines, averaging only 50.8% accuracy\noverall - essentially the same that would be expected by chance alone; (2) that\nLLMs are likewise unable to distinguish between fake and real reviews and\nperform equivalently bad or even worse than humans; and (3) that humans and\nLLMs pursue different strategies for evaluating authenticity which lead to\nequivalently bad accuracy, but different precision, recall and F1 scores -\nindicating they perform worse at different aspects of judgment. The results\nreveal that review systems everywhere are now susceptible to mechanised fraud\nif they do not depend on trustworthy purchase verification to guarantee the\nauthenticity of reviewers. Furthermore, the results provide insight into the\nconsumer psychology of how humans judge authenticity, demonstrating there is an\ninherent 'scepticism bias' towards positive reviews and a special vulnerability\nto misjudge the authenticity of fake negative reviews. Additionally, results\nprovide a first insight into the 'machine psychology' of judging fake reviews,\nrevealing that the strategies LLMs take to evaluate authenticity radically\ndiffer from humans, in ways that are equally wrong in terms of accuracy, but\ndifferent in their misjudgments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "econ.GN",
      "q-fin.EC",
      "J.4; I.2.7"
    ],
    "published": "2025-06-16T09:54:56+00:00",
    "updated": "2025-06-16T09:54:56+00:00",
    "url": "http://arxiv.org/pdf/2506.13313v1"
  },
  {
    "id": "2508.09320v1",
    "title": "Exact Verification of Graph Neural Networks with Incremental Constraint Solving",
    "authors": [
      "Minghao Liu",
      "Chia-Hsuan Lu",
      "Marta Kwiatkowska"
    ],
    "abstract": "Graph neural networks (GNNs) are increasingly employed in high-stakes\napplications, such as fraud detection or healthcare, but are susceptible to\nadversarial attacks. A number of techniques have been proposed to provide\nadversarial robustness guarantees, but support for commonly used aggregation\nfunctions in message-passing GNNs is still lacking. In this paper, we develop\nan exact (sound and complete) verification method for GNNs to compute\nguarantees against attribute and structural perturbations that involve edge\naddition or deletion, subject to budget constraints. Focusing on node\nclassification tasks, our method employs constraint solving with bound\ntightening, and iteratively solves a sequence of relaxed constraint\nsatisfaction problems while relying on incremental solving capabilities of\nsolvers to improve efficiency. We implement GNNev, a versatile solver for\nmessage-passing neural networks, which supports three aggregation functions,\nsum, max and mean, with the latter two considered here for the first time.\nExtensive experimental evaluation of GNNev on two standard benchmarks (Cora and\nCiteSeer) and two real-world fraud datasets (Amazon and Yelp) demonstrates its\nusability and effectiveness, as well as superior performance compared to\nexisting {exact verification} tools on sum-aggregated node classification\ntasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2025-08-12T20:10:31+00:00",
    "updated": "2025-08-12T20:10:31+00:00",
    "url": "http://arxiv.org/pdf/2508.09320v1"
  },
  {
    "id": "2508.09237v1",
    "title": "Blockchain Network Analysis using Quantum Inspired Graph Neural Networks & Ensemble Models",
    "authors": [
      "Luigi D'Amico",
      "Daniel De Rosso",
      "Ninad Dixit",
      "Raul Salles de Padua",
      "Samuel Palmer",
      "Samuel Mugel",
      "Román Orús",
      "Holger Eble",
      "Ali Abedi"
    ],
    "abstract": "In the rapidly evolving domain of financial technology, the detection of\nillicit transactions within blockchain networks remains a critical challenge,\nnecessitating robust and innovative solutions. This work proposes a novel\napproach by combining Quantum Inspired Graph Neural Networks (QI-GNN) with\nflexibility of choice of an Ensemble Model using QBoost or a classic model such\nas Random Forrest Classifier. This system is tailored specifically for\nblockchain network analysis in anti-money laundering (AML) efforts. Our\nmethodology to design this system incorporates a novel component, a Canonical\nPolyadic (CP) decomposition layer within the graph neural network framework,\nenhancing its capability to process and analyze complex data structures\nefficiently. Our technical approach has undergone rigorous evaluation against\nclassical machine learning implementations, achieving an F2 score of 74.8% in\ndetecting fraudulent transactions. These results highlight the potential of\nquantum-inspired techniques, supplemented by the structural advancements of the\nCP layer, to not only match but potentially exceed traditional methods in\ncomplex network analysis for financial security. The findings advocate for a\nbroader adoption and further exploration of quantum-inspired algorithms within\nthe financial sector to effectively combat fraud.",
    "categories": [
      "cs.LG",
      "quant-ph"
    ],
    "published": "2025-08-12T12:11:43+00:00",
    "updated": "2025-08-12T12:11:43+00:00",
    "url": "http://arxiv.org/pdf/2508.09237v1"
  },
  {
    "id": "2508.07495v1",
    "title": "Decomposing Global AUC into Cluster-Level Contributions for Localized Model Diagnostics",
    "authors": [
      "Agus Sudjianto",
      "Alice J. Liu"
    ],
    "abstract": "The Area Under the ROC Curve (AUC) is a widely used performance metric for\nbinary classifiers. However, as a global ranking statistic, the AUC aggregates\nmodel behavior over the entire dataset, masking localized weaknesses in\nspecific subpopulations. In high-stakes applications such as credit approval\nand fraud detection, these weaknesses can lead to financial risk or operational\nfailures. In this paper, we introduce a formal decomposition of global AUC into\nintra- and inter-cluster components. This allows practitioners to evaluate\nclassifier performance within and across clusters of data, enabling granular\ndiagnostics and subgroup analysis. We also compare the AUC with additive\nperformance metrics such as the Brier score and log loss, which support\ndecomposability and direct attribution. Our framework enhances model\ndevelopment and validation practice by providing additional insights to detect\nmodel weakness for model risk management.",
    "categories": [
      "stat.AP",
      "stat.ML"
    ],
    "published": "2025-08-10T21:58:47+00:00",
    "updated": "2025-08-10T21:58:47+00:00",
    "url": "http://arxiv.org/pdf/2508.07495v1"
  },
  {
    "id": "2508.06655v1",
    "title": "The Vertex-Attribute-Constrained Densest $k$-Subgraph Problem",
    "authors": [
      "Qiheng Lu",
      "Nicholas D. Sidiropoulos",
      "Aritra Konar"
    ],
    "abstract": "Dense subgraph mining is a fundamental technique in graph mining, commonly\napplied in fraud detection, community detection, product recommendation, and\ndocument summarization. In such applications, we are often interested in\nidentifying communities, recommendations, or summaries that reflect different\nconstituencies, styles or genres, and points of view. For this task, we\nintroduce a new variant of the Densest $k$-Subgraph (D$k$S) problem that\nincorporates the attribute values of vertices. The proposed\nVertex-Attribute-Constrained Densest $k$-Subgraph (VAC-D$k$S) problem retains\nthe NP-hardness and inapproximability properties of the classical D$k$S.\nNevertheless, we prove that a suitable continuous relaxation of VAC-D$k$S is\ntight and can be efficiently tackled using a projection-free Frank--Wolfe\nalgorithm. We also present an insightful analysis of the optimization landscape\nof the relaxed problem. Extensive experimental results demonstrate the\neffectiveness of our proposed formulation and algorithm, and its ability to\nscale up to large graphs. We further elucidate the properties of VAC-D$k$S\nversus classical D$k$S in a political network mining application, where\nVAC-D$k$S identifies a balanced and more meaningful set of politicians\nrepresenting different ideological camps, in contrast to the classical D$k$S\nsolution which is unbalanced and rather mundane.",
    "categories": [
      "cs.SI",
      "cs.DS"
    ],
    "published": "2025-08-08T19:12:59+00:00",
    "updated": "2025-08-08T19:12:59+00:00",
    "url": "http://arxiv.org/pdf/2508.06655v1"
  },
  {
    "id": "2508.06457v1",
    "title": "ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls",
    "authors": [
      "Sanket Badhe"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive fluency and\nreasoning capabilities, but their potential for misuse has raised growing\nconcern. In this paper, we present ScamAgent, an autonomous multi-turn agent\nbuilt on top of LLMs, capable of generating highly realistic scam call scripts\nthat simulate real-world fraud scenarios. Unlike prior work focused on\nsingle-shot prompt misuse, ScamAgent maintains dialogue memory, adapts\ndynamically to simulated user responses, and employs deceptive persuasion\nstrategies across conversational turns. We show that current LLM safety\nguardrails, including refusal mechanisms and content filters, are ineffective\nagainst such agent-based threats. Even models with strong prompt-level\nsafeguards can be bypassed when prompts are decomposed, disguised, or delivered\nincrementally within an agent framework. We further demonstrate the\ntransformation of scam scripts into lifelike voice calls using modern\ntext-to-speech systems, completing a fully automated scam pipeline. Our\nfindings highlight an urgent need for multi-turn safety auditing, agent-level\ncontrol frameworks, and new methods to detect and disrupt conversational\ndeception powered by generative AI.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "published": "2025-08-08T17:01:41+00:00",
    "updated": "2025-08-08T17:01:41+00:00",
    "url": "http://arxiv.org/pdf/2508.06457v1"
  },
  {
    "id": "2508.05334v1",
    "title": "ShikkhaChain: A Blockchain-Powered Academic Credential Verification System for Bangladesh",
    "authors": [
      "Ahsan Farabi",
      "Israt Khandaker",
      "Nusrat Jahan",
      "Ibrahim Khalil Shanto"
    ],
    "abstract": "Academic credential fraud threatens educational integrity, especially in\ndeveloping countries like Bangladesh, where verification methods are primarily\nmanual and inefficient. To address this challenge, we present ShikkhaChain, a\nblockchain-powered certificate management platform designed to securely issue,\nverify, and revoke academic credentials in a decentralized and tamper-proof\nmanner. Built on Ethereum smart contracts and utilizing IPFS for off-chain\nstorage, the platform offers a transparent, scalable solution accessible\nthrough a React-based DApp with MetaMask integration. ShikkhaChain enables\nrole-based access for governments, regulators, institutions, and public\nverifiers, allowing QR-based validation and on-chain revocation tracking. Our\nprototype demonstrates enhanced trust, reduced verification time, and improved\ninternational credibility for Bangladeshi degrees, promoting a more reliable\nacademic and employment ecosystem.",
    "categories": [
      "cs.CR"
    ],
    "published": "2025-08-07T12:35:12+00:00",
    "updated": "2025-08-07T12:35:12+00:00",
    "url": "http://arxiv.org/pdf/2508.05334v1"
  },
  {
    "id": "2508.06574v1",
    "title": "Semi-Supervised Supply Chain Fraud Detection with Unsupervised Pre-Filtering",
    "authors": [
      "Fatemeh Moradi",
      "Mehran Tarif",
      "Mohammadhossein Homaei"
    ],
    "abstract": "Detecting fraud in modern supply chains is a growing challenge, driven by the\ncomplexity of global networks and the scarcity of labeled data. Traditional\ndetection methods often struggle with class imbalance and limited supervision,\nreducing their effectiveness in real-world applications. This paper proposes a\nnovel two-phase learning framework to address these challenges. In the first\nphase, the Isolation Forest algorithm performs unsupervised anomaly detection\nto identify potential fraud cases and reduce the volume of data requiring\nfurther analysis. In the second phase, a self-training Support Vector Machine\n(SVM) refines the predictions using both labeled and high-confidence\npseudo-labeled samples, enabling robust semi-supervised learning. The proposed\nmethod is evaluated on the DataCo Smart Supply Chain Dataset, a comprehensive\nreal-world supply chain dataset with fraud indicators. It achieves an F1-score\nof 0.817 while maintaining a false positive rate below 3.0%. These results\ndemonstrate the effectiveness and efficiency of combining unsupervised\npre-filtering with semi-supervised refinement for supply chain fraud detection\nunder real-world constraints, though we acknowledge limitations regarding\nconcept drift and the need for comparison with deep learning approaches.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2025-08-07T11:25:09+00:00",
    "updated": "2025-08-07T11:25:09+00:00",
    "url": "http://arxiv.org/pdf/2508.06574v1"
  },
  {
    "id": "2508.04542v1",
    "title": "Privacy Risk Predictions Based on Fundamental Understanding of Personal Data and an Evolving Threat Landscape",
    "authors": [
      "Haoran Niu",
      "K. Suzanne Barber"
    ],
    "abstract": "It is difficult for individuals and organizations to protect personal\ninformation without a fundamental understanding of relative privacy risks. By\nanalyzing over 5,000 empirical identity theft and fraud cases, this research\nidentifies which types of personal data are exposed, how frequently exposures\noccur, and what the consequences of those exposures are. We construct an\nIdentity Ecosystem graph--a foundational, graph-based model in which nodes\nrepresent personally identifiable information (PII) attributes and edges\nrepresent empirical disclosure relationships between them (e.g., the\nprobability that one PII attribute is exposed due to the exposure of another).\nLeveraging this graph structure, we develop a privacy risk prediction framework\nthat uses graph theory and graph neural networks to estimate the likelihood of\nfurther disclosures when certain PII attributes are compromised. The results\nshow that our approach effectively answers the core question: Can the\ndisclosure of a given identity attribute possibly lead to the disclosure of\nanother attribute?",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.SI"
    ],
    "published": "2025-08-06T15:30:07+00:00",
    "updated": "2025-08-06T15:30:07+00:00",
    "url": "http://arxiv.org/pdf/2508.04542v1"
  },
  {
    "id": "2508.04129v1",
    "title": "SVC 2025: the First Multimodal Deception Detection Challenge",
    "authors": [
      "Xun Lin",
      "Xiaobao Guo",
      "Taorui Wang",
      "Yingjie Ma",
      "Jiajian Huang",
      "Jiayu Zhang",
      "Junzhe Cao",
      "Zitong Yu"
    ],
    "abstract": "Deception detection is a critical task in real-world applications such as\nsecurity screening, fraud prevention, and credibility assessment. While deep\nlearning methods have shown promise in surpassing human-level performance,\ntheir effectiveness often depends on the availability of high-quality and\ndiverse deception samples. Existing research predominantly focuses on\nsingle-domain scenarios, overlooking the significant performance degradation\ncaused by domain shifts. To address this gap, we present the SVC 2025\nMultimodal Deception Detection Challenge, a new benchmark designed to evaluate\ncross-domain generalization in audio-visual deception detection. Participants\nare required to develop models that not only perform well within individual\ndomains but also generalize across multiple heterogeneous datasets. By\nleveraging multimodal data, including audio, video, and text, this challenge\nencourages the design of models capable of capturing subtle and implicit\ndeceptive cues. Through this benchmark, we aim to foster the development of\nmore adaptable, explainable, and practically deployable deception detection\nsystems, advancing the broader field of multimodal learning. By the conclusion\nof the workshop competition, a total of 21 teams had submitted their final\nresults. https://sites.google.com/view/svc-mm25 for more information.",
    "categories": [
      "cs.CV"
    ],
    "published": "2025-08-06T06:56:39+00:00",
    "updated": "2025-08-06T06:56:39+00:00",
    "url": "http://arxiv.org/pdf/2508.04129v1"
  },
  {
    "id": "2508.03251v1",
    "title": "Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning",
    "authors": [
      "Osama Mohammed",
      "Jiaxin Pan",
      "Mojtaba Nayyeri",
      "Daniel Hernández",
      "Steffen Staab"
    ],
    "abstract": "Modeling evolving interactions among entities is critical in many real-world\ntasks. For example, predicting driver maneuvers in traffic requires tracking\nhow neighboring vehicles accelerate, brake, and change lanes relative to one\nanother over consecutive frames. Likewise, detecting financial fraud hinges on\nfollowing the flow of funds through successive transactions as they propagate\nthrough the network. Unlike classic time-series forecasting, these settings\ndemand reasoning over who interacts with whom and when, calling for a\ntemporal-graph representation that makes both the relations and their evolution\nexplicit. Existing temporal-graph methods typically use snapshot graphs to\nencode temporal evolution. We introduce a full-history graph that instantiates\none node for every entity at every time step and separates two edge sets: (i)\nintra-time-step edges that capture relations within a single frame and (ii)\ninter-time-step edges that connect an entity to itself at consecutive steps. To\nlearn on this graph we design an Edge-Type Decoupled Network (ETDNet) with\nparallel modules: a graph-attention module aggregates information along\nintra-time-step edges, a multi-head temporal-attention module attends over an\nentity's inter-time-step history, and a fusion module combines the two messages\nafter every layer. Evaluated on driver-intention prediction (Waymo) and Bitcoin\nfraud detection (Elliptic++), ETDNet consistently surpasses strong baselines,\nlifting Waymo joint accuracy to 75.6\\% (vs. 74.1\\%) and raising Elliptic++\nillicit-class F1 to 88.1\\% (vs. 60.4\\%). These gains demonstrate the benefit of\nrepresenting structural and temporal relations as distinct edges in a single\ngraph.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-08-05T09:29:07+00:00",
    "updated": "2025-08-05T09:29:07+00:00",
    "url": "http://arxiv.org/pdf/2508.03251v1"
  },
  {
    "id": "2508.02283v1",
    "title": "An Enhanced Focal Loss Function to Mitigate Class Imbalance in Auto Insurance Fraud Detection with Explainable AI",
    "authors": [
      "Francis Boabang",
      "Samuel Asante Gyamerah"
    ],
    "abstract": "In insurance fraud prediction, handling class imbalance remains a critical\nchallenge. This paper presents a novel multistage focal loss function designed\nto enhance the performance of machine learning models in such imbalanced\nsettings by helping to escape local minima and converge to a good solution.\nBuilding upon the foundation of the standard focal loss, our proposed approach\nintroduces a dynamic, multi-stage convex and nonconvex mechanism that\nprogressively adjusts the focus on hard-to-classify samples across training\nepochs. This strategic refinement facilitates more stable learning and improved\ndiscrimination between fraudulent and legitimate cases. Through extensive\nexperimentation on a real-world insurance dataset, our method achieved better\nperformance than the traditional focal loss, as measured by accuracy,\nprecision, F1-score, recall and Area Under the Curve (AUC) metrics on the auto\ninsurance dataset. These results demonstrate the efficacy of the multistage\nfocal loss in boosting model robustness and predictive accuracy in highly\nskewed classification tasks, offering significant implications for fraud\ndetection systems in the insurance industry. An explainable model is included\nto interpret the results.",
    "categories": [
      "cs.LG",
      "q-fin.CP",
      "q-fin.RM"
    ],
    "published": "2025-08-04T10:53:10+00:00",
    "updated": "2025-08-04T10:53:10+00:00",
    "url": "http://arxiv.org/pdf/2508.02283v1"
  },
  {
    "id": "2507.23267v1",
    "title": "Your Spending Needs Attention: Modeling Financial Habits with Transformers",
    "authors": [
      "D. T. Braithwaite",
      "Misael Cavalcanti",
      "R. Austin McEver",
      "Hiroto Udagawa",
      "Daniel Silva",
      "Rohan Ramanath",
      "Felipe Meneses",
      "Arissa Yoshida",
      "Evan Wingert",
      "Matheus Ramos",
      "Brian Zanfelice",
      "Aman Gupta"
    ],
    "abstract": "Predictive models play a crucial role in the financial industry, enabling\nrisk prediction, fraud detection, and personalized recommendations, where\nslight changes in core model performance can result in billions of dollars in\nrevenue or losses. While financial institutions have access to enormous amounts\nof user data (e.g., bank transactions, in-app events, and customer support\nlogs), leveraging this data effectively remains challenging due to its\ncomplexity and scale. Thus, in many financial institutions, most production\nmodels follow traditional machine learning (ML) approaches by converting\nunstructured data into manually engineered tabular features. Conversely, other\ndomains (e.g., natural language processing) have effectively utilized\nself-supervised learning (SSL) to learn rich representations from raw data,\nremoving the need for manual feature extraction. In this paper, we investigate\nusing transformer-based representation learning models for transaction data,\nhypothesizing that these models, trained on massive data, can provide a novel\nand powerful approach to understanding customer behavior. We propose a new\nmethod enabling the use of SSL with transaction data by adapting\ntransformer-based models to handle both textual and structured attributes. Our\napproach, denoted nuFormer, includes an end-to-end fine-tuning method that\nintegrates user embeddings with existing tabular features. Our experiments\ndemonstrate improvements for large-scale recommendation problems at Nubank.\nNotably, these gains are achieved solely through enhanced representation\nlearning rather than incorporating new data sources.",
    "categories": [
      "cs.IR"
    ],
    "published": "2025-07-31T05:56:21+00:00",
    "updated": "2025-07-31T05:56:21+00:00",
    "url": "http://arxiv.org/pdf/2507.23267v1"
  },
  {
    "id": "2507.22347v1",
    "title": "Benchmarking Fraud Detectors on Private Graph Data",
    "authors": [
      "Alexander Goldberg",
      "Giulia Fanti",
      "Nihar Shah",
      "Zhiwei Steven Wu"
    ],
    "abstract": "We introduce the novel problem of benchmarking fraud detectors on private\ngraph-structured data. Currently, many types of fraud are managed in part by\nautomated detection algorithms that operate over graphs. We consider the\nscenario where a data holder wishes to outsource development of fraud detectors\nto third parties (e.g., vendors or researchers). The third parties submit their\nfraud detectors to the data holder, who evaluates these algorithms on a private\ndataset and then publicly communicates the results. We propose a realistic\nprivacy attack on this system that allows an adversary to de-anonymize\nindividuals' data based only on the evaluation results. In simulations of a\nprivacy-sensitive benchmark for facial recognition algorithms by the National\nInstitute of Standards and Technology (NIST), our attack achieves near perfect\naccuracy in identifying whether individuals' data is present in a private\ndataset, with a True Positive Rate of 0.98 at a False Positive Rate of 0.00. We\nthen study how to benchmark algorithms while satisfying a formal differential\nprivacy (DP) guarantee. We empirically evaluate two classes of solutions:\nsubsample-and-aggregate and DP synthetic graph data. We demonstrate through\nextensive experiments that current approaches do not provide utility when\nguaranteeing DP. Our results indicate that the error arising from DP trades off\nbetween bias from distorting graph structure and variance from adding random\nnoise. Current methods lie on different points along this bias-variance\ntrade-off, but more complex methods tend to require high-variance noise\naddition, undermining utility.",
    "categories": [
      "cs.CR"
    ],
    "published": "2025-07-30T03:20:15+00:00",
    "updated": "2025-07-30T03:20:15+00:00",
    "url": "http://arxiv.org/pdf/2507.22347v1"
  },
  {
    "id": "2507.22153v1",
    "title": "Towards Privacy-preserving Photorealistic Self-avatars in Mixed Reality",
    "authors": [
      "Ethan Wilson",
      "Vincent Bindschaedler",
      "Sophie Jörg",
      "Sean Sheikholeslam",
      "Kevin Butler",
      "Eakta Jain"
    ],
    "abstract": "Photorealistic 3D avatar generation has rapidly improved in recent years, and\nrealistic avatars that match a user's true appearance are more feasible in\nMixed Reality (MR) than ever before. Yet, there are known risks to sharing\none's likeness online, and photorealistic MR avatars could exacerbate these\nrisks. If user likenesses were to be shared broadly, there are risks for cyber\nabuse or targeted fraud based on user appearances. We propose an alternate\navatar rendering scheme for broader social MR -- synthesizing realistic avatars\nthat preserve a user's demographic identity while being distinct enough from\nthe individual user to protect facial biometric information. We introduce a\nmethodology for privatizing appearance by isolating identity within the feature\nspace of identity-encoding generative models. We develop two algorithms that\nthen obfuscate identity: \\epsmethod{} provides differential privacy guarantees\nand \\thetamethod{} provides fine-grained control for the level of identity\noffset. These methods are shown to successfully generate de-identified virtual\navatars across multiple generative architectures in 2D and 3D. With these\ntechniques, it is possible to protect user privacy while largely preserving\nattributes related to sense of self. Employing these techniques in public\nsettings could enable the use of photorealistic avatars broadly in MR,\nmaintaining high realism and immersion without privacy risk.",
    "categories": [
      "cs.HC",
      "cs.CR"
    ],
    "published": "2025-07-29T18:37:24+00:00",
    "updated": "2025-07-29T18:37:24+00:00",
    "url": "http://arxiv.org/pdf/2507.22153v1"
  },
  {
    "id": "2508.02702v1",
    "title": "Evaluating Transfer Learning Methods on Real-World Data Streams: A Case Study in Financial Fraud Detection",
    "authors": [
      "Ricardo Ribeiro Pereira",
      "Jacopo Bono",
      "Hugo Ferreira",
      "Pedro Ribeiro",
      "Carlos Soares",
      "Pedro Bizarro"
    ],
    "abstract": "When the available data for a target domain is limited, transfer learning\n(TL) methods can be used to develop models on related data-rich domains, before\ndeploying them on the target domain. However, these TL methods are typically\ndesigned with specific, static assumptions on the amount of available labeled\nand unlabeled target data. This is in contrast with many real world\napplications, where the availability of data and corresponding labels varies\nover time. Since the evaluation of the TL methods is typically also performed\nunder the same static data availability assumptions, this would lead to\nunrealistic expectations concerning their performance in real world settings.\nTo support a more realistic evaluation and comparison of TL algorithms and\nmodels, we propose a data manipulation framework that (1) simulates varying\ndata availability scenarios over time, (2) creates multiple domains through\nresampling of a given dataset and (3) introduces inter-domain variability by\napplying realistic domain transformations, e.g., creating a variety of\npotentially time-dependent covariate and concept shifts. These capabilities\nenable simulation of a large number of realistic variants of the experiments,\nin turn providing more information about the potential behavior of algorithms\nwhen deployed in dynamic settings. We demonstrate the usefulness of the\nproposed framework by performing a case study on a proprietary real-world suite\nof card payment datasets. Given the confidential nature of the case study, we\nalso illustrate the use of the framework on the publicly available Bank Account\nFraud (BAF) dataset. By providing a methodology for evaluating TL methods over\ntime and in realistic data availability scenarios, our framework facilitates\nunderstanding of the behavior of models and algorithms. This leads to better\ndecision making when deploying models for new domains in real-world\nenvironments.",
    "categories": [
      "q-fin.ST",
      "cs.LG"
    ],
    "published": "2025-07-29T14:12:21+00:00",
    "updated": "2025-07-29T14:12:21+00:00",
    "url": "http://arxiv.org/pdf/2508.02702v1"
  },
  {
    "id": "2507.21653v1",
    "title": "DGP: A Dual-Granularity Prompting Framework for Fraud Detection with Graph-Enhanced LLMs",
    "authors": [
      "Yuan Li",
      "Jun Hu",
      "Bryan Hooi",
      "Bingsheng He",
      "Cheng Chen"
    ],
    "abstract": "Real-world fraud detection applications benefit from graph learning\ntechniques that jointly exploit node features, often rich in textual data, and\ngraph structural information. Recently, Graph-Enhanced LLMs emerge as a\npromising graph learning approach that converts graph information into prompts,\nexploiting LLMs' ability to reason over both textual and structural\ninformation. Among them, text-only prompting, which converts graph information\nto prompts consisting solely of text tokens, offers a solution that relies only\non LLM tuning without requiring additional graph-specific encoders. However,\ntext-only prompting struggles on heterogeneous fraud-detection graphs:\nmulti-hop relations expand exponentially with each additional hop, leading to\nrapidly growing neighborhoods associated with dense textual information. These\nneighborhoods may overwhelm the model with long, irrelevant content in the\nprompt and suppress key signals from the target node, thereby degrading\nperformance. To address this challenge, we propose Dual Granularity Prompting\n(DGP), which mitigates information overload by preserving fine-grained textual\ndetails for the target node while summarizing neighbor information into\ncoarse-grained text prompts. DGP introduces tailored summarization strategies\nfor different data modalities, bi-level semantic abstraction for textual fields\nand statistical aggregation for numerical features, enabling effective\ncompression of verbose neighbor content into concise, informative prompts.\nExperiments across public and industrial datasets demonstrate that DGP operates\nwithin a manageable token budget while improving fraud detection performance by\nup to 6.8% (AUPRC) over state-of-the-art methods, showing the potential of\nGraph-Enhanced LLMs for fraud detection.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-07-29T10:10:47+00:00",
    "updated": "2025-07-29T10:10:47+00:00",
    "url": "http://arxiv.org/pdf/2507.21653v1"
  },
  {
    "id": "2507.20441v1",
    "title": "TIMEST: Temporal Information Motif Estimator Using Sampling Trees",
    "authors": [
      "Yunjie Pan",
      "Omkar Bhalerao",
      "C. Seshadhri",
      "Nishil Talati"
    ],
    "abstract": "The mining of pattern subgraphs, known as motifs, is a core task in the field\nof graph mining. Edges in real-world networks often have timestamps, so there\nis a need for temporal motif mining. A temporal motif is a richer structure\nthat imposes timing constraints on the edges of the motif. Temporal motifs have\nbeen used to analyze social networks, financial transactions, and biological\nnetworks.\n  Motif counting in temporal graphs is particularly challenging. A graph with\nmillions of edges can have trillions of temporal motifs, since the same edge\ncan occur with multiple timestamps. There is a combinatorial explosion of\npossibilities, and state-of-the-art algorithms cannot manage motifs with more\nthan four vertices.\n  In this work, we present TIMEST: a general, fast, and accurate estimation\nalgorithm to count temporal motifs of arbitrary sizes in temporal networks. Our\napproach introduces a temporal spanning tree sampler that leverages weighted\nsampling to generate substructures of target temporal motifs. This method\ncarefully takes a subset of temporal constraints of the motif that can be\njointly and efficiently sampled. TIMEST uses randomized estimation techniques\nto obtain accurate estimates of motif counts.\n  We give theoretical guarantees on the running time and approximation\nguarantees of TIMEST. We perform an extensive experimental evaluation and show\nthat TIMEST is both faster and more accurate than previous algorithms. Our CPU\nimplementation exhibits an average speedup of 28x over state-of-the-art GPU\nimplementation of the exact algorithm, and 6x speedup over SOTA approximate\nalgorithms while consistently showcasing less than 5% error in most cases. For\nexample, TIMEST can count the number of instances of a financial fraud temporal\nmotif in four minutes with 0.6% error, while exact methods take more than two\ndays.",
    "categories": [
      "cs.DB",
      "cs.DS",
      "cs.IR"
    ],
    "published": "2025-07-27T23:31:55+00:00",
    "updated": "2025-07-27T23:31:55+00:00",
    "url": "http://arxiv.org/pdf/2507.20441v1"
  },
  {
    "id": "2507.19402v1",
    "title": "FD4QC: Application of Classical and Quantum-Hybrid Machine Learning for Financial Fraud Detection A Technical Report",
    "authors": [
      "Matteo Cardaioli",
      "Luca Marangoni",
      "Giada Martini",
      "Francesco Mazzolin",
      "Luca Pajola",
      "Andrea Ferretto Parodi",
      "Alessandra Saitta",
      "Maria Chiara Vernillo"
    ],
    "abstract": "The increasing complexity and volume of financial transactions pose\nsignificant challenges to traditional fraud detection systems. This technical\nreport investigates and compares the efficacy of classical, quantum, and\nquantum-hybrid machine learning models for the binary classification of\nfraudulent financial activities.\n  As of our methodology, first, we develop a comprehensive behavioural feature\nengineering framework to transform raw transactional data into a rich,\ndescriptive feature set. Second, we implement and evaluate a range of models on\nthe IBM Anti-Money Laundering (AML) dataset. The classical baseline models\ninclude Logistic Regression, Decision Tree, Random Forest, and XGBoost. These\nare compared against three hybrid classic quantum algorithms architectures: a\nQuantum Support Vector Machine (QSVM), a Variational Quantum Classifier (VQC),\nand a Hybrid Quantum Neural Network (HQNN).\n  Furthermore, we propose Fraud Detection for Quantum Computing (FD4QC), a\npractical, API-driven system architecture designed for real-world deployment,\nfeaturing a classical-first, quantum-enhanced philosophy with robust fallback\nmechanisms.\n  Our results demonstrate that classical tree-based models, particularly\n\\textit{Random Forest}, significantly outperform the quantum counterparts in\nthe current setup, achieving high accuracy (\\(97.34\\%\\)) and F-measure\n(\\(86.95\\%\\)). Among the quantum models, \\textbf{QSVM} shows the most promise,\ndelivering high precision (\\(77.15\\%\\)) and a low false-positive rate\n(\\(1.36\\%\\)), albeit with lower recall and significant computational overhead.\n  This report provides a benchmark for a real-world financial application,\nhighlights the current limitations of quantum machine learning in this domain,\nand outlines promising directions for future research.",
    "categories": [
      "cs.LG",
      "cs.CE"
    ],
    "published": "2025-07-25T16:08:22+00:00",
    "updated": "2025-07-25T16:08:22+00:00",
    "url": "http://arxiv.org/pdf/2507.19402v1"
  },
  {
    "id": "2507.21150v1",
    "title": "WaveVerify: A Novel Audio Watermarking Framework for Media Authentication and Combatting Deepfakes",
    "authors": [
      "Aditya Pujari",
      "Ajita Rattani"
    ],
    "abstract": "The rapid advancement of voice generation technologies has enabled the\nsynthesis of speech that is perceptually indistinguishable from genuine human\nvoices. While these innovations facilitate beneficial applications such as\npersonalized text-to-speech systems and voice preservation, they have also\nintroduced significant risks, including deepfake impersonation scams and\nsynthetic media-driven disinformation campaigns. Recent reports indicate that\nin 2024, deepfake fraud attempts surged by over 1,300% compared to 2023,\nunderscoring the urgent need for robust audio content authentication. The\nfinancial sector has been particularly impacted, with a loss of over 10 million\nUSD to voice scams and individual victims reporting losses exceeding $6,000\nfrom AI-generated deepfake calls. In response, regulators and governments\nworldwide are enacting measures to improve AI content transparency and\ntraceability, emphasizing the development of forensic tools and watermarking\ntechniques as essential strategies to uphold media integrity.",
    "categories": [
      "cs.CR"
    ],
    "published": "2025-07-23T21:16:08+00:00",
    "updated": "2025-07-23T21:16:08+00:00",
    "url": "http://arxiv.org/pdf/2507.21150v1"
  },
  {
    "id": "2507.17543v2",
    "title": "Anticipate, Simulate, Reason (ASR): A Comprehensive Generative AI Framework for Combating Messaging Scams",
    "authors": [
      "Xue Wen Tan",
      "Kenneth See",
      "Stanley Kok"
    ],
    "abstract": "The rapid growth of messaging scams creates an escalating challenge for user\nsecurity and financial safety. In this paper, we present the\n\\textit{Anticipate, Simulate, Reason} (ASR) generative AI framework to enable\nusers to proactively identify and comprehend scams within instant messaging\nplatforms. Using large language models, ASR predicts scammer responses and\ndelivers real-time, interpretable support to end-users. We also develop\nScamGPT-J, a domain-specific language model fine-tuned on a new, high-quality\ndataset of scam conversations covering multiple scam types. Thorough\nexperimental evaluation shows that the ASR framework substantially enhances\nscam detection, particularly in challenging contexts such as job scams, and\nuncovers important demographic patterns in user vulnerability and perceptions\nof AI-generated assistance. Our findings reveal a contradiction where those\nmost at risk are often least receptive to AI support, emphasizing the\nimportance of user-centered design in AI-driven fraud prevention. This work\nadvances both the practical and theoretical foundations for interpretable and\nhuman-centered AI systems in combating evolving digital threats.",
    "categories": [
      "cs.HC"
    ],
    "published": "2025-07-23T14:20:09+00:00",
    "updated": "2025-07-25T03:01:39+00:00",
    "url": "http://arxiv.org/pdf/2507.17543v2"
  },
  {
    "id": "2507.16419v1",
    "title": "Improving Predictions on Highly Unbalanced Data Using Open Source Synthetic Data Upsampling",
    "authors": [
      "Ivona Krchova",
      "Michael Platzer",
      "Paul Tiwald"
    ],
    "abstract": "Unbalanced tabular data sets present significant challenges for predictive\nmodeling and data analysis across a wide range of applications. In many\nreal-world scenarios, such as fraud detection, medical diagnosis, and rare\nevent prediction, minority classes are vastly underrepresented, making it\ndifficult for traditional machine learning algorithms to achieve high accuracy.\nThese algorithms tend to favor the majority class, leading to biased models\nthat struggle to accurately represent minority classes. Synthetic data holds\npromise for addressing the under-representation of minority classes by\nproviding new, diverse, and highly realistic samples. This paper presents a\nbenchmark study on the use of AI-generated synthetic data for upsampling highly\nunbalanced tabular data sets.\n  We evaluate the effectiveness of an open-source solution, the Synthetic Data\nSDK by MOSTLY AI, which provides a flexible and user-friendly approach to\nsynthetic upsampling for mixed-type data. We compare predictive models trained\non data sets upsampled with synthetic records to those using standard methods,\nsuch as naive oversampling and SMOTE-NC. Our results demonstrate that synthetic\ndata can improve predictive accuracy for minority groups by generating diverse\ndata points that fill gaps in sparse regions of the feature space. We show that\nupsampled synthetic training data consistently results in top-performing\npredictive models, particularly for mixed-type data sets containing very few\nminority samples.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-07-22T10:11:32+00:00",
    "updated": "2025-07-22T10:11:32+00:00",
    "url": "http://arxiv.org/pdf/2507.16419v1"
  },
  {
    "id": "2507.16276v1",
    "title": "From Contracts to Code: Automating Smart Contract Generation with Multi-Level Finite State Machines",
    "authors": [
      "Lambard Maxence",
      "Bertelle Cyrille",
      "Duvallet Claude"
    ],
    "abstract": "In an increasingly complex contractual landscape, the demand for\ntransparency, security, and efficiency has intensified. Blockchain technology,\nwith its decentralized and immutable nature, addresses these challenges by\nreducing intermediary costs, minimizing fraud risks, and enhancing system\ncompatibility. Smart contracts, initially conceptualized by Nick Szabo and\nlater implemented on the Ethereum blockchain, automate and secure contractual\nclauses, offering a robust solution for various industries. However, their\ncomplexity and the requirement for advanced programming skills present\nsignificant barriers to widespread adoption. This study introduces a\nmulti-level finite state machine model designed to represent and track the\nexecution of smart contracts. Our model aims to simplify smart contract\ndevelopment by providing a formalized framework that abstracts underlying\ntechnical complexities, making it accessible to professionals without deep\ntechnical expertise. The hierarchical structure of the multi-level finite state\nmachine enhances contract modularity and traceability, facilitating detailed\nrepresentation and evaluation of functional properties. The paper explores the\npotential of this multi-level approach, reviewing existing methodologies and\ntools, and detailing the smart contract generation process with an emphasis on\nreusable components and modularity. We also conduct a security analysis to\nevaluate potential vulnerabilities in our model, ensuring the robustness and\nreliability of the generated smart contracts.",
    "categories": [
      "cs.CR"
    ],
    "published": "2025-07-22T06:41:30+00:00",
    "updated": "2025-07-22T06:41:30+00:00",
    "url": "http://arxiv.org/pdf/2507.16276v1"
  },
  {
    "id": "2507.16247v1",
    "title": "PRAC3 (Privacy, Reputation, Accountability, Consent, Credit, Compensation): Long Tailed Risks of Voice Actors in AI Data-Economy",
    "authors": [
      "Tanusree Sharma",
      "Yihao Zhou",
      "Visar Berisha"
    ],
    "abstract": "Early large-scale audio datasets, such as LibriSpeech, were built with\nhundreds of individual contributors whose voices were instrumental in the\ndevelopment of speech technologies, including audiobooks and voice assistants.\nYet, a decade later, these same contributions have exposed voice actors to a\nrange of risks. While existing ethical frameworks emphasize Consent, Credit,\nand Compensation (C3), they do not adequately address the emergent risks\ninvolving vocal identities that are increasingly decoupled from context,\nauthorship, and control. Drawing on qualitative interviews with 20 professional\nvoice actors, this paper reveals how the synthetic replication of voice without\nenforceable constraints exposes individuals to a range of threats. Beyond\nreputational harm, such as re-purposing voice data in erotic content, offensive\npolitical messaging, and meme culture, we document concerns about\naccountability breakdowns when their voice is leveraged to clone voices that\nare deployed in high-stakes scenarios such as financial fraud, misinformation\ncampaigns, or impersonation scams. In such cases, actors face social and legal\nfallout without recourse, while very few of them have a legal representative or\nunion protection. To make sense of these shifting dynamics, we introduce the\nPRAC3 framework, an expansion of C3 that foregrounds Privacy, Reputation,\nAccountability, Consent, Credit, and Compensation as interdependent pillars of\ndata used in the synthetic voice economy. This framework captures how privacy\nrisks are amplified through non-consensual training, how reputational harm\narises from decontextualized deployment, and how accountability can be\nreimagined AI Data ecosystems. We argue that voice, as both a biometric\nidentifier and creative labor, demands governance models that restore creator\nagency, ensure traceability, and establish enforceable boundaries for ethical\nreuse.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "published": "2025-07-22T05:39:39+00:00",
    "updated": "2025-07-22T05:39:39+00:00",
    "url": "http://arxiv.org/pdf/2507.16247v1"
  },
  {
    "id": "2507.15419v1",
    "title": "PhishIntentionLLM: Uncovering Phishing Website Intentions through Multi-Agent Retrieval-Augmented Generation",
    "authors": [
      "Wenhao Li",
      "Selvakumar Manickam",
      "Yung-wey Chong",
      "Shankar Karuppayah"
    ],
    "abstract": "Phishing websites remain a major cybersecurity threat, yet existing methods\nprimarily focus on detection, while the recognition of underlying malicious\nintentions remains largely unexplored. To address this gap, we propose\nPhishIntentionLLM, a multi-agent retrieval-augmented generation (RAG) framework\nthat uncovers phishing intentions from website screenshots. Leveraging the\nvisual-language capabilities of large language models (LLMs), our framework\nidentifies four key phishing objectives: Credential Theft, Financial Fraud,\nMalware Distribution, and Personal Information Harvesting. We construct and\nrelease the first phishing intention ground truth dataset (~2K samples) and\nevaluate the framework using four commercial LLMs. Experimental results show\nthat PhishIntentionLLM achieves a micro-precision of 0.7895 with GPT-4o and\nsignificantly outperforms the single-agent baseline with a ~95% improvement in\nmicro-precision. Compared to the previous work, it achieves 0.8545 precision\nfor credential theft, marking a ~4% improvement. Additionally, we generate a\nlarger dataset of ~9K samples for large-scale phishing intention profiling\nacross sectors. This work provides a scalable and interpretable solution for\nintention-aware phishing analysis.",
    "categories": [
      "cs.CR"
    ],
    "published": "2025-07-21T09:20:43+00:00",
    "updated": "2025-07-21T09:20:43+00:00",
    "url": "http://arxiv.org/pdf/2507.15419v1"
  },
  {
    "id": "2507.14813v1",
    "title": "Mayura: Exploiting Similarities in Motifs for Temporal Co-Mining",
    "authors": [
      "Sanjay Sri Vallabh Singapuram",
      "Ronald Dreslinski",
      "Nishil Talati"
    ],
    "abstract": "Temporal graphs serve as a critical foundation for modeling evolving\ninteractions in domains ranging from financial networks to social media. Mining\ntemporal motifs is essential for applications such as fraud detection,\ncybersecurity, and dynamic network analysis. However, conventional motif mining\napproaches treat each query independently, incurring significant redundant\ncomputations when similar substructures exist across multiple motifs. In this\npaper, we propose Mayura, a novel framework that unifies the mining of multiple\ntemporal motifs by exploiting their inherent structural and temporal\ncommonalities. Central to our approach is the Motif-Group Tree (MG-Tree), a\nhierarchical data structure that organizes related motifs and enables the reuse\nof common search paths, thereby reducing redundant computation. We propose a\nco-mining algorithm that leverages the MG-Tree and develop a flexible runtime\ncapable of exploiting both CPU and GPU architectures for scalable performance.\nEmpirical evaluations on diverse real-world datasets demonstrate that Mayura\nachieves substantial improvements over the state-of-the-art techniques that\nmine each motif individually, with an average speed-up of 2.4x on the CPU and\n1.7x on the GPU, while maintaining the exactness required for high-stakes\napplications.",
    "categories": [
      "cs.DB",
      "cs.DC",
      "cs.PF"
    ],
    "published": "2025-07-20T04:02:24+00:00",
    "updated": "2025-07-20T04:02:24+00:00",
    "url": "http://arxiv.org/pdf/2507.14813v1"
  },
  {
    "id": "2507.14706v1",
    "title": "Fraud is Not Just Rarity: A Causal Prototype Attention Approach to Realistic Synthetic Oversampling",
    "authors": [
      "Claudio Giusti",
      "Luca Guarnera",
      "Mirko Casu",
      "Sebastiano Battiato"
    ],
    "abstract": "Detecting fraudulent credit card transactions remains a significant\nchallenge, due to the extreme class imbalance in real-world data and the often\nsubtle patterns that separate fraud from legitimate activity. Existing research\ncommonly attempts to address this by generating synthetic samples for the\nminority class using approaches such as GANs, VAEs, or hybrid generative\nmodels. However, these techniques, particularly when applied only to\nminority-class data, tend to result in overconfident classifiers and poor\nlatent cluster separation, ultimately limiting real-world detection\nperformance. In this study, we propose the Causal Prototype Attention\nClassifier (CPAC), an interpretable architecture that promotes class-aware\nclustering and improved latent space structure through prototype-based\nattention mechanisms and we will couple it with the encoder in a VAE-GAN\nallowing it to offer a better cluster separation moving beyond post-hoc sample\naugmentation. We compared CPAC-augmented models to traditional oversamplers,\nsuch as SMOTE, as well as to state-of-the-art generative models, both with and\nwithout CPAC-based latent classifiers. Our results show that classifier-guided\nlatent shaping with CPAC delivers superior performance, achieving an F1-score\nof 93.14\\% percent and recall of 90.18\\%, along with improved latent cluster\nseparation. Further ablation studies and visualizations provide deeper insight\ninto the benefits and limitations of classifier-driven representation learning\nfor fraud detection. The codebase for this work will be available at final\nsubmission.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-07-19T17:51:54+00:00",
    "updated": "2025-07-19T17:51:54+00:00",
    "url": "http://arxiv.org/pdf/2507.14706v1"
  },
  {
    "id": "2507.14660v2",
    "title": "When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems",
    "authors": [
      "Qibing Ren",
      "Sitao Xie",
      "Longxuan Wei",
      "Zhenfei Yin",
      "Junchi Yan",
      "Lizhuang Ma",
      "Jing Shao"
    ],
    "abstract": "Recent large-scale events like election fraud and financial scams have shown\nhow harmful coordinated efforts by human groups can be. With the rise of\nautonomous AI systems, there is growing concern that AI-driven groups could\nalso cause similar harm. While most AI safety research focuses on individual AI\nsystems, the risks posed by multi-agent systems (MAS) in complex real-world\nsituations are still underexplored. In this paper, we introduce a\nproof-of-concept to simulate the risks of malicious MAS collusion, using a\nflexible framework that supports both centralized and decentralized\ncoordination structures. We apply this framework to two high-risk fields:\nmisinformation spread and e-commerce fraud. Our findings show that\ndecentralized systems are more effective at carrying out malicious actions than\ncentralized ones. The increased autonomy of decentralized systems allows them\nto adapt their strategies and cause more damage. Even when traditional\ninterventions, like content flagging, are applied, decentralized groups can\nadjust their tactics to avoid detection. We present key insights into how these\nmalicious groups operate and the need for better detection systems and\ncountermeasures. Code is available at https://github.com/renqibing/RogueAgent.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-07-19T15:17:30+00:00",
    "updated": "2025-07-24T06:00:02+00:00",
    "url": "http://arxiv.org/pdf/2507.14660v2"
  },
  {
    "id": "2507.16840v1",
    "title": "CASPER: Contrastive Approach for Smart Ponzi Scheme Detecter with More Negative Samples",
    "authors": [
      "Weijia Yang",
      "Tian Lan",
      "Leyuan Liu",
      "Wei Chen",
      "Tianqing Zhu",
      "Sheng Wen",
      "Xiaosong Zhang"
    ],
    "abstract": "The rapid evolution of digital currency trading, fueled by the integration of\nblockchain technology, has led to both innovation and the emergence of smart\nPonzi schemes. A smart Ponzi scheme is a fraudulent investment operation in\nsmart contract that uses funds from new investors to pay returns to earlier\ninvestors. Traditional Ponzi scheme detection methods based on deep learning\ntypically rely on fully supervised models, which require large amounts of\nlabeled data. However, such data is often scarce, hindering effective model\ntraining. To address this challenge, we propose a novel contrastive learning\nframework, CASPER (Contrastive Approach for Smart Ponzi detectER with more\nnegative samples), designed to enhance smart Ponzi scheme detection in\nblockchain transactions. By leveraging contrastive learning techniques, CASPER\ncan learn more effective representations of smart contract source code using\nunlabeled datasets, significantly reducing both operational costs and system\ncomplexity. We evaluate CASPER on the XBlock dataset, where it outperforms the\nbaseline by 2.3% in F1 score when trained with 100% labeled data. More\nimpressively, with only 25% labeled data, CASPER achieves an F1 score nearly\n20% higher than the baseline under identical experimental conditions. These\nresults highlight CASPER's potential for effective and cost-efficient detection\nof smart Ponzi schemes, paving the way for scalable fraud detection solutions\nin the future.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-07-19T01:26:02+00:00",
    "updated": "2025-07-19T01:26:02+00:00",
    "url": "http://arxiv.org/pdf/2507.16840v1"
  },
  {
    "id": "2507.14324v1",
    "title": "Quantum-Safe Identity Verification using Relativistic Zero-Knowledge Proof Systems",
    "authors": [
      "Yao Ma",
      "Wen Yu Kon",
      "Jefferson Chu",
      "Kevin Han Yong Loh",
      "Kaushik Chakraborty",
      "Charles Lim"
    ],
    "abstract": "Identity verification is the process of confirming an individual's claimed\nidentity, which is essential in sectors like finance, healthcare, and online\nservices to ensure security and prevent fraud. However, current\npassword/PIN-based identity solutions are susceptible to phishing or skimming\nattacks, where malicious intermediaries attempt to steal credentials using fake\nidentification portals. Alikhani et al. [Nature, 2021] began exploring identity\nverification through graph coloring-based relativistic zero-knowledge proofs\n(RZKPs), a key cryptographic primitive that enables a prover to demonstrate\nknowledge of secret credentials to a verifier without disclosing any\ninformation about the secret. Our work advances this field and addresses\nunresolved issues: From an engineering perspective, we relax further the\nrelativistic constraints from 60m to 30m, and significantly enhance the\nstability and scalability of the experimental demonstration of the 2-prover\ngraph coloring-based RZKP protocol for near-term use cases. At the same time,\nfor long-term security against entangled malicious provers, we propose a\nmodified protocol with comparable computation and communication costs, we\nestablish an upper bound on the soundness parameter for this modified protocol.\nOn the other hand, we extend the two-prover, two-verifier setup to a\nthree-prover configuration, demonstrating the security of such relativistic\nprotocols against entangled malicious provers.",
    "categories": [
      "cs.CR",
      "quant-ph"
    ],
    "published": "2025-07-18T18:59:19+00:00",
    "updated": "2025-07-18T18:59:19+00:00",
    "url": "http://arxiv.org/pdf/2507.14324v1"
  },
  {
    "id": "2507.12932v1",
    "title": "Enkidu: Universal Frequential Perturbation for Real-Time Audio Privacy Protection against Voice Deepfakes",
    "authors": [
      "Zhou Feng",
      "Jiahao Chen",
      "Chunyi Zhou",
      "Yuwen Pu",
      "Qingming Li",
      "Tianyu Du",
      "Shouling Ji"
    ],
    "abstract": "The rapid advancement of voice deepfake technologies has raised serious\nconcerns about user audio privacy, as attackers increasingly exploit publicly\navailable voice data to generate convincing fake audio for malicious purposes\nsuch as identity theft, financial fraud, and misinformation campaigns. While\nexisting defense methods offer partial protection, they face critical\nlimitations, including weak adaptability to unseen user data, poor scalability\nto long audio, rigid reliance on white-box knowledge, and high computational\nand temporal costs during the encryption process. To address these challenges\nand defend against personalized voice deepfake threats, we propose Enkidu, a\nnovel user-oriented privacy-preserving framework that leverages universal\nfrequential perturbations generated through black-box knowledge and few-shot\ntraining on a small amount of user data. These highly malleable\nfrequency-domain noise patches enable real-time, lightweight protection with\nstrong generalization across variable-length audio and robust resistance to\nvoice deepfake attacks, all while preserving perceptual quality and speech\nintelligibility. Notably, Enkidu achieves over 50 to 200 times processing\nmemory efficiency (as low as 0.004 gigabytes) and 3 to 7000 times runtime\nefficiency (real-time coefficient as low as 0.004) compared to six\nstate-of-the-art countermeasures. Extensive experiments across six mainstream\ntext-to-speech models and five cutting-edge automated speaker verification\nmodels demonstrate the effectiveness, transferability, and practicality of\nEnkidu in defending against both vanilla and adaptive voice deepfake attacks.",
    "categories": [
      "cs.SD",
      "cs.MM"
    ],
    "published": "2025-07-17T09:12:36+00:00",
    "updated": "2025-07-17T09:12:36+00:00",
    "url": "http://arxiv.org/pdf/2507.12932v1"
  },
  {
    "id": "2507.12295v1",
    "title": "Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding",
    "authors": [
      "Feng Xiao",
      "Jicong Fan"
    ],
    "abstract": "Text anomaly detection is a critical task in natural language processing\n(NLP), with applications spanning fraud detection, misinformation\nidentification, spam detection and content moderation, etc. Despite significant\nadvances in large language models (LLMs) and anomaly detection algorithms, the\nabsence of standardized and comprehensive benchmarks for evaluating the\nexisting anomaly detection methods on text data limits rigorous comparison and\ndevelopment of innovative approaches. This work performs a comprehensive\nempirical study and introduces a benchmark for text anomaly detection,\nleveraging embeddings from diverse pre-trained language models across a wide\narray of text datasets. Our work systematically evaluates the effectiveness of\nembedding-based text anomaly detection by incorporating (1) early language\nmodels (GloVe, BERT); (2) multiple LLMs (LLaMa-2, LLama-3, Mistral, OpenAI\n(small, ada, large)); (3) multi-domain text datasets (news, social media,\nscientific publications); (4) comprehensive evaluation metrics (AUROC, AUPRC).\nOur experiments reveal a critical empirical insight: embedding quality\nsignificantly governs anomaly detection efficacy, and deep learning-based\napproaches demonstrate no performance advantage over conventional shallow\nalgorithms (e.g., KNN, Isolation Forest) when leveraging LLM-derived\nembeddings.In addition, we observe strongly low-rank characteristics in\ncross-model performance matrices, which enables an efficient strategy for rapid\nmodel evaluation (or embedding evaluation) and selection in practical\napplications. Furthermore, by open-sourcing our benchmark toolkit that includes\nall embeddings from different models and code at\nhttps://github.com/jicongfan/Text-Anomaly-Detection-Benchmark, this work\nprovides a foundation for future research in robust and scalable text anomaly\ndetection systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-07-16T14:47:41+00:00",
    "updated": "2025-07-16T14:47:41+00:00",
    "url": "http://arxiv.org/pdf/2507.12295v1"
  },
  {
    "id": "2507.11997v1",
    "title": "Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection",
    "authors": [
      "Tairan Huang",
      "Yili Wang"
    ],
    "abstract": "Graph fraud detection has garnered significant attention as Graph Neural\nNetworks (GNNs) have proven effective in modeling complex relationships within\nmultimodal data. However, existing graph fraud detection methods typically use\npreprocessed node embeddings and predefined graph structures to reveal\nfraudsters, which ignore the rich semantic cues contained in raw textual\ninformation. Although Large Language Models (LLMs) exhibit powerful\ncapabilities in processing textual information, it remains a significant\nchallenge to perform multimodal fusion of processed textual embeddings with\ngraph structures. In this paper, we propose a \\textbf{M}ulti-level \\textbf{L}LM\n\\textbf{E}nhanced Graph Fraud \\textbf{D}etection framework called MLED. In\nMLED, we utilize LLMs to extract external knowledge from textual information to\nenhance graph fraud detection methods. To integrate LLMs with graph structure\ninformation and enhance the ability to distinguish fraudsters, we design a\nmulti-level LLM enhanced framework including type-level enhancer and\nrelation-level enhancer. One is to enhance the difference between the\nfraudsters and the benign entities, the other is to enhance the importance of\nthe fraudsters in different relations. The experiments on four real-world\ndatasets show that MLED achieves state-of-the-art performance in graph fraud\ndetection as a generalized framework that can be applied to existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-07-16T07:50:43+00:00",
    "updated": "2025-07-16T07:50:43+00:00",
    "url": "http://arxiv.org/pdf/2507.11997v1"
  },
  {
    "id": "2507.22908v1",
    "title": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection",
    "authors": [
      "Abhishek Sawaika",
      "Swetang Krishna",
      "Tushar Tomar",
      "Durga Pritam Suggisetti",
      "Aditi Lal",
      "Tanmaya Shrivastav",
      "Nouhaila Innan",
      "Muhammad Shafique"
    ],
    "abstract": "Rapid growth of digital transactions has led to a surge in fraudulent\nactivities, challenging traditional detection methods in the financial sector.\nTo tackle this problem, we introduce a specialised federated learning framework\nthat uniquely combines a quantum-enhanced Long Short-Term Memory (LSTM) model\nwith advanced privacy preserving techniques. By integrating quantum layers into\nthe LSTM architecture, our approach adeptly captures complex\ncross-transactional patters, resulting in an approximate 5% performance\nimprovement across key evaluation metrics compared to conventional models.\nCentral to our framework is \"FedRansel\", a novel method designed to defend\nagainst poisoning and inference attacks, thereby reducing model degradation and\ninference accuracy by 4-8%, compared to standard differential privacy\nmechanisms. This pseudo-centralised setup with a Quantum LSTM model, enhances\nfraud detection accuracy and reinforces the security and confidentiality of\nsensitive financial data.",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "cs.LG",
      "I.2"
    ],
    "published": "2025-07-15T17:29:12+00:00",
    "updated": "2025-07-15T17:29:12+00:00",
    "url": "http://arxiv.org/pdf/2507.22908v1"
  },
  {
    "id": "2507.10743v1",
    "title": "Language Models for Adult Service Website Text Analysis",
    "authors": [
      "Nickolas Freeman",
      "Thanh Nguyen",
      "Gregory Bott",
      "Jason Parton",
      "Collin Francel"
    ],
    "abstract": "Sex trafficking refers to the use of force, fraud, or coercion to compel an\nindividual to perform in commercial sex acts against their will. Adult service\nwebsites (ASWs) have and continue to be linked to sex trafficking, offering a\nplatform for traffickers to advertise their victims. Thus, organizations\ninvolved in the fight against sex trafficking often use ASW data when\nattempting to identify potential sex trafficking victims. A critical challenge\nin transforming ASW data into actionable insight is text analysis. Previous\nresearch using ASW data has shown that ASW ad text is important for linking\nads. However, working with this text is challenging due to its extensive use of\nemojis, poor grammar, and deliberate obfuscation to evade law enforcement\nscrutiny. We conduct a comprehensive study of language modeling approaches for\nthis application area, including simple information retrieval methods,\npre-trained transformers, and custom transformer models. We demonstrate that\ncharacteristics of ASW text data allow efficient custom transformer models to\nbe trained with relatively small GPU resources and used efficiently for\ninference on consumer hardware. Our custom models outperform fine-tuned\nvariants of well-known encoder-only transformer models, including BERT-base,\nRoBERTa, and ModernBERT, on accuracy, recall, F1 score, and ROC AUC. We\ndemonstrate the use of our best-performing custom configuration on three tasks\nrelated to ASW data analysis: (i) decomposing the giant component in a graph\nrepresentation of ASW data, (ii) clustering ASW ad text, and (iii) using the\nlearned token embeddings to understand the use of emojis in the illicit context\nwe study. The models we develop represent a significant advancement in ASW text\nanalysis, which can be leveraged in a variety of downstream applications and\nresearch.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-07-14T19:08:07+00:00",
    "updated": "2025-07-14T19:08:07+00:00",
    "url": "http://arxiv.org/pdf/2507.10743v1"
  },
  {
    "id": "2509.03939v1",
    "title": "LMAE4Eth: Generalizable and Robust Ethereum Fraud Detection by Exploring Transaction Semantics and Masked Graph Embedding",
    "authors": [
      "Yifan Jia",
      "Yanbin Wang",
      "Jianguo Sun",
      "Ye Tian",
      "Peng Qian"
    ],
    "abstract": "Current Ethereum fraud detection methods rely on context-independent,\nnumerical transaction sequences, failing to capture semantic of account\ntransactions. Furthermore, the pervasive homogeneity in Ethereum transaction\nrecords renders it challenging to learn discriminative account embeddings.\nMoreover, current self-supervised graph learning methods primarily learn node\nrepresentations through graph reconstruction, resulting in suboptimal\nperformance for node-level tasks like fraud account detection, while these\nmethods also encounter scalability challenges. To tackle these challenges, we\npropose LMAE4Eth, a multi-view learning framework that fuses transaction\nsemantics, masked graph embedding, and expert knowledge. We first propose a\ntransaction-token contrastive language model (TxCLM) that transforms\ncontext-independent numerical transaction records into logically cohesive\nlinguistic representations. To clearly characterize the semantic differences\nbetween accounts, we also use a token-aware contrastive learning pre-training\nobjective together with the masked transaction model pre-training objective,\nlearns high-expressive account representations. We then propose a masked\naccount graph autoencoder (MAGAE) using generative self-supervised learning,\nwhich achieves superior node-level account detection by focusing on\nreconstructing account node features. To enable MAGAE to scale for large-scale\ntraining, we propose to integrate layer-neighbor sampling into the graph, which\nreduces the number of sampled vertices by several times without compromising\ntraining quality. Finally, using a cross-attention fusion network, we unify the\nembeddings of TxCLM and MAGAE to leverage the benefits of both. We evaluate our\nmethod against 21 baseline approaches on three datasets. Experimental results\nshow that our method outperforms the best baseline by over 10% in F1-score on\ntwo of the datasets.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-09-04T06:56:32+00:00",
    "updated": "2025-09-04T06:56:32+00:00",
    "url": "http://arxiv.org/pdf/2509.03939v1"
  },
  {
    "id": "2509.01211v1",
    "title": "Web Fraud Attacks Against LLM-Driven Multi-Agent Systems",
    "authors": [
      "Dezhang Kong",
      "Hujin Peng",
      "Yilun Zhang",
      "Lele Zhao",
      "Zhenhua Xu",
      "Shi Lin",
      "Changting Lin",
      "Meng Han"
    ],
    "abstract": "With the proliferation of applications built upon LLM-driven multi-agent\nsystems (MAS), the security of Web links has become a critical concern in\nensuring system reliability. Once an agent is induced to visit a malicious\nwebsite, attackers can use it as a springboard to conduct diverse subsequent\nattacks, which will drastically expand the attack surface. In this paper, we\npropose Web Fraud Attacks, a novel type of attack aiming at inducing MAS to\nvisit malicious websites. We design 11 representative attack variants that\nencompass domain name tampering (homoglyph deception, character substitution,\netc.), link structure camouflage (sub-directory nesting, sub-domain grafting,\nparameter obfuscation, etc.), and other deceptive techniques tailored to\nexploit MAS's vulnerabilities in link validation. Through extensive experiments\non these crafted attack vectors, we demonstrate that Web fraud attacks not only\nexhibit significant destructive potential across different MAS architectures\nbut also possess a distinct advantage in evasion: they circumvent the need for\ncomplex input formats such as jailbreaking, which inherently carry higher\nexposure risks. These results underscore the importance of addressing Web fraud\nattacks in LLM-driven MAS, as their stealthiness and destructiveness pose\nnon-negligible threats to system security and user safety.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-09-01T07:47:24+00:00",
    "updated": "2025-09-01T07:47:24+00:00",
    "url": "http://arxiv.org/pdf/2509.01211v1"
  },
  {
    "id": "2509.01168v1",
    "title": "Detecting Rug Pulls in Decentralized Exchanges: Machine Learning Evidence from the TON Blockchain",
    "authors": [
      "Dmitry Yaremus",
      "Jianghai Li",
      "Alisa Kalacheva",
      "Igor Vodolazov",
      "Yury Yanovich"
    ],
    "abstract": "This paper presents a machine learning framework for the early detection of\nrug pull scams on decentralized exchanges (DEXs) within The Open Network (TON)\nblockchain. TON's unique architecture, characterized by asynchronous execution\nand a massive web2 user base from Telegram, presents a novel and critical\nenvironment for fraud analysis. We conduct a comprehensive study on the two\nlargest TON DEXs, Ston.Fi and DeDust, fusing data from both platforms to train\nour models. A key contribution is the implementation and comparative analysis\nof two distinct rug pull definitions--TVL-based (a catastrophic liquidity\nwithdrawal) and idle-based (a sudden cessation of all trading activity)--within\na single, unified study. We demonstrate that Gradient Boosting models can\neffectively identify rug pulls within the first five minutes of trading, with\nthe TVL-based method achieving superior AUC (up to 0.891) while the idle-based\nmethod excels at recall. Our analysis reveals that while feature sets are\nconsistent across exchanges, their underlying distributions differ\nsignificantly, challenging straightforward data fusion and highlighting the\nneed for robust, platform-aware models. This work provides a crucial\nearly-warning mechanism for investors and enhances the security infrastructure\nof the rapidly growing TON DeFi ecosystem.",
    "categories": [
      "cs.DC",
      "cs.LG"
    ],
    "published": "2025-09-01T06:39:50+00:00",
    "updated": "2025-09-01T06:39:50+00:00",
    "url": "http://arxiv.org/pdf/2509.01168v1"
  },
  {
    "id": "2509.00931v2",
    "title": "Semi-Supervised Bayesian GANs with Log-Signatures for Uncertainty-Aware Credit Card Fraud Detection",
    "authors": [
      "David Hirnschall"
    ],
    "abstract": "We present a novel deep generative semi-supervised framework for credit card\nfraud detection, formulated as time series classification task. As financial\ntransaction data streams grow in scale and complexity, traditional methods\noften require large labeled datasets, struggle with time series of irregular\nsampling frequencies and varying sequence lengths. To address these challenges,\nwe extend conditional Generative Adversarial Networks (GANs) for targeted data\naugmentation, integrate Bayesian inference to obtain predictive distributions\nand quantify uncertainty, and leverage log-signatures for robust feature\nencoding of transaction histories. We introduce a novel Wasserstein\ndistance-based loss to align generated and real unlabeled samples while\nsimultaneously maximizing classification accuracy on labeled data. Our approach\nis evaluated on the BankSim dataset, a widely used simulator for credit card\ntransaction data, under varying proportions of labeled samples, demonstrating\nconsistent improvements over benchmarks in both global statistical and\ndomain-specific metrics. These findings highlight the effectiveness of\nGAN-driven semi-supervised learning with log-signatures for irregularly sampled\ntime series and emphasize the importance of uncertainty-aware predictions.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-08-31T16:57:02+00:00",
    "updated": "2025-09-05T09:15:52+00:00",
    "url": "http://arxiv.org/pdf/2509.00931v2"
  },
  {
    "id": "2508.21366v1",
    "title": "CircuitHunt: Automated Quantum Circuit Screening for Superior Credit-Card Fraud Detection",
    "authors": [
      "Nouhaila Innan",
      "Akshat Singh",
      "Muhammad Shafique"
    ],
    "abstract": "Designing effective quantum models for real-world tasks remains a key\nchallenge within Quantum Machine Learning (QML), particularly in applications\nsuch as credit card fraud detection, where extreme class imbalance and evolving\nattack patterns demand both accuracy and adaptability. Most existing approaches\nrely on either manually designed or randomly initialized circuits, leading to\nhigh failure rates and limited scalability. In this work, we introduce\nCircuitHunt, a fully automated quantum circuit screening framework that\nstreamlines the discovery of high-performing models. CircuitHunt filters\ncircuits from the KetGPT dataset using qubit and parameter constraints, embeds\neach candidate into a standardized hybrid QNN, and performs rapid training with\ncheckpointing based on macro-F1 scores to discard weak performers early. The\ntop-ranked circuit is then fully trained, achieving 97% test accuracy and a\nhigh macro-F1 score on a challenging fraud detection benchmark. By combining\nbudget-aware pruning, empirical evaluation, and end-to-end automation,\nCircuitHunt reduces architecture search time from days to hours while\nmaintaining performance. It thus provides a scalable and task-driven tool for\nQML deployment in critical financial applications.",
    "categories": [
      "quant-ph"
    ],
    "published": "2025-08-29T07:14:20+00:00",
    "updated": "2025-08-29T07:14:20+00:00",
    "url": "http://arxiv.org/pdf/2508.21366v1"
  },
  {
    "id": "2508.20829v1",
    "title": "ATM-GAD: Adaptive Temporal Motif Graph Anomaly Detection for Financial Transaction Networks",
    "authors": [
      "Zeyue Zhang",
      "Lin Song",
      "Erkang Bao",
      "Xiaoling Lv",
      "Xinyue Wang"
    ],
    "abstract": "Financial fraud detection is essential to safeguard billions of dollars, yet\nthe intertwined entities and fast-changing transaction behaviors in modern\nfinancial systems routinely defeat conventional machine learning models. Recent\ngraph-based detectors make headway by representing transactions as networks,\nbut they still overlook two fraud hallmarks rooted in time: (1) temporal\nmotifs--recurring, telltale subgraphs that reveal suspicious money flows as\nthey unfold--and (2) account-specific intervals of anomalous activity, when\nfraud surfaces only in short bursts unique to each entity. To exploit both\nsignals, we introduce ATM-GAD, an adaptive graph neural network that leverages\ntemporal motifs for financial anomaly detection. A Temporal Motif Extractor\ncondenses each account's transaction history into the most informative motifs,\npreserving both topology and temporal patterns. These motifs are then analyzed\nby dual-attention blocks: IntraA reasons over interactions within a single\nmotif, while InterA aggregates evidence across motifs to expose multi-step\nfraud schemes. In parallel, a differentiable Adaptive Time-Window Learner\ntailors the observation window for every node, allowing the model to focus\nprecisely on the most revealing time slices. Experiments on four real-world\ndatasets show that ATM-GAD consistently outperforms seven strong\nanomaly-detection baselines, uncovering fraud patterns missed by earlier\nmethods.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-08-28T14:25:07+00:00",
    "updated": "2025-08-28T14:25:07+00:00",
    "url": "http://arxiv.org/pdf/2508.20829v1"
  },
  {
    "id": "2508.19817v1",
    "title": "Disrupting the scammer lifecycle: A dynamically-consistent numerical analysis of a compartment model for scam-victim dynamics",
    "authors": [
      "Y. O. Tijani",
      "I. Ghosh",
      "S. D. Oloniiju",
      "H. O. Fatoyinbo"
    ],
    "abstract": "Online deception and financial scams represent a pervasive threat in the\ndigital age, yet a quantitative analysis and understanding of their propagation\nis lacking. This study introduces a novel model based on the framework of\nepidemiological models to describe the interaction between scammers and their\nvictims. We propose a five-compartment deterministic model ($S-V-R-A_s-R_s$)\ncalibrated using longitudinal data in fraud reports from the Canadian\nAnti-Fraud Centre. The model's theoretical properties are established,\nincluding the non-negativity of the state variables and the stability threshold\ndefined by the basic reproduction number ($\\mathcal{R}_0$). A non-standard\nfinite difference scheme is developed for the numerical simulations to ensure\ndynamical consistency between the continuous deterministic model and its\ndiscrete equivalent. A key finding of the model sensitivity analysis indicates\nthat the proliferation of scams is overwhelmingly driven by the lifecycle of\nscammers, their recruitment, attrition, and arrest, rather than the\nsusceptibility of the victim population. The results of this study provide\nstrong quantitative evidence that the most effective control strategies are\nthose that directly disrupt the scammers' population. Overall, this study\nprovides a crucial model for designing and evaluating evidence-based policies\nto combat the scourge of cybercrime.",
    "categories": [
      "math.DS"
    ],
    "published": "2025-08-27T12:06:00+00:00",
    "updated": "2025-08-27T12:06:00+00:00",
    "url": "http://arxiv.org/pdf/2508.19817v1"
  },
  {
    "id": "2508.19313v1",
    "title": "Are Companies Taking AI Risks Seriously? A Systematic Analysis of Companies' AI Risk Disclosures in SEC 10-K forms",
    "authors": [
      "Lucas G. Uberti-Bona Marin",
      "Bram Rijsbosch",
      "Gerasimos Spanakis",
      "Konrad Kollnig"
    ],
    "abstract": "As Artificial Intelligence becomes increasingly central to corporate\nstrategies, concerns over its risks are growing too. In response, regulators\nare pushing for greater transparency in how companies identify, report and\nmitigate AI-related risks. In the US, the Securities and Exchange Commission\n(SEC) repeatedly warned companies to provide their investors with more accurate\ndisclosures of AI-related risks; recent enforcement and litigation against\ncompanies' misleading AI claims reinforce these warnings. In the EU, new laws -\nlike the AI Act and Digital Services Act - introduced additional rules on AI\nrisk reporting and mitigation. Given these developments, it is essential to\nexamine if and how companies report AI-related risks to the public. This study\npresents the first large-scale systematic analysis of AI risk disclosures in\nSEC 10-K filings, which require public companies to report material risks to\ntheir company. We analyse over 30,000 filings from more than 7,000 companies\nover the past five years, combining quantitative and qualitative analysis. Our\nfindings reveal a sharp increase in the companies that mention AI risk, up from\n4% in 2020 to over 43% in the most recent 2024 filings. While legal and\ncompetitive AI risks are the most frequently mentioned, we also find growing\nattention to societal AI risks, such as cyberattacks, fraud, and technical\nlimitations of AI systems. However, many disclosures remain generic or lack\ndetails on mitigation strategies, echoing concerns raised recently by the SEC\nabout the quality of AI-related risk reporting. To support future research, we\npublicly release a web-based tool for easily extracting and analysing\nkeyword-based disclosures across SEC filings.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "published": "2025-08-26T10:19:29+00:00",
    "updated": "2025-08-26T10:19:29+00:00",
    "url": "http://arxiv.org/pdf/2508.19313v1"
  },
  {
    "id": "2508.18616v1",
    "title": "Optimal $(α,β)$-Dense Subgraph Search in Bipartite Graphs",
    "authors": [
      "Yalong Zhang",
      "Rong-Hua Li",
      "Qi Zhang",
      "Guoren Wang"
    ],
    "abstract": "Dense subgraph search in bipartite graphs is a fundamental problem in graph\nanalysis, with wide-ranging applications in fraud detection, recommendation\nsystems, and social network analysis. The recently proposed $(\\alpha,\n\\beta)$-dense subgraph model has demonstrated superior capability in capturing\nthe intrinsic density structure of bipartite graphs compared to existing\nalternatives. However, despite its modeling advantages, the $(\\alpha,\n\\beta)$-dense subgraph model lacks efficient support for query processing and\ndynamic updates, limiting its practical utility in large-scale applications. To\naddress these limitations, we propose BD-Index, a novel index that answers\n$(\\alpha, \\beta)$-dense subgraph queries in optimal time while using only\nlinear space $O(|E|)$, making it well-suited for real-world applications\nrequiring both fast query processing and low memory consumption. We further\ndevelop two complementary maintenance strategies for dynamic bipartite graphs\nto support efficient updates to the BD-Index. The space-efficient strategy\nupdates the index in time complexity of $O(p \\cdot |E|^{1.5})$ per edge\ninsertion or deletion, while maintaining a low space cost of $O(|E|)$ (the same\nas the index itself), where $p$ is typically a small constant in real-world\ngraphs. In contrast, the time-efficient strategy significantly reduces the\nupdate time to $O(p \\cdot |E|)$ per edge update by maintaining auxiliary\norientation structures, at the cost of increased memory usage up to $O(p \\cdot\n|E|)$. These two strategies provide flexible trade-offs between maintenance\nefficiency and memory usage, enabling BD-Index to adapt to diverse application\nrequirements. Extensive experiments on 10 large-scale real-world datasets\ndemonstrate high efficiency and scalability of our proposed solutions.",
    "categories": [
      "cs.DB"
    ],
    "published": "2025-08-26T02:41:34+00:00",
    "updated": "2025-08-26T02:41:34+00:00",
    "url": "http://arxiv.org/pdf/2508.18616v1"
  },
  {
    "id": "2508.21081v1",
    "title": "Normalisation of SWIFT Message Counterparties with Feature Extraction and Clustering",
    "authors": [
      "Thanasis Schoinas",
      "Benjamin Guinard",
      "Diba Esbati",
      "Richard Chalk"
    ],
    "abstract": "Short text clustering is a known use case in the text analytics community.\nWhen the structure and content falls in the natural language domain e.g.\nTwitter posts or instant messages, then natural language techniques can be\nused, provided texts are of sufficient length to allow for use of (pre)trained\nmodels to extract meaningful information, such as part-of-speech or topic\nannotations. However, natural language models are not suitable for clustering\ntransaction counterparties, as they are found in bank payment messaging\nsystems, such as SWIFT. The manually typed tags are typically physical or legal\nentity details, which lack sentence structure, while containing all the\nvariations and noise that manual entry introduces. This leaves a gap in an\ninvestigator or counter-fraud professional's toolset when looking to augment\ntheir knowledge of payment flow originator and beneficiary entities and trace\nfunds and assets. A gap that vendors traditionally try to close with fuzzy\nmatching tools. With these considerations in mind, we are proposing a hybrid\nstring similarity, topic modelling, hierarchical clustering and rule-based\npipeline to facilitate clustering of transaction counterparties, also catering\nfor unknown number of expected clusters. We are also devising metrics to\nsupplement the evaluation of the approach, based on the well-known measures of\nprecision and recall. Testing on a real-life labelled dataset demonstrates\nsignificantly improved performance over a baseline rule-based ('keyword')\napproach. The approach retains most of the interpretability found in rule-based\nsystems, as the former adds an additional level of cluster refinement to the\nlatter. The resulting workflow reduces the need for manual review. When only a\nsubset of the population needs to be investigated, such as in sanctions\ninvestigations, the approach allows for better control of the risks of missing\nentity variations.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-08-24T12:41:44+00:00",
    "updated": "2025-08-24T12:41:44+00:00",
    "url": "http://arxiv.org/pdf/2508.21081v1"
  },
  {
    "id": "2508.16941v1",
    "title": "Investigating red packet fraud in Android applications: Insights from user reviews",
    "authors": [
      "Yu Cheng",
      "Xiaofang Qi",
      "Yanhui Li"
    ],
    "abstract": "With the popularization of smartphones, red packets have been widely used in\nmobile apps. However, the issues of fraud associated with them have also become\nincreasingly prominent. As reported in user reviews from mobile app markets,\nmany users have complained about experiencing red packet fraud and being\npersistently troubled by fraudulent red packets. To uncover this phenomenon, we\nconduct the first investigation into an extensive collection of user reviews on\napps with red packets. In this paper, we first propose a novel automated\napproach, ReckDetector, for effectively identifying apps with red packets from\napp markets. We then collect over 360,000 real user reviews from 334 apps with\nred packets available on Google Play and three popular alternative Android app\nmarkets. We preprocess the user reviews to extract those related to red packets\nand fine-tune a pre-trained BERT model to identify negative reviews. Finally,\nbased on semantic analysis, we have summarized six distinct categories of red\npacket fraud issues reported by users. Through our study, we found that red\npacket fraud is highly prevalent, significantly impacting user experience and\ndamaging the reputation of apps. Moreover, red packets have been widely\nexploited by unscrupulous app developers as a deceptive incentive mechanism to\nentice users into completing their designated tasks, thereby maximizing their\nprofits.",
    "categories": [
      "cs.CR"
    ],
    "published": "2025-08-23T08:19:26+00:00",
    "updated": "2025-08-23T08:19:26+00:00",
    "url": "http://arxiv.org/pdf/2508.16941v1"
  },
  {
    "id": "2508.16915v1",
    "title": "Reinforcement-Guided Hyper-Heuristic Hyperparameter Optimization for Fair and Explainable Spiking Neural Network-Based Financial Fraud Detection",
    "authors": [
      "Sadman Mohammad Nasif",
      "Md Abrar Jahin",
      "M. F. Mridha"
    ],
    "abstract": "The growing adoption of home banking systems has heightened the risk of\ncyberfraud, necessitating fraud detection mechanisms that are not only accurate\nbut also fair and explainable. While AI models have shown promise in this\ndomain, they face key limitations, including computational inefficiency, the\ninterpretability challenges of spiking neural networks (SNNs), and the\ncomplexity and convergence instability of hyper-heuristic reinforcement\nlearning (RL)-based hyperparameter optimization. To address these issues, we\npropose a novel framework that integrates a Cortical Spiking Network with\nPopulation Coding (CSNPC) and a Reinforcement-Guided Hyper-Heuristic Optimizer\nfor Spiking Systems (RHOSS). The CSNPC, a biologically inspired SNN, employs\npopulation coding for robust classification, while RHOSS uses Q-learning to\ndynamically select low-level heuristics for hyperparameter optimization under\nfairness and recall constraints. Embedded within the Modular Supervisory\nFramework for Spiking Network Training and Interpretation (MoSSTI), the system\nincorporates explainable AI (XAI) techniques, specifically, saliency-based\nattribution and spike activity profiling, to increase transparency. Evaluated\non the Bank Account Fraud (BAF) dataset suite, our model achieves a $90.8\\%$\nrecall at a strict $5\\%$ false positive rate (FPR), outperforming\nstate-of-the-art spiking and non-spiking models while maintaining over $98\\%$\npredictive equality across key demographic attributes. The explainability\nmodule further confirms that saliency attributions align with spiking dynamics,\nvalidating interpretability. These results demonstrate the potential of\ncombining population-coded SNNs with reinforcement-guided hyper-heuristics for\nfair, transparent, and high-performance fraud detection in real-world financial\napplications.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-08-23T06:24:15+00:00",
    "updated": "2025-08-23T06:24:15+00:00",
    "url": "http://arxiv.org/pdf/2508.16915v1"
  },
  {
    "id": "2508.16672v1",
    "title": "The AI Model Risk Catalog: What Developers and Researchers Miss About Real-World AI Harms",
    "authors": [
      "Pooja S. B. Rao",
      "Sanja Šćepanović",
      "Dinesh Babu Jayagopi",
      "Mauro Cherubini",
      "Daniele Quercia"
    ],
    "abstract": "We analyzed nearly 460,000 AI model cards from Hugging Face to examine how\ndevelopers report risks. From these, we extracted around 3,000 unique risk\nmentions and built the \\emph{AI Model Risk Catalog}. We compared these with\nrisks identified by researchers in the MIT Risk Repository and with real-world\nincidents from the AI Incident Database. Developers focused on technical issues\nlike bias and safety, while researchers emphasized broader social impacts. Both\ngroups paid little attention to fraud and manipulation, which are common harms\narising from how people interact with AI. Our findings show the need for\nclearer, structured risk reporting that helps developers think about\nhuman-interaction and systemic risks early in the design process. The catalog\nand paper appendix are available at:\nhttps://social-dynamics.net/ai-risks/catalog.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "published": "2025-08-21T07:07:41+00:00",
    "updated": "2025-08-21T07:07:41+00:00",
    "url": "http://arxiv.org/pdf/2508.16672v1"
  },
  {
    "id": "2508.16662v1",
    "title": "Bridging the Mobile Trust Gap: A Zero Trust Framework for Consumer-Facing Applications",
    "authors": [
      "Alexander Tabalipa"
    ],
    "abstract": "Zero Trust Architecture (ZTA) has become a widely adopted model for securing\nenterprise environments, promoting continuous verification and minimal trust\nacross systems. However, its application in mobile contexts remains limited,\ndespite mobile applications now accounting for most global digital interactions\nand being increasingly targeted by sophisticated threats. Existing Zero Trust\nframeworks developed by organisations such as the National Institute of\nStandards and Technology (NIST) and the Cybersecurity and Infrastructure\nSecurity Agency (CISA) primarily focus on enterprise-managed infrastructure,\nassuming organisational control over devices, networks, and identities. This\npaper addresses a critical gap by proposing an extended Zero Trust model\ndesigned for mobile applications operating in untrusted, user-controlled\nenvironments. Using a design science methodology, the study introduced a\nsix-pillar framework that supports runtime enforcement of trust through\ncontrols including device integrity, user identity validation, data protection,\nsecure application programming interface (API) usage, behavioural monitoring,\nand live application protection. Each pillar was mapped to relevant regulatory\nand security standards to support compliance. A phased implementation roadmap\nand maturity assessment model were also developed to guide adoption across\nvarying organisational contexts. The proposed model offers a practical and\nstandards-aligned approach to securing mobile applications beyond\npre-deployment controls, aligning real-time enforcement with Zero Trust\nprinciples. This contribution expands the operational boundaries of ZTA and\nprovides organisations with a deployable path to reduce fraud, enhance\ncompliance, and address emerging mobile security challenges. Future research\nmay include empirical validation of the framework and cross-sector application\ntesting.",
    "categories": [
      "cs.CR",
      "cs.CY",
      "cs.NI",
      "cs.SE",
      "K.6.5; C.2.0; D.4.6"
    ],
    "published": "2025-08-20T18:42:36+00:00",
    "updated": "2025-08-20T18:42:36+00:00",
    "url": "http://arxiv.org/pdf/2508.16662v1"
  },
  {
    "id": "2508.14699v1",
    "title": "Foe for Fraud: Transferable Adversarial Attacks in Credit Card Fraud Detection",
    "authors": [
      "Jan Lum Fok",
      "Qingwen Zeng",
      "Shiping Chen",
      "Oscar Fawkes",
      "Huaming Chen"
    ],
    "abstract": "Credit card fraud detection (CCFD) is a critical application of Machine\nLearning (ML) in the financial sector, where accurately identifying fraudulent\ntransactions is essential for mitigating financial losses. ML models have\ndemonstrated their effectiveness in fraud detection task, in particular with\nthe tabular dataset. While adversarial attacks have been extensively studied in\ncomputer vision and deep learning, their impacts on the ML models, particularly\nthose trained on CCFD tabular datasets, remains largely unexplored. These\nlatent vulnerabilities pose significant threats to the security and stability\nof the financial industry, especially in high-value transactions where losses\ncould be substantial. To address this gap, in this paper, we present a holistic\nframework that investigate the robustness of CCFD ML model against adversarial\nperturbations under different circumstances. Specifically, the gradient-based\nattack methods are incorporated into the tabular credit card transaction data\nin both black- and white-box adversarial attacks settings. Our findings confirm\nthat tabular data is also susceptible to subtle perturbations, highlighting the\nneed for heightened awareness among financial technology practitioners\nregarding ML model security and trustworthiness. Furthermore, the experiments\nby transferring adversarial samples from gradient-based attack method to\nnon-gradient-based models also verify our findings. Our results demonstrate\nthat such attacks remain effective, emphasizing the necessity of developing\nrobust defenses for CCFD algorithms.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-08-20T13:23:28+00:00",
    "updated": "2025-08-20T13:23:28+00:00",
    "url": "http://arxiv.org/pdf/2508.14699v1"
  },
  {
    "id": "2508.13984v1",
    "title": "The AI-Fraud Diamond: A Novel Lens for Auditing Algorithmic Deception",
    "authors": [
      "Benjamin Zweers",
      "Diptish Dey",
      "Debarati Bhaumik"
    ],
    "abstract": "As artificial intelligence (AI) systems become increasingly integral to\norganizational processes, they introduce new forms of fraud that are often\nsubtle, systemic, and concealed within technical complexity. This paper\nintroduces the AI-Fraud Diamond, an extension of the traditional Fraud Triangle\nthat adds technical opacity as a fourth condition alongside pressure,\nopportunity, and rationalization. Unlike traditional fraud, AI-enabled\ndeception may not involve clear human intent but can arise from system-level\nfeatures such as opaque model behavior, flawed training data, or unregulated\ndeployment practices. The paper develops a taxonomy of AI-fraud across five\ncategories: input data manipulation, model exploitation, algorithmic decision\nmanipulation, synthetic misinformation, and ethics-based fraud. To assess the\nrelevance and applicability of the AI-Fraud Diamond, the study draws on expert\ninterviews with auditors from two of the Big Four consulting firms. The\nfindings underscore the challenges auditors face when addressing fraud in\nopaque and automated environments, including limited technical expertise,\ninsufficient cross-disciplinary collaboration, and constrained access to\ninternal system processes. These conditions hinder fraud detection and reduce\naccountability. The paper argues for a shift in audit methodology-from\noutcome-based checks to a more diagnostic approach focused on identifying\nsystemic vulnerabilities. Ultimately, the work lays a foundation for future\nempirical research and audit innovation in a rapidly evolving AI governance\nlandscape.",
    "categories": [
      "cs.CY"
    ],
    "published": "2025-08-19T16:21:44+00:00",
    "updated": "2025-08-19T16:21:44+00:00",
    "url": "http://arxiv.org/pdf/2508.13984v1"
  },
  {
    "id": "2508.12641v1",
    "title": "MPOCryptoML: Multi-Pattern based Off-Chain Crypto Money Laundering Detection",
    "authors": [
      "Yasaman Samadi",
      "Hai Dong",
      "Xiaoyu Xia"
    ],
    "abstract": "Recent advancements in money laundering detection have demonstrated the\npotential of using graph neural networks to capture laundering patterns\naccurately. However, existing models are not explicitly designed to detect the\ndiverse patterns of off-chain cryptocurrency money laundering. Neglecting any\nlaundering pattern introduces critical detection gaps, as each pattern reflects\nunique transactional structures that facilitate the obfuscation of illicit fund\norigins and movements. Failure to account for these patterns may result in\nunder-detection or omission of specific laundering activities, diminishing\nmodel accuracy and allowing schemes to bypass detection. To address this gap,\nwe propose the MPOCryptoML model to effectively detect multiple laundering\npatterns in cryptocurrency transactions. MPOCryptoML includes the development\nof a multi-source Personalized PageRank algorithm to identify random laundering\npatterns. Additionally, we introduce two novel algorithms by analyzing the\ntimestamp and weight of transactions in high-volume financial networks to\ndetect various money laundering structures, including fan-in, fan-out,\nbipartite, gather-scatter, and stack patterns. We further examine correlations\nbetween these patterns using a logistic regression model. An anomaly score\nfunction integrates results from each module to rank accounts by anomaly score,\nsystematically identifying high-risk accounts. Extensive experiments on public\ndatasets including Elliptic++, Ethereum fraud detection, and Wormhole\ntransaction datasets validate the efficacy and efficiency of MPOCryptoML.\nResults show consistent performance gains, with improvements up to 9.13% in\nprecision, up to 10.16% in recall, up to 7.63% in F1-score, and up to 10.19% in\naccuracy.",
    "categories": [
      "cs.CR"
    ],
    "published": "2025-08-18T06:06:32+00:00",
    "updated": "2025-08-18T06:06:32+00:00",
    "url": "http://arxiv.org/pdf/2508.12641v1"
  },
  {
    "id": "2508.11579v1",
    "title": "Intergenerational Support for Deepfake Scams Targeting Older Adults",
    "authors": [
      "Karina LaRubbio",
      "Alyssa Lanter",
      "Seihyun Lee",
      "Mahima Ramesh",
      "Diana Freed"
    ],
    "abstract": "AI-enhanced scams now employ deepfake technology to produce convincing audio\nand visual impersonations of trusted family members, often grandchildren, in\nreal time. These attacks fabricate urgent scenarios, such as legal or medical\nemergencies, to socially engineer older adults into transferring money. The\nrealism of these AI-generated impersonations undermines traditional cues used\nto detect fraud, making them a powerful tool for financial exploitation. In\nthis study, we explore older adults' perceptions of these emerging threats and\ntheir responses, with a particular focus on the role of youth, who may also be\nimpacted by having their identities exploited, in supporting older family\nmembers' online safety. We conducted focus groups with 37 older adults (ages\n65+) to examine their understanding of deepfake impersonation scams and the\nvalue of intergenerational technology support. Findings suggest that older\nadults frequently rely on trusted relationships to detect scams and develop\nprotective practices. Based on this, we identify opportunities to engage youth\nas active partners in enhancing resilience across generations.",
    "categories": [
      "cs.CY"
    ],
    "published": "2025-08-15T16:37:59+00:00",
    "updated": "2025-08-15T16:37:59+00:00",
    "url": "http://arxiv.org/pdf/2508.11579v1"
  },
  {
    "id": "2508.11395v1",
    "title": "Banking 2.0: The Stablecoin Banking Revolution -- How Digital Assets Are Reshaping Global Finance",
    "authors": [
      "Kevin McNamara",
      "Rhea Pritham Marpu"
    ],
    "abstract": "The global financial system stands at an inflection point. Stablecoins\nrepresent the most significant evolution in banking since the abandonment of\nthe gold standard, positioned to enable \"Banking 2.0\" by seamlessly integrating\ncryptocurrency innovation with traditional finance infrastructure. This\ntransformation rivals artificial intelligence as the next major disruptor in\nthe financial sector. Modern fiat currencies derive value entirely from\ninstitutional trust rather than physical backing, creating vulnerabilities that\nstablecoins address through enhanced stability, reduced fraud risk, and unified\nglobal transactions that transcend national boundaries. Recent developments\ndemonstrate accelerating institutional adoption: landmark U.S. legislation\nincluding the GENIUS Act of 2025, strategic industry pivots from major players\nlike JPMorgan's crypto-backed loan initiatives, and PayPal's comprehensive \"Pay\nwith Crypto\" service. Widespread stablecoin implementation addresses critical\nmacroeconomic imbalances, particularly the inflation-productivity gap plaguing\nmodern monetary systems, through more robust and diversified backing\nmechanisms. Furthermore, stablecoins facilitate deregulation and efficiency\ngains, paving the way for a more interconnected international financial system.\nThis whitepaper comprehensively explores how stablecoins are poised to reshape\nbanking, supported by real-world examples, current market data, and analysis of\ntheir transformative potential.",
    "categories": [
      "cs.ET",
      "cs.CE",
      "cs.CR",
      "cs.CY",
      "econ.GN",
      "q-fin.EC"
    ],
    "published": "2025-08-15T11:05:16+00:00",
    "updated": "2025-08-15T11:05:16+00:00",
    "url": "http://arxiv.org/pdf/2508.11395v1"
  },
  {
    "id": "2508.11030v3",
    "title": "Families' Vision of Generative AI Agents for Household Safety Against Digital and Physical Threats",
    "authors": [
      "Zikai Wen",
      "Lanjing Liu",
      "Yaxing Yao"
    ],
    "abstract": "As families face increasingly complex safety challenges in digital and\nphysical environments, generative AI (GenAI) presents new opportunities to\nsupport household safety through multiple specialized AI agents. Through a\ntwo-phase qualitative study consisting of individual interviews and\ncollaborative sessions with 13 parent-child dyads, we explored families'\nconceptualizations of GenAI and their envisioned use of AI agents in daily\nfamily life. Our findings reveal that families preferred to distribute\nsafety-related support across multiple AI agents, each embodying a familiar\ncaregiving role: a household manager coordinating routine tasks and mitigating\nrisks such as digital fraud and home accidents; a private tutor providing\npersonalized educational support, including safety education; and a family\ntherapist offering emotional support to address sensitive safety issues such as\ncyberbullying and digital harassment. Families emphasized the need for\nagent-specific privacy boundaries, recognized generational differences in trust\ntoward AI agents, and stressed the importance of maintaining open family\ncommunication alongside the assistance of AI agents. Based on these findings,\nwe propose a multi-agent system design featuring four privacy-preserving\nprinciples: memory segregation, conversational consent, selective data sharing,\nand progressive memory management to help balance safety, privacy, and autonomy\nwithin family contexts.",
    "categories": [
      "cs.HC"
    ],
    "published": "2025-08-14T19:29:35+00:00",
    "updated": "2025-08-28T01:40:23+00:00",
    "url": "http://arxiv.org/pdf/2508.11030v3"
  },
  {
    "id": "2508.11021v1",
    "title": "Can Multi-modal (reasoning) LLMs detect document manipulation?",
    "authors": [
      "Zisheng Liang",
      "Kidus Zewde",
      "Rudra Pratap Singh",
      "Disha Patil",
      "Zexi Chen",
      "Jiayu Xue",
      "Yao Yao",
      "Yifei Chen",
      "Qinzhe Liu",
      "Simiao Ren"
    ],
    "abstract": "Document fraud poses a significant threat to industries reliant on secure and\nverifiable documentation, necessitating robust detection mechanisms. This study\ninvestigates the efficacy of state-of-the-art multi-modal large language models\n(LLMs)-including OpenAI O1, OpenAI 4o, Gemini Flash (thinking), Deepseek Janus,\nGrok, Llama 3.2 and 4, Qwen 2 and 2.5 VL, Mistral Pixtral, and Claude 3.5 and\n3.7 Sonnet-in detecting fraudulent documents. We benchmark these models against\neach other and prior work on document fraud detection techniques using a\nstandard dataset with real transactional documents. Through prompt optimization\nand detailed analysis of the models' reasoning processes, we evaluate their\nability to identify subtle indicators of fraud, such as tampered text,\nmisaligned formatting, and inconsistent transactional sums. Our results reveal\nthat top-performing multi-modal LLMs demonstrate superior zero-shot\ngeneralization, outperforming conventional methods on out-of-distribution\ndatasets, while several vision LLMs exhibit inconsistent or subpar performance.\nNotably, model size and advanced reasoning capabilities show limited\ncorrelation with detection accuracy, suggesting task-specific fine-tuning is\ncritical. This study underscores the potential of multi-modal LLMs in enhancing\ndocument fraud detection systems and provides a foundation for future research\ninto interpretable and scalable fraud mitigation strategies.",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "published": "2025-08-14T18:57:07+00:00",
    "updated": "2025-08-14T18:57:07+00:00",
    "url": "http://arxiv.org/pdf/2508.11021v1"
  }
]