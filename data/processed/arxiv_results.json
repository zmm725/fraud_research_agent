{"id": "2201.09202v1", "title": "One-Shot Learning on Attributed Sequences", "authors": ["Zhongfang Zhuang", "Xiangnan Kong", "Elke Rundensteiner", "Aditya Arora", "Jihane Zouaoui"], "abstract": "One-shot learning has become an important research topic in the last decade\nwith many real-world applications. The goal of one-shot learning is to classify\nunlabeled instances when there is only one labeled example per class.\nConventional problem setting of one-shot learning mainly focuses on the data\nthat is already in feature space (such as images). However, the data instances\nin real-world applications are often more complex and feature vectors may not\nbe available. In this paper, we study the problem of one-shot learning on\nattributed sequences, where each instance is composed of a set of attributes\n(e.g., user profile) and a sequence of categorical items (e.g., clickstream).\nThis problem is important for a variety of real-world applications ranging from\nfraud prevention to network intrusion detection. This problem is more\nchallenging than conventional one-shot learning since there are dependencies\nbetween attributes and sequences. We design a deep learning framework OLAS to\ntackle this problem. The proposed OLAS utilizes a twin network to generalize\nthe features from pairwise attributed sequence examples. Empirical results on\nreal-world datasets demonstrate the proposed OLAS can outperform the\nstate-of-the-art methods under a rich variety of parameter settings.", "categories": ["cs.LG", "cs.AI"], "published": "2022-01-23T07:19:11+00:00", "updated": "2022-01-23T07:19:11+00:00", "url": "http://arxiv.org/pdf/2201.09202v1", "data_source_type": ["user behavior", "network activity"], "data_source_name": [], "fraud_type": "fraud prevention, network intrusion detection", "technical_approach_category": ["deep learning", "one-shot learning", "twin network", "feature extraction"], "technical_approach_method": ["OLAS framework", "twin network"], "technical_approach_description": "A deep learning framework called OLAS that utilizes a twin network to generalize features from pairwise attributed sequence examples for one-shot classification of complex data instances with attributes and categorical sequences.", "innovation_points": "Proposes a framework for one-shot learning on attributed sequences where instances combine attributes and categorical sequences, addressing dependencies between attributes and sequences, which is more challenging than conventional feature-space one-shot learning.", "github_repo": ""}
{"id": "2201.01004v1", "title": "Modeling Users' Behavior Sequences with Hierarchical Explainable Network for Cross-domain Fraud Detection", "authors": ["Yongchun Zhu", "Dongbo Xi", "Bowen Song", "Fuzhen Zhuang", "Shuai Chen", "Xi Gu", "Qing He"], "abstract": "With the explosive growth of the e-commerce industry, detecting online\ntransaction fraud in real-world applications has become increasingly important\nto the development of e-commerce platforms. The sequential behavior history of\nusers provides useful information in differentiating fraudulent payments from\nregular ones. Recently, some approaches have been proposed to solve this\nsequence-based fraud detection problem. However, these methods usually suffer\nfrom two problems: the prediction results are difficult to explain and the\nexploitation of the internal information of behaviors is insufficient. To\ntackle the above two problems, we propose a Hierarchical Explainable Network\n(HEN) to model users' behavior sequences, which could not only improve the\nperformance of fraud detection but also make the inference process\ninterpretable. Meanwhile, as e-commerce business expands to new domains, e.g.,\nnew countries or new markets, one major problem for modeling user behavior in\nfraud detection systems is the limitation of data collection, e.g., very few\ndata/labels available. Thus, in this paper, we further propose a transfer\nframework to tackle the cross-domain fraud detection problem, which aims to\ntransfer knowledge from existing domains (source domains) with enough and\nmature data to improve the performance in the new domain (target domain). Our\nproposed method is a general transfer framework that could not only be applied\nupon HEN but also various existing models in the Embedding & MLP paradigm.\nBased on 90 transfer task experiments, we also demonstrate that our transfer\nframework could not only contribute to the cross-domain fraud detection task\nwith HEN, but also be universal and expandable for various existing models.", "categories": ["cs.LG", "cs.AI", "cs.IR"], "published": "2022-01-04T06:37:16+00:00", "updated": "2022-01-04T06:37:16+00:00", "url": "http://arxiv.org/pdf/2201.01004v1", "data_source_type": ["e-commerce"], "data_source_name": [], "fraud_type": "online transaction fraud", "technical_approach_category": ["sequence modeling", "explainable AI", "transfer learning", "cross-domain learning"], "technical_approach_method": ["Hierarchical Explainable Network (HEN)", "Embedding & MLP paradigm"], "technical_approach_description": "Proposes a Hierarchical Explainable Network to model users' behavior sequences for fraud detection, improving performance while making the inference process interpretable. Also introduces a transfer learning framework for cross-domain fraud detection to transfer knowledge from source domains to target domains.", "innovation_points": "Addresses two key problems: prediction results being difficult to explain and insufficient exploitation of internal behavior information. Proposes a general transfer framework applicable to both HEN and various existing models in the Embedding & MLP paradigm for cross-domain fraud detection.", "github_repo": ""}
{"id": "2202.12457v1", "title": "Stacked Residuals of Dynamic Layers for Time Series Anomaly Detection", "authors": ["L. Zancato", "A. Achille", "G. Paolini", "A. Chiuso", "S. Soatto"], "abstract": "We present an end-to-end differentiable neural network architecture to\nperform anomaly detection in multivariate time series by incorporating a\nSequential Probability Ratio Test on the prediction residual. The architecture\nis a cascade of dynamical systems designed to separate linearly predictable\ncomponents of the signal such as trends and seasonality, from the non-linear\nones. The former are modeled by local Linear Dynamic Layers, and their residual\nis fed to a generic Temporal Convolutional Network that also aggregates global\nstatistics from different time series as context for the local predictions of\neach one. The last layer implements the anomaly detector, which exploits the\ntemporal structure of the prediction residuals to detect both isolated point\nanomalies and set-point changes. It is based on a novel application of the\nclassic CUMSUM algorithm, adapted through the use of a variational\napproximation of f-divergences. The model automatically adapts to the time\nscales of the observed signals. It approximates a SARIMA model at the get-go,\nand auto-tunes to the statistics of the signal and its covariates, without the\nneed for supervision, as more data is observed. The resulting system, which we\ncall STRIC, outperforms both state-of-the-art robust statistical methods and\ndeep neural network architectures on multiple anomaly detection benchmarks.", "categories": ["cs.LG", "cs.SY", "eess.SY", "stat.ML"], "published": "2022-02-25T01:50:22+00:00", "updated": "2022-02-25T01:50:22+00:00", "url": "http://arxiv.org/pdf/2202.12457v1", "data_source_type": [], "data_source_name": [], "fraud_type": "time series anomaly detection", "technical_approach_category": ["anomaly detection", "temporal convolutional network", "dynamical systems", "variational approximation"], "technical_approach_method": ["Sequential Probability Ratio Test", "Linear Dynamic Layers", "Temporal Convolutional Network", "CUMSUM algorithm", "variational approximation of f-divergences"], "technical_approach_description": "An end-to-end differentiable neural network that separates linearly predictable signal components (trends, seasonality) using Linear Dynamic Layers from non-linear components processed by a Temporal Convolutional Network. Anomaly detection is performed on the prediction residuals using a novel adaptation of the CUMSUM algorithm.", "innovation_points": "Novel application of the classic CUMSUM algorithm adapted through variational approximation of f-divergences. The model automatically adapts to signal time scales, approximates a SARIMA model initially, and auto-tunes to signal statistics without supervision.", "github_repo": ""}
{"id": "2202.10418v6", "title": "Anomaly Search over Composite Hypotheses in Hierarchical Statistical Models", "authors": ["Benjamin Wolff", "Tomer Gafni", "Guy Revach", "Nir Shlezinger", "Kobi Cohen"], "abstract": "Detection of anomalies among a large number of processes is a fundamental\ntask that has been studied in multiple research areas, with diverse\napplications spanning from spectrum access to cyber-security. Anomalous events\nare characterized by deviations in data distributions, and thus can be inferred\nfrom noisy observations based on statistical methods. In some scenarios, one\ncan often obtain noisy observations aggregated from a chosen subset of\nprocesses. Such hierarchical search can further minimize the sample complexity\nwhile retaining accuracy. An anomaly search strategy should thus be designed\nbased on multiple requirements, such as maximizing the detection accuracy;\nefficiency, be efficient in terms of sample complexity; and be able to cope\nwith statistical models that are known only up to some missing parameters\n(i.e., composite hypotheses). In this paper, we consider anomaly detection with\nobservations taken from a chosen subset of processes that conforms to a\npredetermined tree structure with partially known statistical model. We propose\nHierarchical Dynamic Search (HDS), a sequential search strategy that uses two\nvariations of the Generalized Log Likelihood Ratio (GLLR) statistic, and can be\nused for detection of multiple anomalies. HDS is shown to be order-optimal in\nterms of the size of the search space, and asymptotically optimal in terms of\ndetection accuracy. An explicit upper bound on the error probability is\nestablished for the finite sample regime. In addition to extensive experiments\non synthetic datasets, experiments have been conducted on the DARPA intrusion\ndetection dataset, showing that HDS is superior to existing methods.", "categories": ["cs.IT", "eess.SP", "math.IT", "stat.ME"], "published": "2022-02-21T18:30:23+00:00", "updated": "2022-08-11T06:11:53+00:00", "url": "http://arxiv.org/pdf/2202.10418v6", "data_source_type": ["cyber-security", "synthetic"], "data_source_name": ["DARPA intrusion detection dataset"], "fraud_type": "anomaly detection", "technical_approach_category": ["statistical methods", "sequential search", "hierarchical models", "anomaly detection"], "technical_approach_method": ["Hierarchical Dynamic Search (HDS)", "Generalized Log Likelihood Ratio (GLLR)"], "technical_approach_description": "A sequential search strategy using hierarchical statistical models with partially known parameters. HDS uses two variations of the GLLR statistic for detecting multiple anomalies from noisy observations aggregated from chosen subsets of processes.", "innovation_points": "Proposes HDS, a sequential search strategy shown to be order-optimal in search space size and asymptotically optimal in detection accuracy. Establishes explicit upper bound on error probability for finite sample regime.", "github_repo": ""}
{"id": "2202.06580v1", "title": "Improved Aggregating and Accelerating Training Methods for Spatial Graph Neural Networks on Fraud Detection", "authors": ["Yufan Zeng", "Jiashan Tang"], "abstract": "Graph neural networks (GNNs) have been widely applied to numerous fields. A\nrecent work which combines layered structure and residual connection proposes\nan improved deep architecture to extend CAmouflage-REsistant GNN (CARE-GNN) to\ndeep models named as Residual Layered CARE-GNN (RLC-GNN), which forms\nself-correcting and incremental learning mechanism, and achieves significant\nperformance improvements on fraud detection task. However, we spot three issues\nof RLC-GNN, which are the usage of neighboring information reaching limitation,\nthe training difficulty which is inherent problem to deep models and lack of\ncomprehensive consideration about node features and external patterns. In this\nwork, we propose three approaches to solve those three problems respectively.\nFirst, we suggest conducting similarity measure via cosine distance to take\nboth local features and external patterns into consideration. Then, we combine\nthe similarity measure module and the idea of adjacency-wise normalization with\nnode-wise and batch-wise normalization and then propound partial neighborhood\nnormalization methods to overcome the training difficulty while mitigating the\nimpact of too much noise caused by high-density of graph. Finally, we put\nforward intermediate information supplement to solve the information\nlimitation. Experiments are conducted on Yelp and Amazon datasets. And the\nresults show that our proposed methods effectively solve the three problems.\nAfter applying the three methods, we achieve 4.81%, 6.62% and 6.81%\nimprovements in the metrics of recall, AUC and Macro-F1 respectively on the\nYelp dataset. And we obtain 1.65% and 0.29% improvements in recall and AUC\nrespectively on the Amazon datasets.", "categories": ["cs.LG", "cs.AI"], "published": "2022-02-14T09:51:35+00:00", "updated": "2022-02-14T09:51:35+00:00", "url": "http://arxiv.org/pdf/2202.06580v1", "data_source_type": ["e-commerce", "review platform"], "data_source_name": ["Yelp", "Amazon"], "fraud_type": "fraud detection", "technical_approach_category": ["Graph Neural Networks", "anomaly detection", "feature engineering", "normalization techniques"], "technical_approach_method": ["Residual Layered CARE-GNN (RLC-GNN)", "cosine similarity measure", "partial neighborhood normalization", "intermediate information supplement"], "technical_approach_description": "Proposes three improvements to RLC-GNN for fraud detection: cosine similarity measure for local features and external patterns, partial neighborhood normalization combining adjacency-wise, node-wise and batch-wise normalization, and intermediate information supplement to overcome information limitations.", "innovation_points": "Three novel approaches addressing RLC-GNN limitations: similarity measure via cosine distance, partial neighborhood normalization methods, and intermediate information supplement to solve information limitation and training difficulty.", "github_repo": ""}
{"id": "2202.06096v2", "title": "Improving Fraud Detection via Hierarchical Attention-based Graph Neural Network", "authors": ["Yajing Liu", "Zhengya Sun", "Wensheng Zhang"], "abstract": "Graph neural networks (GNN) have emerged as a powerful tool for fraud\ndetection tasks, where fraudulent nodes are identified by aggregating neighbor\ninformation via different relations. To get around such detection, crafty\nfraudsters resort to camouflage via connecting to legitimate users (i.e.,\nrelation camouflage) or providing seemingly legitimate feedbacks (i.e., feature\ncamouflage). A wide-spread solution reinforces the GNN aggregation process with\nneighbor selectors according to original node features. This method may carry\nlimitations when identifying fraudsters not only with the relation camouflage,\nbut with the feature camouflage making them hard to distinguish from their\nlegitimate neighbors. In this paper, we propose a Hierarchical Attention-based\nGraph Neural Network (HA-GNN) for fraud detection, which incorporates weighted\nadjacency matrices across different relations against camouflage. This is\nmotivated in the Relational Density Theory and is exploited for forming a\nhierarchical attention-based graph neural network. Specifically, we design a\nrelation attention module to reflect the tie strength between two nodes, while\na neighborhood attention module to capture the long-range structural affinity\nassociated with the graph. We generate node embeddings by aggregating\ninformation from local/long-range structures and original node features.\nExperiments on three real-world datasets demonstrate the effectiveness of our\nmodel over the state-of-the-arts.", "categories": ["cs.LG", "cs.SI"], "published": "2022-02-12T16:27:16+00:00", "updated": "2022-02-21T08:29:28+00:00", "url": "http://arxiv.org/pdf/2202.06096v2", "data_source_type": [], "data_source_name": [], "fraud_type": "fraud detection", "technical_approach_category": ["GNN", "attention mechanism", "anomaly detection"], "technical_approach_method": ["Hierarchical Attention-based Graph Neural Network (HA-GNN)", "relation attention module", "neighborhood attention module"], "technical_approach_description": "Proposes a Hierarchical Attention-based Graph Neural Network (HA-GNN) for fraud detection. It incorporates weighted adjacency matrices across relations to combat camouflage. The model uses a relation attention module to reflect tie strength and a neighborhood attention module to capture long-range structural affinity, generating node embeddings by aggregating information from local/long-range structures and original features.", "innovation_points": "Incorporates weighted adjacency matrices across different relations against camouflage, motivated by Relational Density Theory. Designs a relation attention module to reflect tie strength and a neighborhood attention module to capture long-range structural affinity.", "github_repo": ""}
{"id": "2203.12363v3", "title": "Ethereum Fraud Detection with Heterogeneous Graph Neural Networks", "authors": ["Hiroki Kanezashi", "Toyotaro Suzumura", "Xin Liu", "Takahiro Hirofuchi"], "abstract": "While transactions with cryptocurrencies such as Ethereum are becoming more\nprevalent, fraud and other criminal transactions are not uncommon. Graph\nanalysis algorithms and machine learning techniques detect suspicious\ntransactions that lead to phishing in large transaction networks. Many graph\nneural network (GNN) models have been proposed to apply deep learning\ntechniques to graph structures. Although there is research on phishing\ndetection using GNN models in the Ethereum transaction network, models that\naddress the scale of the number of vertices and edges and the imbalance of\nlabels have not yet been studied. In this paper, we compared the model\nperformance of GNN models on the actual Ethereum transaction network dataset\nand phishing reported label data to exhaustively compare and verify which GNN\nmodels and hyperparameters produce the best accuracy. Specifically, we\nevaluated the model performance of representative homogeneous GNN models which\nconsider single-type nodes and edges and heterogeneous GNN models which support\ndifferent types of nodes and edges. We showed that heterogeneous models had\nbetter model performance than homogeneous models. In particular, the RGCN model\nachieved the best performance in the overall metrics.", "categories": ["cs.LG", "cs.CR", "cs.SI"], "published": "2022-03-23T12:35:59+00:00", "updated": "2022-07-04T08:55:10+00:00", "url": "http://arxiv.org/pdf/2203.12363v3", "data_source_type": ["cryptocurrency"], "data_source_name": ["Ethereum"], "fraud_type": "phishing transaction fraud", "technical_approach_category": ["graph neural networks", "anomaly detection", "heterogeneous graph learning"], "technical_approach_method": ["RGCN", "homogeneous GNN models", "heterogeneous GNN models"], "technical_approach_description": "Evaluated and compared the performance of homogeneous and heterogeneous Graph Neural Network models on the Ethereum transaction network dataset with phishing labels, focusing on handling network scale and label imbalance.", "innovation_points": "Exhaustive comparison of GNN models and hyperparameters for phishing detection in Ethereum, demonstrating that heterogeneous models outperform homogeneous models, with RGCN achieving the best overall performance metrics.", "github_repo": ""}
{"id": "2203.09360v3", "title": "Behavior-aware Account De-anonymization on Ethereum Interaction Graph", "authors": ["Jiajun Zhou", "Chenkai Hu", "Jianlei Chi", "Jiajing Wu", "Meng Shen", "Qi Xuan"], "abstract": "Blockchain technology has the characteristics of decentralization,\ntraceability and tamper-proof, which creates a reliable decentralized trust\nmechanism, further accelerating the development of blockchain finance. However,\nthe anonymization of blockchain hinders market regulation, resulting in\nincreasing illegal activities such as money laundering, gambling and phishing\nfraud on blockchain financial platforms. Thus, financial security has become a\ntop priority in the blockchain ecosystem, calling for effective market\nregulation. In this paper, we consider identifying Ethereum accounts from a\ngraph classification perspective, and propose an end-to-end graph neural\nnetwork framework named Ethident, to characterize the behavior patterns of\naccounts and further achieve account de-anonymization. Specifically, we first\nconstruct an Account Interaction Graph (AIG) using raw Ethereum data. Then we\ndesign a hierarchical graph attention encoder named HGATE as the backbone of\nour framework, which can effectively characterize the node-level account\nfeatures and subgraph-level behavior patterns. For alleviating account label\nscarcity, we further introduce contrastive self-supervision mechanism as\nregularization to jointly train our framework. Comprehensive experiments on\nEthereum datasets demonstrate that our framework achieves superior performance\nin account identification, yielding 1.13% ~ 4.93% relative improvement over\nprevious state-of-the-art. Furthermore, detailed analyses illustrate the\neffectiveness of Ethident in identifying and understanding the behavior of\nknown participants in Ethereum (e.g. exchanges, miners, etc.), as well as that\nof the lawbreakers (e.g. phishing scammers, hackers, etc.), which may aid in\nrisk assessment and market regulation.", "categories": ["cs.SI"], "published": "2022-03-17T14:49:31+00:00", "updated": "2022-09-13T08:11:27+00:00", "url": "http://arxiv.org/pdf/2203.09360v3", "data_source_type": ["blockchain", "financial"], "data_source_name": ["Ethereum"], "fraud_type": "account de-anonymization for illegal activities (money laundering, gambling, phishing fraud)", "technical_approach_category": ["graph neural networks", "graph classification", "contrastive learning", "self-supervised learning", "anomaly detection"], "technical_approach_method": ["Ethident", "hierarchical graph attention encoder (HGATE)"], "technical_approach_description": "Proposes an end-to-end graph neural network framework to characterize account behavior patterns on Ethereum for de-anonymization. Constructs an Account Interaction Graph and uses a hierarchical graph attention encoder with contrastive self-supervision to handle label scarcity.", "innovation_points": "Hierarchical graph attention encoder (HGATE) for node-level and subgraph-level pattern characterization, introduction of contrastive self-supervision mechanism to alleviate account label scarcity, and superior performance in account identification.", "github_repo": ""}
{"id": "2203.05842v1", "title": "Multiple Inputs Neural Networks for Medicare fraud Detection", "authors": ["Mansour Zoubeirou A Mayaki", "Michel Riveill"], "abstract": "Medicare fraud results in considerable losses for governments and insurance\ncompanies and results in higher premiums from clients. Medicare fraud costs\naround 13 billion euros in Europe and between 21 billion and 71 billion US\ndollars per year in the United States. This study aims to use artificial neural\nnetwork based classifiers to predict medicare fraud. The main difficulty using\nmachine learning techniques in fraud detection or more generally anomaly\ndetection is that the data sets are highly imbalanced. To detect medicare\nfrauds, we propose a multiple inputs deep neural network based classifier with\na Long-short Term Memory (LSTM) autoencoder component. This architecture makes\nit possible to take into account many sources of data without mixing them and\nmakes the classification task easier for the final model. The latent features\nextracted from the LSTM autoencoder have a strong discriminating power and\nseparate the providers into homogeneous clusters. We use the data sets from the\nCenters for Medicaid and Medicare Services (CMS) of the US federal government.\nThe CMS provides publicly available data that brings together all of the cost\nprice requests sent by American hospitals to medicare companies. Our results\nshow that although baseline artificial neural network give good performances,\nthey are outperformed by our multiple inputs neural networks. We have shown\nthat using a LSTM autoencoder to embed the provider behavior gives better\nresults and makes the classifiers more robust to class imbalance.", "categories": ["cs.LG"], "published": "2022-03-11T10:36:53+00:00", "updated": "2022-03-11T10:36:53+00:00", "url": "http://arxiv.org/pdf/2203.05842v1", "data_source_type": ["government", "healthcare"], "data_source_name": ["Centers for Medicaid and Medicare Services (CMS)"], "fraud_type": "Medicare fraud", "technical_approach_category": ["deep learning", "neural networks", "autoencoder", "anomaly detection", "feature extraction"], "technical_approach_method": ["Multiple Inputs Deep Neural Network", "LSTM Autoencoder"], "technical_approach_description": "Proposes a multiple inputs deep neural network classifier with an LSTM autoencoder component to handle highly imbalanced Medicare fraud detection data. The architecture processes multiple data sources separately and uses latent features from the autoencoder to create homogeneous provider clusters.", "innovation_points": "Multiple inputs neural network architecture that handles multiple data sources without mixing them, using LSTM autoencoder to extract discriminative latent features that improve classification performance and robustness to class imbalance.", "github_repo": ""}
{"id": "2204.10614v1", "title": "Modelling graph dynamics in fraud detection with \"Attention\"", "authors": ["Susie Xi Rao", "Clémence Lanfranchi", "Shuai Zhang", "Zhichao Han", "Zitao Zhang", "Wei Min", "Mo Cheng", "Yinan Shan", "Yang Zhao", "Ce Zhang"], "abstract": "At online retail platforms, detecting fraudulent accounts and transactions is\ncrucial to improve customer experience, minimize loss, and avoid unauthorized\ntransactions. Despite the variety of different models for deep learning on\ngraphs, few approaches have been proposed for dealing with graphs that are both\nheterogeneous and dynamic. In this paper, we propose DyHGN (Dynamic\nHeterogeneous Graph Neural Network) and its variants to capture both temporal\nand heterogeneous information. We first construct dynamic heterogeneous graphs\nfrom registration and transaction data from eBay. Then, we build models with\ndiachronic entity embedding and heterogeneous graph transformer. We also use\nmodel explainability techniques to understand the behaviors of DyHGN-* models.\nOur findings reveal that modelling graph dynamics with heterogeneous inputs\nneed to be conducted with \"attention\" depending on the data structure,\ndistribution, and computation cost.", "categories": ["cs.LG", "cs.AI", "cs.SI"], "published": "2022-04-22T10:17:21+00:00", "updated": "2022-04-22T10:17:21+00:00", "url": "http://arxiv.org/pdf/2204.10614v1", "data_source_type": ["e-commerce"], "data_source_name": ["eBay"], "fraud_type": "fraudulent accounts and transactions", "technical_approach_category": ["Graph Neural Network", "Transformer", "temporal modeling", "heterogeneous graph", "explainable AI"], "technical_approach_method": ["DyHGN (Dynamic Heterogeneous Graph Neural Network)", "diachronic entity embedding", "heterogeneous graph transformer"], "technical_approach_description": "Proposes DyHGN and its variants to capture both temporal and heterogeneous information for fraud detection. Models are built on dynamic heterogeneous graphs constructed from registration and transaction data, utilizing diachronic entity embedding and a heterogeneous graph transformer.", "innovation_points": "Proposes an approach for dealing with graphs that are both heterogeneous and dynamic, capturing temporal and heterogeneous information. Findings reveal that modelling graph dynamics with heterogeneous inputs need to be conducted with \"attention\" depending on data structure, distribution, and computation cost.", "github_repo": ""}
{"id": "2204.10085v2", "title": "Forgetting Prevention for Cross-regional Fraud Detection with Heterogeneous Trade Graph", "authors": ["Yujie Li", "Yuxuan Yang", "Xin Yang", "Qiang Gao", "Fan Zhou"], "abstract": "With the booming growth of e-commerce, detecting financial fraud has become\nan urgent task to avoid transaction risks. Despite the successful applications\nof Graph Neural Networks (GNNs) in fraud detection, the existing solutions are\nonly suitable for a narrow scope due to the limitation in data collection.\nEspecially when expanding a business into new territory, e.g., new cities or\nnew countries, developing a totally new model will bring the cost issue and\nresult in forgetting previous knowledge. Moreover, recent works strive to\ndevise GNNs to expose the implicit interactions behind financial transactions.\nHowever, most existing GNNs-based solutions concentrate on either homogeneous\ngraphs or decomposing heterogeneous interactions into several homogeneous\nconnections for convenience. To this end, this study proposes a novel solution\nbased on heterogeneous trade graphs, namely HTG-CFD, to prevent knowledge\nforgetting of cross-regional fraud detection. In particular, the heterogeneous\ntrade graph (HTG) is meticulously constructed from original transaction records\nto explore the complex semantics among different types of entities and\nrelationships. And motivated by recent continual learning, we present a\npractical and task-oriented forgetting prevention method to alleviate knowledge\nforgetting in the context of cross-regional detection. Extensive experiments\ndemonstrate that the proposed HTG-CFD not only promotes the performance in\ncross-regional scenarios but also significantly contributes to single-regional\nfraud detection.", "categories": ["cs.CE"], "published": "2022-04-21T13:25:22+00:00", "updated": "2022-05-22T12:10:56+00:00", "url": "http://arxiv.org/pdf/2204.10085v2", "data_source_type": ["e-commerce"], "data_source_name": [], "fraud_type": "financial fraud", "technical_approach_category": ["Graph Neural Networks (GNNs)", "heterogeneous graphs", "continual learning"], "technical_approach_method": ["HTG-CFD", "heterogeneous trade graph (HTG)"], "technical_approach_description": "Proposes a solution based on heterogeneous trade graphs for cross-regional fraud detection. Constructs a heterogeneous graph from transaction records to explore complex semantics and uses a continual learning-inspired method to prevent knowledge forgetting when expanding to new regions.", "innovation_points": "Proposes a novel solution based on heterogeneous trade graphs (HTG-CFD) to prevent knowledge forgetting in cross-regional fraud detection, using a practical task-oriented forgetting prevention method and exploring complex semantics among different entity/relationship types.", "github_repo": ""}
{"id": "2205.06742v2", "title": "Neurochaos Feature Transformation and Classification for Imbalanced Learning", "authors": ["Deeksha Sethi", "Nithin Nagaraj", "Harikrishnan N B"], "abstract": "Learning from limited and imbalanced data is a challenging problem in the\nArtificial Intelligence community. Real-time scenarios demand decision-making\nfrom rare events wherein the data are typically imbalanced. These situations\ncommonly arise in medical applications, cybersecurity, catastrophic predictions\netc. This motivates the development of learning algorithms capable of learning\nfrom imbalanced data. Human brain effortlessly learns from imbalanced data.\nInspired by the chaotic neuronal firing in the human brain, a novel learning\nalgorithm namely Neurochaos Learning (NL) was recently proposed. NL is\ncategorized in three blocks: Feature Transformation, Neurochaos Feature\nExtraction (CFX), and Classification. In this work, the efficacy of neurochaos\nfeature transformation and extraction for classification in imbalanced learning\nis studied. We propose a unique combination of neurochaos based feature\ntransformation and extraction with traditional ML algorithms. The explored\ndatasets in this study revolve around medical diagnosis, banknote fraud\ndetection, environmental applications and spoken-digit classification. In this\nstudy, experiments are performed in both high and low training sample regime.\nIn the former, five out of nine datasets have shown a performance boost in\nterms of macro F1-score after using CFX features. The highest performance boost\nobtained is 25.97% for Statlog (Heart) dataset using CFX+Decision Tree. In the\nlow training sample regime (from just one to nine training samples per class),\nthe highest performance boost of 144.38% is obtained for Haberman's Survival\ndataset using CFX+Random Forest. NL offers enormous flexibility of combining\nCFX with any ML classifier to boost its performance, especially for learning\ntasks with limited and imbalanced data.", "categories": ["cs.NE", "cs.LG"], "published": "2022-04-20T16:11:45+00:00", "updated": "2022-05-16T15:13:54+00:00", "url": "http://arxiv.org/pdf/2205.06742v2", "data_source_type": ["medical", "banking", "environmental", "audio"], "data_source_name": [], "fraud_type": "banknote fraud detection", "technical_approach_category": ["feature engineering", "feature transformation", "imbalanced learning", "chaos theory"], "technical_approach_method": ["Neurochaos Learning", "Neurochaos Feature Extraction (CFX)", "Decision Tree", "Random Forest"], "technical_approach_description": "A novel learning algorithm combining neurochaos-based feature transformation and extraction with traditional ML classifiers for imbalanced learning. The method extracts features inspired by chaotic neuronal firing in the human brain and integrates them with standard classifiers.", "innovation_points": "Proposes a unique combination of neurochaos-based feature transformation and extraction with traditional ML algorithms, offering enormous flexibility to boost performance for learning tasks with limited and imbalanced data.", "github_repo": ""}
{"id": "2204.08916v1", "title": "Heterogeneous Feature Augmentation for Ponzi Detection in Ethereum", "authors": ["Chengxiang Jin", "Jie Jin", "Jiajun Zhou", "Jiajing Wu", "Qi Xuan"], "abstract": "While blockchain technology triggers new industrial and technological\nrevolutions, it also brings new challenges. Recently, a large number of new\nscams with a \"blockchain\" sock-puppet continue to emerge, such as Ponzi\nschemes, money laundering, etc., seriously threatening financial security.\nExisting fraud detection methods in blockchain mainly concentrate on manual\nfeature and graph analytics, which first construct a homogeneous transaction\ngraph using partial blockchain data and then use graph analytics to detect\nanomaly, resulting in a loss of pattern information. In this paper, we mainly\nfocus on Ponzi scheme detection and propose HFAug, a generic Heterogeneous\nFeature Augmentation module that can capture the heterogeneous information\nassociated with account behavior patterns and can be combined with existing\nPonzi detection methods. HFAug learns the metapath-based behavior\ncharacteristics in an auxiliary heterogeneous interaction graph, and aggregates\nthe heterogeneous features to corresponding account nodes in the homogeneous\none where the Ponzi detection methods are performed. Comprehensive experimental\nresults demonstrate that our HFAug can help existing Ponzi detection methods\nachieve significant performance improvement on Ethereum datasets, suggesting\nthe effectiveness of heterogeneous information on detecting Ponzi schemes.", "categories": ["cs.CR", "cs.SI"], "published": "2022-04-19T14:27:23+00:00", "updated": "2022-04-19T14:27:23+00:00", "url": "http://arxiv.org/pdf/2204.08916v1", "data_source_type": ["blockchain", "cryptocurrency"], "data_source_name": ["Ethereum"], "fraud_type": "Ponzi scheme detection", "technical_approach_category": ["graph analytics", "heterogeneous graph learning", "feature augmentation", "anomaly detection"], "technical_approach_method": ["HFAug (Heterogeneous Feature Augmentation)", "metapath-based behavior characteristics learning"], "technical_approach_description": "Proposes HFAug, a generic heterogeneous feature augmentation module that captures heterogeneous information from account behavior patterns. It learns metapath-based behavior characteristics in an auxiliary heterogeneous interaction graph and aggregates heterogeneous features to account nodes in homogeneous graphs for Ponzi detection.", "innovation_points": "A generic heterogeneous feature augmentation module that captures heterogeneous information associated with account behavior patterns, overcoming limitations of existing methods that use only homogeneous transaction graphs and lose pattern information.", "github_repo": ""}
{"id": "2204.05265v1", "title": "The Importance of Future Information in Credit Card Fraud Detection", "authors": ["Van Bach Nguyen", "Kanishka Ghosh Dastidar", "Michael Granitzer", "Wissam Siblini"], "abstract": "Fraud detection systems (FDS) mainly perform two tasks: (i) real-time\ndetection while the payment is being processed and (ii) posterior detection to\nblock the card retrospectively and avoid further frauds. Since human\nverification is often necessary and the payment processing time is limited, the\nsecond task manages the largest volume of transactions. In the literature,\nfraud detection challenges and algorithms performance are widely studied but\nthe very formulation of the problem is never disrupted: it aims at predicting\nif a transaction is fraudulent based on its characteristics and the past\ntransactions of the cardholder. Yet, in posterior detection, verification often\ntakes days, so new payments on the card become available before a decision is\ntaken. This is our motivation to propose a new paradigm: posterior fraud\ndetection with \"future\" information. We start by providing evidence of the\non-time availability of subsequent transactions, usable as extra context to\nimprove detection. We then design a Bidirectional LSTM to make use of these\ntransactions. On a real-world dataset with over 30 million transactions, it\nachieves higher performance than a regular LSTM, which is the state-of-the-art\nclassifier for fraud detection that only uses the past context. We also\nintroduce new metrics to show that the proposal catches more frauds, more\ncompromised cards, and based on their earliest frauds. We believe that future\nworks on this new paradigm will have a significant impact on the detection of\ncompromised cards.", "categories": ["cs.LG"], "published": "2022-04-11T17:11:34+00:00", "updated": "2022-04-11T17:11:34+00:00", "url": "http://arxiv.org/pdf/2204.05265v1", "data_source_type": ["payment"], "data_source_name": [], "fraud_type": "credit card fraud", "technical_approach_category": ["RNN/LSTM", "anomaly detection"], "technical_approach_method": ["Bidirectional LSTM"], "technical_approach_description": "Proposes a new paradigm for posterior fraud detection using future transaction information as extra context. A Bidirectional LSTM is designed to utilize both past and subsequent transactions on a card to improve detection performance.", "innovation_points": "Introduces a new paradigm for posterior fraud detection using future information (subsequent transactions) as context. Proposes a Bidirectional LSTM architecture that outperforms regular LSTMs and introduces new evaluation metrics.", "github_repo": ""}
{"id": "2205.13084v2", "title": "BRIGHT -- Graph Neural Networks in Real-Time Fraud Detection", "authors": ["Mingxuan Lu", "Zhichao Han", "Susie Xi Rao", "Zitao Zhang", "Yang Zhao", "Yinan Shan", "Ramesh Raghunathan", "Ce Zhang", "Jiawei Jiang"], "abstract": "Detecting fraudulent transactions is an essential component to control risk\nin e-commerce marketplaces. Apart from rule-based and machine learning filters\nthat are already deployed in production, we want to enable efficient real-time\ninference with graph neural networks (GNNs), which is useful to catch multihop\nrisk propagation in a transaction graph. However, two challenges arise in the\nimplementation of GNNs in production. First, future information in a dynamic\ngraph should not be considered in message passing to predict the past. Second,\nthe latency of graph query and GNN model inference is usually up to hundreds of\nmilliseconds, which is costly for some critical online services. To tackle\nthese challenges, we propose a Batch and Real-time Inception GrapH Topology\n(BRIGHT) framework to conduct an end-to-end GNN learning that allows efficient\nonline real-time inference. BRIGHT framework consists of a graph transformation\nmodule (Two-Stage Directed Graph) and a corresponding GNN architecture (Lambda\nNeural Network). The Two-Stage Directed Graph guarantees that the information\npassed through neighbors is only from the historical payment transactions. It\nconsists of two subgraphs representing historical relationships and real-time\nlinks, respectively. The Lambda Neural Network decouples inference into two\nstages: batch inference of entity embeddings and real-time inference of\ntransaction prediction. Our experiments show that BRIGHT outperforms the\nbaseline models by >2\\% in average w.r.t.~precision. Furthermore, BRIGHT is\ncomputationally efficient for real-time fraud detection. Regarding end-to-end\nperformance (including neighbor query and inference), BRIGHT can reduce the P99\nlatency by >75\\%. For the inference stage, our speedup is on average\n7.8$\\times$ compared to the traditional GNN.", "categories": ["cs.LG", "cs.AI"], "published": "2022-05-25T23:51:27+00:00", "updated": "2022-08-24T07:32:16+00:00", "url": "http://arxiv.org/pdf/2205.13084v2", "data_source_type": ["e-commerce"], "data_source_name": [], "fraud_type": "transaction fraud", "technical_approach_category": ["graph neural networks", "real-time inference", "anomaly detection", "graph transformation"], "technical_approach_method": ["Two-Stage Directed Graph", "Lambda Neural Network"], "technical_approach_description": "Proposes BRIGHT framework with a graph transformation module (Two-Stage Directed Graph) that separates historical and real-time transaction links, and a GNN architecture (Lambda Neural Network) that decouples inference into batch entity embedding and real-time transaction prediction stages.", "innovation_points": "Enables efficient real-time GNN inference for fraud detection by addressing future information leakage and high latency challenges. Framework guarantees historical-only information flow and significantly reduces end-to-end latency by >75% P99 with 7.8× inference speedup.", "github_repo": ""}
{"id": "2207.11950v1", "title": "One-off Negative Sequential Pattern Mining", "authors": ["Youxi Wu", "Mingjie Chen", "Yan Li", "Jing Liu", "Zhao Li", "Jinyan Li", "Xindong Wu"], "abstract": "Negative sequential pattern mining (SPM) is an important SPM research topic.\nUnlike positive SPM, negative SPM can discover events that should have occurred\nbut have not occurred, and it can be used for financial risk management and\nfraud detection. However, existing methods generally ignore the repetitions of\nthe pattern and do not consider gap constraints, which can lead to mining\nresults containing a large number of patterns that users are not interested in.\nTo solve this problem, this paper discovers frequent one-off negative\nsequential patterns (ONPs). This problem has the following two characteristics.\nFirst, the support is calculated under the one-off condition, which means that\nany character in the sequence can only be used once at most. Second, the gap\nconstraint can be given by the user. To efficiently mine patterns, this paper\nproposes the ONP-Miner algorithm, which employs depth-first and backtracking\nstrategies to calculate the support. Therefore, ONP-Miner can effectively avoid\ncreating redundant nodes and parent-child relationships. Moreover, to\neffectively reduce the number of candidate patterns, ONP-Miner uses pattern\njoin and pruning strategies to generate and further prune the candidate\npatterns, respectively. Experimental results show that ONP-Miner not only\nimproves the mining efficiency, but also has better mining performance than the\nstate-of-the-art algorithms. More importantly, ONP mining can find more\ninteresting patterns in traffic volume data to predict future traffic.", "categories": ["cs.DB"], "published": "2022-07-25T07:37:13+00:00", "updated": "2022-07-25T07:37:13+00:00", "url": "http://arxiv.org/pdf/2207.11950v1", "data_source_type": ["traffic volume"], "data_source_name": [], "fraud_type": "financial risk management and fraud detection", "technical_approach_category": ["pattern mining", "sequential pattern mining", "negative pattern mining", "gap constraint mining", "one-off condition mining"], "technical_approach_method": ["ONP-Miner algorithm", "depth-first search", "backtracking strategies", "pattern join", "pruning strategies"], "technical_approach_description": "Proposes ONP-Miner algorithm to discover frequent one-off negative sequential patterns with gap constraints, using depth-first and backtracking strategies to calculate support under one-off conditions where sequence characters can be used only once.", "innovation_points": "Introduces one-off negative sequential pattern mining with gap constraints, addressing limitations of existing methods that ignore pattern repetitions and lack gap constraints, resulting in more meaningful patterns for users.", "github_repo": ""}
{"id": "2207.11466v1", "title": "Anomaly Detection for Fraud in Cryptocurrency Time Series", "authors": ["Eran Kaufman", "Andrey Iaremenko"], "abstract": "Since the inception of Bitcoin in 2009, the market of cryptocurrencies has\ngrown beyond initial expectations as daily trades exceed $10 billion. As\nindustries become automated, the need for an automated fraud detector becomes\nvery apparent. Detecting anomalies in real time prevents potential accidents\nand economic losses. Anomaly detection in multivariate time series data poses a\nparticular challenge because it requires simultaneous consideration of temporal\ndependencies and relationships between variables. Identifying an anomaly in\nreal time is not an easy task specifically because of the exact anomalistic\nbehavior they observe. Some points may present pointwise global or local\nanomalistic behavior, while others may be anomalistic due to their frequency or\nseasonal behavior or due to a change in the trend. In this paper we suggested\nworking on real time series of trades of Ethereum from specific accounts and\nsurveyed a large variety of different algorithms traditional and new. We\ncategorized them according to the strategy and the anomalistic behavior which\nthey search and showed that when bundling them together to different groups,\nthey can prove to be a good real-time detector with an alarm time of no longer\nthan a few seconds and with very high confidence.", "categories": ["cs.LG", "cs.CR"], "published": "2022-07-23T08:58:57+00:00", "updated": "2022-07-23T08:58:57+00:00", "url": "http://arxiv.org/pdf/2207.11466v1", "data_source_type": ["cryptocurrency exchange"], "data_source_name": [], "fraud_type": "cryptocurrency trade fraud", "technical_approach_category": ["anomaly detection", "multivariate time series analysis", "ensemble methods"], "technical_approach_method": [], "technical_approach_description": "Surveyed and categorized various traditional and new algorithms for detecting anomalies in multivariate time series data of Ethereum trades, focusing on different anomalistic behaviors including pointwise anomalies, frequency/seasonal anomalies, and trend changes.", "innovation_points": "Proposed bundling different algorithms together into groups to create a real-time detector with alarm time of no longer than a few seconds and very high confidence for cryptocurrency trade fraud detection.", "github_repo": ""}
{"id": "2209.04635v1", "title": "A Comparative Study on Unsupervised Anomaly Detection for Time Series: Experiments and Analysis", "authors": ["Yan Zhao", "Liwei Deng", "Xuanhao Chen", "Chenjuan Guo", "Bin Yang", "Tung Kieu", "Feiteng Huang", "Torben Bach Pedersen", "Kai Zheng", "Christian S. Jensen"], "abstract": "The continued digitization of societal processes translates into a\nproliferation of time series data that cover applications such as fraud\ndetection, intrusion detection, and energy management, where anomaly detection\nis often essential to enable reliability and safety. Many recent studies target\nanomaly detection for time series data. Indeed, area of time series anomaly\ndetection is characterized by diverse data, methods, and evaluation strategies,\nand comparisons in existing studies consider only part of this diversity, which\nmakes it difficult to select the best method for a particular problem setting.\nTo address this shortcoming, we introduce taxonomies for data, methods, and\nevaluation strategies, provide a comprehensive overview of unsupervised time\nseries anomaly detection using the taxonomies, and systematically evaluate and\ncompare state-of-the-art traditional as well as deep learning techniques. In\nthe empirical study using nine publicly available datasets, we apply the most\ncommonly-used performance evaluation metrics to typical methods under a fair\nimplementation standard. Based on the structuring offered by the taxonomies, we\nreport on empirical studies and provide guidelines, in the form of comparative\ntables, for choosing the methods most suitable for particular application\nsettings. Finally, we propose research directions for this dynamic field.", "categories": ["cs.LG", "cs.AI"], "published": "2022-09-10T10:44:25+00:00", "updated": "2022-09-10T10:44:25+00:00", "url": "http://arxiv.org/pdf/2209.04635v1", "data_source_type": [], "data_source_name": [], "fraud_type": "time series anomaly detection", "technical_approach_category": ["unsupervised learning", "anomaly detection", "traditional methods", "deep learning"], "technical_approach_method": [], "technical_approach_description": "This paper conducts a comprehensive comparative study on unsupervised anomaly detection methods for time series. It introduces taxonomies for data, methods, and evaluation strategies, and systematically evaluates state-of-the-art traditional and deep learning techniques across nine public datasets.", "innovation_points": "Introduces taxonomies for data, methods, and evaluation strategies to address the difficulty of method selection. Provides a systematic empirical comparison and guidelines for choosing methods suitable for particular application settings.", "github_repo": ""}
{"id": "2210.12384v1", "title": "The Devil is in the Conflict: Disentangled Information Graph Neural Networks for Fraud Detection", "authors": ["Zhixun Li", "Dingshuo Chen", "Qiang Liu", "Shu Wu"], "abstract": "Graph-based fraud detection has heretofore received considerable attention.\nOwning to the great success of Graph Neural Networks (GNNs), many approaches\nadopting GNNs for fraud detection has been gaining momentum. However, most\nexisting methods are based on the strong inductive bias of homophily, which\nindicates that the context neighbors tend to have same labels or similar\nfeatures. In real scenarios, fraudsters often engage in camouflage behaviors in\norder to avoid detection system. Therefore, the homophilic assumption no longer\nholds, which is known as the inconsistency problem. In this paper, we argue\nthat the performance degradation is mainly attributed to the inconsistency\nbetween topology and attribute. To address this problem, we propose to\ndisentangle the fraud network into two views, each corresponding to topology\nand attribute respectively. Then we propose a simple and effective method that\nuses the attention mechanism to adaptively fuse two views which captures\ndata-specific preference. In addition, we further improve it by introducing\nmutual information constraints for topology and attribute. To this end, we\npropose a Disentangled Information Graph Neural Network (DIGNN) model, which\nutilizes variational bounds to find an approximate solution to our proposed\noptimization objective function. Extensive experiments demonstrate that our\nmodel can significantly outperform stateof-the-art baselines on real-world\nfraud detection datasets.", "categories": ["cs.LG", "cs.AI", "cs.SI"], "published": "2022-10-22T08:21:49+00:00", "updated": "2022-10-22T08:21:49+00:00", "url": "http://arxiv.org/pdf/2210.12384v1", "data_source_type": [], "data_source_name": [], "fraud_type": "fraud detection", "technical_approach_category": ["GNN", "attention mechanism", "multimodal fusion", "anomaly detection", "mutual information"], "technical_approach_method": ["Disentangled Information Graph Neural Network (DIGNN)", "attention mechanism", "variational bounds"], "technical_approach_description": "Proposes a Disentangled Information Graph Neural Network (DIGNN) model that disentangles a fraud network into topology and attribute views, uses attention to fuse them adaptively, and applies mutual information constraints to address the inconsistency problem between topology and attribute.", "innovation_points": "Addresses the inconsistency problem in fraud detection graphs by disentangling the network into topology and attribute views, adaptively fusing them with attention, and introducing mutual information constraints.", "github_repo": ""}
{"id": "2210.06968v1", "title": "Behavioral graph fraud detection in E-commerce", "authors": ["Hang Yin", "Zitao Zhang", "Zhurong Wang", "Yilmazcan Ozyurt", "Weiming Liang", "Wenyu Dong", "Yang Zhao", "Yinan Shan"], "abstract": "In e-commerce industry, graph neural network methods are the new trends for\ntransaction risk modeling.The power of graph algorithms lie in the capability\nto catch transaction linking network information, which is very hard to be\ncaptured by other algorithms.However, in most existing approaches, transaction\nor user connections are defined by hard link strategies on shared properties,\nsuch as same credit card, same device, same ip address, same shipping address,\netc. Those types of strategies will result in sparse linkages by entities with\nstrong identification characteristics (ie. device) and over-linkages by\nentities that could be widely shared (ie. ip address), making it more difficult\nto learn useful information from graph. To address aforementioned problems, we\npresent a novel behavioral biometric based method to establish transaction\nlinkings based on user behavioral similarities, then train an unsupervised GNN\nto extract embedding features for downstream fraud prediction tasks. To our\nknowledge, this is the first time similarity based soft link has been used in\ngraph embedding applications. To speed up similarity calculation, we apply an\nin-house GPU based HDBSCAN clustering method to remove highly concentrated and\nisolated nodes before graph construction. Our experiments show that embedding\nfeatures learned from similarity based behavioral graph have achieved\nsignificant performance increase to the baseline fraud detection model in\nvarious business scenarios. In new guest buyer transaction scenario, this\nsegment is a challenge for traditional method, we can make precision increase\nfrom 0.82 to 0.86 at the same recall of 0.27, which means we can decrease false\npositive rate using this method.", "categories": ["cs.LG"], "published": "2022-10-13T12:47:09+00:00", "updated": "2022-10-13T12:47:09+00:00", "url": "http://arxiv.org/pdf/2210.06968v1", "data_source_type": ["e-commerce"], "data_source_name": [], "fraud_type": "transaction risk", "technical_approach_category": ["graph neural network", "unsupervised learning", "behavioral biometrics", "clustering", "anomaly detection"], "technical_approach_method": ["GNN", "HDBSCAN"], "technical_approach_description": "Presents a method using behavioral biometric similarities to establish transaction linkages, then trains an unsupervised GNN to extract embedding features for downstream fraud prediction tasks. Applies GPU-based HDBSCAN clustering to remove highly concentrated and isolated nodes before graph construction.", "innovation_points": "First time similarity-based soft link has been used in graph embedding applications, addressing problems of sparse linkages from strong identifiers and over-linkages from widely shared entities.", "github_repo": ""}
{"id": "2210.04145v1", "title": "Fine-grained Anomaly Detection in Sequential Data via Counterfactual Explanations", "authors": ["He Cheng", "Depeng Xu", "Shuhan Yuan", "Xintao Wu"], "abstract": "Anomaly detection in sequential data has been studied for a long time because\nof its potential in various applications, such as detecting abnormal system\nbehaviors from log data. Although many approaches can achieve good performance\non anomalous sequence detection, how to identify the anomalous entries in\nsequences is still challenging due to a lack of information at the entry-level.\nIn this work, we propose a novel framework called CFDet for fine-grained\nanomalous entry detection. CFDet leverages the idea of interpretable machine\nlearning. Given a sequence that is detected as anomalous, we can consider\nanomalous entry detection as an interpretable machine learning task because\nidentifying anomalous entries in the sequence is to provide an interpretation\nto the detection result. We make use of the deep support vector data\ndescription (Deep SVDD) approach to detect anomalous sequences and propose a\nnovel counterfactual interpretation-based approach to identify anomalous\nentries in the sequences. Experimental results on three datasets show that\nCFDet can correctly detect anomalous entries.", "categories": ["cs.LG"], "published": "2022-10-09T02:38:11+00:00", "updated": "2022-10-09T02:38:11+00:00", "url": "http://arxiv.org/pdf/2210.04145v1", "data_source_type": ["system logs"], "data_source_name": [], "fraud_type": "anomalous system behavior detection", "technical_approach_category": ["anomaly detection", "interpretable machine learning", "counterfactual explanations"], "technical_approach_method": ["Deep Support Vector Data Description (Deep SVDD)", "counterfactual interpretation-based approach"], "technical_approach_description": "Proposes CFDet framework for fine-grained anomalous entry detection in sequences. Uses Deep SVDD for anomalous sequence detection and a novel counterfactual interpretation approach to identify specific anomalous entries within sequences.", "innovation_points": "Novel framework called CFDet for fine-grained anomalous entry detection that leverages interpretable machine learning and counterfactual explanations to identify anomalous entries in sequences, addressing the challenge of entry-level anomaly detection.", "github_repo": ""}
{"id": "2210.01707v1", "title": "Multiple Instance Learning for Detecting Anomalies over Sequential Real-World Datasets", "authors": ["Parastoo Kamranfar", "David Lattanzi", "Amarda Shehu", "Daniel Barbará"], "abstract": "Detecting anomalies over real-world datasets remains a challenging task. Data\nannotation is an intensive human labor problem, particularly in sequential\ndatasets, where the start and end time of anomalies are not known. As a result,\ndata collected from sequential real-world processes can be largely unlabeled or\ncontain inaccurate labels. These characteristics challenge the application of\nanomaly detection techniques based on supervised learning. In contrast,\nMultiple Instance Learning (MIL) has been shown effective on problems with\nincomplete knowledge of labels in the training dataset, mainly due to the\nnotion of bags. While largely under-leveraged for anomaly detection, MIL\nprovides an appealing formulation for anomaly detection over real-world\ndatasets, and it is the primary contribution of this paper. In this paper, we\npropose an MIL-based formulation and various algorithmic instantiations of this\nframework based on different design decisions for key components of the\nframework. We evaluate the resulting algorithms over four datasets that capture\ndifferent physical processes along different modalities. The experimental\nevaluation draws out several observations. The MIL-based formulation performs\nno worse than single instance learning on easy to moderate datasets and\noutperforms single-instance learning on more challenging datasets. Altogether,\nthe results show that the framework generalizes well over diverse datasets\nresulting from different real-world application domains.", "categories": ["cs.LG"], "published": "2022-10-04T16:02:09+00:00", "updated": "2022-10-04T16:02:09+00:00", "url": "http://arxiv.org/pdf/2210.01707v1", "data_source_type": ["real-world physical processes"], "data_source_name": [], "fraud_type": "anomaly detection in sequential datasets", "technical_approach_category": ["Multiple Instance Learning", "anomaly detection", "supervised learning"], "technical_approach_method": ["Multiple Instance Learning (MIL)"], "technical_approach_description": "Proposes an MIL-based formulation and various algorithmic instantiations for anomaly detection in sequential datasets where labels are incomplete or inaccurate, using the concept of bags to handle uncertain labeling.", "innovation_points": "Introduces an MIL-based framework for anomaly detection over real-world sequential datasets, providing an appealing formulation for problems with incomplete knowledge of labels in training data.", "github_repo": ""}
{"id": "2211.13123v2", "title": "Motif-aware temporal GCN for fraud detection in signed cryptocurrency trust networks", "authors": ["Song Li", "Jiandong Zhou", "Chong MO", "Jin LI", "Geoffrey K. F. Tso", "Yuxing Tian"], "abstract": "Graph convolutional networks (GCNs) is a class of artificial neural networks\nfor processing data that can be represented as graphs. Since financial\ntransactions can naturally be constructed as graphs, GCNs are widely applied in\nthe financial industry, especially for financial fraud detection. In this\npaper, we focus on fraud detection on cryptocurrency truct networks. In the\nliterature, most works focus on static networks. Whereas in this study, we\nconsider the evolving nature of cryptocurrency networks, and use local\nstructural as well as the balance theory to guide the training process. More\nspecifically, we compute motif matrices to capture the local topological\ninformation, then use them in the GCN aggregation process. The generated\nembedding at each snapshot is a weighted average of embeddings within a time\nwindow, where the weights are learnable parameters. Since the trust networks is\nsigned on each edge, balance theory is used to guide the training process.\nExperimental results on bitcoin-alpha and bitcoin-otc datasets show that the\nproposed model outperforms those in the literature.", "categories": ["cs.LG", "cs.AI", "cs.CR", "q-fin.TR"], "published": "2022-11-22T02:03:27+00:00", "updated": "2023-03-29T04:01:17+00:00", "url": "http://arxiv.org/pdf/2211.13123v2", "data_source_type": ["cryptocurrency"], "data_source_name": ["bitcoin-alpha", "bitcoin-otc"], "fraud_type": "fraud in cryptocurrency trust networks", "technical_approach_category": ["GNN", "temporal modeling", "anomaly detection", "graph theory"], "technical_approach_method": ["Graph Convolutional Networks (GCNs)", "motif-aware aggregation", "temporal weighted averaging"], "technical_approach_description": "Proposes a motif-aware temporal GCN for fraud detection in evolving signed cryptocurrency trust networks. It computes motif matrices to capture local topology, uses them in GCN aggregation, generates temporal embeddings via a weighted average over a time window, and applies balance theory to guide training.", "innovation_points": "Considers the evolving nature of cryptocurrency networks, uses local structural motifs and balance theory to guide the training process, and employs a temporal aggregation with learnable weights.", "github_repo": ""}
{"id": "2211.06315v2", "title": "Fraudulent User Detection Via Behavior Information Aggregation Network (BIAN) On Large-Scale Financial Social Network", "authors": ["Hanyi Hu", "Long Zhang", "Shuan Li", "Zhi Liu", "Yao Yang", "Chongning Na"], "abstract": "Financial frauds cause billions of losses annually and yet it lacks efficient\napproaches in detecting frauds considering user profile and their behaviors\nsimultaneously in social network . A social network forms a graph structure\nwhilst Graph neural networks (GNN), a promising research domain in Deep\nLearning, can seamlessly process non-Euclidean graph data . In financial fraud\ndetection, the modus operandi of criminals can be identified by analyzing user\nprofile and their behaviors such as transaction, loaning etc. as well as their\nsocial connectivity. Currently, most GNNs are incapable of selecting important\nneighbors since the neighbors' edge attributes (i.e., behaviors) are ignored.\nIn this paper, we propose a novel behavior information aggregation network\n(BIAN) to combine the user behaviors with other user features. Different from\nits close \"relatives\" such as Graph Attention Networks (GAT) and Graph\nTransformer Networks (GTN), it aggregates neighbors based on neighboring edge\nattribute distribution, namely, user behaviors in financial social network. The\nexperimental results on a real-world large-scale financial social network\ndataset, DGraph, show that BIAN obtains the 10.2% gain in AUROC comparing with\nthe State-Of-The-Art models.", "categories": ["cs.SI", "cs.AI"], "published": "2022-11-04T08:33:06+00:00", "updated": "2023-03-26T10:04:27+00:00", "url": "http://arxiv.org/pdf/2211.06315v2", "data_source_type": ["financial social network"], "data_source_name": ["DGraph"], "fraud_type": "financial fraud", "technical_approach_category": ["Graph Neural Networks", "anomaly detection", "behavior analysis", "social network analysis"], "technical_approach_method": ["Behavior Information Aggregation Network (BIAN)", "Graph Attention Networks (GAT)", "Graph Transformer Networks (GTN)"], "technical_approach_description": "Proposes a novel graph neural network (BIAN) that aggregates neighbors based on neighboring edge attribute distribution (user behaviors) to combine user behaviors with other user features for fraudulent user detection in financial social networks.", "innovation_points": "Aggregates neighbors based on neighboring edge attribute distribution (user behaviors), unlike GAT and GTN which ignore edge attributes. This approach specifically handles user behaviors in financial social networks.", "github_repo": ""}
{"id": "2212.02906v1", "title": "A Time Series Approach to Explainability for Neural Nets with Applications to Risk-Management and Fraud Detection", "authors": ["Marc Wildi", "Branka Hadji Misheva"], "abstract": "Artificial intelligence is creating one of the biggest revolution across\ntechnology driven application fields. For the finance sector, it offers many\nopportunities for significant market innovation and yet broad adoption of AI\nsystems heavily relies on our trust in their outputs. Trust in technology is\nenabled by understanding the rationale behind the predictions made. To this\nend, the concept of eXplainable AI emerged introducing a suite of techniques\nattempting to explain to users how complex models arrived at a certain\ndecision. For cross-sectional data classical XAI approaches can lead to\nvaluable insights about the models' inner workings, but these techniques\ngenerally cannot cope well with longitudinal data (time series) in the presence\nof dependence structure and non-stationarity. We here propose a novel XAI\ntechnique for deep learning methods which preserves and exploits the natural\ntime ordering of the data.", "categories": ["q-fin.RM", "cs.LG", "q-fin.TR"], "published": "2022-12-06T12:04:01+00:00", "updated": "2022-12-06T12:04:01+00:00", "url": "http://arxiv.org/pdf/2212.02906v1", "data_source_type": ["finance"], "data_source_name": [], "fraud_type": "fraud detection", "technical_approach_category": ["explainable AI", "deep learning", "time series analysis"], "technical_approach_method": ["novel XAI technique"], "technical_approach_description": "A novel eXplainable AI technique for deep learning methods designed specifically for longitudinal data (time series) that preserves and exploits the natural time ordering of the data, addressing limitations of classical XAI approaches with dependence structure and non-stationarity.", "innovation_points": "Proposes a novel XAI technique for deep learning that can effectively handle longitudinal data with dependence structure and non-stationarity, overcoming the limitations of classical XAI approaches which generally cannot cope well with time series data.", "github_repo": ""}
{"id": "2212.02679v1", "title": "Self-supervised Graph Representation Learning for Black Market Account Detection", "authors": ["Zequan Xu", "Lianyun Li", "Hui Li", "Qihang Sun", "Shaofeng Hu", "Rongrong Ji"], "abstract": "Nowadays, Multi-purpose Messaging Mobile App (MMMA) has become increasingly\nprevalent. MMMAs attract fraudsters and some cybercriminals provide support for\nfrauds via black market accounts (BMAs). Compared to fraudsters, BMAs are not\ndirectly involved in frauds and are more difficult to detect. This paper\nillustrates our BMA detection system SGRL (Self-supervised Graph Representation\nLearning) used in WeChat, a representative MMMA with over a billion users. We\ntailor Graph Neural Network and Graph Self-supervised Learning in SGRL for BMA\ndetection. The workflow of SGRL contains a pretraining phase that utilizes\nstructural information, node attribute information and available human\nknowledge, and a lightweight detection phase. In offline experiments, SGRL\noutperforms state-of-the-art methods by 16.06%-58.17% on offline evaluation\nmeasures. We deploy SGRL in the online environment to detect BMAs on the\nbillion-scale WeChat graph, and it exceeds the alternative by 7.27% on the\nonline evaluation measure. In conclusion, SGRL can alleviate label reliance,\ngeneralize well to unseen data, and effectively detect BMAs in WeChat.", "categories": ["cs.SI", "cs.AI"], "published": "2022-12-06T00:42:00+00:00", "updated": "2022-12-06T00:42:00+00:00", "url": "http://arxiv.org/pdf/2212.02679v1", "data_source_type": ["social_messaging_platform"], "data_source_name": ["WeChat"], "fraud_type": "black_market_account_detection", "technical_approach_category": ["graph_neural_networks", "self_supervised_learning", "anomaly_detection"], "technical_approach_method": ["Graph Neural Network", "Graph Self-supervised Learning"], "technical_approach_description": "A self-supervised graph representation learning system with a pretraining phase that utilizes structural information, node attributes, and human knowledge, followed by a lightweight detection phase for identifying black market accounts.", "innovation_points": "Tailors GNN and graph self-supervised learning for black market account detection; alleviates label reliance, generalizes well to unseen data, and effectively detects BMAs on billion-scale WeChat graph.", "github_repo": ""}
{"id": "2301.05412v3", "title": "Evolve Path Tracer: Early Detection of Malicious Addresses in Cryptocurrency", "authors": ["Ling Cheng", "Feida Zhu", "Yong Wang", "Ruicheng Liang", "Huiwen Liu"], "abstract": "With the ever-increasing boom of Cryptocurrency, detecting fraudulent\nbehaviors and associated malicious addresses draws significant research effort.\nHowever, most existing studies still rely on the full history features or\nfull-fledged address transaction networks, thus cannot meet the requirements of\nearly malicious address detection, which is urgent but seldom discussed by\nexisting studies. To detect fraud behaviors of malicious addresses in the early\nstage, we present Evolve Path Tracer, which consists of Evolve Path Encoder\nLSTM, Evolve Path Graph GCN, and Hierarchical Survival Predictor. Specifically,\nin addition to the general address features, we propose asset transfer paths\nand corresponding path graphs to characterize early transaction patterns.\nFurther, since the transaction patterns are changing rapidly during the early\nstage, we propose Evolve Path Encoder LSTM and Evolve Path Graph GCN to encode\nasset transfer path and path graph under an evolving structure setting.\nHierarchical Survival Predictor then predicts addresses' labels with nice\nscalability and faster prediction speed. We investigate the effectiveness and\nversatility of Evolve Path Tracer on three real-world illicit bitcoin datasets.\nOur experimental results demonstrate that Evolve Path Tracer outperforms the\nstate-of-the-art methods. Extensive scalability experiments demonstrate the\nmodel's adaptivity under a dynamic prediction setting.", "categories": ["cs.AI"], "published": "2023-01-13T06:59:52+00:00", "updated": "2023-06-03T05:59:42+00:00", "url": "http://arxiv.org/pdf/2301.05412v3", "data_source_type": ["cryptocurrency"], "data_source_name": ["bitcoin"], "fraud_type": "malicious cryptocurrency address fraud", "technical_approach_category": ["LSTM", "GCN", "Graph Neural Networks", "anomaly detection", "survival analysis"], "technical_approach_method": ["Evolve Path Encoder LSTM", "Evolve Path Graph GCN", "Hierarchical Survival Predictor"], "technical_approach_description": "Proposes Evolve Path Tracer for early detection of malicious cryptocurrency addresses. It uses asset transfer paths and path graphs to characterize early transaction patterns, encodes them with LSTM and GCN under evolving structures, and employs a hierarchical survival predictor for classification.", "innovation_points": "Focuses on early detection of malicious addresses, which is seldom discussed. Introduces asset transfer paths and path graphs to characterize early transaction patterns, and proposes methods to encode these under evolving structures for scalable and faster prediction.", "github_repo": ""}
{"id": "2302.10407v1", "title": "Label Information Enhanced Fraud Detection against Low Homophily in Graphs", "authors": ["Yuchen Wang", "Jinghui Zhang", "Zhengjie Huang", "Weibin Li", "Shikun Feng", "Ziheng Ma", "Yu Sun", "Dianhai Yu", "Fang Dong", "Jiahui Jin", "Beilun Wang", "Junzhou Luo"], "abstract": "Node classification is a substantial problem in graph-based fraud detection.\nMany existing works adopt Graph Neural Networks (GNNs) to enhance fraud\ndetectors. While promising, currently most GNN-based fraud detectors fail to\ngeneralize to the low homophily setting. Besides, label utilization has been\nproved to be significant factor for node classification problem. But we find\nthey are less effective in fraud detection tasks due to the low homophily in\ngraphs. In this work, we propose GAGA, a novel Group AGgregation enhanced\nTrAnsformer, to tackle the above challenges. Specifically, the group\naggregation provides a portable method to cope with the low homophily issue.\nSuch an aggregation explicitly integrates the label information to generate\ndistinguishable neighborhood information. Along with group aggregation, an\nattempt towards end-to-end trainable group encoding is proposed which augments\nthe original feature space with the class labels. Meanwhile, we devise two\nadditional learnable encodings to recognize the structural and relational\ncontext. Then, we combine the group aggregation and the learnable encodings\ninto a Transformer encoder to capture the semantic information. Experimental\nresults clearly show that GAGA outperforms other competitive graph-based fraud\ndetectors by up to 24.39% on two trending public datasets and a real-world\nindustrial dataset from Anonymous. Even more, the group aggregation is\ndemonstrated to outperform other label utilization methods (e.g., C&S,\nBoT/UniMP) in the low homophily setting.", "categories": ["cs.AI"], "published": "2023-02-21T02:42:28+00:00", "updated": "2023-02-21T02:42:28+00:00", "url": "http://arxiv.org/pdf/2302.10407v1", "data_source_type": ["e-commerce"], "data_source_name": ["Anonymous"], "fraud_type": "graph-based fraud detection", "technical_approach_category": ["Graph Neural Networks", "Transformer", "anomaly detection", "feature engineering"], "technical_approach_method": ["Group AGgregation enhanced Transformer (GAGA)", "group aggregation", "Transformer encoder", "learnable encodings"], "technical_approach_description": "Proposes GAGA, a novel Group AGgregation enhanced Transformer that explicitly integrates label information to handle low homophily in graphs. Uses group aggregation to generate distinguishable neighborhood information, learnable encodings for structural and relational context, and a Transformer encoder to capture semantic information.", "innovation_points": "Novel group aggregation method to cope with low homophily issue, end-to-end trainable group encoding that augments original features with class labels, and integration of group aggregation with learnable encodings in Transformer architecture.", "github_repo": ""}
{"id": "2303.02622v1", "title": "A Multi-Agent Adaptive Deep Learning Framework for Online Intrusion Detection", "authors": ["Mahdi Soltani", "Khashayar Khajavi", "Mahdi Jafari Siavoshani", "Amir Hossein Jahangir"], "abstract": "The network security analyzers use intrusion detection systems (IDSes) to\ndistinguish malicious traffic from benign ones. The deep learning-based IDSes\nare proposed to auto-extract high-level features and eliminate the\ntime-consuming and costly signature extraction process. However, this new\ngeneration of IDSes still suffers from a number of challenges. One of the main\nissues of an IDS is facing traffic concept drift which manifests itself as new\n(i.e., zero-day) attacks, in addition to the changing behavior of benign\nusers/applications. Furthermore, a practical DL-based IDS needs to be conformed\nto a distributed architecture to handle big data challenges.\n  We propose a framework for adapting DL-based models to the changing\nattack/benign traffic behaviors, considering a more practical scenario (i.e.,\nonline adaptable IDSes). This framework employs continual deep anomaly\ndetectors in addition to the federated learning approach to solve the\nabove-mentioned challenges. Furthermore, the proposed framework implements\nsequential packet labeling for each flow, which provides an attack probability\nscore for the flow by gradually observing each flow packet and updating its\nestimation. We evaluate the proposed framework by employing different deep\nmodels (including CNN-based and LSTM-based) over the CIC-IDS2017 and\nCSE-CIC-IDS2018 datasets. Through extensive evaluations and experiments, we\nshow that the proposed distributed framework is well adapted to the traffic\nconcept drift. More precisely, our results indicate that the CNN-based models\nare well suited for continually adapting to the traffic concept drift (i.e.,\nachieving an average detection rate of above 95% while needing just 128 new\nflows for the updating phase), and the LSTM-based models are a good candidate\nfor sequential packet labeling in practical online IDSes (i.e., detecting\nintrusions by just observing their first 15 packets).", "categories": ["cs.CR", "cs.NI"], "published": "2023-03-05T09:43:39+00:00", "updated": "2023-03-05T09:43:39+00:00", "url": "http://arxiv.org/pdf/2303.02622v1", "data_source_type": ["network traffic"], "data_source_name": ["CIC-IDS2017", "CSE-CIC-IDS2018"], "fraud_type": "network intrusion", "technical_approach_category": ["deep learning", "anomaly detection", "federated learning", "continual learning"], "technical_approach_method": ["CNN-based models", "LSTM-based models", "continual deep anomaly detectors", "sequential packet labeling"], "technical_approach_description": "Proposes a multi-agent framework using continual deep anomaly detectors and federated learning to adapt to traffic concept drift. Implements sequential packet labeling to provide attack probability scores by gradually observing each flow's packets.", "innovation_points": "A distributed framework combining continual deep anomaly detection with federated learning to handle traffic concept drift and big data challenges in online intrusion detection. Features sequential packet labeling for early intrusion detection.", "github_repo": ""}
{"id": "2303.18138v2", "title": "BERT4ETH: A Pre-trained Transformer for Ethereum Fraud Detection", "authors": ["Sihao Hu", "Zhen Zhang", "Bingqiao Luo", "Shengliang Lu", "Bingsheng He", "Ling Liu"], "abstract": "As various forms of fraud proliferate on Ethereum, it is imperative to\nsafeguard against these malicious activities to protect susceptible users from\nbeing victimized. While current studies solely rely on graph-based fraud\ndetection approaches, it is argued that they may not be well-suited for dealing\nwith highly repetitive, skew-distributed and heterogeneous Ethereum\ntransactions. To address these challenges, we propose BERT4ETH, a universal\npre-trained Transformer encoder that serves as an account representation\nextractor for detecting various fraud behaviors on Ethereum. BERT4ETH features\nthe superior modeling capability of Transformer to capture the dynamic\nsequential patterns inherent in Ethereum transactions, and addresses the\nchallenges of pre-training a BERT model for Ethereum with three practical and\neffective strategies, namely repetitiveness reduction, skew alleviation and\nheterogeneity modeling. Our empirical evaluation demonstrates that BERT4ETH\noutperforms state-of-the-art methods with significant enhancements in terms of\nthe phishing account detection and de-anonymization tasks. The code for\nBERT4ETH is available at: https://github.com/git-disl/BERT4ETH.", "categories": ["cs.CR", "cs.LG"], "published": "2023-03-29T20:30:52+00:00", "updated": "2023-10-30T20:03:08+00:00", "url": "http://arxiv.org/pdf/2303.18138v2", "data_source_type": ["cryptocurrency"], "data_source_name": ["Ethereum"], "fraud_type": "phishing account detection and de-anonymization", "technical_approach_category": ["Transformer", "pre-trained language model", "representation learning", "anomaly detection"], "technical_approach_method": ["BERT", "Transformer encoder"], "technical_approach_description": "A universal pre-trained Transformer encoder that serves as an account representation extractor for detecting fraud on Ethereum. It captures dynamic sequential patterns in transactions and addresses challenges with repetitiveness reduction, skew alleviation, and heterogeneity modeling.", "innovation_points": "Proposes a pre-trained Transformer for Ethereum fraud detection, addressing limitations of graph-based methods. Introduces three practical strategies for pre-training: repetitiveness reduction, skew alleviation, and heterogeneity modeling.", "github_repo": "https://github.com/git-disl/BERT4ETH"}
{"id": "2303.17334v1", "title": "GAT-COBO: Cost-Sensitive Graph Neural Network for Telecom Fraud Detection", "authors": ["Xinxin Hu", "Haotian Chen", "Junjie Zhang", "Hongchang Chen", "Shuxin Liu", "Xing Li", "Yahui Wang", "Xiangyang Xue"], "abstract": "Along with the rapid evolution of mobile communication technologies, such as\n5G, there has been a drastically increase in telecom fraud, which significantly\ndissipates individual fortune and social wealth. In recent years, graph mining\ntechniques are gradually becoming a mainstream solution for detecting telecom\nfraud. However, the graph imbalance problem, caused by the Pareto principle,\nbrings severe challenges to graph data mining. This is a new and challenging\nproblem, but little previous work has been noticed. In this paper, we propose a\nGraph ATtention network with COst-sensitive BOosting (GAT-COBO) for the graph\nimbalance problem. First, we design a GAT-based base classifier to learn the\nembeddings of all nodes in the graph. Then, we feed the embeddings into a\nwell-designed cost-sensitive learner for imbalanced learning. Next, we update\nthe weights according to the misclassification cost to make the model focus\nmore on the minority class. Finally, we sum the node embeddings obtained by\nmultiple cost-sensitive learners to obtain a comprehensive node representation,\nwhich is used for the downstream anomaly detection task. Extensive experiments\non two real-world telecom fraud detection datasets demonstrate that our\nproposed method is effective for the graph imbalance problem, outperforming the\nstate-of-the-art GNNs and GNN-based fraud detectors. In addition, our model is\nalso helpful for solving the widespread over-smoothing problem in GNNs. The\nGAT-COBO code and datasets are available at https://github.com/xxhu94/GAT-COBO.", "categories": ["cs.LG", "cs.AI"], "published": "2023-03-29T07:02:50+00:00", "updated": "2023-03-29T07:02:50+00:00", "url": "http://arxiv.org/pdf/2303.17334v1", "data_source_type": ["telecom"], "data_source_name": [], "fraud_type": "telecom fraud", "technical_approach_category": ["Graph Neural Network", "anomaly detection", "cost-sensitive learning", "imbalanced learning"], "technical_approach_method": ["Graph ATtention network (GAT)", "Cost-sensitive BOosting (COBO)"], "technical_approach_description": "Proposes GAT-COBO, a cost-sensitive graph neural network that first uses a GAT-based classifier to learn node embeddings, then feeds them into a cost-sensitive learner for imbalanced learning. Node weights are updated based on misclassification cost to focus on the minority class, and comprehensive node representations are summed for downstream anomaly detection.", "innovation_points": "Addresses the graph imbalance problem, a new and challenging issue with little previous work. The proposed method is effective for this problem and also helps solve the widespread over-smoothing problem in GNNs.", "github_repo": "https://github.com/xxhu94/GAT-COBO"}
{"id": "2303.17486v1", "title": "Cost Sensitive GNN-based Imbalanced Learning for Mobile Social Network Fraud Detection", "authors": ["Xinxin Hu", "Haotian Chen", "Hongchang Chen", "Shuxin Liu", "Xing Li", "Shibo Zhang", "Yahui Wang", "Xiangyang Xue"], "abstract": "With the rapid development of mobile networks, the people's social contacts\nhave been considerably facilitated. However, the rise of mobile social network\nfraud upon those networks, has caused a great deal of distress, in case of\ndepleting personal and social wealth, then potentially doing significant\neconomic harm. To detect fraudulent users, call detail record (CDR) data, which\nportrays the social behavior of users in mobile networks, has been widely\nutilized. But the imbalance problem in the aforementioned data, which could\nseverely hinder the effectiveness of fraud detectors based on graph neural\nnetworks(GNN), has hardly been addressed in previous work. In this paper, we\nare going to present a novel Cost-Sensitive Graph Neural Network (CSGNN) by\ncreatively combining cost-sensitive learning and graph neural networks. We\nconduct extensive experiments on two open-source realworld mobile network fraud\ndatasets. The results show that CSGNN can effectively solve the graph imbalance\nproblem and then achieve better detection performance than the state-of-the-art\nalgorithms. We believe that our research can be applied to solve the graph\nimbalance problems in other fields. The CSGNN code and datasets are publicly\navailable at https://github.com/xxhu94/CSGNN.", "categories": ["cs.SI", "cs.AI", "cs.LG"], "published": "2023-03-28T01:43:32+00:00", "updated": "2023-03-28T01:43:32+00:00", "url": "http://arxiv.org/pdf/2303.17486v1", "data_source_type": ["telecommunications"], "data_source_name": ["call detail record (CDR)"], "fraud_type": "mobile social network fraud", "technical_approach_category": ["GNN", "cost-sensitive learning", "imbalanced learning"], "technical_approach_method": ["Cost-Sensitive Graph Neural Network (CSGNN)"], "technical_approach_description": "A novel method that combines cost-sensitive learning with graph neural networks to address the class imbalance problem in call detail record data for detecting fraudulent users in mobile networks.", "innovation_points": "Creatively combining cost-sensitive learning and graph neural networks to solve the graph imbalance problem, which has hardly been addressed in previous work.", "github_repo": "https://github.com/xxhu94/CSGNN"}
{"id": "2305.05538v1", "title": "Efficient pattern-based anomaly detection in a network of multivariate devices", "authors": ["Len Feremans", "Boris Cule", "Bart Goethals"], "abstract": "Many organisations manage service quality and monitor a large set devices and\nservers where each entity is associated with telemetry or physical sensor data\nseries. Recently, various methods have been proposed to detect behavioural\nanomalies, however existing approaches focus on multivariate time series and\nignore communication between entities. Moreover, we aim to support end-users in\nnot only in locating entities and sensors causing an anomaly at a certain\nperiod, but also explain this decision. We propose a scalable approach to\ndetect anomalies using a two-step approach. First, we recover relations between\nentities in the network, since relations are often dynamic in nature and caused\nby an unknown underlying process. Next, we report anomalies based on an\nembedding of sequential patterns. Pattern mining is efficient and supports\ninterpretation, i.e. patterns represent frequent occurring behaviour in time\nseries. We extend pattern mining to filter sequential patterns based on\nfrequency, temporal constraints and minimum description length. We collect and\nrelease two public datasets for international broadcasting and X from an\nInternet company. \\textit{BAD} achieves an overall F1-Score of 0.78 on 9\nbenchmark datasets, significantly outperforming the best baseline by 3\\%.\nAdditionally, \\textit{BAD} is also an order-of-magnitude faster than\nstate-of-the-art anomaly detection methods.", "categories": ["cs.SI", "cs.AI", "cs.LG", "cs.NI"], "published": "2023-05-07T16:05:30+00:00", "updated": "2023-05-07T16:05:30+00:00", "url": "http://arxiv.org/pdf/2305.05538v1", "data_source_type": ["telemetry", "sensor data", "network devices", "servers"], "data_source_name": ["international broadcasting", "Internet company X"], "fraud_type": "behavioral anomaly detection in multivariate network devices", "technical_approach_category": ["pattern mining", "anomaly detection", "network analysis", "embedding", "interpretable AI"], "technical_approach_method": ["sequential pattern mining", "minimum description length", "temporal constraint filtering", "network relation recovery", "embedding-based anomaly detection"], "technical_approach_description": "A two-step approach that first recovers dynamic relations between entities in a network, then detects anomalies using an embedding of sequential patterns. Pattern mining is extended with frequency, temporal constraints and minimum description length filtering for efficiency and interpretability.", "innovation_points": "Detects anomalies while considering communication between entities, supports interpretation by locating entities and sensors causing anomalies, and achieves higher F1-score with significantly faster performance than state-of-the-art methods.", "github_repo": ""}
{"id": "2307.10028v1", "title": "Organized crime behavior of shell-company networks in procurement: prevention insights for policy and reform", "authors": ["J. R. Nicolás-Carlock", "I. Luna-Pla"], "abstract": "In recent years, the analysis of economic crime and corruption in procurement\nhas benefited from integrative studies that acknowledge the interconnected\nnature of the procurement ecosystem. Following this line of research, we\npresent a networks approach for the analysis of shell-companies operations in\nprocurement that makes use of contracting and ownership data under one\nframework to gain knowledge about the organized crime behavior that emerges in\nthis setting. In this approach, ownership and management data are used to\nidentify connected components in shell-company networks that, together with the\ncontracting data, allows to develop an alternative representation of the\ntraditional buyer-supplier network: the module-component bipartite network,\nwhere the modules are groups of buyers and the connected components are groups\nof suppliers. This is applied to two documented cases of procurement corruption\nin Mexico characterized by the involvement of large groups of shell-companies\nin the misappropriation of millions of dollars across many sectors. We quantify\nthe economic impact of single versus connected shell-companies operations. In\naddition, we incorporate metrics for the diversity of operations and favoritism\nlevels. This paper builds into the quantitative organized crime in the private\nsector studies and contributes by proposing a networks approach for preventing\nfraud and understanding the need for legal reforms.", "categories": ["physics.soc-ph"], "published": "2023-07-13T22:38:00+00:00", "updated": "2023-07-13T22:38:00+00:00", "url": "http://arxiv.org/pdf/2307.10028v1", "data_source_type": ["procurement", "government contracting"], "data_source_name": [], "fraud_type": "procurement corruption and organized crime through shell-company networks", "technical_approach_category": ["network analysis", "graph theory", "anomaly detection"], "technical_approach_method": ["module-component bipartite network", "connected components analysis"], "technical_approach_description": "A network approach that integrates contracting and ownership data to analyze shell-company operations in procurement. Uses ownership data to identify connected components in shell-company networks and creates a bipartite network representation with buyer groups as modules and supplier groups as connected components.", "innovation_points": "Proposes a networks approach for preventing fraud and understanding the need for legal reforms in procurement corruption. Quantifies economic impact of single versus connected shell-company operations and incorporates metrics for diversity of operations and favoritism levels.", "github_repo": ""}
{"id": "2307.05121v1", "title": "Transaction Fraud Detection via Spatial-Temporal-Aware Graph Transformer", "authors": ["Yue Tian", "Guanjun Liu"], "abstract": "How to obtain informative representations of transactions and then perform\nthe identification of fraudulent transactions is a crucial part of ensuring\nfinancial security. Recent studies apply Graph Neural Networks (GNNs) to the\ntransaction fraud detection problem. Nevertheless, they encounter challenges in\neffectively learning spatial-temporal information due to structural\nlimitations. Moreover, few prior GNN-based detectors have recognized the\nsignificance of incorporating global information, which encompasses similar\nbehavioral patterns and offers valuable insights for discriminative\nrepresentation learning. Therefore, we propose a novel heterogeneous graph\nneural network called Spatial-Temporal-Aware Graph Transformer (STA-GT) for\ntransaction fraud detection problems. Specifically, we design a temporal\nencoding strategy to capture temporal dependencies and incorporate it into the\ngraph neural network framework, enhancing spatial-temporal information modeling\nand improving expressive ability. Furthermore, we introduce a transformer\nmodule to learn local and global information. Pairwise node-node interactions\novercome the limitation of the GNN structure and build up the interactions with\nthe target node and long-distance ones. Experimental results on two financial\ndatasets compared to general GNN models and GNN-based fraud detectors\ndemonstrate that our proposed method STA-GT is effective on the transaction\nfraud detection task.", "categories": ["cs.LG", "q-fin.GN"], "published": "2023-07-11T08:56:53+00:00", "updated": "2023-07-11T08:56:53+00:00", "url": "http://arxiv.org/pdf/2307.05121v1", "data_source_type": ["financial"], "data_source_name": [], "fraud_type": "transaction fraud", "technical_approach_category": ["Graph Neural Networks (GNNs)", "Transformer", "spatial-temporal modeling"], "technical_approach_method": ["Spatial-Temporal-Aware Graph Transformer (STA-GT)", "heterogeneous graph neural network", "temporal encoding strategy"], "technical_approach_description": "Proposes a heterogeneous graph neural network with temporal encoding to capture spatial-temporal dependencies and a transformer module to learn both local and global information through pairwise node-node interactions for transaction fraud detection.", "innovation_points": "Overcomes limitations of prior GNNs in learning spatial-temporal information and incorporating global information. Introduces temporal encoding strategy and transformer module for pairwise node interactions with target and long-distance nodes.", "github_repo": ""}
{"id": "2307.05633v1", "title": "Transaction Fraud Detection via an Adaptive Graph Neural Network", "authors": ["Yue Tian", "Guanjun Liu", "Jiacun Wang", "Mengchu Zhou"], "abstract": "Many machine learning methods have been proposed to achieve accurate\ntransaction fraud detection, which is essential to the financial security of\nindividuals and banks. However, most existing methods leverage original\nfeatures only or require manual feature engineering. They lack the ability to\nlearn discriminative representations from transaction data. Moreover, criminals\noften commit fraud by imitating cardholders' behaviors, which causes the poor\nperformance of existing detection models. In this paper, we propose an Adaptive\nSampling and Aggregation-based Graph Neural Network (ASA-GNN) that learns\ndiscriminative representations to improve the performance of transaction fraud\ndetection. A neighbor sampling strategy is performed to filter noisy nodes and\nsupplement information for fraudulent nodes. Specifically, we leverage cosine\nsimilarity and edge weights to adaptively select neighbors with similar\nbehavior patterns for target nodes and then find multi-hop neighbors for\nfraudulent nodes. A neighbor diversity metric is designed by calculating the\nentropy among neighbors to tackle the camouflage issue of fraudsters and\nexplicitly alleviate the over-smoothing phenomena. Extensive experiments on\nthree real financial datasets demonstrate that the proposed method ASA-GNN\noutperforms state-of-the-art ones.", "categories": ["cs.LG"], "published": "2023-07-11T07:48:39+00:00", "updated": "2023-07-11T07:48:39+00:00", "url": "http://arxiv.org/pdf/2307.05633v1", "data_source_type": ["financial"], "data_source_name": [], "fraud_type": "transaction fraud", "technical_approach_category": ["Graph Neural Network", "anomaly detection", "feature engineering"], "technical_approach_method": ["Adaptive Sampling and Aggregation-based Graph Neural Network (ASA-GNN)"], "technical_approach_description": "Proposes an Adaptive Sampling and Aggregation-based Graph Neural Network (ASA-GNN) that learns discriminative representations for transaction fraud detection. It uses a neighbor sampling strategy to filter noisy nodes and supplement information for fraudulent nodes, leveraging cosine similarity and edge weights to adaptively select neighbors with similar behavior patterns.", "innovation_points": "An adaptive neighbor sampling strategy to filter noise and supplement information for fraudulent nodes. A neighbor diversity metric based on entropy to tackle fraudster camouflage and explicitly alleviate over-smoothing phenomena.", "github_repo": ""}
{"id": "2309.02012v1", "title": "iLoRE: Dynamic Graph Representation with Instant Long-term Modeling and Re-occurrence Preservation", "authors": ["Siwei Zhang", "Yun Xiong", "Yao Zhang", "Xixi Wu", "Yiheng Sun", "Jiawei Zhang"], "abstract": "Continuous-time dynamic graph modeling is a crucial task for many real-world\napplications, such as financial risk management and fraud detection. Though\nexisting dynamic graph modeling methods have achieved satisfactory results,\nthey still suffer from three key limitations, hindering their scalability and\nfurther applicability. i) Indiscriminate updating. For incoming edges, existing\nmethods would indiscriminately deal with them, which may lead to more time\nconsumption and unexpected noisy information. ii) Ineffective node-wise\nlong-term modeling. They heavily rely on recurrent neural networks (RNNs) as a\nbackbone, which has been demonstrated to be incapable of fully capturing\nnode-wise long-term dependencies in event sequences. iii) Neglect of\nre-occurrence patterns. Dynamic graphs involve the repeated occurrence of\nneighbors that indicates their importance, which is disappointedly neglected by\nexisting methods. In this paper, we present iLoRE, a novel dynamic graph\nmodeling method with instant node-wise Long-term modeling and Re-occurrence\npreservation. To overcome the indiscriminate updating issue, we introduce the\nAdaptive Short-term Updater module that will automatically discard the useless\nor noisy edges, ensuring iLoRE's effectiveness and instant ability. We further\npropose the Long-term Updater to realize more effective node-wise long-term\nmodeling, where we innovatively propose the Identity Attention mechanism to\nempower a Transformer-based updater, bypassing the limited effectiveness of\ntypical RNN-dominated designs. Finally, the crucial re-occurrence patterns are\nalso encoded into a graph module for informative representation learning, which\nwill further improve the expressiveness of our method. Our experimental results\non real-world datasets demonstrate the effectiveness of our iLoRE for dynamic\ngraph modeling.", "categories": ["cs.LG", "cs.AI", "cs.SI"], "published": "2023-09-05T07:48:52+00:00", "updated": "2023-09-05T07:48:52+00:00", "url": "http://arxiv.org/pdf/2309.02012v1", "data_source_type": ["financial"], "data_source_name": [], "fraud_type": "financial fraud detection", "technical_approach_category": ["dynamic graph modeling", "graph representation learning", "Transformer", "attention mechanism", "anomaly detection"], "technical_approach_method": ["Adaptive Short-term Updater", "Long-term Updater", "Identity Attention mechanism", "Transformer-based updater"], "technical_approach_description": "iLoRE is a dynamic graph modeling method that addresses three key limitations: indiscriminate edge updating, ineffective node-wise long-term modeling, and neglect of re-occurrence patterns. It uses an Adaptive Short-term Updater to filter noisy edges, a Long-term Updater with Identity Attention for effective node-wise dependency modeling, and encodes re-occurrence patterns for informative representation learning.", "innovation_points": "Introduces Adaptive Short-term Updater to automatically discard useless/noisy edges, proposes Long-term Updater with innovative Identity Attention mechanism using Transformer architecture instead of RNNs, and encodes crucial re-occurrence patterns into graph representation learning.", "github_repo": ""}
{"id": "2308.16391v2", "title": "Improving the Accuracy of Transaction-Based Ponzi Detection on Ethereum", "authors": ["Phuong Duy Huynh", "Son Hoang Dau", "Xiaodong Li", "Phuc Luong", "Emanuele Viterbo"], "abstract": "The Ponzi scheme, an old-fashioned fraud, is now popular on the Ethereum\nblockchain, causing considerable financial losses to many crypto investors. A\nfew Ponzi detection methods have been proposed in the literature, most of which\ndetect a Ponzi scheme based on its smart contract source code. This\ncontract-code-based approach, while achieving very high accuracy, is not robust\nbecause a Ponzi developer can fool a detection model by obfuscating the opcode\nor inventing a new profit distribution logic that cannot be detected. On the\ncontrary, a transaction-based approach could improve the robustness of\ndetection because transactions, unlike smart contracts, are harder to be\nmanipulated. However, the current transaction-based detection models achieve\nfairly low accuracy. In this paper, we aim to improve the accuracy of the\ntransaction-based models by employing time-series features, which turn out to\nbe crucial in capturing the life-time behaviour a Ponzi application but were\ncompletely overlooked in previous works. We propose a new set of 85 features\n(22 known account-based and 63 new time-series features), which allows\noff-the-shelf machine learning algorithms to achieve up to 30% higher F1-scores\ncompared to existing works.", "categories": ["cs.CR", "cs.CE", "cs.LG", "q-fin.ST"], "published": "2023-08-31T01:54:31+00:00", "updated": "2024-07-18T03:05:50+00:00", "url": "http://arxiv.org/pdf/2308.16391v2", "data_source_type": ["blockchain"], "data_source_name": ["Ethereum"], "fraud_type": "Ponzi scheme fraud", "technical_approach_category": ["feature engineering", "time-series analysis", "machine learning", "anomaly detection"], "technical_approach_method": ["time-series feature extraction", "off-the-shelf machine learning algorithms"], "technical_approach_description": "Proposes a transaction-based detection approach using 85 features (22 account-based and 63 new time-series features) to capture lifetime behavior patterns of Ponzi schemes, improving detection accuracy through machine learning algorithms.", "innovation_points": "Introduces time-series features to capture the life-time behavior of Ponzi applications, which were completely overlooked in previous works, achieving up to 30% higher F1-scores compared to existing transaction-based detection models.", "github_repo": ""}
{"id": "2310.11640v1", "title": "Free-text Keystroke Authentication using Transformers: A Comparative Study of Architectures and Loss Functions", "authors": ["Saleh Momeni", "Bagher BabaAli"], "abstract": "Keystroke biometrics is a promising approach for user identification and\nverification, leveraging the unique patterns in individuals' typing behavior.\nIn this paper, we propose a Transformer-based network that employs\nself-attention to extract informative features from keystroke sequences,\nsurpassing the performance of traditional Recurrent Neural Networks. We explore\ntwo distinct architectures, namely bi-encoder and cross-encoder, and compare\ntheir effectiveness in keystroke authentication. Furthermore, we investigate\ndifferent loss functions, including triplet, batch-all triplet, and WDCL loss,\nalong with various distance metrics such as Euclidean, Manhattan, and cosine\ndistances. These experiments allow us to optimize the training process and\nenhance the performance of our model. To evaluate our proposed model, we employ\nthe Aalto desktop keystroke dataset. The results demonstrate that the\nbi-encoder architecture with batch-all triplet loss and cosine distance\nachieves the best performance, yielding an exceptional Equal Error Rate of\n0.0186%. Furthermore, alternative algorithms for calculating similarity scores\nare explored to enhance accuracy. Notably, the utilization of a one-class\nSupport Vector Machine reduces the Equal Error Rate to an impressive 0.0163%.\nThe outcomes of this study indicate that our model surpasses the previous\nstate-of-the-art in free-text keystroke authentication. These findings\ncontribute to advancing the field of keystroke authentication and offer\npractical implications for secure user verification systems.", "categories": ["cs.CR", "cs.LG"], "published": "2023-10-18T00:34:26+00:00", "updated": "2023-10-18T00:34:26+00:00", "url": "http://arxiv.org/pdf/2310.11640v1", "data_source_type": ["academic research dataset"], "data_source_name": ["Aalto desktop keystroke dataset"], "fraud_type": "unauthorized access prevention", "technical_approach_category": ["Transformer", "self-attention", "anomaly detection", "metric learning"], "technical_approach_method": ["bi-encoder", "cross-encoder", "triplet loss", "batch-all triplet loss", "WDCL loss", "one-class Support Vector Machine"], "technical_approach_description": "Proposes Transformer-based network using self-attention to extract features from keystroke sequences for user authentication. Compares bi-encoder and cross-encoder architectures with various loss functions (triplet, batch-all triplet, WDCL) and distance metrics (Euclidean, Manhattan, cosine).", "innovation_points": "Transformer-based approach surpasses traditional RNNs in keystroke authentication. Achieves state-of-the-art performance with bi-encoder architecture using batch-all triplet loss and cosine distance, achieving exceptional Equal Error Rate of 0.0186%.", "github_repo": ""}
{"id": "2310.08800v2", "title": "DDMT: Denoising Diffusion Mask Transformer Models for Multivariate Time Series Anomaly Detection", "authors": ["Chaocheng Yang", "Tingyin Wang", "Xuanhui Yan"], "abstract": "Anomaly detection in multivariate time series has emerged as a crucial\nchallenge in time series research, with significant research implications in\nvarious fields such as fraud detection, fault diagnosis, and system state\nestimation. Reconstruction-based models have shown promising potential in\nrecent years for detecting anomalies in time series data. However, due to the\nrapid increase in data scale and dimensionality, the issues of noise and Weak\nIdentity Mapping (WIM) during time series reconstruction have become\nincreasingly pronounced. To address this, we introduce a novel Adaptive Dynamic\nNeighbor Mask (ADNM) mechanism and integrate it with the Transformer and\nDenoising Diffusion Model, creating a new framework for multivariate time\nseries anomaly detection, named Denoising Diffusion Mask Transformer (DDMT).\nThe ADNM module is introduced to mitigate information leakage between input and\noutput features during data reconstruction, thereby alleviating the problem of\nWIM during reconstruction. The Denoising Diffusion Transformer (DDT) employs\nthe Transformer as an internal neural network structure for Denoising Diffusion\nModel. It learns the stepwise generation process of time series data to model\nthe probability distribution of the data, capturing normal data patterns and\nprogressively restoring time series data by removing noise, resulting in a\nclear recovery of anomalies. To the best of our knowledge, this is the first\nmodel that combines Denoising Diffusion Model and the Transformer for\nmultivariate time series anomaly detection. Experimental evaluations were\nconducted on five publicly available multivariate time series anomaly detection\ndatasets. The results demonstrate that the model effectively identifies\nanomalies in time series data, achieving state-of-the-art performance in\nanomaly detection.", "categories": ["cs.LG", "cs.AI"], "published": "2023-10-13T01:18:41+00:00", "updated": "2023-10-30T06:23:59+00:00", "url": "http://arxiv.org/pdf/2310.08800v2", "data_source_type": [], "data_source_name": [], "fraud_type": "multivariate time series anomaly detection", "technical_approach_category": ["transformer", "denoising diffusion model", "anomaly detection", "reconstruction-based model"], "technical_approach_method": ["Adaptive Dynamic Neighbor Mask (ADNM)", "Denoising Diffusion Transformer (DDT)", "Transformer", "Denoising Diffusion Model"], "technical_approach_description": "Proposes DDMT framework combining Adaptive Dynamic Neighbor Mask mechanism with Transformer and Denoising Diffusion Model for multivariate time series anomaly detection. ADNM mitigates information leakage and Weak Identity Mapping issues, while the diffusion model learns data distribution to progressively restore time series by removing noise.", "innovation_points": "First model combining Denoising Diffusion Model and Transformer for multivariate time series anomaly detection. Introduces Adaptive Dynamic Neighbor Mask mechanism to address information leakage and Weak Identity Mapping problems in reconstruction-based models.", "github_repo": ""}
{"id": "2310.04768v2", "title": "Online Corrupted User Detection and Regret Minimization", "authors": ["Zhiyong Wang", "Jize Xie", "Tong Yu", "Shuai Li", "John C. S. Lui"], "abstract": "In real-world online web systems, multiple users usually arrive sequentially\ninto the system. For applications like click fraud and fake reviews, some users\ncan maliciously perform corrupted (disrupted) behaviors to trick the system.\nTherefore, it is crucial to design efficient online learning algorithms to\nrobustly learn from potentially corrupted user behaviors and accurately\nidentify the corrupted users in an online manner. Existing works propose bandit\nalgorithms robust to adversarial corruption. However, these algorithms are\ndesigned for a single user, and cannot leverage the implicit social relations\namong multiple users for more efficient learning. Moreover, none of them\nconsider how to detect corrupted users online in the multiple-user scenario. In\nthis paper, we present an important online learning problem named LOCUD to\nlearn and utilize unknown user relations from disrupted behaviors to speed up\nlearning, and identify the corrupted users in an online setting. To robustly\nlearn and utilize the unknown relations among potentially corrupted users, we\npropose a novel bandit algorithm RCLUB-WCU. To detect the corrupted users, we\ndevise a novel online detection algorithm OCCUD based on RCLUB-WCU's inferred\nuser relations. We prove a regret upper bound for RCLUB-WCU, which\nasymptotically matches the lower bound with respect to $T$ up to logarithmic\nfactors, and matches the state-of-the-art results in degenerate cases. We also\ngive a theoretical guarantee for the detection accuracy of OCCUD. With\nextensive experiments, our methods achieve superior performance over previous\nbandit algorithms and high corrupted user detection accuracy.", "categories": ["cs.LG"], "published": "2023-10-07T10:20:26+00:00", "updated": "2023-10-10T01:55:28+00:00", "url": "http://arxiv.org/pdf/2310.04768v2", "data_source_type": ["online web systems"], "data_source_name": [], "fraud_type": "click fraud and fake reviews", "technical_approach_category": ["bandit algorithms", "online learning", "anomaly detection", "relation learning"], "technical_approach_method": ["RCLUB-WCU", "OCCUD"], "technical_approach_description": "Proposes a novel bandit algorithm RCLUB-WCU to robustly learn and utilize unknown user relations from potentially corrupted behaviors, and an online detection algorithm OCCUD to identify corrupted users based on the inferred relations.", "innovation_points": "First to consider leveraging implicit social relations among multiple users for efficient learning and corrupted user detection in online settings, overcoming limitations of single-user focused adversarial bandit algorithms.", "github_repo": ""}
{"id": "2310.04171v3", "title": "Dynamic Relation-Attentive Graph Neural Networks for Fraud Detection", "authors": ["Heehyeon Kim", "Jinhyeok Choi", "Joyce Jiyoung Whang"], "abstract": "Fraud detection aims to discover fraudsters deceiving other users by, for\nexample, leaving fake reviews or making abnormal transactions. Graph-based\nfraud detection methods consider this task as a classification problem with two\nclasses: frauds or normal. We address this problem using Graph Neural Networks\n(GNNs) by proposing a dynamic relation-attentive aggregation mechanism. Based\non the observation that many real-world graphs include different types of\nrelations, we propose to learn a node representation per relation and aggregate\nthe node representations using a learnable attention function that assigns a\ndifferent attention coefficient to each relation. Furthermore, we combine the\nnode representations from different layers to consider both the local and\nglobal structures of a target node, which is beneficial to improving the\nperformance of fraud detection on graphs with heterophily. By employing dynamic\ngraph attention in all the aggregation processes, our method adaptively\ncomputes the attention coefficients for each node. Experimental results show\nthat our method, DRAG, outperforms state-of-the-art fraud detection methods on\nreal-world benchmark datasets.", "categories": ["cs.LG", "cs.AI", "cs.CR", "I.2"], "published": "2023-10-06T11:41:38+00:00", "updated": "2024-01-03T07:32:11+00:00", "url": "http://arxiv.org/pdf/2310.04171v3", "data_source_type": [], "data_source_name": [], "fraud_type": "fake reviews, abnormal transactions", "technical_approach_category": ["Graph Neural Networks", "attention mechanism", "heterophily-aware learning", "dynamic graph processing"], "technical_approach_method": ["dynamic relation-attentive aggregation mechanism", "multi-layer node representation combination"], "technical_approach_description": "Proposes DRAG, a GNN-based fraud detection method that learns node representations per relation and aggregates them using a learnable attention function. Combines node representations from different layers to capture both local and global structures, particularly effective for graphs with heterophily.", "innovation_points": "Dynamic relation-attentive aggregation mechanism that assigns different attention coefficients to each relation, and combination of node representations from different layers to handle heterophily in graphs.", "github_repo": ""}
{"id": "2310.00856v1", "title": "Multi-triplet Feature Augmentation for Ponzi Scheme Detection in Ethereum", "authors": ["Chengxiang Jin", "Jiajun Zhou", "Shengbo Gong", "Chenxuan Xie", "Qi Xuan"], "abstract": "Blockchain technology revolutionizes the Internet, but also poses increasing\nrisks, particularly in cryptocurrency finance. On the Ethereum platform, Ponzi\nschemes, phishing scams, and a variety of other frauds emerge. Existing Ponzi\nscheme detection approaches based on heterogeneous transaction graph modeling\nleverages semantic information between node (account) pairs to establish\nconnections, overlooking the semantic attributes inherent to the edges\n(interactions). To overcome this, we construct heterogeneous Ethereum\ninteraction graphs with multiple triplet interaction patterns to better depict\nthe real Ethereum environment. Based on this, we design a new framework named\nmulti-triplet augmented heterogeneous graph neural network (MAHGNN) for Ponzi\nscheme detection. We introduce the Conditional Variational Auto Encoder (CVAE)\nto capture the semantic information of different triplet interaction patterns,\nwhich facilitates the characterization on account features. Extensive\nexperiments demonstrate that MAHGNN is capable of addressing the problem of\nmulti-edge interactions in heterogeneous Ethereum interaction graphs and\nachieving state-of-the-art performance in Ponzi scheme detection.", "categories": ["cs.SI"], "published": "2023-10-02T02:36:44+00:00", "updated": "2023-10-02T02:36:44+00:00", "url": "http://arxiv.org/pdf/2310.00856v1", "data_source_type": ["cryptocurrency", "blockchain"], "data_source_name": ["Ethereum"], "fraud_type": "Ponzi scheme detection", "technical_approach_category": ["graph neural networks", "heterogeneous graph modeling", "feature augmentation", "anomaly detection", "variational autoencoder"], "technical_approach_method": ["multi-triplet augmented heterogeneous graph neural network (MAHGNN)", "Conditional Variational Auto Encoder (CVAE)"], "technical_approach_description": "Constructs heterogeneous Ethereum interaction graphs with multiple triplet interaction patterns to better depict the real Ethereum environment. Uses MAHGNN framework with CVAE to capture semantic information of different triplet interaction patterns for characterizing account features.", "innovation_points": "Overcomes limitation of existing approaches that overlook semantic attributes inherent to edges (interactions) by constructing graphs with multiple triplet interaction patterns and introducing CVAE to capture semantic information of different triplet patterns.", "github_repo": ""}
{"id": "2309.14880v1", "title": "Credit Card Fraud Detection with Subspace Learning-based One-Class Classification", "authors": ["Zaffar Zaffar", "Fahad Sohrab", "Juho Kanniainen", "Moncef Gabbouj"], "abstract": "In an increasingly digitalized commerce landscape, the proliferation of\ncredit card fraud and the evolution of sophisticated fraudulent techniques have\nled to substantial financial losses. Automating credit card fraud detection is\na viable way to accelerate detection, reducing response times and minimizing\npotential financial losses. However, addressing this challenge is complicated\nby the highly imbalanced nature of the datasets, where genuine transactions\nvastly outnumber fraudulent ones. Furthermore, the high number of dimensions\nwithin the feature set gives rise to the ``curse of dimensionality\". In this\npaper, we investigate subspace learning-based approaches centered on One-Class\nClassification (OCC) algorithms, which excel in handling imbalanced data\ndistributions and possess the capability to anticipate and counter the\ntransactions carried out by yet-to-be-invented fraud techniques. The study\nhighlights the potential of subspace learning-based OCC algorithms by\ninvestigating the limitations of current fraud detection strategies and the\nspecific challenges of credit card fraud detection. These algorithms integrate\nsubspace learning into the data description; hence, the models transform the\ndata into a lower-dimensional subspace optimized for OCC. Through rigorous\nexperimentation and analysis, the study validated that the proposed approach\nhelps tackle the curse of dimensionality and the imbalanced nature of credit\ncard data for automatic fraud detection to mitigate financial losses caused by\nfraudulent activities.", "categories": ["cs.LG"], "published": "2023-09-26T12:26:28+00:00", "updated": "2023-09-26T12:26:28+00:00", "url": "http://arxiv.org/pdf/2309.14880v1", "data_source_type": ["banking", "payment"], "data_source_name": [], "fraud_type": "credit card fraud", "technical_approach_category": ["subspace learning", "one-class classification", "dimensionality reduction", "anomaly detection"], "technical_approach_method": ["One-Class Classification (OCC)"], "technical_approach_description": "The paper investigates subspace learning-based approaches centered on One-Class Classification algorithms. These algorithms integrate subspace learning into the data description, transforming data into a lower-dimensional subspace optimized for OCC to handle imbalanced data distributions and high dimensionality.", "innovation_points": "The approach integrates subspace learning into One-Class Classification to tackle the curse of dimensionality and the imbalanced nature of credit card data, with capability to anticipate transactions from yet-to-be-invented fraud techniques.", "github_repo": ""}
{"id": "2312.14406v1", "title": "Generative Pretraining at Scale: Transformer-Based Encoding of Transactional Behavior for Fraud Detection", "authors": ["Ze Yu Zhao", "Zheng Zhu", "Guilin Li", "Wenhan Wang", "Bo Wang"], "abstract": "In this work, we introduce an innovative autoregressive model leveraging\nGenerative Pretrained Transformer (GPT) architectures, tailored for fraud\ndetection in payment systems. Our approach innovatively confronts token\nexplosion and reconstructs behavioral sequences, providing a nuanced\nunderstanding of transactional behavior through temporal and contextual\nanalysis. Utilizing unsupervised pretraining, our model excels in feature\nrepresentation without the need for labeled data. Additionally, we integrate a\ndifferential convolutional approach to enhance anomaly detection, bolstering\nthe security and efficacy of one of the largest online payment merchants in\nChina. The scalability and adaptability of our model promise broad\napplicability in various transactional contexts.", "categories": ["cs.LG", "cs.AI"], "published": "2023-12-22T03:15:17+00:00", "updated": "2023-12-22T03:15:17+00:00", "url": "http://arxiv.org/pdf/2312.14406v1", "data_source_type": ["payment"], "data_source_name": [], "fraud_type": "payment fraud", "technical_approach_category": ["Transformer", "unsupervised learning", "anomaly detection", "feature representation"], "technical_approach_method": ["Generative Pretrained Transformer (GPT)", "autoregressive model", "differential convolutional approach"], "technical_approach_description": "An autoregressive model using GPT architectures for fraud detection that addresses token explosion and reconstructs behavioral sequences through temporal and contextual analysis. Uses unsupervised pretraining for feature representation and integrates a differential convolutional approach to enhance anomaly detection.", "innovation_points": "Innovatively confronts token explosion and reconstructs behavioral sequences for nuanced understanding of transactional behavior. Utilizes unsupervised pretraining for feature representation without labeled data and integrates a differential convolutional approach to enhance anomaly detection.", "github_repo": ""}
{"id": "2312.06441v3", "title": "Revisiting Graph-Based Fraud Detection in Sight of Heterophily and Spectrum", "authors": ["Fan Xu", "Nan Wang", "Hao Wu", "Xuezhi Wen", "Xibin Zhao", "Hai Wan"], "abstract": "Graph-based fraud detection (GFD) can be regarded as a challenging\nsemi-supervised node binary classification task. In recent years, Graph Neural\nNetworks (GNN) have been widely applied to GFD, characterizing the anomalous\npossibility of a node by aggregating neighbor information. However, fraud\ngraphs are inherently heterophilic, thus most of GNNs perform poorly due to\ntheir assumption of homophily. In addition, due to the existence of heterophily\nand class imbalance problem, the existing models do not fully utilize the\nprecious node label information. To address the above issues, this paper\nproposes a semi-supervised GNN-based fraud detector SEC-GFD. This detector\nincludes a hybrid filtering module and a local environmental constraint module,\nthe two modules are utilized to solve heterophily and label utilization problem\nrespectively. The first module starts from the perspective of the spectral\ndomain, and solves the heterophily problem to a certain extent. Specifically,\nit divides the spectrum into various mixed-frequency bands based on the\ncorrelation between spectrum energy distribution and heterophily. Then in order\nto make full use of the node label information, a local environmental\nconstraint module is adaptively designed. The comprehensive experimental\nresults on four real-world fraud detection datasets denote that SEC-GFD\noutperforms other competitive graph-based fraud detectors. We release our code\nat https://github.com/Sunxkissed/SEC-GFD.", "categories": ["cs.LG", "cs.AI", "cs.SI"], "published": "2023-12-11T15:18:51+00:00", "updated": "2024-07-08T06:54:37+00:00", "url": "http://arxiv.org/pdf/2312.06441v3", "data_source_type": [], "data_source_name": [], "fraud_type": "graph-based fraud detection", "technical_approach_category": ["Graph Neural Networks", "semi-supervised learning", "spectral analysis", "anomaly detection"], "technical_approach_method": ["SEC-GFD", "hybrid filtering module", "local environmental constraint module"], "technical_approach_description": "Proposes SEC-GFD, a semi-supervised GNN-based fraud detector with two modules: a hybrid filtering module that addresses graph heterophily through spectral domain analysis by dividing the spectrum into mixed-frequency bands, and a local environmental constraint module that improves node label utilization.", "innovation_points": "Addresses heterophily in fraud graphs through spectral analysis and improves label utilization with a local environmental constraint module. Solves the problems of heterophily and class imbalance that limit existing GNN models in fraud detection.", "github_repo": "https://github.com/Sunxkissed/SEC-GFD"}
{"id": "2401.03246v1", "title": "SeqNAS: Neural Architecture Search for Event Sequence Classification", "authors": ["Igor Udovichenko", "Egor Shvetsov", "Denis Divitsky", "Dmitry Osin", "Ilya Trofimov", "Anatoly Glushenko", "Ivan Sukharev", "Dmitry Berestenev", "Evgeny Burnaev"], "abstract": "Neural Architecture Search (NAS) methods are widely used in various\nindustries to obtain high quality taskspecific solutions with minimal human\nintervention. Event Sequences find widespread use in various industrial\napplications including churn prediction customer segmentation fraud detection\nand fault diagnosis among others. Such data consist of categorical and\nreal-valued components with irregular timestamps. Despite the usefulness of NAS\nmethods previous approaches only have been applied to other domains images\ntexts or time series. Our work addresses this limitation by introducing a novel\nNAS algorithm SeqNAS specifically designed for event sequence classification.\nWe develop a simple yet expressive search space that leverages commonly used\nbuilding blocks for event sequence classification including multihead self\nattention convolutions and recurrent cells. To perform the search we adopt\nsequential Bayesian Optimization and utilize previously trained models as an\nensemble of teachers to augment knowledge distillation. As a result of our work\nwe demonstrate that our method surpasses state of the art NAS methods and\npopular architectures suitable for sequence classification and holds great\npotential for various industrial applications.", "categories": ["cs.LG", "cs.AI"], "published": "2024-01-06T16:00:26+00:00", "updated": "2024-01-06T16:00:26+00:00", "url": "http://arxiv.org/pdf/2401.03246v1", "data_source_type": [], "data_source_name": [], "fraud_type": "event sequence classification", "technical_approach_category": ["Neural Architecture Search", "knowledge distillation", "Bayesian Optimization"], "technical_approach_method": ["SeqNAS", "multihead self attention", "convolutions", "recurrent cells", "sequential Bayesian Optimization"], "technical_approach_description": "Introduces a novel NAS algorithm, SeqNAS, specifically designed for event sequence classification. It uses a search space with building blocks like multihead self-attention, convolutions, and recurrent cells, and employs sequential Bayesian Optimization with an ensemble of teachers for knowledge distillation.", "innovation_points": "Introduces a novel NAS algorithm, SeqNAS, specifically designed for event sequence classification, addressing a limitation as previous NAS approaches have only been applied to images, texts, or time series.", "github_repo": ""}
{"id": "2401.02450v1", "title": "Locally Differentially Private Embedding Models in Distributed Fraud Prevention Systems", "authors": ["Iker Perez", "Jason Wong", "Piotr Skalski", "Stuart Burrell", "Richard Mortier", "Derek McAuley", "David Sutton"], "abstract": "Global financial crime activity is driving demand for machine learning\nsolutions in fraud prevention. However, prevention systems are commonly\nserviced to financial institutions in isolation, and few provisions exist for\ndata sharing due to fears of unintentional leaks and adversarial attacks.\nCollaborative learning advances in finance are rare, and it is hard to find\nreal-world insights derived from privacy-preserving data processing systems. In\nthis paper, we present a collaborative deep learning framework for fraud\nprevention, designed from a privacy standpoint, and awarded at the recent PETs\nPrize Challenges. We leverage latent embedded representations of varied-length\ntransaction sequences, along with local differential privacy, in order to\nconstruct a data release mechanism which can securely inform externally hosted\nfraud and anomaly detection models. We assess our contribution on two\ndistributed data sets donated by large payment networks, and demonstrate\nrobustness to popular inference-time attacks, along with utility-privacy\ntrade-offs analogous to published work in alternative application domains.", "categories": ["cs.CR", "cs.LG"], "published": "2024-01-03T14:04:18+00:00", "updated": "2024-01-03T14:04:18+00:00", "url": "http://arxiv.org/pdf/2401.02450v1", "data_source_type": ["payment"], "data_source_name": [], "fraud_type": "financial fraud prevention", "technical_approach_category": ["deep learning", "privacy-preserving machine learning", "anomaly detection", "embedding models", "collaborative learning"], "technical_approach_method": ["local differential privacy", "latent embedded representations"], "technical_approach_description": "A collaborative deep learning framework using latent embedded representations of transaction sequences with local differential privacy to create a secure data release mechanism for externally hosted fraud and anomaly detection models.", "innovation_points": "Privacy-first collaborative deep learning framework for fraud prevention awarded at PETs Prize Challenges, featuring secure data release mechanism with local differential privacy and robustness to inference-time attacks.", "github_repo": ""}
{"id": "2401.01641v2", "title": "Towards a Foundation Purchasing Model: Pretrained Generative Autoregression on Transaction Sequences", "authors": ["Piotr Skalski", "David Sutton", "Stuart Burrell", "Iker Perez", "Jason Wong"], "abstract": "Machine learning models underpin many modern financial systems for use cases\nsuch as fraud detection and churn prediction. Most are based on supervised\nlearning with hand-engineered features, which relies heavily on the\navailability of labelled data. Large self-supervised generative models have\nshown tremendous success in natural language processing and computer vision,\nyet so far they haven't been adapted to multivariate time series of financial\ntransactions. In this paper, we present a generative pretraining method that\ncan be used to obtain contextualised embeddings of financial transactions.\nBenchmarks on public datasets demonstrate that it outperforms state-of-the-art\nself-supervised methods on a range of downstream tasks. We additionally perform\nlarge-scale pretraining of an embedding model using a corpus of data from 180\nissuing banks containing 5.1 billion transactions and apply it to the card\nfraud detection problem on hold-out datasets. The embedding model significantly\nimproves value detection rate at high precision thresholds and transfers well\nto out-of-domain distributions.", "categories": ["cs.LG"], "published": "2024-01-03T09:32:48+00:00", "updated": "2024-01-04T16:52:11+00:00", "url": "http://arxiv.org/pdf/2401.01641v2", "data_source_type": ["banking", "payment"], "data_source_name": [], "fraud_type": "card fraud detection", "technical_approach_category": ["self-supervised learning", "generative model", "pretraining", "embedding learning", "multivariate time series analysis"], "technical_approach_method": ["generative pretraining", "autoregressive modeling"], "technical_approach_description": "A generative pretraining method for obtaining contextualized embeddings of financial transactions from multivariate time series data, which can be applied to downstream tasks like fraud detection.", "innovation_points": "First adaptation of large self-supervised generative models to multivariate time series of financial transactions, outperforming state-of-the-art self-supervised methods on downstream tasks and demonstrating effective transfer to out-of-domain distributions.", "github_repo": ""}
{"id": "2401.00965v1", "title": "Improve Fidelity and Utility of Synthetic Credit Card Transaction Time Series from Data-centric Perspective", "authors": ["Din-Yin Hsieh", "Chi-Hua Wang", "Guang Cheng"], "abstract": "Exploring generative model training for synthetic tabular data, specifically\nin sequential contexts such as credit card transaction data, presents\nsignificant challenges. This paper addresses these challenges, focusing on\nattaining both high fidelity to actual data and optimal utility for machine\nlearning tasks. We introduce five pre-processing schemas to enhance the\ntraining of the Conditional Probabilistic Auto-Regressive Model (CPAR),\ndemonstrating incremental improvements in the synthetic data's fidelity and\nutility. Upon achieving satisfactory fidelity levels, our attention shifts to\ntraining fraud detection models tailored for time-series data, evaluating the\nutility of the synthetic data. Our findings offer valuable insights and\npractical guidelines for synthetic data practitioners in the finance sector,\ntransitioning from real to synthetic datasets for training purposes, and\nilluminating broader methodologies for synthesizing credit card transaction\ntime series.", "categories": ["cs.LG"], "published": "2024-01-01T22:34:14+00:00", "updated": "2024-01-01T22:34:14+00:00", "url": "http://arxiv.org/pdf/2401.00965v1", "data_source_type": ["finance", "credit card"], "data_source_name": [], "fraud_type": "credit card fraud detection", "technical_approach_category": ["generative modeling", "synthetic data generation", "time series analysis", "data pre-processing"], "technical_approach_method": ["Conditional Probabilistic Auto-Regressive Model (CPAR)"], "technical_approach_description": "Introduces five pre-processing schemas to enhance training of CPAR model for generating synthetic credit card transaction time series data, focusing on achieving high fidelity to actual data and optimal utility for machine learning tasks.", "innovation_points": "Five pre-processing schemas to improve CPAR model training, demonstrating incremental improvements in synthetic data fidelity and utility for fraud detection model training in time-series data.", "github_repo": ""}
{"id": "2402.09830v1", "title": "Utilizing GANs for Fraud Detection: Model Training with Synthetic Transaction Data", "authors": ["Mengran Zhu", "Yulu Gong", "Yafei Xiang", "Hanyi Yu", "Shuning Huo"], "abstract": "Anomaly detection is a critical challenge across various research domains,\naiming to identify instances that deviate from normal data distributions. This\npaper explores the application of Generative Adversarial Networks (GANs) in\nfraud detection, comparing their advantages with traditional methods. GANs, a\ntype of Artificial Neural Network (ANN), have shown promise in modeling complex\ndata distributions, making them effective tools for anomaly detection. The\npaper systematically describes the principles of GANs and their derivative\nmodels, emphasizing their application in fraud detection across different\ndatasets. And by building a collection of adversarial verification graphs, we\nwill effectively prevent fraud caused by bots or automated systems and ensure\nthat the users in the transaction are real. The objective of the experiment is\nto design and implement a fake face verification code and fraud detection\nsystem based on Generative Adversarial network (GANs) algorithm to enhance the\nsecurity of the transaction process.The study demonstrates the potential of\nGANs in enhancing transaction security through deep learning techniques.", "categories": ["cs.LG", "cs.AI", "cs.CE"], "published": "2024-02-15T09:48:20+00:00", "updated": "2024-02-15T09:48:20+00:00", "url": "http://arxiv.org/pdf/2402.09830v1", "data_source_type": [], "data_source_name": [], "fraud_type": "transaction fraud", "technical_approach_category": ["GAN", "deep learning", "anomaly detection"], "technical_approach_method": ["Generative Adversarial Networks (GANs)"], "technical_approach_description": "The paper applies Generative Adversarial Networks (GANs) for fraud detection by modeling complex data distributions to identify anomalies. It involves building adversarial verification graphs to prevent bot-driven fraud and implementing a fake face verification code system to enhance transaction security.", "innovation_points": "Application of GANs and their derivative models for fraud detection across different datasets, building adversarial verification graphs to prevent bot fraud, and implementing a GAN-based fake face verification code system for transaction security.", "github_repo": ""}
{"id": "2403.00775v1", "title": "Detecting Anomalous Events in Object-centric Business Processes via Graph Neural Networks", "authors": ["Alessandro Niro", "Michael Werner"], "abstract": "Detecting anomalies is important for identifying inefficiencies, errors, or\nfraud in business processes. Traditional process mining approaches focus on\nanalyzing 'flattened', sequential, event logs based on a single case notion.\nHowever, many real-world process executions exhibit a graph-like structure,\nwhere events can be associated with multiple cases. Flattening event logs\nrequires selecting a single case identifier which creates a gap with the real\nevent data and artificially introduces anomalies in the event logs.\nObject-centric process mining avoids these limitations by allowing events to be\nrelated to different cases. This study proposes a novel framework for anomaly\ndetection in business processes that exploits graph neural networks and the\nenhanced information offered by object-centric process mining. We first\nreconstruct and represent the process dependencies of the object-centric event\nlogs as attributed graphs and then employ a graph convolutional autoencoder\narchitecture to detect anomalous events. Our results show that our approach\nprovides promising performance in detecting anomalies at the activity type and\nattributes level, although it struggles to detect anomalies in the temporal\norder of events.", "categories": ["q-fin.ST", "cs.DB", "cs.LG"], "published": "2024-02-14T14:17:56+00:00", "updated": "2024-02-14T14:17:56+00:00", "url": "http://arxiv.org/pdf/2403.00775v1", "data_source_type": ["business process"], "data_source_name": [], "fraud_type": "business process anomalies (inefficiencies, errors, fraud)", "technical_approach_category": ["graph neural networks", "anomaly detection", "autoencoder", "object-centric process mining"], "technical_approach_method": ["Graph Convolutional Autoencoder"], "technical_approach_description": "Proposes a framework for anomaly detection in business processes using graph neural networks on object-centric event logs. Reconstructs process dependencies as attributed graphs and employs a graph convolutional autoencoder to detect anomalous events at activity type and attributes level.", "innovation_points": "Novel framework combining graph neural networks with object-centric process mining to avoid limitations of traditional flattened event logs. Exploits enhanced information from object-centric event logs to detect anomalies without artificial flattening artifacts.", "github_repo": ""}
{"id": "2402.05396v3", "title": "TASER: Temporal Adaptive Sampling for Fast and Accurate Dynamic Graph Representation Learning", "authors": ["Gangda Deng", "Hongkuan Zhou", "Hanqing Zeng", "Yinglong Xia", "Christopher Leung", "Jianbo Li", "Rajgopal Kannan", "Viktor Prasanna"], "abstract": "Recently, Temporal Graph Neural Networks (TGNNs) have demonstrated\nstate-of-the-art performance in various high-impact applications, including\nfraud detection and content recommendation. Despite the success of TGNNs, they\nare prone to the prevalent noise found in real-world dynamic graphs like\ntime-deprecated links and skewed interaction distribution. The noise causes two\ncritical issues that significantly compromise the accuracy of TGNNs: (1) models\nare supervised by inferior interactions, and (2) noisy input induces high\nvariance in the aggregated messages. However, current TGNN denoising techniques\ndo not consider the diverse and dynamic noise pattern of each node. In\naddition, they also suffer from the excessive mini-batch generation overheads\ncaused by traversing more neighbors. We believe the remedy for fast and\naccurate TGNNs lies in temporal adaptive sampling. In this work, we propose\nTASER, the first adaptive sampling method for TGNNs optimized for accuracy,\nefficiency, and scalability. TASER adapts its mini-batch selection based on\ntraining dynamics and temporal neighbor selection based on the contextual,\nstructural, and temporal properties of past interactions. To alleviate the\nbottleneck in mini-batch generation, TASER implements a pure GPU-based temporal\nneighbor finder and a dedicated GPU feature cache. We evaluate the performance\nof TASER using two state-of-the-art backbone TGNNs. On five popular datasets,\nTASER outperforms the corresponding baselines by an average of 2.3% in Mean\nReciprocal Rank (MRR) while achieving an average of 5.1x speedup in training\ntime.", "categories": ["cs.LG", "cs.AI"], "published": "2024-02-08T04:16:35+00:00", "updated": "2024-11-23T10:42:11+00:00", "url": "http://arxiv.org/pdf/2402.05396v3", "data_source_type": [], "data_source_name": [], "fraud_type": "fraud detection", "technical_approach_category": ["Temporal Graph Neural Networks", "adaptive sampling", "denoising", "GPU acceleration"], "technical_approach_method": ["TASER (Temporal Adaptive Sampling)"], "technical_approach_description": "A temporal adaptive sampling method for TGNNs that adapts mini-batch selection based on training dynamics and temporal neighbor selection based on contextual, structural, and temporal properties of past interactions. It includes a GPU-based temporal neighbor finder and feature cache to accelerate processing.", "innovation_points": "The first adaptive sampling method for TGNNs optimized for accuracy, efficiency, and scalability. It considers diverse and dynamic noise patterns of each node and addresses the excessive mini-batch generation overhead in existing methods.", "github_repo": ""}
{"id": "2402.04567v1", "title": "OIL-AD: An Anomaly Detection Framework for Sequential Decision Sequences", "authors": ["Chen Wang", "Sarah Erfani", "Tansu Alpcan", "Christopher Leckie"], "abstract": "Anomaly detection in decision-making sequences is a challenging problem due\nto the complexity of normality representation learning and the sequential\nnature of the task. Most existing methods based on Reinforcement Learning (RL)\nare difficult to implement in the real world due to unrealistic assumptions,\nsuch as having access to environment dynamics, reward signals, and online\ninteractions with the environment. To address these limitations, we propose an\nunsupervised method named Offline Imitation Learning based Anomaly Detection\n(OIL-AD), which detects anomalies in decision-making sequences using two\nextracted behaviour features: action optimality and sequential association. Our\noffline learning model is an adaptation of behavioural cloning with a\ntransformer policy network, where we modify the training process to learn a Q\nfunction and a state value function from normal trajectories. We propose that\nthe Q function and the state value function can provide sufficient information\nabout agents' behavioural data, from which we derive two features for anomaly\ndetection. The intuition behind our method is that the action optimality\nfeature derived from the Q function can differentiate the optimal action from\nothers at each local state, and the sequential association feature derived from\nthe state value function has the potential to maintain the temporal\ncorrelations between decisions (state-action pairs). Our experiments show that\nOIL-AD can achieve outstanding online anomaly detection performance with up to\n34.8% improvement in F1 score over comparable baselines.", "categories": ["cs.LG", "cs.AI"], "published": "2024-02-07T04:06:53+00:00", "updated": "2024-02-07T04:06:53+00:00", "url": "http://arxiv.org/pdf/2402.04567v1", "data_source_type": [], "data_source_name": [], "fraud_type": "anomalous decision-making sequences", "technical_approach_category": ["anomaly detection", "offline learning", "imitation learning", "reinforcement learning", "transformer"], "technical_approach_method": ["Offline Imitation Learning based Anomaly Detection (OIL-AD)", "behavioral cloning", "transformer policy network"], "technical_approach_description": "An unsupervised offline method that uses a modified behavioral cloning process with a transformer policy network to learn a Q function and state value function from normal trajectories. It derives two behavioral features for anomaly detection: action optimality from the Q function and sequential association from the state value function.", "innovation_points": "Proposes an offline unsupervised method that overcomes limitations of existing RL-based approaches by not requiring access to environment dynamics, reward signals, or online interactions. Introduces two novel behavioral features extracted from learned functions for detecting anomalies in decision sequences.", "github_repo": ""}
{"id": "2402.17472v4", "title": "RAGFormer: Learning Semantic Attributes and Topological Structure for Fraud Detection", "authors": ["Haolin Li", "Shuyang Jiang", "Lifeng Zhang", "Siyuan Du", "Guangnan Ye", "Hongfeng Chai"], "abstract": "Fraud detection remains a challenging task due to the complex and deceptive\nnature of fraudulent activities. Current approaches primarily concentrate on\nlearning only one perspective of the graph: either the topological structure of\nthe graph or the attributes of individual nodes. However, we conduct empirical\nstudies to reveal that these two types of features, while nearly orthogonal,\nare each independently effective. As a result, previous methods can not fully\ncapture the comprehensive characteristics of the fraud graph. To address this\ndilemma, we present a novel framework called Relation-Aware GNN with\ntransFormer~(RAGFormer) which simultaneously embeds both semantic and\ntopological features into a target node. The simple yet effective network\nconsists of a semantic encoder, a topology encoder, and an attention fusion\nmodule. The semantic encoder utilizes Transformer to learn semantic features\nand node interactions across different relations. We introduce Relation-Aware\nGNN as the topology encoder to learn topological features and node interactions\nwithin each relation. These two complementary features are interleaved through\nan attention fusion module to support prediction by both orthogonal features.\nExtensive experiments on two popular public datasets demonstrate that RAGFormer\nachieves state-of-the-art performance. The significant improvement of RAGFormer\nin an industrial credit card fraud detection dataset further validates the\napplicability of our method in real-world business scenarios.", "categories": ["cs.LG", "cs.AI"], "published": "2024-02-27T12:53:15+00:00", "updated": "2025-02-11T12:29:00+00:00", "url": "http://arxiv.org/pdf/2402.17472v4", "data_source_type": ["banking", "payment"], "data_source_name": [], "fraud_type": "credit card fraud", "technical_approach_category": ["Graph Neural Networks", "Transformer", "multimodal fusion", "attention mechanism"], "technical_approach_method": ["Relation-Aware GNN", "Transformer", "attention fusion module"], "technical_approach_description": "A framework that simultaneously embeds semantic attributes and topological structure features for fraud detection. It consists of a Transformer-based semantic encoder for cross-relation features, a Relation-Aware GNN topology encoder for intra-relation features, and an attention fusion module to combine these complementary orthogonal features.", "innovation_points": "Simultaneously learns both semantic attributes and topological structure features which are nearly orthogonal but independently effective, addressing the limitation of previous methods that focused on only one perspective.", "github_repo": ""}
{"id": "2402.14708v2", "title": "CaT-GNN: Enhancing Credit Card Fraud Detection via Causal Temporal Graph Neural Networks", "authors": ["Yifan Duan", "Guibin Zhang", "Shilong Wang", "Xiaojiang Peng", "Wang Ziqi", "Junyuan Mao", "Hao Wu", "Xinke Jiang", "Kun Wang"], "abstract": "Credit card fraud poses a significant threat to the economy. While Graph\nNeural Network (GNN)-based fraud detection methods perform well, they often\noverlook the causal effect of a node's local structure on predictions. This\npaper introduces a novel method for credit card fraud detection, the\n\\textbf{\\underline{Ca}}usal \\textbf{\\underline{T}}emporal\n\\textbf{\\underline{G}}raph \\textbf{\\underline{N}}eural \\textbf{N}etwork\n(CaT-GNN), which leverages causal invariant learning to reveal inherent\ncorrelations within transaction data. By decomposing the problem into discovery\nand intervention phases, CaT-GNN identifies causal nodes within the transaction\ngraph and applies a causal mixup strategy to enhance the model's robustness and\ninterpretability. CaT-GNN consists of two key components: Causal-Inspector and\nCausal-Intervener. The Causal-Inspector utilizes attention weights in the\ntemporal attention mechanism to identify causal and environment nodes without\nintroducing additional parameters. Subsequently, the Causal-Intervener performs\na causal mixup enhancement on environment nodes based on the set of nodes.\nEvaluated on three datasets, including a private financial dataset and two\npublic datasets, CaT-GNN demonstrates superior performance over existing\nstate-of-the-art methods. Our findings highlight the potential of integrating\ncausal reasoning with graph neural networks to improve fraud detection\ncapabilities in financial transactions.", "categories": ["cs.LG", "cs.AI", "q-fin.ST"], "published": "2024-02-22T17:08:09+00:00", "updated": "2024-11-27T12:15:06+00:00", "url": "http://arxiv.org/pdf/2402.14708v2", "data_source_type": ["financial", "banking"], "data_source_name": ["private financial dataset"], "fraud_type": "credit card fraud", "technical_approach_category": ["GNN", "causal invariant learning", "temporal modeling", "anomaly detection", "explainable AI"], "technical_approach_method": ["Causal Temporal Graph Neural Network", "Causal-Inspector", "Causal-Intervener", "temporal attention mechanism", "causal mixup strategy"], "technical_approach_description": "Leverages causal invariant learning to reveal inherent correlations in transaction data through a two-phase approach: Causal-Inspector identifies causal nodes using temporal attention weights, and Causal-Intervener applies causal mixup enhancement on environment nodes to improve robustness and interpretability.", "innovation_points": "Integrates causal reasoning with graph neural networks, introduces causal invariant learning for fraud detection, identifies causal nodes without additional parameters using temporal attention, and applies causal mixup strategy to enhance model robustness and interpretability.", "github_repo": ""}
{"id": "2404.09802v1", "title": "The Performance of Sequential Deep Learning Models in Detecting Phishing Websites Using Contextual Features of URLs", "authors": ["Saroj Gopali", "Akbar S. Namin", "Faranak Abri", "Keith S. Jones"], "abstract": "Cyber attacks continue to pose significant threats to individuals and\norganizations, stealing sensitive data such as personally identifiable\ninformation, financial information, and login credentials. Hence, detecting\nmalicious websites before they cause any harm is critical to preventing fraud\nand monetary loss. To address the increasing number of phishing attacks,\nprotective mechanisms must be highly responsive, adaptive, and scalable.\nFortunately, advances in the field of machine learning, coupled with access to\nvast amounts of data, have led to the adoption of various deep learning models\nfor timely detection of these cyber crimes. This study focuses on the detection\nof phishing websites using deep learning models such as Multi-Head Attention,\nTemporal Convolutional Network (TCN), BI-LSTM, and LSTM where URLs of the\nphishing websites are treated as a sequence. The results demonstrate that\nMulti-Head Attention and BI-LSTM model outperform some other deep\nlearning-based algorithms such as TCN and LSTM in producing better precision,\nrecall, and F1-scores.", "categories": ["cs.CR", "cs.LG"], "published": "2024-04-15T13:58:22+00:00", "updated": "2024-04-15T13:58:22+00:00", "url": "http://arxiv.org/pdf/2404.09802v1", "data_source_type": ["web"], "data_source_name": [], "fraud_type": "phishing website detection", "technical_approach_category": ["deep learning", "sequence modeling", "attention mechanism", "anomaly detection"], "technical_approach_method": ["Multi-Head Attention", "Temporal Convolutional Network (TCN)", "BI-LSTM", "LSTM"], "technical_approach_description": "This study focuses on detecting phishing websites using deep learning models that treat URLs as sequences. The models include Multi-Head Attention, Temporal Convolutional Network (TCN), BI-LSTM, and LSTM for timely detection of cyber crimes.", "innovation_points": "The research demonstrates that Multi-Head Attention and BI-LSTM models outperform other deep learning algorithms like TCN and LSTM in producing better precision, recall, and F1-scores for phishing detection.", "github_repo": ""}
{"id": "2404.02595v5", "title": "QFNN-FFD: Quantum Federated Neural Network for Financial Fraud Detection", "authors": ["Nouhaila Innan", "Alberto Marchisio", "Mohamed Bennai", "Muhammad Shafique"], "abstract": "This study introduces the Quantum Federated Neural Network for Financial\nFraud Detection (QFNN-FFD), a cutting-edge framework merging Quantum Machine\nLearning (QML) and quantum computing with Federated Learning (FL) for financial\nfraud detection. Using quantum technologies' computational power and the robust\ndata privacy protections offered by FL, QFNN-FFD emerges as a secure and\nefficient method for identifying fraudulent transactions within the financial\nsector. Implementing a dual-phase training model across distributed clients\nenhances data integrity and enables superior performance metrics, achieving\nprecision rates consistently above 95%. Additionally, QFNN-FFD demonstrates\nexceptional resilience by maintaining an impressive 80% accuracy, highlighting\nits robustness and readiness for real-world applications. This combination of\nhigh performance, security, and robustness against noise positions QFNN-FFD as\na transformative advancement in financial technology solutions and establishes\nit as a new benchmark for privacy-focused fraud detection systems. This\nframework facilitates the broader adoption of secure, quantum-enhanced\nfinancial services and inspires future innovations that could use QML to tackle\ncomplex challenges in other areas requiring high confidentiality and accuracy.", "categories": ["quant-ph", "cs.LG", "q-fin.RM"], "published": "2024-04-03T09:19:46+00:00", "updated": "2025-07-13T04:24:08+00:00", "url": "http://arxiv.org/pdf/2404.02595v5", "data_source_type": ["financial"], "data_source_name": [], "fraud_type": "financial fraud detection", "technical_approach_category": ["Quantum Machine Learning", "Federated Learning", "neural networks"], "technical_approach_method": ["Quantum Federated Neural Network (QFNN-FFD)"], "technical_approach_description": "A framework merging Quantum Machine Learning and quantum computing with Federated Learning for financial fraud detection, implementing a dual-phase training model across distributed clients to enhance data integrity and performance.", "innovation_points": "Introduces QFNN-FFD as a secure and efficient method combining quantum technologies' computational power with FL's data privacy protections for fraud detection, achieving high precision and robustness against noise.", "github_repo": ""}
{"id": "2404.00060v1", "title": "Temporal Graph Networks for Graph Anomaly Detection in Financial Networks", "authors": ["Yejin Kim", "Youngbin Lee", "Minyoung Choe", "Sungju Oh", "Yongjae Lee"], "abstract": "This paper explores the utilization of Temporal Graph Networks (TGN) for\nfinancial anomaly detection, a pressing need in the era of fintech and\ndigitized financial transactions. We present a comprehensive framework that\nleverages TGN, capable of capturing dynamic changes in edges within financial\nnetworks, for fraud detection. Our study compares TGN's performance against\nstatic Graph Neural Network (GNN) baselines, as well as cutting-edge hypergraph\nneural network baselines using DGraph dataset for a realistic financial\ncontext. Our results demonstrate that TGN significantly outperforms other\nmodels in terms of AUC metrics. This superior performance underlines TGN's\npotential as an effective tool for detecting financial fraud, showcasing its\nability to adapt to the dynamic and complex nature of modern financial systems.\nWe also experimented with various graph embedding modules within the TGN\nframework and compared the effectiveness of each module. In conclusion, we\ndemonstrated that, even with variations within TGN, it is possible to achieve\ngood performance in the anomaly detection task.", "categories": ["q-fin.ST", "cs.AI", "cs.LG"], "published": "2024-03-27T07:17:16+00:00", "updated": "2024-03-27T07:17:16+00:00", "url": "http://arxiv.org/pdf/2404.00060v1", "data_source_type": ["financial"], "data_source_name": ["DGraph"], "fraud_type": "financial fraud", "technical_approach_category": ["Graph Neural Network", "Temporal Graph Network", "anomaly detection"], "technical_approach_method": ["Temporal Graph Networks (TGN)", "static Graph Neural Network (GNN)", "hypergraph neural network"], "technical_approach_description": "Presents a framework leveraging Temporal Graph Networks (TGN) to capture dynamic changes in edges within financial networks for fraud detection. Compares TGN performance against static GNN and hypergraph neural network baselines.", "innovation_points": "Demonstrates that TGN significantly outperforms other models in AUC metrics for financial anomaly detection, showcasing its ability to adapt to the dynamic and complex nature of modern financial systems.", "github_repo": ""}
{"id": "2405.01448v1", "title": "GTX: A Transactional Graph Data System For HTAP Workloads", "authors": ["Libin Zhou", "Walid Aref"], "abstract": "Processing, managing, and analyzing dynamic graphs are the cornerstone in\nmultiple application domains including fraud detection, recommendation system,\ngraph neural network training, etc. This demo presents GTX, a latch-free\nwrite-optimized transactional graph data system that supports high throughput\nread-write transactions while maintaining competitive graph analytics. GTX has\na unique latch-free graph storage and a transaction and concurrency control\nprotocol for dynamic power-law graphs. GTX leverages atomic operations to\neliminate latches, proposes a delta-based multi-version storage, and designs a\nhybrid transaction commit protocol to reduce interference between concurrent\noperations. To further improve its throughput, we design a delta-chains index\nto support efficient edge lookups. GTX manages concurrency control at\ndelta-chain level, and provides adaptive concurrency according to the workload.\nReal-world graph access and updates exhibit temporal localities and hotspots.\nUnlike other transactional graph systems that experience significant\nperformance degradation, GTX is the only system that can adapt to temporal\nlocalities and hotspots in graph updates and maintain\nmillion-transactions-per-second throughput. GTX is prototyped as a graph\nlibrary and is evaluated using a graph library evaluation tool using real and\nsynthetic datasets.", "categories": ["cs.DB", "H.2.4"], "published": "2024-05-02T16:32:37+00:00", "updated": "2024-05-02T16:32:37+00:00", "url": "http://arxiv.org/pdf/2405.01448v1", "data_source_type": [], "data_source_name": [], "fraud_type": "fraud detection", "technical_approach_category": ["transactional database", "concurrency control", "graph storage", "indexing"], "technical_approach_method": ["latch-free graph storage", "delta-based multi-version storage", "hybrid transaction commit protocol", "delta-chains index"], "technical_approach_description": "A transactional graph data system with a latch-free storage, a concurrency control protocol for dynamic power-law graphs, and a delta-chains index for efficient edge lookups. It uses atomic operations and a hybrid commit protocol to reduce interference between concurrent operations.", "innovation_points": "A unique latch-free graph storage and transaction protocol. It is the only system that can adapt to temporal localities and hotspots in graph updates and maintain million-transactions-per-second throughput.", "github_repo": ""}
{"id": "2404.13690v1", "title": "Detecting Compromised IoT Devices Using Autoencoders with Sequential Hypothesis Testing", "authors": ["Md Mainuddin", "Zhenhai Duan", "Yingfei Dong"], "abstract": "IoT devices fundamentally lack built-in security mechanisms to protect\nthemselves from security attacks. Existing works on improving IoT security\nmostly focus on detecting anomalous behaviors of IoT devices. However, these\nexisting anomaly detection schemes may trigger an overwhelmingly large number\nof false alerts, rendering them unusable in detecting compromised IoT devices.\nIn this paper we develop an effective and efficient framework, named CUMAD, to\ndetect compromised IoT devices. Instead of directly relying on individual\nanomalous events, CUMAD aims to accumulate sufficient evidence in detecting\ncompromised IoT devices, by integrating an autoencoder-based anomaly detection\nsubsystem with a sequential probability ratio test (SPRT)-based sequential\nhypothesis testing subsystem. CUMAD can effectively reduce the number of false\nalerts in detecting compromised IoT devices, and moreover, it can detect\ncompromised IoT devices quickly. Our evaluation studies based on the\npublic-domain N-BaIoT dataset show that CUMAD can on average reduce the false\npositive rate from about 3.57% using only the autoencoder-based anomaly\ndetection scheme to about 0.5%; in addition, CUMAD can detect compromised IoT\ndevices quickly, with less than 5 observations on average.", "categories": ["cs.CR", "cs.LG"], "published": "2024-04-21T15:33:17+00:00", "updated": "2024-04-21T15:33:17+00:00", "url": "http://arxiv.org/pdf/2404.13690v1", "data_source_type": ["IoT"], "data_source_name": ["N-BaIoT"], "fraud_type": "compromised IoT device detection", "technical_approach_category": ["anomaly detection", "sequential hypothesis testing", "autoencoder"], "technical_approach_method": ["autoencoder", "sequential probability ratio test (SPRT)"], "technical_approach_description": "Develops CUMAD framework integrating an autoencoder-based anomaly detection subsystem with a sequential probability ratio test (SPRT)-based sequential hypothesis testing subsystem to accumulate sufficient evidence for detecting compromised IoT devices.", "innovation_points": "Effectively reduces false alerts by accumulating evidence rather than relying on individual anomalous events, significantly lowering false positive rates and enabling quick detection with few observations.", "github_repo": ""}
{"id": "2406.11389v1", "title": "SEFraud: Graph-based Self-Explainable Fraud Detection via Interpretative Mask Learning", "authors": ["Kaidi Li", "Tianmeng Yang", "Min Zhou", "Jiahao Meng", "Shendi Wang", "Yihui Wu", "Boshuai Tan", "Hu Song", "Lujia Pan", "Fan Yu", "Zhenli Sheng", "Yunhai Tong"], "abstract": "Graph-based fraud detection has widespread application in modern industry\nscenarios, such as spam review and malicious account detection. While\nconsiderable efforts have been devoted to designing adequate fraud detectors,\nthe interpretability of their results has often been overlooked. Previous works\nhave attempted to generate explanations for specific instances using post-hoc\nexplaining methods such as a GNNExplainer. However, post-hoc explanations can\nnot facilitate the model predictions and the computational cost of these\nmethods cannot meet practical requirements, thus limiting their application in\nreal-world scenarios. To address these issues, we propose SEFraud, a novel\ngraph-based self-explainable fraud detection framework that simultaneously\ntackles fraud detection and result in interpretability. Concretely, SEFraud\nfirst leverages customized heterogeneous graph transformer networks with\nlearnable feature masks and edge masks to learn expressive representations from\nthe informative heterogeneously typed transactions. A new triplet loss is\nfurther designed to enhance the performance of mask learning. Empirical results\non various datasets demonstrate the effectiveness of SEFraud as it shows\nconsiderable advantages in both the fraud detection performance and\ninterpretability of prediction results. Moreover, SEFraud has been deployed and\noffers explainable fraud detection service for the largest bank in China,\nIndustrial and Commercial Bank of China Limited (ICBC). Results collected from\nthe production environment of ICBC show that SEFraud can provide accurate\ndetection results and comprehensive explanations that align with the expert\nbusiness understanding, confirming its efficiency and applicability in\nlarge-scale online services.", "categories": ["cs.LG"], "published": "2024-06-17T10:18:53+00:00", "updated": "2024-06-17T10:18:53+00:00", "url": "http://arxiv.org/pdf/2406.11389v1", "data_source_type": ["banking"], "data_source_name": ["Industrial and Commercial Bank of China Limited (ICBC)"], "fraud_type": "fraud detection in financial transactions", "technical_approach_category": ["graph neural networks", "transformer", "interpretable AI", "anomaly detection", "mask learning"], "technical_approach_method": ["heterogeneous graph transformer networks", "learnable feature masks", "learnable edge masks", "triplet loss"], "technical_approach_description": "Proposes SEFraud, a graph-based self-explainable fraud detection framework that uses customized heterogeneous graph transformer networks with learnable feature and edge masks to learn expressive representations from heterogeneous transaction data, enhanced by a novel triplet loss for mask learning.", "innovation_points": "Simultaneously tackles fraud detection and result interpretability through self-explainable framework with learnable masks, eliminating need for post-hoc explanations and providing comprehensive explanations that align with expert business understanding.", "github_repo": ""}
{"id": "2406.03733v4", "title": "Credit Card Fraud Detection Using Advanced Transformer Model", "authors": ["Chang Yu", "Yongshun Xu", "Jin Cao", "Ye Zhang", "Yinxin Jin", "Mengran Zhu"], "abstract": "With the proliferation of various online and mobile payment systems, credit\ncard fraud has emerged as a significant threat to financial security. This\nstudy focuses on innovative applications of the latest Transformer models for\nmore robust and precise fraud detection. To ensure the reliability of the data,\nwe meticulously processed the data sources, balancing the dataset to address\nthe issue of data sparsity significantly. We also selected highly correlated\nvectors to strengthen the training process.To guarantee the reliability and\npracticality of the new Transformer model, we conducted performance comparisons\nwith several widely adopted models, including Support Vector Machine (SVM),\nRandom Forest, Neural Network, and Logistic Regression. We rigorously compared\nthese models using metrics such as Precision, Recall, and F1 Score. Through\nthese detailed analyses and comparisons, we present to the readers a highly\nefficient and powerful anti-fraud mechanism with promising prospects. The\nresults demonstrate that the Transformer model not only excels in traditional\napplications but also shows great potential in niche areas like fraud\ndetection, offering a substantial advancement in the field.", "categories": ["cs.LG", "cs.AI"], "published": "2024-06-06T04:12:57+00:00", "updated": "2024-11-12T16:44:14+00:00", "url": "http://arxiv.org/pdf/2406.03733v4", "data_source_type": ["payment"], "data_source_name": [], "fraud_type": "credit card fraud", "technical_approach_category": ["Transformer"], "technical_approach_method": ["Transformer"], "technical_approach_description": "Applies the latest Transformer model for robust and precise credit card fraud detection, with meticulous data processing including dataset balancing to address data sparsity and selection of highly correlated vectors to strengthen training.", "innovation_points": "Innovative application of the latest Transformer models for fraud detection, demonstrating its potential in this niche area and presenting a highly efficient anti-fraud mechanism.", "github_repo": ""}
{"id": "2405.13692v2", "title": "Challenging Gradient Boosted Decision Trees with Tabular Transformers for Fraud Detection at Booking.com", "authors": ["Sergei Krutikov", "Bulat Khaertdinov", "Rodion Kiriukhin", "Shubham Agrawal", "Mozhdeh Ariannezhad", "Kees Jan De Vries"], "abstract": "Transformer-based neural networks, empowered by Self-Supervised Learning\n(SSL), have demonstrated unprecedented performance across various domains.\nHowever, related literature suggests that tabular Transformers may struggle to\noutperform classical Machine Learning algorithms, such as Gradient Boosted\nDecision Trees (GBDT). In this paper, we aim to challenge GBDTs with tabular\nTransformers on a typical task faced in e-commerce, namely fraud detection. Our\nstudy is additionally motivated by the problem of selection bias, often\noccurring in real-life fraud detection systems. It is caused by the production\nsystem affecting which subset of traffic becomes labeled. This issue is\ntypically addressed by sampling randomly a small part of the whole production\ndata, referred to as a Control Group. This subset follows a target distribution\nof production data and therefore is usually preferred for training\nclassification models with standard ML algorithms. Our methodology leverages\nthe capabilities of Transformers to learn transferable representations using\nall available data by means of SSL, giving it an advantage over classical\nmethods. Furthermore, we conduct large-scale experiments, pre-training tabular\nTransformers on vast amounts of data instances and fine-tuning them on smaller\ntarget datasets. The proposed approach outperforms heavily tuned GBDTs by a\nconsiderable margin of the Average Precision (AP) score in offline evaluations.\nFinally, we report the results of an online A/B experiment. Experimental\nresults confirm the superiority of tabular Transformers compared to GBDTs in\nproduction, demonstrated by a statistically significant improvement in our\nbusiness metric.", "categories": ["cs.LG"], "published": "2024-05-22T14:38:48+00:00", "updated": "2025-06-30T08:01:46+00:00", "url": "http://arxiv.org/pdf/2405.13692v2", "data_source_type": ["e-commerce"], "data_source_name": ["Booking.com"], "fraud_type": "fraud detection", "technical_approach_category": ["Transformer", "self-supervised learning", "representation learning", "transfer learning"], "technical_approach_method": ["tabular Transformers", "self-supervised pre-training", "fine-tuning"], "technical_approach_description": "Leverages tabular Transformers with self-supervised learning to learn transferable representations from all available data, pre-trained on vast data and fine-tuned on smaller target datasets to address selection bias in fraud detection.", "innovation_points": "Outperforms heavily tuned GBDTs by a considerable margin in offline evaluations and shows statistically significant improvement in online A/B testing by using SSL with Transformers on all data instead of just control group data.", "github_repo": ""}
{"id": "2407.06529v1", "title": "Advanced Financial Fraud Detection Using GNN-CL Model", "authors": ["Yu Cheng", "Junjie Guo", "Shiqing Long", "You Wu", "Mengfang Sun", "Rong Zhang"], "abstract": "The innovative GNN-CL model proposed in this paper marks a breakthrough in\nthe field of financial fraud detection by synergistically combining the\nadvantages of graph neural networks (gnn), convolutional neural networks (cnn)\nand long short-term memory (LSTM) networks. This convergence enables\nmultifaceted analysis of complex transaction patterns, improving detection\naccuracy and resilience against complex fraudulent activities. A key novelty of\nthis paper is the use of multilayer perceptrons (MLPS) to estimate node\nsimilarity, effectively filtering out neighborhood noise that can lead to false\npositives. This intelligent purification mechanism ensures that only the most\nrelevant information is considered, thereby improving the model's understanding\nof the network structure. Feature weakening often plagues graph-based models\ndue to the dilution of key signals. In order to further address the challenge\nof feature weakening, GNN-CL adopts reinforcement learning strategies. By\ndynamically adjusting the weights assigned to central nodes, it reinforces the\nimportance of these influential entities to retain important clues of fraud\neven in less informative data. Experimental evaluations on Yelp datasets show\nthat the results highlight the superior performance of GNN-CL compared to\nexisting methods.", "categories": ["cs.LG", "q-fin.ST"], "published": "2024-07-09T03:59:06+00:00", "updated": "2024-07-09T03:59:06+00:00", "url": "http://arxiv.org/pdf/2407.06529v1", "data_source_type": ["e-commerce", "review platform"], "data_source_name": ["Yelp"], "fraud_type": "financial fraud", "technical_approach_category": ["Graph Neural Networks", "Convolutional Neural Networks", "LSTM", "Reinforcement Learning", "Anomaly Detection"], "technical_approach_method": ["GNN", "CNN", "LSTM", "Multilayer Perceptrons (MLPs)", "Reinforcement Learning"], "technical_approach_description": "The GNN-CL model combines graph neural networks, convolutional neural networks, and LSTM networks to analyze complex transaction patterns for fraud detection. It uses MLPs to estimate node similarity for neighborhood noise filtering and reinforcement learning to dynamically adjust node weights to address feature weakening.", "innovation_points": "Synergistic combination of GNN, CNN, and LSTM networks; use of MLPs to estimate node similarity for filtering neighborhood noise; adoption of reinforcement learning strategies to dynamically adjust node weights and address feature weakening.", "github_repo": ""}
{"id": "2408.00513v1", "title": "VecAug: Unveiling Camouflaged Frauds with Cohort Augmentation for Enhanced Detection", "authors": ["Fei Xiao", "Shaofeng Cai", "Gang Chen", "H. V. Jagadish", "Beng Chin Ooi", "Meihui Zhang"], "abstract": "Fraud detection presents a challenging task characterized by ever-evolving\nfraud patterns and scarce labeled data. Existing methods predominantly rely on\ngraph-based or sequence-based approaches. While graph-based approaches connect\nusers through shared entities to capture structural information, they remain\nvulnerable to fraudsters who can disrupt or manipulate these connections. In\ncontrast, sequence-based approaches analyze users' behavioral patterns,\noffering robustness against tampering but overlooking the interactions between\nsimilar users. Inspired by cohort analysis in retention and healthcare, this\npaper introduces VecAug, a novel cohort-augmented learning framework that\naddresses these challenges by enhancing the representation learning of target\nusers with personalized cohort information. To this end, we first propose a\nvector burn-in technique for automatic cohort identification, which retrieves a\ntask-specific cohort for each target user. Then, to fully exploit the cohort\ninformation, we introduce an attentive cohort aggregation technique for\naugmenting target user representations. To improve the robustness of such\ncohort augmentation, we also propose a novel label-aware cohort neighbor\nseparation mechanism to distance negative cohort neighbors and calibrate the\naggregated cohort information. By integrating this cohort information with\ntarget user representations, VecAug enhances the modeling capacity and\ngeneralization capabilities of the model to be augmented. Our framework is\nflexible and can be seamlessly integrated with existing fraud detection models.\nWe deploy our framework on e-commerce platforms and evaluate it on three fraud\ndetection datasets, and results show that VecAug improves the detection\nperformance of base models by up to 2.48\\% in AUC and 22.5\\% in R@P$_{0.9}$,\noutperforming state-of-the-art methods significantly.", "categories": ["cs.LG"], "published": "2024-08-01T12:39:27+00:00", "updated": "2024-08-01T12:39:27+00:00", "url": "http://arxiv.org/pdf/2408.00513v1", "data_source_type": ["e-commerce"], "data_source_name": [], "fraud_type": "e-commerce fraud", "technical_approach_category": ["representation learning", "cohort analysis", "anomaly detection", "feature augmentation"], "technical_approach_method": ["vector burn-in", "attentive cohort aggregation", "label-aware cohort neighbor separation"], "technical_approach_description": "VecAug is a cohort-augmented learning framework that enhances fraud detection by automatically identifying task-specific cohorts for each target user, aggregating cohort information through attention mechanisms, and separating negative cohort neighbors to improve robustness.", "innovation_points": "Introduces cohort-augmented learning framework with automatic cohort identification via vector burn-in, attentive cohort aggregation, and label-aware cohort neighbor separation to enhance user representation learning and model generalization.", "github_repo": ""}
{"id": "2407.17333v2", "title": "Global Confidence Degree Based Graph Neural Network for Financial Fraud Detection", "authors": ["Jiaxun Liu", "Yue Tian", "Guanjun Liu"], "abstract": "Graph Neural Networks (GNNs) are widely used in financial fraud detection due\nto their excellent ability on handling graph-structured financial data and\nmodeling multilayer connections by aggregating information of neighbors.\nHowever, these GNN-based methods focus on extracting neighbor-level information\nbut neglect a global perspective. This paper presents the concept and\ncalculation formula of Global Confidence Degree (GCD) and thus designs\nGCD-based GNN (GCD-GNN) that can address the challenges of camouflage in\nfraudulent activities and thus can capture more global information. To obtain a\nprecise GCD for each node, we use a multilayer perceptron to transform features\nand then the new features and the corresponding prototype are used to eliminate\nunnecessary information. The GCD of a node evaluates the typicality of the node\nand thus we can leverage GCD to generate attention values for message\naggregation. This process is carried out through both the original GCD and its\ninverse, allowing us to capture both the typical neighbors with high GCD and\nthe atypical ones with low GCD. Extensive experiments on two public datasets\ndemonstrate that GCD-GNN outperforms state-of-the-art baselines, highlighting\nthe effectiveness of GCD. We also design a lightweight GCD-GNN\n(GCD-GNN$_{light}$) that also outperforms the baselines but is slightly weaker\nthan GCD-GNN on fraud detection performance. However, GCD-GNN$_{light}$\nobviously outperforms GCD-GNN on convergence and inference speed.", "categories": ["cs.LG"], "published": "2024-07-24T14:55:37+00:00", "updated": "2024-08-18T06:39:56+00:00", "url": "http://arxiv.org/pdf/2407.17333v2", "data_source_type": ["financial"], "data_source_name": [], "fraud_type": "financial fraud", "technical_approach_category": ["Graph Neural Networks", "anomaly detection", "feature transformation", "attention mechanism"], "technical_approach_method": ["GCD-GNN", "multilayer perceptron", "prototype-based feature elimination", "message aggregation with attention"], "technical_approach_description": "Proposes a Global Confidence Degree (GCD) based Graph Neural Network that calculates node typicality using feature transformation and prototype comparison, then uses GCD to generate attention values for message aggregation to capture both typical and atypical neighbors.", "innovation_points": "Introduces the concept and calculation formula of Global Confidence Degree (GCD) to provide a global perspective, addressing camouflage in fraudulent activities by capturing both typical neighbors with high GCD and atypical ones with low GCD.", "github_repo": ""}
{"id": "2409.09892v1", "title": "Dynamic Fraud Detection: Integrating Reinforcement Learning into Graph Neural Networks", "authors": ["Yuxin Dong", "Jianhua Yao", "Jiajing Wang", "Yingbin Liang", "Shuhan Liao", "Minheng Xiao"], "abstract": "Financial fraud refers to the act of obtaining financial benefits through\ndishonest means. Such behavior not only disrupts the order of the financial\nmarket but also harms economic and social development and breeds other illegal\nand criminal activities. With the popularization of the internet and online\npayment methods, many fraudulent activities and money laundering behaviors in\nlife have shifted from offline to online, posing a great challenge to\nregulatory authorities. How to efficiently detect these financial fraud\nactivities has become an urgent issue that needs to be resolved. Graph neural\nnetworks are a type of deep learning model that can utilize the interactive\nrelationships within graph structures, and they have been widely applied in the\nfield of fraud detection. However, there are still some issues. First,\nfraudulent activities only account for a very small part of transaction\ntransfers, leading to an inevitable problem of label imbalance in fraud\ndetection. At the same time, fraudsters often disguise their behavior, which\ncan have a negative impact on the final prediction results. In addition,\nexisting research has overlooked the importance of balancing neighbor\ninformation and central node information. For example, when the central node\nhas too many neighbors, the features of the central node itself are often\nneglected. Finally, fraud activities and patterns are constantly changing over\ntime, so considering the dynamic evolution of graph edge relationships is also\nvery important.", "categories": ["cs.LG", "cs.SI"], "published": "2024-09-15T23:08:31+00:00", "updated": "2024-09-15T23:08:31+00:00", "url": "http://arxiv.org/pdf/2409.09892v1", "data_source_type": ["financial", "online payment"], "data_source_name": [], "fraud_type": "financial fraud", "technical_approach_category": ["Graph Neural Networks", "Reinforcement Learning", "anomaly detection"], "technical_approach_method": ["Graph Neural Networks", "Reinforcement Learning"], "technical_approach_description": "Proposes integrating reinforcement learning into graph neural networks to address financial fraud detection challenges, including class imbalance, fraudster disguise tactics, neighbor-central node information balancing, and dynamic evolution of graph relationships over time.", "innovation_points": "Addresses label imbalance, fraudster disguise impact, balances neighbor and central node information importance, and considers dynamic evolution of graph edge relationships over time for fraud detection.", "github_repo": ""}
{"id": "2409.07494v2", "title": "Ethereum Fraud Detection via Joint Transaction Language Model and Graph Representation Learning", "authors": ["Jianguo Sun", "Yifan Jia", "Yanbin Wang", "Yiwei Liu", "Zhang Sheng", "Ye Tian"], "abstract": "Ethereum faces growing fraud threats. Current fraud detection methods,\nwhether employing graph neural networks or sequence models, fail to consider\nthe semantic information and similarity patterns within transactions. Moreover,\nthese approaches do not leverage the potential synergistic benefits of\ncombining both types of models. To address these challenges, we propose\nTLMG4Eth that combines a transaction language model with graph-based methods to\ncapture semantic, similarity, and structural features of transaction data in\nEthereum. We first propose a transaction language model that converts numerical\ntransaction data into meaningful transaction sentences, enabling the model to\nlearn explicit transaction semantics. Then, we propose a transaction attribute\nsimilarity graph to learn transaction similarity information, enabling us to\ncapture intuitive insights into transaction anomalies. Additionally, we\nconstruct an account interaction graph to capture the structural information of\nthe account transaction network. We employ a deep multi-head attention network\nto fuse transaction semantic and similarity embeddings, and ultimately propose\na joint training approach for the multi-head attention network and the account\ninteraction graph to obtain the synergistic benefits of both.", "categories": ["cs.CR", "cs.LG", "q-fin.GN"], "published": "2024-09-09T07:13:44+00:00", "updated": "2025-02-18T12:26:02+00:00", "url": "http://arxiv.org/pdf/2409.07494v2", "data_source_type": ["cryptocurrency"], "data_source_name": ["Ethereum"], "fraud_type": "Ethereum fraud", "technical_approach_category": ["graph representation learning", "language model", "multi-head attention", "anomaly detection", "multimodal fusion"], "technical_approach_method": ["transaction language model", "transaction attribute similarity graph", "account interaction graph", "deep multi-head attention network", "joint training"], "technical_approach_description": "Proposes TLMG4Eth, a method combining a transaction language model and graph-based methods. The transaction language model converts numerical data into transaction sentences to learn explicit semantics. A transaction attribute similarity graph captures similarity patterns, and an account interaction graph captures structural information. A deep multi-head attention network fuses semantic and similarity embeddings, with joint training for synergistic benefits.", "innovation_points": "Addresses the failure of current methods to consider semantic information and similarity patterns within transactions and to leverage the synergistic benefits of combining graph neural networks and sequence models.", "github_repo": ""}
{"id": "2410.08390v1", "title": "KnowGraph: Knowledge-Enabled Anomaly Detection via Logical Reasoning on Graph Data", "authors": ["Andy Zhou", "Xiaojun Xu", "Ramesh Raghunathan", "Alok Lal", "Xinze Guan", "Bin Yu", "Bo Li"], "abstract": "Graph-based anomaly detection is pivotal in diverse security applications,\nsuch as fraud detection in transaction networks and intrusion detection for\nnetwork traffic. Standard approaches, including Graph Neural Networks (GNNs),\noften struggle to generalize across shifting data distributions. Meanwhile,\nreal-world domain knowledge is more stable and a common existing component of\nreal-world detection strategies. To explicitly integrate such knowledge into\ndata-driven models such as GCNs, we propose KnowGraph, which integrates domain\nknowledge with data-driven learning for enhanced graph-based anomaly detection.\nKnowGraph comprises two principal components: (1) a statistical learning\ncomponent that utilizes a main model for the overarching detection task,\naugmented by multiple specialized knowledge models that predict domain-specific\nsemantic entities; (2) a reasoning component that employs probabilistic\ngraphical models to execute logical inferences based on model outputs, encoding\ndomain knowledge through weighted first-order logic formulas. Extensive\nexperiments on these large-scale real-world datasets show that KnowGraph\nconsistently outperforms state-of-the-art baselines in both transductive and\ninductive settings, achieving substantial gains in average precision when\ngeneralizing to completely unseen test graphs. Further ablation studies\ndemonstrate the effectiveness of the proposed reasoning component in improving\ndetection performance, especially under extreme class imbalance. These results\nhighlight the potential of integrating domain knowledge into data-driven models\nfor high-stakes, graph-based security applications.", "categories": ["cs.CR", "cs.AI", "cs.LG"], "published": "2024-10-10T21:53:33+00:00", "updated": "2024-10-10T21:53:33+00:00", "url": "http://arxiv.org/pdf/2410.08390v1", "data_source_type": ["transaction networks", "network traffic"], "data_source_name": [], "fraud_type": "anomaly detection in security applications", "technical_approach_category": ["Graph Neural Networks", "probabilistic graphical models", "knowledge integration", "logical reasoning", "anomaly detection"], "technical_approach_method": ["KnowGraph", "GCNs", "weighted first-order logic formulas"], "technical_approach_description": "Proposes KnowGraph framework that integrates domain knowledge with data-driven learning for graph-based anomaly detection. It combines statistical learning with probabilistic graphical models that execute logical inferences using weighted first-order logic formulas.", "innovation_points": "Integrates domain knowledge with data-driven models for enhanced graph-based anomaly detection. Uses specialized knowledge models and probabilistic graphical models for logical inference, demonstrating improved generalization across shifting data distributions.", "github_repo": ""}
{"id": "2410.08121v1", "title": "Heterogeneous Graph Auto-Encoder for CreditCard Fraud Detection", "authors": ["Moirangthem Tiken Singh", "Rabinder Kumar Prasad", "Gurumayum Robert Michael", "N K Kaphungkui", "N. Hemarjit Singh"], "abstract": "The digital revolution has significantly impacted financial transactions,\nleading to a notable increase in credit card usage. However, this convenience\ncomes with a trade-off: a substantial rise in fraudulent activities.\nTraditional machine learning methods for fraud detection often struggle to\ncapture the inherent interconnectedness within financial data. This paper\nproposes a novel approach for credit card fraud detection that leverages Graph\nNeural Networks (GNNs) with attention mechanisms applied to heterogeneous graph\nrepresentations of financial data. Unlike homogeneous graphs, heterogeneous\ngraphs capture intricate relationships between various entities in the\nfinancial ecosystem, such as cardholders, merchants, and transactions,\nproviding a richer and more comprehensive data representation for fraud\nanalysis. To address the inherent class imbalance in fraud data, where genuine\ntransactions significantly outnumber fraudulent ones, the proposed approach\nintegrates an autoencoder. This autoencoder, trained on genuine transactions,\nlearns a latent representation and flags deviations during reconstruction as\npotential fraud. This research investigates two key questions: (1) How\neffectively can a GNN with an attention mechanism detect and prevent credit\ncard fraud when applied to a heterogeneous graph? (2) How does the efficacy of\nthe autoencoder with attention approach compare to traditional methods? The\nresults are promising, demonstrating that the proposed model outperforms\nbenchmark algorithms such as Graph Sage and FI-GRL, achieving a superior AUC-PR\nof 0.89 and an F1-score of 0.81. This research significantly advances fraud\ndetection systems and the overall security of financial transactions by\nleveraging GNNs with attention mechanisms and addressing class imbalance\nthrough an autoencoder.", "categories": ["cs.LG", "cs.AI"], "published": "2024-10-10T17:05:27+00:00", "updated": "2024-10-10T17:05:27+00:00", "url": "http://arxiv.org/pdf/2410.08121v1", "data_source_type": ["banking", "payment"], "data_source_name": [], "fraud_type": "credit card fraud", "technical_approach_category": ["Graph Neural Networks (GNN)", "attention mechanism", "autoencoder", "anomaly detection", "representation learning"], "technical_approach_method": ["Heterogeneous Graph Auto-Encoder", "GNN with attention mechanism"], "technical_approach_description": "Leverages Graph Neural Networks with attention mechanisms on heterogeneous graph representations of financial data (cardholders, merchants, transactions) and integrates an autoencoder trained on genuine transactions to detect fraud through reconstruction deviations.", "innovation_points": "Proposes a novel approach using GNNs with attention on heterogeneous graphs for richer data representation and integrates an autoencoder to address class imbalance by flagging reconstruction deviations from genuine transactions.", "github_repo": ""}
{"id": "2410.09069v2", "title": "Explainable AI for Fraud Detection: An Attention-Based Ensemble of CNNs, GNNs, and A Confidence-Driven Gating Mechanism", "authors": ["Mehdi Hosseini Chagahi", "Niloufar Delfan", "Saeed Mohammadi Dashtaki", "Behzad Moshiri", "Md. Jalil Piran"], "abstract": "The rapid expansion of e-commerce and the widespread use of credit cards in\nonline purchases and financial transactions have significantly heightened the\nimportance of promptly and accurately detecting credit card fraud (CCF). Not\nonly do fraudulent activities in financial transactions lead to substantial\nmonetary losses for banks and financial institutions, but they also undermine\nuser trust in digital services. This study presents a new stacking-based\napproach for CCF detection by adding two extra layers to the usual\nclassification process: an attention layer and a confidence-based combination\nlayer. In the attention layer, we combine soft outputs from a convolutional\nneural network (CNN) and a recurrent neural network (RNN) using the dependent\nordered weighted averaging (DOWA) operator, and from a graph neural network\n(GNN) and a long short-term memory (LSTM) network using the induced ordered\nweighted averaging (IOWA) operator. These weighted outputs capture different\npredictive signals, increasing the model's accuracy. Next, in the\nconfidence-based layer, we select whichever aggregate (DOWA or IOWA) shows\nlower uncertainty to feed into a meta-learner. To make the model more\nexplainable, we use shapley additive explanations (SHAP) to identify the top\nten most important features for distinguishing between fraud and normal\ntransactions. These features are then used in our attention-based model.\nExperiments on three datasets show that our method achieves high accuracy and\nrobust generalization, making it effective for CCF detection.", "categories": ["q-fin.RM", "cs.LG"], "published": "2024-10-01T09:56:23+00:00", "updated": "2025-02-22T11:00:27+00:00", "url": "http://arxiv.org/pdf/2410.09069v2", "data_source_type": ["e-commerce", "banking", "financial"], "data_source_name": [], "fraud_type": "credit card fraud", "technical_approach_category": ["feature engineering", "CNN", "RNN", "LSTM", "GNN", "ensemble learning", "explainable AI", "attention mechanism"], "technical_approach_method": ["Convolutional Neural Network (CNN)", "Recurrent Neural Network (RNN)", "Graph Neural Network (GNN)", "Long Short-Term Memory (LSTM)", "Dependent Ordered Weighted Averaging (DOWA)", "Induced Ordered Weighted Averaging (IOWA)", "SHAP (SHapley Additive exPlanations)", "stacking-based ensemble", "confidence-driven gating mechanism"], "technical_approach_description": "A stacking-based ensemble approach for credit card fraud detection that adds an attention layer using DOWA and IOWA operators to combine outputs from CNN, RNN, GNN, and LSTM models, followed by a confidence-based gating layer that selects the aggregate with lower uncertainty for the meta-learner.", "innovation_points": "Introduces a stacking-based approach with two extra layers: an attention layer using DOWA and IOWA operators to combine model outputs, and a confidence-based combination layer that selects the aggregate with lower uncertainty. Also incorporates SHAP for explainability to identify important features.", "github_repo": ""}
{"id": "2409.18455v1", "title": "Review of Digital Asset Development with Graph Neural Network Unlearning", "authors": ["Zara Lisbon"], "abstract": "In the rapidly evolving landscape of digital assets, the imperative for\nrobust data privacy and compliance with regulatory frameworks has intensified.\nThis paper investigates the critical role of Graph Neural Networks (GNNs) in\nthe management of digital assets and introduces innovative unlearning\ntechniques specifically tailored to GNN architectures. We categorize unlearning\nstrategies into two primary classes: data-driven approximation, which\nmanipulates the graph structure to isolate and remove the influence of specific\nnodes, and model-driven approximation, which modifies the internal parameters\nand architecture of the GNN itself. By examining recent advancements in these\nunlearning methodologies, we highlight their applicability in various use\ncases, including fraud detection, risk assessment, token relationship\nprediction, and decentralized governance. We discuss the challenges inherent in\nbalancing model performance with the requirements for data unlearning,\nparticularly in the context of real-time financial applications. Furthermore,\nwe propose a hybrid approach that combines the strengths of both unlearning\nstrategies to enhance the efficiency and effectiveness of GNNs in digital asset\necosystems. Ultimately, this paper aims to provide a comprehensive framework\nfor understanding and implementing GNN unlearning techniques, paving the way\nfor secure and compliant deployment of machine learning in the digital asset\ndomain.", "categories": ["cs.LG", "cs.AI"], "published": "2024-09-27T05:31:04+00:00", "updated": "2024-09-27T05:31:04+00:00", "url": "http://arxiv.org/pdf/2409.18455v1", "data_source_type": ["digital asset ecosystems"], "data_source_name": [], "fraud_type": "fraud detection", "technical_approach_category": ["Graph Neural Networks", "unlearning techniques", "machine learning compliance"], "technical_approach_method": ["Graph Neural Network unlearning", "data-driven approximation", "model-driven approximation", "hybrid approach"], "technical_approach_description": "This paper investigates Graph Neural Networks (GNNs) for digital asset management and introduces specialized unlearning techniques. It categorizes strategies into data-driven approximation (manipulating graph structure to remove node influence) and model-driven approximation (modifying GNN parameters and architecture).", "innovation_points": "Introduces innovative unlearning techniques specifically tailored to GNN architectures and proposes a hybrid approach that combines the strengths of both data-driven and model-driven unlearning strategies.", "github_repo": ""}
{"id": "2409.15366v1", "title": "Trajectory Anomaly Detection with Language Models", "authors": ["Jonathan Mbuya", "Dieter Pfoser", "Antonios Anastasopoulos"], "abstract": "This paper presents a novel approach for trajectory anomaly detection using\nan autoregressive causal-attention model, termed LM-TAD. This method leverages\nthe similarities between language statements and trajectories, both of which\nconsist of ordered elements requiring coherence through external rules and\ncontextual variations. By treating trajectories as sequences of tokens, our\nmodel learns the probability distributions over trajectories, enabling the\nidentification of anomalous locations with high precision. We incorporate\nuser-specific tokens to account for individual behavior patterns, enhancing\nanomaly detection tailored to user context. Our experiments demonstrate the\neffectiveness of LM-TAD on both synthetic and real-world datasets. In\nparticular, the model outperforms existing methods on the Pattern of Life (PoL)\ndataset by detecting user-contextual anomalies and achieves competitive results\non the Porto taxi dataset, highlighting its adaptability and robustness.\nAdditionally, we introduce the use of perplexity and surprisal rate metrics for\ndetecting outliers and pinpointing specific anomalous locations within\ntrajectories. The LM-TAD framework supports various trajectory representations,\nincluding GPS coordinates, staypoints, and activity types, proving its\nversatility in handling diverse trajectory data. Moreover, our approach is\nwell-suited for online trajectory anomaly detection, significantly reducing\ncomputational latency by caching key-value states of the attention mechanism,\nthereby avoiding repeated computations.", "categories": ["cs.LG", "cs.AI"], "published": "2024-09-18T17:33:31+00:00", "updated": "2024-09-18T17:33:31+00:00", "url": "http://arxiv.org/pdf/2409.15366v1", "data_source_type": ["transportation", "location-based services"], "data_source_name": ["Porto taxi dataset", "Pattern of Life (PoL) dataset"], "fraud_type": "trajectory anomaly detection", "technical_approach_category": ["language modeling", "autoregressive modeling", "attention mechanism", "anomaly detection", "user behavior modeling"], "technical_approach_method": ["LM-TAD", "autoregressive causal-attention model"], "technical_approach_description": "Treats trajectories as sequences of tokens using an autoregressive causal-attention model to learn probability distributions over trajectories, enabling identification of anomalous locations with user-specific tokens to account for individual behavior patterns.", "innovation_points": "Novel approach leveraging similarities between language and trajectories, introduces perplexity and surprisal rate metrics for outlier detection, supports various trajectory representations, and enables online detection with reduced computational latency through cached key-value states.", "github_repo": ""}
{"id": "2412.00020v1", "title": "Partitioning Message Passing for Graph Fraud Detection", "authors": ["Wei Zhuo", "Zemin Liu", "Bryan Hooi", "Bingsheng He", "Guang Tan", "Rizal Fathony", "Jia Chen"], "abstract": "Label imbalance and homophily-heterophily mixture are the fundamental\nproblems encountered when applying Graph Neural Networks (GNNs) to Graph Fraud\nDetection (GFD) tasks. Existing GNN-based GFD models are designed to augment\ngraph structure to accommodate the inductive bias of GNNs towards homophily, by\nexcluding heterophilic neighbors during message passing. In our work, we argue\nthat the key to applying GNNs for GFD is not to exclude but to {\\em\ndistinguish} neighbors with different labels. Grounded in this perspective, we\nintroduce Partitioning Message Passing (PMP), an intuitive yet effective\nmessage passing paradigm expressly crafted for GFD. Specifically, in the\nneighbor aggregation stage of PMP, neighbors with different classes are\naggregated with distinct node-specific aggregation functions. By this means,\nthe center node can adaptively adjust the information aggregated from its\nheterophilic and homophilic neighbors, thus avoiding the model gradient being\ndominated by benign nodes which occupy the majority of the population. We\ntheoretically establish a connection between the spatial formulation of PMP and\nspectral analysis to characterize that PMP operates an adaptive node-specific\nspectral graph filter, which demonstrates the capability of PMP to handle\nheterophily-homophily mixed graphs. Extensive experimental results show that\nPMP can significantly boost the performance on GFD tasks.", "categories": ["cs.AI", "cs.LG", "cs.SI"], "published": "2024-11-16T11:30:53+00:00", "updated": "2024-11-16T11:30:53+00:00", "url": "http://arxiv.org/pdf/2412.00020v1", "data_source_type": [], "data_source_name": [], "fraud_type": "graph fraud detection", "technical_approach_category": ["Graph Neural Networks", "message passing", "spectral analysis", "anomaly detection"], "technical_approach_method": ["Partitioning Message Passing (PMP)", "node-specific aggregation functions", "adaptive node-specific spectral graph filter"], "technical_approach_description": "Proposes Partitioning Message Passing (PMP) paradigm that aggregates neighbors with different classes using distinct node-specific aggregation functions, allowing adaptive adjustment of information from heterophilic and homophilic neighbors to handle label imbalance in graph fraud detection.", "innovation_points": "Introduces PMP to distinguish rather than exclude neighbors with different labels, operates an adaptive node-specific spectral graph filter to handle heterophily-homophily mixed graphs, preventing model gradient domination by majority benign nodes.", "github_repo": ""}
{"id": "2411.05857v2", "title": "Financial Fraud Detection using Jump-Attentive Graph Neural Networks", "authors": ["Prashank Kadam"], "abstract": "As the availability of financial services online continues to grow, the\nincidence of fraud has surged correspondingly. Fraudsters continually seek new\nand innovative ways to circumvent the detection algorithms in place.\nTraditionally, fraud detection relied on rule-based methods, where rules were\nmanually created based on transaction data features. However, these techniques\nsoon became ineffective due to their reliance on manual rule creation and their\ninability to detect complex data patterns. Today, a significant portion of the\nfinancial services sector employs various machine learning algorithms, such as\nXGBoost, Random Forest, and neural networks, to model transaction data. While\nthese techniques have proven more efficient than rule-based methods, they still\nfail to capture interactions between different transactions and their\ninterrelationships. Recently, graph-based techniques have been adopted for\nfinancial fraud detection, leveraging graph topology to aggregate neighborhood\ninformation of transaction data using Graph Neural Networks (GNNs). Despite\nshowing improvements over previous methods, these techniques still struggle to\nkeep pace with the evolving camouflaging tactics of fraudsters and suffer from\ninformation loss due to over-smoothing. In this paper, we propose a novel\nalgorithm that employs an efficient neighborhood sampling method, effective for\ncamouflage detection and preserving crucial feature information from\nnon-similar nodes. Additionally, we introduce a novel GNN architecture that\nutilizes attention mechanisms and preserves holistic neighborhood information\nto prevent information loss. We test our algorithm on financial data to show\nthat our method outperforms other state-of-the-art graph algorithms.", "categories": ["cs.LG", "cs.CR", "J.1"], "published": "2024-11-07T05:12:51+00:00", "updated": "2024-11-22T18:34:58+00:00", "url": "http://arxiv.org/pdf/2411.05857v2", "data_source_type": ["financial services"], "data_source_name": [], "fraud_type": "financial fraud", "technical_approach_category": ["Graph Neural Networks", "graph-based techniques", "attention mechanisms", "anomaly detection", "neighborhood sampling"], "technical_approach_method": ["Graph Neural Networks (GNNs)", "attention mechanisms"], "technical_approach_description": "Proposes a novel GNN architecture with an efficient neighborhood sampling method for camouflage detection and an attention mechanism to preserve holistic neighborhood information and prevent information loss from over-smoothing.", "innovation_points": "Novel algorithm with efficient neighborhood sampling effective for camouflage detection and preserving crucial feature information from non-similar nodes. Novel GNN architecture utilizing attention mechanisms to preserve holistic neighborhood information and prevent information loss.", "github_repo": ""}
{"id": "2411.00431v1", "title": "Integrating Fuzzy Logic into Deep Symbolic Regression", "authors": ["Wout Gerdes", "Erman Acar"], "abstract": "Credit card fraud detection is a critical concern for financial institutions,\nintensified by the rise of contactless payment technologies. While deep\nlearning models offer high accuracy, their lack of explainability poses\nsignificant challenges in financial settings. This paper explores the\nintegration of fuzzy logic into Deep Symbolic Regression (DSR) to enhance both\nperformance and explainability in fraud detection. We investigate the\neffectiveness of different fuzzy logic implications, specifically\n{\\L}ukasiewicz, G\\\"odel, and Product, in handling the complexity and\nuncertainty of fraud detection datasets. Our analysis suggest that the\n{\\L}ukasiewicz implication achieves the highest F1-score and overall accuracy,\nwhile the Product implication offers a favorable balance between performance\nand explainability. Despite having a performance lower than state-of-the-art\n(SOTA) models due to information loss in data transformation, our approach\nprovides novelty and insights into into integrating fuzzy logic into DSR for\nfraud detection, providing a comprehensive comparison between different\nimplications and methods.", "categories": ["cs.AI", "cs.LO", "cs.SC"], "published": "2024-11-01T07:55:17+00:00", "updated": "2024-11-01T07:55:17+00:00", "url": "http://arxiv.org/pdf/2411.00431v1", "data_source_type": ["payment", "financial"], "data_source_name": [], "fraud_type": "credit card fraud", "technical_approach_category": ["symbolic regression", "fuzzy logic", "explainable AI"], "technical_approach_method": ["Deep Symbolic Regression (DSR)", "Łukasiewicz implication", "Gödel implication", "Product implication"], "technical_approach_description": "Integrates fuzzy logic into Deep Symbolic Regression to enhance both performance and explainability in fraud detection by investigating different fuzzy logic implications to handle complexity and uncertainty in datasets.", "innovation_points": "Novel integration of fuzzy logic into DSR for fraud detection, providing comprehensive comparison between different implications and methods, offering insights into balancing performance and explainability.", "github_repo": ""}
{"id": "2410.20281v1", "title": "Proactive Fraud Defense: Machine Learning's Evolving Role in Protecting Against Online Fraud", "authors": ["Md Kamrul Hasan Chy"], "abstract": "As online fraud becomes more sophisticated and pervasive, traditional fraud\ndetection methods are struggling to keep pace with the evolving tactics\nemployed by fraudsters. This paper explores the transformative role of machine\nlearning in addressing these challenges by offering more advanced, scalable,\nand adaptable solutions for fraud detection and prevention. By analyzing key\nmodels such as Random Forest, Neural Networks, and Gradient Boosting, this\npaper highlights the strengths of machine learning in processing vast datasets,\nidentifying intricate fraud patterns, and providing real-time predictions that\nenable a proactive approach to fraud prevention. Unlike rule-based systems that\nreact after fraud has occurred, machine learning models continuously learn from\nnew data, adapting to emerging fraud schemes and reducing false positives,\nwhich ultimately minimizes financial losses. This research emphasizes the\npotential of machine learning to revolutionize fraud detection frameworks by\nmaking them more dynamic, efficient, and capable of handling the growing\ncomplexity of fraud across various industries. Future developments in machine\nlearning, including deep learning and hybrid models, are expected to further\nenhance the predictive accuracy and applicability of these systems, ensuring\nthat organizations remain resilient in the face of new and emerging fraud\ntactics.", "categories": ["cs.LG"], "published": "2024-10-26T21:34:28+00:00", "updated": "2024-10-26T21:34:28+00:00", "url": "http://arxiv.org/pdf/2410.20281v1", "data_source_type": [], "data_source_name": [], "fraud_type": "online fraud", "technical_approach_category": ["machine learning", "anomaly detection"], "technical_approach_method": ["Random Forest", "Neural Networks", "Gradient Boosting"], "technical_approach_description": "The paper analyzes machine learning models for processing vast datasets, identifying intricate fraud patterns, and providing real-time predictions to enable proactive fraud prevention. These models continuously learn from new data, adapt to emerging fraud schemes, and reduce false positives.", "innovation_points": "Highlights the transformative role of machine learning in offering more advanced, scalable, and adaptable solutions compared to traditional rule-based systems, enabling a proactive approach to fraud prevention.", "github_repo": ""}
{"id": "2410.17459v1", "title": "Data Obfuscation through Latent Space Projection (LSP) for Privacy-Preserving AI Governance: Case Studies in Medical Diagnosis and Finance Fraud Detection", "authors": ["Mahesh Vaijainthymala Krishnamoorthy"], "abstract": "As AI systems increasingly integrate into critical societal sectors, the\ndemand for robust privacy-preserving methods has escalated. This paper\nintroduces Data Obfuscation through Latent Space Projection (LSP), a novel\ntechnique aimed at enhancing AI governance and ensuring Responsible AI\ncompliance. LSP uses machine learning to project sensitive data into a latent\nspace, effectively obfuscating it while preserving essential features for model\ntraining and inference. Unlike traditional privacy methods like differential\nprivacy or homomorphic encryption, LSP transforms data into an abstract,\nlower-dimensional form, achieving a delicate balance between data utility and\nprivacy. Leveraging autoencoders and adversarial training, LSP separates\nsensitive from non-sensitive information, allowing for precise control over\nprivacy-utility trade-offs. We validate LSP's effectiveness through experiments\non benchmark datasets and two real-world case studies: healthcare cancer\ndiagnosis and financial fraud analysis. Our results show LSP achieves high\nperformance (98.7% accuracy in image classification) while providing strong\nprivacy (97.3% protection against sensitive attribute inference), outperforming\ntraditional anonymization and privacy-preserving methods. The paper also\nexamines LSP's alignment with global AI governance frameworks, such as GDPR,\nCCPA, and HIPAA, highlighting its contribution to fairness, transparency, and\naccountability. By embedding privacy within the machine learning pipeline, LSP\noffers a promising approach to developing AI systems that respect privacy while\ndelivering valuable insights. We conclude by discussing future research\ndirections, including theoretical privacy guarantees, integration with\nfederated learning, and enhancing latent space interpretability, positioning\nLSP as a critical tool for ethical AI advancement.", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CY", "F.2.1; E.3"], "published": "2024-10-22T22:31:03+00:00", "updated": "2024-10-22T22:31:03+00:00", "url": "http://arxiv.org/pdf/2410.17459v1", "data_source_type": ["medical", "finance"], "data_source_name": [], "fraud_type": "financial fraud analysis", "technical_approach_category": ["autoencoders", "adversarial training", "privacy-preserving AI", "latent space representation"], "technical_approach_method": ["Latent Space Projection (LSP)", "adversarial training"], "technical_approach_description": "Projects sensitive data into a latent space using machine learning to obfuscate it while preserving essential features for model training and inference. Leverages autoencoders and adversarial training to separate sensitive from non-sensitive information.", "innovation_points": "Introduces Data Obfuscation through Latent Space Projection (LSP) as a novel technique that transforms data into an abstract, lower-dimensional form, achieving a balance between data utility and privacy unlike traditional methods.", "github_repo": ""}
{"id": "2412.04693v1", "title": "Sequential anomaly identification with observation control under generalized error metrics", "authors": ["Aristomenis Tsopelakos", "Georgios Fellouris"], "abstract": "The problem of sequential anomaly detection and identification is considered,\nwhere multiple data sources are simultaneously monitored and the goal is to\nidentify in real time those, if any, that exhibit ``anomalous\" statistical\nbehavior. An upper bound is postulated on the number of data sources that can\nbe sampled at each sampling instant, but the decision maker selects which ones\nto sample based on the already collected data. Thus, in this context, a policy\nconsists not only of a stopping rule and a decision rule that determine when\nsampling should be terminated and which sources to identify as anomalous upon\nstopping, but also of a sampling rule that determines which sources to sample\nat each time instant subject to the sampling constraint. Two distinct\nformulations are considered, which require control of different, ``generalized\"\nerror metrics. The first one tolerates a certain user-specified number of\nerrors, of any kind, whereas the second tolerates distinct, user-specified\nnumbers of false positives and false negatives. For each of them, a universal\nasymptotic lower bound on the expected time for stopping is established as the\nerror probabilities go to 0, and it is shown to be attained by a policy that\ncombines the stopping and decision rules proposed in the full-sampling case\nwith a probabilistic sampling rule that achieves a specific long-run sampling\nfrequency for each source. Moreover, the optimal to a first order asymptotic\napproximation expected time for stopping is compared in simulation studies with\nthe corresponding factor in a finite regime, and the impact of the sampling\nconstraint and tolerance to errors is assessed.", "categories": ["math.ST", "stat.TH"], "published": "2024-12-06T01:07:49+00:00", "updated": "2024-12-06T01:07:49+00:00", "url": "http://arxiv.org/pdf/2412.04693v1", "data_source_type": [], "data_source_name": [], "fraud_type": "sequential anomaly detection and identification", "technical_approach_category": ["sequential analysis", "anomaly detection", "sampling control", "statistical decision theory"], "technical_approach_method": ["probabilistic sampling rule", "stopping rule", "decision rule"], "technical_approach_description": "Develops a policy for sequential anomaly identification with constrained sampling, combining stopping rules, decision rules, and a sampling rule that determines which sources to sample at each time instant subject to sampling constraints under generalized error metrics.", "innovation_points": "Establishes universal asymptotic lower bounds on expected stopping time as error probabilities go to 0, and shows these bounds are attained by a policy combining full-sampling rules with a probabilistic sampling rule achieving specific long-run sampling frequencies.", "github_repo": ""}
{"id": "2411.19457v1", "title": "Multi-task CNN Behavioral Embedding Model For Transaction Fraud Detection", "authors": ["Bo Qu", "Zhurong Wang", "Minghao Gu", "Daisuke Yagi", "Yang Zhao", "Yinan Shan", "Frank Zahradnik"], "abstract": "The burgeoning e-Commerce sector requires advanced solutions for the\ndetection of transaction fraud. With an increasing risk of financial\ninformation theft and account takeovers, deep learning methods have become\nintegral to the embedding of behavior sequence data in fraud detection.\nHowever, these methods often struggle to balance modeling capabilities and\nefficiency and incorporate domain knowledge. To address these issues, we\nintroduce the multitask CNN behavioral Embedding Model for Transaction Fraud\nDetection. Our contributions include 1) introducing a single-layer CNN design\nfeaturing multirange kernels which outperform LSTM and Transformer models in\nterms of scalability and domain-focused inductive bias, and 2) the integration\nof positional encoding with CNN to introduce sequence-order signals enhancing\noverall performance, and 3) implementing multitask learning with randomly\nassigned label weights, thus removing the need for manual tuning. Testing on\nreal-world data reveals our model's enhanced performance of downstream\ntransaction models and comparable competitiveness with the Transformer Time\nSeries (TST) model.", "categories": ["cs.LG"], "published": "2024-11-29T03:58:11+00:00", "updated": "2024-11-29T03:58:11+00:00", "url": "http://arxiv.org/pdf/2411.19457v1", "data_source_type": ["e-commerce"], "data_source_name": [], "fraud_type": "transaction fraud", "technical_approach_category": ["CNN", "multitask learning", "behavioral embedding", "sequence modeling"], "technical_approach_method": ["multitask CNN behavioral embedding model", "single-layer CNN with multirange kernels", "positional encoding with CNN", "multitask learning with randomly assigned label weights"], "technical_approach_description": "A multitask CNN model for behavioral embedding in transaction fraud detection, featuring multirange kernels that outperform LSTM and Transformers in scalability and domain-focused inductive bias, with integrated positional encoding for sequence-order signals.", "innovation_points": "1) Single-layer CNN with multirange kernels outperforms LSTM/Transformers in scalability and domain bias, 2) Integration of positional encoding with CNN for sequence-order signals, 3) Multitask learning with randomly assigned label weights eliminating manual tuning.", "github_repo": ""}
{"id": "2411.18875v2", "title": "Know Your Account: Double Graph Inference-based Account De-anonymization on Ethereum", "authors": ["Shuyi Miao", "Wangjie Qiu", "Hongwei Zheng", "Qinnan Zhang", "Xiaofan Tu", "Xunan Liu", "Yang Liu", "Jin Dong", "Zhiming Zheng"], "abstract": "The scaled Web 3.0 digital economy, represented by decentralized finance\n(DeFi), has sparked increasing interest in the past few years, which usually\nrelies on blockchain for token transfer and diverse transaction logic. However,\nillegal behaviors, such as financial fraud, hacker attacks, and money\nlaundering, are rampant in the blockchain ecosystem and seriously threaten its\nintegrity and security. In this paper, we propose a novel double graph-based\nEthereum account de-anonymization inference method, dubbed DBG4ETH, which aims\nto capture the behavioral patterns of accounts comprehensively and has more\nrobust analytical and judgment capabilities for current complex and\ncontinuously generated transaction behaviors. Specifically, we first construct\na global static graph to build complex interactions between the various account\nnodes for all transaction data. Then, we also construct a local dynamic graph\nto learn about the gradual evolution of transactions over different periods.\nDifferent graphs focus on information from different perspectives, and features\nof global and local, static and dynamic transaction graphs are available\nthrough DBG4ETH. In addition, we propose an adaptive confidence calibration\nmethod to predict the results by feeding the calibrated weighted prediction\nvalues into the classifier. Experimental results show that DBG4ETH achieves\nstate-of-the-art results in the account identification task, improving the\nF1-score by at least 3.75% and up to 40.52% compared to processing each graph\ntype individually and outperforming similar account identity inference methods\nby 5.23% to 12.91%.", "categories": ["cs.SI"], "published": "2024-11-28T03:00:27+00:00", "updated": "2025-01-14T03:46:32+00:00", "url": "http://arxiv.org/pdf/2411.18875v2", "data_source_type": ["blockchain", "cryptocurrency"], "data_source_name": ["Ethereum"], "fraud_type": "account de-anonymization and identity inference", "technical_approach_category": ["graph neural networks", "temporal analysis", "anomaly detection", "multimodal fusion"], "technical_approach_method": ["double graph inference", "global static graph construction", "local dynamic graph construction", "adaptive confidence calibration"], "technical_approach_description": "Proposes DBG4ETH, a double graph-based Ethereum account de-anonymization method that constructs both global static graphs for complex account interactions and local dynamic graphs for temporal transaction evolution, followed by adaptive confidence calibration for prediction.", "innovation_points": "Novel double graph inference approach combining global static and local dynamic graphs to capture comprehensive behavioral patterns, with adaptive confidence calibration method for improved prediction accuracy in account identification tasks.", "github_repo": ""}
{"id": "2412.18370v3", "title": "Unveiling the Threat of Fraud Gangs to Graph Neural Networks: Multi-Target Graph Injection Attacks Against GNN-Based Fraud Detectors", "authors": ["Jinhyeok Choi", "Heehyeon Kim", "Joyce Jiyoung Whang"], "abstract": "Graph neural networks (GNNs) have emerged as an effective tool for fraud\ndetection, identifying fraudulent users, and uncovering malicious behaviors.\nHowever, attacks against GNN-based fraud detectors and their risks have rarely\nbeen studied, thereby leaving potential threats unaddressed. Recent findings\nsuggest that frauds are increasingly organized as gangs or groups. In this\nwork, we design attack scenarios where fraud gangs aim to make their fraud\nnodes misclassified as benign by camouflaging their illicit activities in\ncollusion. Based on these scenarios, we study adversarial attacks against\nGNN-based fraud detectors by simulating attacks of fraud gangs in three\nreal-world fraud cases: spam reviews, fake news, and medical insurance frauds.\nWe define these attacks as multi-target graph injection attacks and propose\nMonTi, a transformer-based Multi-target one-Time graph injection attack model.\nMonTi simultaneously generates attributes and edges of all attack nodes with a\ntransformer encoder, capturing interdependencies between attributes and edges\nmore effectively than most existing graph injection attack methods that\ngenerate these elements sequentially. Additionally, MonTi adaptively allocates\nthe degree budget for each attack node to explore diverse injection structures\ninvolving target, candidate, and attack nodes, unlike existing methods that fix\nthe degree budget across all attack nodes. Experiments show that MonTi\noutperforms the state-of-the-art graph injection attack methods on five\nreal-world graphs.", "categories": ["cs.LG", "cs.AI", "cs.CR"], "published": "2024-12-24T11:53:24+00:00", "updated": "2025-04-15T11:43:49+00:00", "url": "http://arxiv.org/pdf/2412.18370v3", "data_source_type": ["e-commerce", "social media", "healthcare"], "data_source_name": [], "fraud_type": "multi-target graph injection attacks against GNN-based fraud detectors", "technical_approach_category": ["graph neural networks", "adversarial attacks", "transformer", "graph injection attacks"], "technical_approach_method": ["MonTi", "transformer encoder"], "technical_approach_description": "Proposes MonTi, a transformer-based multi-target one-time graph injection attack model that simultaneously generates attributes and edges of attack nodes to camouflage fraud gangs and evade GNN-based fraud detectors.", "innovation_points": "Simultaneously generates attributes and edges with transformer encoder capturing interdependencies, and adaptively allocates degree budget per attack node to explore diverse injection structures, unlike sequential generation methods with fixed budgets.", "github_repo": ""}
{"id": "2412.18287v1", "title": "Semi-supervised Credit Card Fraud Detection via Attribute-Driven Graph Representation", "authors": ["Sheng Xiang", "Mingzhi Zhu", "Dawei Cheng", "Enxia Li", "Ruihui Zhao", "Yi Ouyang", "Ling Chen", "Yefeng Zheng"], "abstract": "Credit card fraud incurs a considerable cost for both cardholders and issuing\nbanks. Contemporary methods apply machine learning-based classifiers to detect\nfraudulent behavior from labeled transaction records. But labeled data are\nusually a small proportion of billions of real transactions due to expensive\nlabeling costs, which implies that they do not well exploit many natural\nfeatures from unlabeled data. Therefore, we propose a semi-supervised graph\nneural network for fraud detection. Specifically, we leverage transaction\nrecords to construct a temporal transaction graph, which is composed of\ntemporal transactions (nodes) and interactions (edges) among them. Then we pass\nmessages among the nodes through a Gated Temporal Attention Network (GTAN) to\nlearn the transaction representation. We further model the fraud patterns\nthrough risk propagation among transactions. The extensive experiments are\nconducted on a real-world transaction dataset and two publicly available fraud\ndetection datasets. The result shows that our proposed method, namely GTAN,\noutperforms other state-of-the-art baselines on three fraud detection datasets.\nSemi-supervised experiments demonstrate the excellent fraud detection\nperformance of our model with only a tiny proportion of labeled data.", "categories": ["cs.LG", "cs.AI", "cs.SI"], "published": "2024-12-24T08:48:48+00:00", "updated": "2024-12-24T08:48:48+00:00", "url": "http://arxiv.org/pdf/2412.18287v1", "data_source_type": ["payment", "banking"], "data_source_name": [], "fraud_type": "credit card fraud", "technical_approach_category": ["graph neural network", "semi-supervised learning", "temporal modeling", "anomaly detection"], "technical_approach_method": ["Gated Temporal Attention Network (GTAN)"], "technical_approach_description": "Proposes a semi-supervised graph neural network that constructs a temporal transaction graph from transaction records and learns transaction representations through message passing using a Gated Temporal Attention Network (GTAN), modeling fraud patterns via risk propagation.", "innovation_points": "Leverages unlabeled transaction data through semi-supervised learning, constructs a temporal transaction graph, and introduces a Gated Temporal Attention Network for representation learning, demonstrating excellent performance with minimal labeled data.", "github_repo": ""}
{"id": "2412.16788v2", "title": "DCOR: Anomaly Detection in Attributed Networks via Dual Contrastive Learning Reconstruction", "authors": ["Hossein Rafieizadeh", "Hadi Zare", "Mohsen Ghassemi Parsa", "Hadi Davardoust", "Meshkat Shariat Bagheri"], "abstract": "Anomaly detection using a network-based approach is one of the most efficient\nways to identify abnormal events such as fraud, security breaches, and system\nfaults in a variety of applied domains. While most of the earlier works address\nthe complex nature of graph-structured data and predefined anomalies, the\nimpact of data attributes and emerging anomalies are often neglected. This\npaper introduces DCOR, a novel approach on attributed networks that integrates\nreconstruction-based anomaly detection with Contrastive Learning. Utilizing a\nGraph Neural Network (GNN) framework, DCOR contrasts the reconstructed\nadjacency and feature matrices from both the original and augmented graphs to\ndetect subtle anomalies. We employed comprehensive experimental studies on\nbenchmark datasets through standard evaluation measures. The results show that\nDCOR significantly outperforms state-of-the-art methods. Obtained results\ndemonstrate the efficacy of proposed approach in attributed networks with the\npotential of uncovering new patterns of anomalies.", "categories": ["cs.AI", "05C82 05C82 05C82 05C82", "I.2.6; G.2.2"], "published": "2024-12-21T22:02:06+00:00", "updated": "2025-01-20T20:17:59+00:00", "url": "http://arxiv.org/pdf/2412.16788v2", "data_source_type": [], "data_source_name": [], "fraud_type": "anomaly detection in attributed networks", "technical_approach_category": ["Graph Neural Network (GNN)", "contrastive learning", "reconstruction-based anomaly detection"], "technical_approach_method": ["DCOR (Dual Contrastive Learning Reconstruction)"], "technical_approach_description": "A novel approach that integrates reconstruction-based anomaly detection with Contrastive Learning. It utilizes a GNN framework to contrast the reconstructed adjacency and feature matrices from both the original and augmented graphs to detect subtle anomalies.", "innovation_points": "Introduces DCOR, a novel approach that integrates reconstruction-based anomaly detection with Contrastive Learning on attributed networks, designed to detect subtle anomalies by contrasting reconstructions from original and augmented graphs.", "github_repo": ""}
{"id": "2503.22681v1", "title": "detectGNN: Harnessing Graph Neural Networks for Enhanced Fraud Detection in Credit Card Transactions", "authors": ["Irin Sultana", "Syed Mustavi Maheen", "Naresh Kshetri", "Md Nasim Fardous Zim"], "abstract": "Credit card fraud is a major issue nowadays, costing huge money and affecting\ntrust in financial systems. Traditional fraud detection methods often fail to\ndetect advanced and growing fraud techniques. This study focuses on using Graph\nNeural Networks (GNNs) to improve fraud detection by analyzing transactions as\na network of connected data points, such as accounts, traders, and devices. The\nproposed \"detectGNN\" model uses advanced features like time-based patterns and\ndynamic updates to expose hidden fraud and improve detection accuracy. Tests\nshow that GNNs perform better than traditional methods in finding complex and\nmulti-layered fraud. The model also addresses real-time processing, data\nimbalance, and privacy concerns, making it practical for real-world use. This\nresearch shows that GNNs can provide a powerful, accurate, and a scalable\nsolution for detecting fraud. Future work will focus on making the models\neasier to understand, privacy-friendly, and adaptable to new types of fraud,\nensuring safer financial transactions in the digital world.", "categories": ["cs.CR"], "published": "2025-02-09T00:01:36+00:00", "updated": "2025-02-09T00:01:36+00:00", "url": "http://arxiv.org/pdf/2503.22681v1", "data_source_type": ["financial"], "data_source_name": [], "fraud_type": "credit card fraud", "technical_approach_category": ["GNN", "anomaly detection", "feature engineering"], "technical_approach_method": ["Graph Neural Networks"], "technical_approach_description": "Proposes detectGNN model that analyzes credit card transactions as a network of connected data points (accounts, traders, devices) using time-based patterns and dynamic updates to detect complex fraud patterns with improved accuracy.", "innovation_points": "Uses Graph Neural Networks to model transactions as connected networks, incorporates time-based patterns and dynamic updates for enhanced fraud detection, addresses real-time processing, data imbalance, and privacy concerns for practical deployment.", "github_repo": ""}
{"id": "2502.00529v1", "title": "Graph Data Management and Graph Machine Learning: Synergies and Opportunities", "authors": ["Arijit Khan", "Xiangyu Ke", "Yinghui Wu"], "abstract": "The ubiquity of machine learning, particularly deep learning, applied to\ngraphs is evident in applications ranging from cheminformatics (drug discovery)\nand bioinformatics (protein interaction prediction) to knowledge graph-based\nquery answering, fraud detection, and social network analysis. Concurrently,\ngraph data management deals with the research and development of effective,\nefficient, scalable, robust, and user-friendly systems and algorithms for\nstoring, processing, and analyzing vast quantities of heterogeneous and complex\ngraph data. Our survey provides a comprehensive overview of the synergies\nbetween graph data management and graph machine learning, illustrating how they\nintertwine and mutually reinforce each other across the entire spectrum of the\ngraph data science and machine learning pipeline. Specifically, the survey\nhighlights two crucial aspects: (1) How graph data management enhances graph\nmachine learning, including contributions such as improved graph neural network\nperformance through graph data cleaning, scalable graph embedding, efficient\ngraph-based vector data management, robust graph neural networks, user-friendly\nexplainability methods; and (2) how graph machine learning, in turn, aids in\ngraph data management, with a focus on applications like query answering over\nknowledge graphs and various data science tasks. We discuss pertinent open\nproblems and delineate crucial research directions.", "categories": ["cs.DB"], "published": "2025-02-01T19:04:25+00:00", "updated": "2025-02-01T19:04:25+00:00", "url": "http://arxiv.org/pdf/2502.00529v1", "data_source_type": [], "data_source_name": [], "fraud_type": "", "technical_approach_category": ["graph data management", "graph machine learning", "graph neural networks", "graph embedding", "explainable AI", "data cleaning", "anomaly detection"], "technical_approach_method": [], "technical_approach_description": "Survey paper exploring the synergies between graph data management systems and graph machine learning techniques across the entire graph data science pipeline, including how each field enhances the other.", "innovation_points": "Comprehensive overview of how graph data management enhances graph ML (through data cleaning, scalable embeddings, robust GNNs, explainability) and how graph ML aids graph data management (query answering, data science tasks)", "github_repo": ""}
{"id": "2502.00201v2", "title": "Year-over-Year Developments in Financial Fraud Detection via Deep Learning: A Systematic Literature Review", "authors": ["Yisong Chen", "Chuqing Zhao", "Yixin Xu", "Chuanhao Nie", "Yixin Zhang"], "abstract": "This paper systematically reviews advancements in deep learning (DL)\ntechniques for financial fraud detection, a critical issue in the financial\nsector. Using the Kitchenham systematic literature review approach, 57 studies\npublished between 2019 and 2024 were analyzed. The review highlights the\neffectiveness of various deep learning models such as Convolutional Neural\nNetworks, Long Short-Term Memory, and transformers across domains such as\ncredit card transactions, insurance claims, and financial statement audits.\nPerformance metrics such as precision, recall, F1-score, and AUC-ROC were\nevaluated. Key themes explored include the impact of data privacy frameworks\nand advancements in feature engineering and data preprocessing. The study\nemphasizes challenges such as imbalanced datasets, model interpretability, and\nethical considerations, alongside opportunities for automation and\nprivacy-preserving techniques such as blockchain integration and Principal\nComponent Analysis. By examining trends over the past five years, this review\nidentifies critical gaps and promising directions for advancing DL applications\nin financial fraud detection, offering actionable insights for researchers and\npractitioners.", "categories": ["cs.LG", "cs.AI", "q-fin.ST"], "published": "2025-01-31T22:31:50+00:00", "updated": "2025-07-30T04:32:58+00:00", "url": "http://arxiv.org/pdf/2502.00201v2", "data_source_type": ["credit card", "insurance", "financial auditing"], "data_source_name": [], "fraud_type": "financial fraud detection", "technical_approach_category": ["deep learning", "convolutional neural networks", "long short-term memory", "transformers", "feature engineering", "data preprocessing", "privacy-preserving techniques", "blockchain integration", "principal component analysis"], "technical_approach_method": ["CNN", "LSTM", "transformers"], "technical_approach_description": "Systematic review of deep learning techniques for financial fraud detection, analyzing 57 studies from 2019-2024 covering CNN, LSTM, and transformer models across credit card transactions, insurance claims, and financial statement audits.", "innovation_points": "Identifies trends over five years, examines impact of data privacy frameworks, highlights challenges of imbalanced datasets and model interpretability, and identifies opportunities for automation and privacy-preserving techniques.", "github_repo": ""}
{"id": "2501.19267v1", "title": "Transformer-Based Financial Fraud Detection with Cloud-Optimized Real-Time Streaming", "authors": ["Tingting Deng", "Shuochen Bi", "Jue Xiao"], "abstract": "As the financial industry becomes more interconnected and reliant on digital\nsystems, fraud detection systems must evolve to meet growing threats.\nCloud-enabled Transformer models present a transformative opportunity to\naddress these challenges. By leveraging the scalability, flexibility, and\nadvanced AI capabilities of cloud platforms, companies can deploy fraud\ndetection solutions that adapt to real-time data patterns and proactively\nrespond to evolving threats. Using the Graph self-attention Transformer neural\nnetwork module, we can directly excavate gang fraud features from the\ntransaction network without constructing complicated feature engineering.\nFinally, the fraud prediction network is combined to optimize the topological\npattern and the temporal transaction pattern to realize the high-precision\ndetection of fraudulent transactions. The results of antifraud experiments on\ncredit card transaction data show that the proposed model outperforms the 7\nbaseline models on all evaluation indicators: In the transaction fraud\ndetection task, the average accuracy (AP) increased by 20% and the area under\nthe ROC curve (AUC) increased by 2.7% on average compared with the benchmark\ngraph attention neural network (GAT), which verified the effectiveness of the\nproposed model in the detection of credit card fraud transactions.", "categories": ["cs.CE"], "published": "2025-01-31T16:27:58+00:00", "updated": "2025-01-31T16:27:58+00:00", "url": "http://arxiv.org/pdf/2501.19267v1", "data_source_type": ["banking", "payment"], "data_source_name": [], "fraud_type": "credit card transaction fraud", "technical_approach_category": ["Transformer", "GNN", "Graph Attention", "anomaly detection", "real-time streaming"], "technical_approach_method": ["Graph self-attention Transformer neural network", "GAT (Graph Attention Network)"], "technical_approach_description": "Proposes a cloud-optimized Transformer model for real-time fraud detection. Uses a Graph self-attention Transformer module to directly extract gang fraud features from transaction networks without complex feature engineering. Combines fraud prediction network to optimize topological and temporal transaction patterns for high-precision detection.", "innovation_points": "Leverages cloud platforms for scalable, real-time fraud detection. Uses Graph self-attention Transformer to directly excavate gang fraud features without constructing complicated feature engineering. Combines optimization of topological pattern and temporal transaction pattern.", "github_repo": ""}
{"id": "2501.12430v1", "title": "SCFCRC: Simultaneously Counteract Feature Camouflage and Relation Camouflage for Fraud Detection", "authors": ["Xiaocheng Zhang", "Zhuangzhuang Ye", "GuoPing Zhao", "Jianing Wang", "Xiaohong Su"], "abstract": "In fraud detection, fraudsters often interact with many benign users,\ncamouflaging their features or relations to hide themselves. Most existing work\nconcentrates solely on either feature camouflage or relation camouflage, or\ndecoupling feature learning and relation learning to avoid the two camouflage\nfrom affecting each other. However, this inadvertently neglects the valuable\ninformation derived from features or relations, which could mutually enhance\ntheir adversarial camouflage strategies. In response to this gap, we propose\nSCFCRC, a Transformer-based fraud detector that Simultaneously Counteract\nFeature Camouflage and Relation Camouflage. SCFCRC consists of two components:\nFeature Camouflage Filter and Relation Camouflage Refiner. The feature\ncamouflage filter utilizes pseudo labels generated through label propagation to\ntrain the filter and uses contrastive learning that combines instance-wise and\nprototype-wise to improve the quality of features. The relation camouflage\nrefiner uses Mixture-of-Experts(MoE) network to disassemble the multi-relations\ngraph into multiple substructures and divide and conquer them to mitigate the\ndegradation of detection performance caused by relation camouflage.\nFurthermore, we introduce a regularization method for MoE to enhance the\nrobustness of the model. Extensive experiments on two fraud detection benchmark\ndatasets demonstrate that our method outperforms state-of-the-art baselines.", "categories": ["cs.LG", "cs.AI"], "published": "2025-01-21T15:50:51+00:00", "updated": "2025-01-21T15:50:51+00:00", "url": "http://arxiv.org/pdf/2501.12430v1", "data_source_type": [], "data_source_name": [], "fraud_type": "fraud detection", "technical_approach_category": ["Transformer", "contrastive learning", "graph neural network", "anomaly detection", "multi-task learning"], "technical_approach_method": ["Transformer-based fraud detector", "Feature Camouflage Filter", "Relation Camouflage Refiner", "label propagation", "instance-wise and prototype-wise contrastive learning", "Mixture-of-Experts (MoE) network"], "technical_approach_description": "A Transformer-based fraud detector that simultaneously counteracts feature and relation camouflage. It uses a Feature Camouflage Filter with pseudo labels and contrastive learning to improve feature quality, and a Relation Camouflage Refiner with a Mixture-of-Experts network to disassemble multi-relation graphs and mitigate camouflage effects.", "innovation_points": "Simultaneously addresses both feature and relation camouflage instead of focusing on one or decoupling them. Introduces a feature camouflage filter with contrastive learning and a relation camouflage refiner with a regularized MoE network to handle multi-relation graphs.", "github_repo": ""}
{"id": "2503.12037v1", "title": "Unsupervised Graph Anomaly Detection via Multi-Hypersphere Heterophilic Graph Learning", "authors": ["Hang Ni", "Jindong Han", "Nengjun Zhu", "Hao Liu"], "abstract": "Graph Anomaly Detection (GAD) plays a vital role in various data mining\napplications such as e-commerce fraud prevention and malicious user detection.\nRecently, Graph Neural Network (GNN) based approach has demonstrated great\neffectiveness in GAD by first encoding graph data into low-dimensional\nrepresentations and then identifying anomalies under the guidance of supervised\nor unsupervised signals. However, existing GNN-based approaches implicitly\nfollow the homophily principle (i.e., the \"like attracts like\" phenomenon) and\nfail to learn discriminative embedding for anomalies that connect vast normal\nnodes. Moreover, such approaches identify anomalies in a unified global\nperspective but overlook diversified abnormal patterns conditioned on local\ngraph context, leading to suboptimal performance. To overcome the\naforementioned limitations, in this paper, we propose a Multi-hypersphere\nHeterophilic Graph Learning (MHetGL) framework for unsupervised GAD.\nSpecifically, we first devise a Heterophilic Graph Encoding (HGE) module to\nlearn distinguishable representations for potential anomalies by purifying and\naugmenting their neighborhood in a fully unsupervised manner. Then, we propose\na Multi-Hypersphere Learning (MHL) module to enhance the detection capability\nfor context-dependent anomalies by jointly incorporating critical patterns from\nboth global and local perspectives. Extensive experiments on ten real-world\ndatasets show that MHetGL outperforms 14 baselines. Our code is publicly\navailable at https://github.com/KennyNH/MHetGL.", "categories": ["cs.LG", "cs.AI"], "published": "2025-03-15T08:08:13+00:00", "updated": "2025-03-15T08:08:13+00:00", "url": "http://arxiv.org/pdf/2503.12037v1", "data_source_type": ["e-commerce", "social platform"], "data_source_name": [], "fraud_type": "e-commerce fraud prevention, malicious user detection", "technical_approach_category": ["Graph Neural Network", "unsupervised learning", "anomaly detection", "heterophilic graph learning", "multi-hypersphere learning"], "technical_approach_method": ["Heterophilic Graph Encoding (HGE)", "Multi-Hypersphere Learning (MHL)"], "technical_approach_description": "Proposes a Multi-hypersphere Heterophilic Graph Learning framework for unsupervised graph anomaly detection. It uses a Heterophilic Graph Encoding module to learn distinguishable representations for anomalies by purifying and augmenting their neighborhood, and a Multi-Hypersphere Learning module to detect context-dependent anomalies from both global and local perspectives.", "innovation_points": "Overcomes limitations of existing GNN approaches that follow homophily principle and use unified global perspective. Learns discriminative embeddings for anomalies connecting normal nodes and handles diversified abnormal patterns conditioned on local graph context.", "github_repo": "https://github.com/KennyNH/MHetGL"}
{"id": "2503.01556v1", "title": "Effective High-order Graph Representation Learning for Credit Card Fraud Detection", "authors": ["Yao Zou", "Dawei Cheng"], "abstract": "Credit card fraud imposes significant costs on both cardholders and issuing\nbanks. Fraudsters often disguise their crimes, such as using legitimate\ntransactions through several benign users to bypass anti-fraud detection.\nExisting graph neural network (GNN) models struggle with learning features of\ncamouflaged, indirect multi-hop transactions due to their inherent\nover-smoothing issues in deep multi-layer aggregation, presenting a major\nchallenge in detecting disguised relationships. Therefore, in this paper, we\npropose a novel High-order Graph Representation Learning model (HOGRL) to avoid\nincorporating excessive noise during the multi-layer aggregation process. In\nparticular, HOGRL learns different orders of \\emph{pure} representations\ndirectly from high-order transaction graphs. We realize this goal by\neffectively constructing high-order transaction graphs first and then learning\nthe \\emph{pure} representations of each order so that the model could identify\nfraudsters' multi-hop indirect transactions via multi-layer \\emph{pure} feature\nlearning. In addition, we introduce a mixture-of-expert attention mechanism to\nautomatically determine the importance of different orders for jointly\noptimizing fraud detection performance. We conduct extensive experiments in\nboth the open source and real-world datasets, the result demonstrates the\nsignificant improvements of our proposed HOGRL compared with state-of-the-art\nfraud detection baselines. HOGRL's superior performance also proves its\neffectiveness in addressing high-order fraud camouflage criminals.", "categories": ["cs.LG", "cs.AI", "68T07, 91B06", "I.2.6; H.2.8"], "published": "2025-03-03T13:59:46+00:00", "updated": "2025-03-03T13:59:46+00:00", "url": "http://arxiv.org/pdf/2503.01556v1", "data_source_type": ["payment"], "data_source_name": [], "fraud_type": "credit card fraud", "technical_approach_category": ["graph neural network", "anomaly detection", "attention mechanism"], "technical_approach_method": ["High-order Graph Representation Learning model (HOGRL)", "mixture-of-expert attention mechanism"], "technical_approach_description": "Proposes HOGRL to learn pure representations directly from high-order transaction graphs, avoiding noise from multi-layer aggregation. It constructs high-order graphs and uses an attention mechanism to determine the importance of different orders for fraud detection.", "innovation_points": "Learns pure representations directly from high-order transaction graphs instead of through multi-layer aggregation, and introduces a mixture-of-expert attention mechanism to automatically determine the importance of different orders.", "github_repo": ""}
{"id": "2502.10624v1", "title": "Network evasion detection with Bi-LSTM model", "authors": ["Kehua Chen", "Jingping Jia"], "abstract": "Network evasion detection aims to distinguish whether the network flow comes\nfrom link layer exists network evasion threat, which is a means to disguise the\ndata traffic on detection system by confusing the signature. Since the previous\nresearch works has all sorts of frauds, we propose a architecture with deep\nlearning network to handle this problem. In this paper, we extract the critical\ninformation as key features from data frame and also specifically propose to\nuse bidirectional long short-term memory (Bi-LSTM) neural network which shows\nan outstanding performance to trace the serial information, to encode both the\npast and future trait on the network flows. Furthermore we introduce a\nclassifier named Softmax at the bottom of Bi-LSTM, holding a character to\nselect the correct class. All experiments results shows that we can achieve a\nsignificant performance with a deep Bi-LSTM in network evasion detection and\nit's average accuracy reaches 96.1%.", "categories": ["cs.CR", "cs.AI"], "published": "2025-02-15T01:25:13+00:00", "updated": "2025-02-15T01:25:13+00:00", "url": "http://arxiv.org/pdf/2502.10624v1", "data_source_type": ["network traffic"], "data_source_name": [], "fraud_type": "network evasion", "technical_approach_category": ["feature engineering", "RNN/LSTM", "deep learning"], "technical_approach_method": ["Bi-LSTM", "Softmax classifier"], "technical_approach_description": "Extracts critical information as key features from data frames and uses a bidirectional long short-term memory (Bi-LSTM) neural network to encode both past and future traits in network flows, followed by a Softmax classifier for correct class selection.", "innovation_points": "Proposes an architecture with deep learning network to handle network evasion detection, specifically using Bi-LSTM to trace serial information and encode both past and future traits on network flows.", "github_repo": ""}
{"id": "2504.08183v1", "title": "Detecting Credit Card Fraud via Heterogeneous Graph Neural Networks with Graph Attention", "authors": ["Qiuwu Sha", "Tengda Tang", "Xinyu Du", "Jie Liu", "Yixian Wang", "Yuan Sheng"], "abstract": "This study proposes a credit card fraud detection method based on\nHeterogeneous Graph Neural Network (HGNN) to address fraud in complex\ntransaction networks. Unlike traditional machine learning methods that rely\nsolely on numerical features of transaction records, this approach constructs\nheterogeneous transaction graphs. These graphs incorporate multiple node types,\nincluding users, merchants, and transactions. By leveraging graph neural\nnetworks, the model captures higher-order transaction relationships. A Graph\nAttention Mechanism is employed to dynamically assign weights to different\ntransaction relationships. Additionally, a Temporal Decay Mechanism is\nintegrated to enhance the model's sensitivity to time-related fraud patterns.\nTo address the scarcity of fraudulent transaction samples, this study applies\nSMOTE oversampling and Cost-sensitive Learning. These techniques strengthen the\nmodel's ability to identify fraudulent transactions. Experimental results\ndemonstrate that the proposed method outperforms existing GNN models, including\nGCN, GAT, and GraphSAGE, on the IEEE-CIS Fraud Detection dataset. The model\nachieves notable improvements in both accuracy and OC-ROC. Future research may\nexplore the integration of dynamic graph neural networks and reinforcement\nlearning. Such advancements could enhance the real-time adaptability of fraud\ndetection systems and provide more intelligent solutions for financial risk\ncontrol.", "categories": ["cs.LG", "cs.CR"], "published": "2025-04-11T00:53:53+00:00", "updated": "2025-04-11T00:53:53+00:00", "url": "http://arxiv.org/pdf/2504.08183v1", "data_source_type": ["payment"], "data_source_name": ["IEEE-CIS Fraud Detection"], "fraud_type": "credit card fraud", "technical_approach_category": ["GNN", "anomaly detection", "class imbalance handling", "attention mechanism"], "technical_approach_method": ["Heterogeneous Graph Neural Network (HGNN)", "Graph Attention Mechanism", "Temporal Decay Mechanism", "SMOTE", "Cost-sensitive Learning"], "technical_approach_description": "Proposes a credit card fraud detection method using Heterogeneous Graph Neural Networks that constructs transaction graphs with multiple node types (users, merchants, transactions). The approach captures higher-order transaction relationships using graph attention to dynamically weight relationships and incorporates temporal decay for time-sensitive fraud patterns.", "innovation_points": "Constructs heterogeneous transaction graphs to capture complex relationships, employs graph attention mechanism for dynamic relationship weighting, integrates temporal decay for time-sensitive patterns, and combines SMOTE oversampling with cost-sensitive learning to address class imbalance.", "github_repo": ""}
{"id": "2504.03750v1", "title": "Detecting Financial Fraud with Hybrid Deep Learning: A Mix-of-Experts Approach to Sequential and Anomalous Patterns", "authors": ["Diego Vallarino"], "abstract": "Financial fraud detection remains a critical challenge due to the dynamic and\nadversarial nature of fraudulent behavior. As fraudsters evolve their tactics,\ndetection systems must combine robustness, adaptability, and precision. This\nstudy presents a hybrid architecture for credit card fraud detection that\nintegrates a Mixture of Experts (MoE) framework with Recurrent Neural Networks\n(RNNs), Transformer encoders, and Autoencoders. Each expert module contributes\na specialized capability: RNNs capture sequential behavior, Transformers\nextract high-order feature interactions, and Autoencoders detect anomalies\nthrough reconstruction loss. The MoE framework dynamically assigns predictive\nresponsibility among the experts, enabling adaptive and context-sensitive\ndecision-making.\n  Trained on a high-fidelity synthetic dataset that simulates real-world\ntransaction patterns and fraud typologies, the hybrid model achieved 98.7\npercent accuracy, 94.3 percent precision, and 91.5 percent recall,\noutperforming standalone models and classical machine learning baselines. The\nAutoencoder component significantly enhanced the system's ability to identify\nemerging fraud strategies and atypical behaviors.\n  Beyond technical performance, the model contributes to broader efforts in\nfinancial governance and crime prevention. It supports regulatory compliance\nwith Anti-Money Laundering (AML) and Know Your Customer (KYC) protocols and\naligns with routine activity theory by operationalizing AI as a capable\nguardian within financial ecosystems. The proposed hybrid system offers a\nscalable, modular, and regulation-aware approach to detecting increasingly\nsophisticated fraud patterns, contributing both to the advancement of\nintelligent systems and to the strengthening of institutional fraud defense\ninfrastructures.", "categories": ["cs.CR", "cs.LG"], "published": "2025-04-01T20:47:18+00:00", "updated": "2025-04-01T20:47:18+00:00", "url": "http://arxiv.org/pdf/2504.03750v1", "data_source_type": ["payment"], "data_source_name": [], "fraud_type": "credit card fraud", "technical_approach_category": ["RNN/LSTM", "Transformer", "Autoencoder", "anomaly detection", "hybrid architecture"], "technical_approach_method": ["Mixture of Experts (MoE)", "Recurrent Neural Networks (RNNs)", "Transformer encoders", "Autoencoders"], "technical_approach_description": "A hybrid architecture combining Mixture of Experts with RNNs for sequential behavior, Transformers for high-order feature interactions, and Autoencoders for anomaly detection via reconstruction loss. The MoE framework dynamically assigns predictive responsibility among experts for adaptive decision-making.", "innovation_points": "Presents a hybrid architecture integrating MoE with RNNs, Transformers, and Autoencoders for credit card fraud detection. The Autoencoder component significantly enhances identification of emerging fraud strategies and atypical behaviors, offering a scalable and regulation-aware approach.", "github_repo": ""}
{"id": "2503.20477v1", "title": "Development of New Methods for Detection and Control of Credit Card Fraud Attacks", "authors": ["Alexander Stotsky"], "abstract": "Credit card fraud causes significant financial losses and frequently occurs\nas fraud attack, defined as short-term sequence of fraudulent transactions\nassociated with high transaction rates and amounts, business areas historically\ntied to fraud, unusual transaction times and locations and different types of\nerrors. Confidence interval method in the moving window with exponential\nforgetting is proposed in this report which allows to capture recent changes in\nthe shopping behaviour of the cardholder, detect fraudulent amounts and\nmitigate the attack. Fraud risk scoring method is used for estimation of the\nintensity of the fraudulent activity via monitoring of the transaction rates,\nmerchant category codes, times and some other factors for detection of the\nstart of the attack. The development and verification are based on detailed\nanalysis of the transaction patterns from the dataset, which represents an\nextensive collection of around 24.4 million credit card transactions from IBM\nfinancial database. Recommendations for further development of the detection\ntechniques are also presented.", "categories": ["math.OC", "math.DS"], "published": "2025-03-26T12:06:27+00:00", "updated": "2025-03-26T12:06:27+00:00", "url": "http://arxiv.org/pdf/2503.20477v1", "data_source_type": ["banking", "financial"], "data_source_name": ["IBM financial database"], "fraud_type": "credit card fraud attacks", "technical_approach_category": ["statistical methods", "anomaly detection", "risk scoring"], "technical_approach_method": ["Confidence interval method in moving window with exponential forgetting", "Fraud risk scoring method"], "technical_approach_description": "Proposes confidence interval method with exponential forgetting in moving window to capture recent shopping behavior changes and detect fraudulent amounts. Uses fraud risk scoring to estimate fraudulent activity intensity by monitoring transaction rates, merchant codes, times, and other factors.", "innovation_points": "Development of confidence interval method with exponential forgetting in moving window to detect fraudulent transactions and mitigate attacks, along with fraud risk scoring for monitoring transaction patterns to identify attack start.", "github_repo": ""}
{"id": "2503.16901v1", "title": "TeMP-TraG: Edge-based Temporal Message Passing in Transaction Graphs", "authors": ["Steve Gounoue", "Ashutosh Sao", "Simon Gottschalk"], "abstract": "Transaction graphs, which represent financial and trade transactions between\nentities such as bank accounts and companies, can reveal patterns indicative of\nfinancial crimes like money laundering and fraud. However, effective detection\nof such cases requires node and edge classification methods capable of\naddressing the unique challenges of transaction graphs, including rich edge\nfeatures, multigraph structures and temporal dynamics. To tackle these\nchallenges, we propose TeMP-TraG, a novel graph neural network mechanism that\nincorporates temporal dynamics into message passing. TeMP-TraG prioritises more\nrecent transactions when aggregating node messages, enabling better detection\nof time-sensitive patterns. We demonstrate that TeMP-TraG improves four\nstate-of-the-art graph neural networks by 6.19% on average. Our results\nhighlight TeMP-TraG as an advancement in leveraging transaction graphs to\ncombat financial crime.", "categories": ["cs.LG"], "published": "2025-03-21T07:10:27+00:00", "updated": "2025-03-21T07:10:27+00:00", "url": "http://arxiv.org/pdf/2503.16901v1", "data_source_type": ["financial", "trade"], "data_source_name": [], "fraud_type": "money laundering and fraud", "technical_approach_category": ["Graph Neural Network", "temporal modeling", "anomaly detection"], "technical_approach_method": ["TeMP-TraG", "temporal message passing"], "technical_approach_description": "A novel graph neural network mechanism that incorporates temporal dynamics into message passing by prioritizing more recent transactions when aggregating node messages, enabling better detection of time-sensitive patterns in transaction graphs.", "innovation_points": "Proposes TeMP-TraG, a novel GNN mechanism that incorporates temporal dynamics into message passing by prioritizing more recent transactions. Demonstrates improvement of four state-of-the-art GNNs by 6.19% on average.", "github_repo": ""}
{"id": "2505.00137v1", "title": "Toward Practical Quantum Machine Learning: A Novel Hybrid Quantum LSTM for Fraud Detection", "authors": ["Rushikesh Ubale", "Sujan K. K.", "Sangram Deshpande", "Gregory T. Byrd"], "abstract": "We present a novel hybrid quantum-classical neural network architecture for\nfraud detection that integrates a classical Long Short-Term Memory (LSTM)\nnetwork with a variational quantum circuit. By leveraging quantum phenomena\nsuch as superposition and entanglement, our model enhances the feature\nrepresentation of sequential transaction data, capturing complex non-linear\npatterns that are challenging for purely classical models. A comprehensive data\npreprocessing pipeline is employed to clean, encode, balance, and normalize a\ncredit card fraud dataset, ensuring a fair comparison with baseline models.\nNotably, our hybrid approach achieves per-epoch training times in the range of\n45-65 seconds, which is significantly faster than similar architectures\nreported in the literature, where training typically requires several minutes\nper epoch. Both classical and quantum gradients are jointly optimized via a\nunified backpropagation procedure employing the parameter-shift rule for the\nquantum parameters. Experimental evaluations demonstrate competitive\nimprovements in accuracy, precision, recall, and F1 score relative to a\nconventional LSTM baseline. These results underscore the promise of hybrid\nquantum-classical techniques in advancing the efficiency and performance of\nfraud detection systems.\n  Keywords: Hybrid Quantum-Classical Neural Networks, Quantum Computing, Fraud\nDetection, Hybrid Quantum LSTM, Variational Quantum Circuit, Parameter-Shift\nRule, Financial Risk Analysis", "categories": ["quant-ph", "cs.IT", "cs.LG", "math.IT"], "published": "2025-04-30T19:09:12+00:00", "updated": "2025-04-30T19:09:12+00:00", "url": "http://arxiv.org/pdf/2505.00137v1", "data_source_type": ["payment", "banking"], "data_source_name": [], "fraud_type": "credit card fraud", "technical_approach_category": ["quantum computing", "hybrid quantum-classical neural networks", "LSTM", "feature engineering", "anomaly detection"], "technical_approach_method": ["Hybrid Quantum LSTM", "Variational Quantum Circuit", "Parameter-Shift Rule", "backpropagation"], "technical_approach_description": "A hybrid quantum-classical neural network that integrates a classical LSTM with a variational quantum circuit to enhance feature representation of sequential transaction data by leveraging quantum superposition and entanglement for capturing complex non-linear patterns.", "innovation_points": "Novel hybrid quantum-classical architecture achieving significantly faster per-epoch training times (45-65 seconds) compared to similar architectures requiring several minutes per epoch, with competitive improvements in accuracy, precision, recall, and F1 score.", "github_repo": ""}
{"id": "2504.18785v2", "title": "ALF: Advertiser Large Foundation Model for Multi-Modal Advertiser Understanding", "authors": ["Santosh Rajagopalan", "Jonathan Vronsky", "Songbai Yan", "S. Alireza Golestaneh", "Shubhra Chandra", "Min Zhou"], "abstract": "We present ALF (Advertiser Large Foundation model), a multi-modal transformer\narchitecture for understanding advertiser behavior and intent across text,\nimage, video, and structured data modalities. Through contrastive learning and\nmulti-task optimization, ALF creates unified advertiser representations that\ncapture both content and behavioral patterns. Our model achieves\nstate-of-the-art performance on critical tasks including fraud detection,\npolicy violation identification, and advertiser similarity matching. In\nproduction deployment, ALF demonstrates significant real-world impact by\ndelivering simultaneous gains in both precision and recall, for instance\nboosting recall by over 40 percentage points on one critical policy and\nincreasing precision to 99.8% on another. The architecture's effectiveness\nstems from its novel combination of multi-modal transformations, inter-sample\nattention mechanism, spectrally normalized projections, and calibrated\nprobabilistic outputs.", "categories": ["cs.LG"], "published": "2025-04-26T03:33:42+00:00", "updated": "2025-09-05T00:45:08+00:00", "url": "http://arxiv.org/pdf/2504.18785v2", "data_source_type": ["advertising"], "data_source_name": [], "fraud_type": "ad fraud detection and policy violation identification", "technical_approach_category": ["transformer", "multimodal fusion", "contrastive learning", "multi-task learning", "anomaly detection"], "technical_approach_method": ["multi-modal transformer architecture", "contrastive learning", "multi-task optimization", "inter-sample attention mechanism", "spectrally normalized projections"], "technical_approach_description": "A multi-modal transformer architecture that creates unified advertiser representations across text, image, video, and structured data modalities to understand advertiser behavior and intent through contrastive learning and multi-task optimization.", "innovation_points": "Novel combination of multi-modal transformations, inter-sample attention mechanism, spectrally normalized projections, and calibrated probabilistic outputs for unified advertiser understanding.", "github_repo": ""}
{"id": "2504.15491v1", "title": "Application of Deep Generative Models for Anomaly Detection in Complex Financial Transactions", "authors": ["Tengda Tang", "Jianhua Yao", "Yixian Wang", "Qiuwu Sha", "Hanrui Feng", "Zhen Xu"], "abstract": "This study proposes an algorithm for detecting suspicious behaviors in large\npayment flows based on deep generative models. By combining Generative\nAdversarial Networks (GAN) and Variational Autoencoders (VAE), the algorithm is\ndesigned to detect abnormal behaviors in financial transactions. First, the GAN\nis used to generate simulated data that approximates normal payment flows. The\ndiscriminator identifies anomalous patterns in transactions, enabling the\ndetection of potential fraud and money laundering behaviors. Second, a VAE is\nintroduced to model the latent distribution of payment flows, ensuring that the\ngenerated data more closely resembles real transaction features, thus improving\nthe model's detection accuracy. The method optimizes the generative\ncapabilities of both GAN and VAE, ensuring that the model can effectively\ncapture suspicious behaviors even in sparse data conditions. Experimental\nresults show that the proposed method significantly outperforms traditional\nmachine learning algorithms and other deep learning models across various\nevaluation metrics, especially in detecting rare fraudulent behaviors.\nFurthermore, this study provides a detailed comparison of performance in\nrecognizing different transaction patterns (such as normal, money laundering,\nand fraud) in large payment flows, validating the advantages of generative\nmodels in handling complex financial data.", "categories": ["cs.LG"], "published": "2025-04-21T23:49:10+00:00", "updated": "2025-04-21T23:49:10+00:00", "url": "http://arxiv.org/pdf/2504.15491v1", "data_source_type": ["payment"], "data_source_name": [], "fraud_type": "fraud and money laundering in financial transactions", "technical_approach_category": ["deep generative models", "anomaly detection", "GAN", "VAE"], "technical_approach_method": ["Generative Adversarial Networks (GAN)", "Variational Autoencoders (VAE)"], "technical_approach_description": "Combines GAN and VAE to detect abnormal behaviors in financial transactions. GAN generates simulated normal payment flows while its discriminator identifies anomalies. VAE models latent distribution to improve data realism and detection accuracy, particularly effective in sparse data conditions.", "innovation_points": "Novel combination of GAN and VAE for financial anomaly detection, optimized generative capabilities for sparse data, significantly outperforms traditional ML and other deep learning models in detecting rare fraudulent behaviors.", "github_repo": ""}
{"id": "2504.14205v2", "title": "Dual-channel Heterophilic Message Passing for Graph Fraud Detection", "authors": ["Wenxin Zhang", "Jingxing Zhong", "Guangzhen Yao", "Renda Han", "Xiaojian Lin", "Zeyu Zhang", "Cuicui Luo"], "abstract": "Fraudulent activities have significantly increased across various domains,\nsuch as e-commerce, online review platforms, and social networks, making fraud\ndetection a critical task. Spatial Graph Neural Networks (GNNs) have been\nsuccessfully applied to fraud detection tasks due to their strong inductive\nlearning capabilities. However, existing spatial GNN-based methods often\nenhance the graph structure by excluding heterophilic neighbors during message\npassing to align with the homophilic bias of GNNs. Unfortunately, this approach\ncan disrupt the original graph topology and increase uncertainty in\npredictions. To address these limitations, this paper proposes a novel\nframework, Dual-channel Heterophilic Message Passing (DHMP), for fraud\ndetection. DHMP leverages a heterophily separation module to divide the graph\ninto homophilic and heterophilic subgraphs, mitigating the low-pass inductive\nbias of traditional GNNs. It then applies shared weights to capture signals at\ndifferent frequencies independently and incorporates a customized sampling\nstrategy for training. This allows nodes to adaptively balance the\ncontributions of various signals based on their labels. Extensive experiments\non three real-world datasets demonstrate that DHMP outperforms existing\nmethods, highlighting the importance of separating signals with different\nfrequencies for improved fraud detection. The code is available at\nhttps://github.com/shaieesss/DHMP.", "categories": ["cs.LG", "cs.AI"], "published": "2025-04-19T06:41:24+00:00", "updated": "2025-04-26T08:03:12+00:00", "url": "http://arxiv.org/pdf/2504.14205v2", "data_source_type": ["e-commerce", "online review platforms", "social networks"], "data_source_name": [], "fraud_type": "graph fraud detection", "technical_approach_category": ["Graph Neural Networks", "heterophilic graph processing", "anomaly detection", "graph partitioning"], "technical_approach_method": ["Dual-channel Heterophilic Message Passing (DHMP)", "heterophily separation module", "customized sampling strategy"], "technical_approach_description": "Proposes DHMP framework that separates graph into homophilic and heterophilic subgraphs using a heterophily separation module, applies shared weights to capture signals at different frequencies independently, and uses a customized sampling strategy for training.", "innovation_points": "Addresses limitations of existing spatial GNNs by preserving original graph topology, mitigating low-pass inductive bias through heterophily separation, and allowing nodes to adaptively balance signal contributions based on their labels.", "github_repo": "https://github.com/shaieesss/DHMP"}
{"id": "2506.10842v1", "title": "Advanced fraud detection using machine learning models: enhancing financial transaction security", "authors": ["Nudrat Fariha", "Md Nazmuddin Moin Khan", "Md Iqbal Hossain", "Syed Ali Reza", "Joy Chakra Bortty", "Kazi Sharmin Sultana", "Md Shadidur Islam Jawad", "Saniah Safat", "Md Abdul Ahad", "Maksuda Begum"], "abstract": "The rise of digital payments has accelerated the need for intelligent and\nscalable systems to detect fraud. This research presents an end-to-end,\nfeature-rich machine learning framework for detecting credit card transaction\nanomalies and fraud using real-world data. The study begins by merging\ntransactional, cardholder, merchant, and merchant category datasets from a\nrelational database to create a unified analytical view. Through the feature\nengineering process, we extract behavioural signals such as average spending,\ndeviation from historical patterns, transaction timing irregularities, and\ncategory frequency metrics. These features are enriched with temporal markers\nsuch as hour, day of week, and weekend indicators to expose all latent patterns\nthat indicate fraudulent behaviours. Exploratory data analysis reveals\ncontextual transaction trends across all the dataset features. Using the\ntransactional data, we train and evaluate a range of unsupervised models:\nIsolation Forest, One Class SVM, and a deep autoencoder trained to reconstruct\nnormal behavior. These models flag the top 1% of reconstruction errors as\noutliers. PCA visualizations illustrate each models ability to separate\nanomalies into a two-dimensional latent space. We further segment the\ntransaction landscape using K-Means clustering and DBSCAN to identify dense\nclusters of normal activity and isolate sparse, suspicious regions.", "categories": ["cs.LG"], "published": "2025-06-12T15:59:25+00:00", "updated": "2025-06-12T15:59:25+00:00", "url": "http://arxiv.org/pdf/2506.10842v1", "data_source_type": ["banking", "payment"], "data_source_name": [], "fraud_type": "credit card transaction fraud", "technical_approach_category": ["feature engineering", "anomaly detection", "unsupervised learning", "clustering", "dimensionality reduction"], "technical_approach_method": ["Isolation Forest", "One Class SVM", "deep autoencoder", "K-Means", "DBSCAN", "PCA"], "technical_approach_description": "An end-to-end machine learning framework for detecting credit card transaction anomalies using unsupervised models. The approach involves feature engineering to extract behavioral signals and temporal patterns, followed by training Isolation Forest, One Class SVM, and deep autoencoder models to flag reconstruction errors as outliers, with clustering and PCA for visualization and segmentation.", "innovation_points": "Presents a feature-rich machine learning framework that merges multiple datasets to create a unified analytical view, extracts behavioral signals and temporal markers, and employs unsupervised models with PCA visualization to separate anomalies in latent space.", "github_repo": ""}
{"id": "2506.00282v1", "title": "Shill Bidding Prevention in Decentralized Auctions Using Smart Contracts", "authors": ["M. A. Bouaicha", "G. Destefanis", "T. Montanaro", "N. Lasla", "L. Patrono"], "abstract": "In online auctions, fraudulent behaviors such as shill bidding pose\nsignificant risks. This paper presents a conceptual framework that applies\ndynamic, behavior-based penalties to deter auction fraud using blockchain smart\ncontracts. Unlike traditional post-auction detection methods, this approach\nprevents manipulation in real-time by introducing an economic disincentive\nsystem where penalty severity scales with suspicious bidding patterns. The\nframework employs the proposed Bid Shill Score (BSS) to evaluate nine distinct\nbidding behaviors, dynamically adjusting the penalty fees to make fraudulent\nactivity financially unaffordable while providing fair competition.\n  The system is implemented within a decentralized English auction on the\nEthereum blockchain, demonstrating how smart contracts enforce transparent\nauction rules without trusted intermediaries. Simulations confirm the\neffectiveness of the proposed model: the dynamic penalty mechanism reduces the\nprofitability of shill bidding while keeping penalties low for honest bidders.\nPerformance evaluation shows that the system introduces only moderate gas and\nlatency overhead, keeping transaction costs and response times within practical\nbounds for real-world use. The approach provides a practical method for\nbehaviour-based fraud prevention in decentralised systems where trust cannot be\nassumed.", "categories": ["cs.GT", "cs.CR", "cs.SE"], "published": "2025-05-30T22:23:29+00:00", "updated": "2025-05-30T22:23:29+00:00", "url": "http://arxiv.org/pdf/2506.00282v1", "data_source_type": ["online auctions", "blockchain"], "data_source_name": ["Ethereum blockchain"], "fraud_type": "shill bidding in online auctions", "technical_approach_category": ["smart contracts", "behavior-based analysis", "economic disincentive system", "real-time prevention"], "technical_approach_method": ["Bid Shill Score (BSS)", "dynamic penalty mechanism"], "technical_approach_description": "A conceptual framework using blockchain smart contracts to apply dynamic, behavior-based penalties that deter auction fraud in real-time. The Bid Shill Score evaluates nine distinct bidding behaviors, with penalty severity scaling with suspicious patterns.", "innovation_points": "Real-time prevention of shill bidding through dynamic economic disincentives integrated into smart contracts, moving beyond traditional post-auction detection methods. Provides transparent auction enforcement without trusted intermediaries.", "github_repo": ""}
{"id": "2507.09385v1", "title": "Credit Card Fraud Detection Using RoFormer Model With Relative Distance Rotating Encoding", "authors": ["Kevin Reyes", "Vasco Cortez"], "abstract": "Fraud detection is one of the most important challenges that financial\nsystems must address. Detecting fraudulent transactions is critical for payment\ngateway companies like Flow Payment, which process millions of transactions\nmonthly and require robust security measures to mitigate financial risks.\nIncreasing transaction authorization rates while reducing fraud is essential\nfor providing a good user experience and building a sustainable business. For\nthis reason, discovering novel and improved methods to detect fraud requires\ncontinuous research and investment for any company that wants to succeed in\nthis industry. In this work, we introduced a novel method for detecting\ntransactional fraud by incorporating the Relative Distance Rotating Encoding\n(ReDRE) in the RoFormer model. The incorporation of angle rotation using ReDRE\nenhances the characterization of time series data within a Transformer, leading\nto improved fraud detection by better capturing temporal dependencies and event\nrelationships.", "categories": ["cs.NE", "cs.LG"], "published": "2025-07-12T20:02:02+00:00", "updated": "2025-07-12T20:02:02+00:00", "url": "http://arxiv.org/pdf/2507.09385v1", "data_source_type": ["payment"], "data_source_name": ["Flow Payment"], "fraud_type": "transactional fraud", "technical_approach_category": ["Transformer", "time series analysis"], "technical_approach_method": ["RoFormer", "Relative Distance Rotating Encoding (ReDRE)"], "technical_approach_description": "A novel method for detecting transactional fraud by incorporating Relative Distance Rotating Encoding (ReDRE) in the RoFormer model, which enhances the characterization of time series data within a Transformer to better capture temporal dependencies and event relationships.", "innovation_points": "Incorporation of Relative Distance Rotating Encoding (ReDRE) in the RoFormer model to enhance time series characterization and improve fraud detection by better capturing temporal dependencies.", "github_repo": ""}
{"id": "2507.04464v1", "title": "Anomalous Decision Discovery using Inverse Reinforcement Learning", "authors": ["Ashish Bastola", "Mert D. Pesé", "Long Cheng", "Jonathon Smereka", "Abolfazl Razi"], "abstract": "Anomaly detection plays a critical role in Autonomous Vehicles (AVs) by\nidentifying unusual behaviors through perception systems that could compromise\nsafety and lead to hazardous situations. Current approaches, which often rely\non predefined thresholds or supervised learning paradigms, exhibit reduced\nefficacy when confronted with unseen scenarios, sensor noise, and occlusions,\nleading to potential safety-critical failures. Moreover, supervised methods\nrequire large annotated datasets, limiting their real-world feasibility. To\naddress these gaps, we propose an anomaly detection framework based on Inverse\nReinforcement Learning (IRL) to infer latent driving intentions from sequential\nperception data, thus enabling robust identification. Specifically, we present\nTrajectory-Reward Guided Adaptive Pre-training (TRAP), a novel IRL framework\nfor anomaly detection, to address two critical limitations of existing methods:\nnoise robustness and generalization to unseen scenarios. Our core innovation is\nimplicitly learning temporal credit assignments via reward and worst-case\nsupervision. We leverage pre-training with variable-horizon sampling to\nmaximize time-to-consequence, resulting in early detection of behavior\ndeviation. Experiments on 14,000+ simulated trajectories demonstrate\nstate-of-the-art performance, achieving 0.90 AUC and 82.2\\% F1-score -\noutperforming similarly trained supervised and unsupervised baselines by 39\\%\non Recall and 12\\% on F1-score, respectively. Similar performance is achieved\nwhile exhibiting robustness to various noise types and generalization to unseen\nanomaly types. Our code will be available at:\nhttps://github.com/abastola0/TRAP.git", "categories": ["cs.AI"], "published": "2025-07-06T17:01:02+00:00", "updated": "2025-07-06T17:01:02+00:00", "url": "http://arxiv.org/pdf/2507.04464v1", "data_source_type": ["autonomous_vehicle_simulation"], "data_source_name": [], "fraud_type": "autonomous_vehicle_anomalous_behavior", "technical_approach_category": ["inverse_reinforcement_learning", "anomaly_detection", "temporal_modeling", "pre-training"], "technical_approach_method": ["Trajectory-Reward Guided Adaptive Pre-training (TRAP)", "Inverse Reinforcement Learning (IRL)", "variable-horizon sampling"], "technical_approach_description": "Proposes an IRL-based framework to infer latent driving intentions from sequential perception data for anomaly detection. Uses pre-training with variable-horizon sampling to maximize time-to-consequence for early detection of behavior deviations.", "innovation_points": "Implicitly learning temporal credit assignments via reward and worst-case supervision. Addresses critical limitations of noise robustness and generalization to unseen scenarios in existing methods.", "github_repo": "https://github.com/abastola0/TRAP.git"}
{"id": "2507.01924v1", "title": "Exploring a Hybrid Deep Learning Approach for Anomaly Detection in Mental Healthcare Provider Billing: Addressing Label Scarcity through Semi-Supervised Anomaly Detection", "authors": ["Samirah Bakker", "Yao Ma", "Seyed Sahand Mohammadi Ziabari"], "abstract": "The complexity of mental healthcare billing enables anomalies, including\nfraud. While machine learning methods have been applied to anomaly detection,\nthey often struggle with class imbalance, label scarcity, and complex\nsequential patterns. This study explores a hybrid deep learning approach\ncombining Long Short-Term Memory (LSTM) networks and Transformers, with\npseudo-labeling via Isolation Forests (iForest) and Autoencoders (AE). Prior\nwork has not evaluated such hybrid models trained on pseudo-labeled data in the\ncontext of healthcare billing. The approach is evaluated on two real-world\nbilling datasets related to mental healthcare. The iForest LSTM baseline\nachieves the highest recall (0.963) on declaration-level data. On the\noperation-level data, the hybrid iForest-based model achieves the highest\nrecall (0.744), though at the cost of lower precision. These findings highlight\nthe potential of combining pseudo-labeling with hybrid deep learning in\ncomplex, imbalanced anomaly detection settings.", "categories": ["cs.LG", "cs.AI"], "published": "2025-07-02T17:33:47+00:00", "updated": "2025-07-02T17:33:47+00:00", "url": "http://arxiv.org/pdf/2507.01924v1", "data_source_type": ["healthcare", "mental healthcare billing"], "data_source_name": [], "fraud_type": "mental healthcare provider billing anomalies and fraud", "technical_approach_category": ["semi-supervised learning", "deep learning", "anomaly detection", "hybrid models", "pseudo-labeling"], "technical_approach_method": ["Long Short-Term Memory (LSTM)", "Transformers", "Isolation Forests (iForest)", "Autoencoders (AE)"], "technical_approach_description": "A hybrid deep learning approach combining LSTM networks and Transformers with pseudo-labeling using Isolation Forests and Autoencoders for anomaly detection in mental healthcare billing data, addressing class imbalance and label scarcity.", "innovation_points": "Evaluates hybrid models trained on pseudo-labeled data in healthcare billing context, combining pseudo-labeling with hybrid deep learning for complex, imbalanced anomaly detection settings.", "github_repo": ""}
{"id": "2506.23446v2", "title": "User-Based Sequential Modeling with Transformer Encoders for Insider Threat Detection", "authors": ["Mohamed Elbasheer", "Adewale Akinfaderin"], "abstract": "Insider threat detection presents unique challenges due to the authorized\nstatus of malicious actors and the subtlety of anomalous behaviors. Existing\nmachine learning methods often treat user activity as isolated events, thereby\nfailing to leverage sequential dependencies in user behavior. In this study, we\npropose a User-Based Sequencing (UBS) methodology, transforming the CERT\ninsider threat dataset into structured temporal sequences suitable for deep\nsequential modeling. We deploy a Transformer Encoder architecture to model\nbenign user activity and employ its reconstruction errors as anomaly scores.\nThese scores are subsequently evaluated using three unsupervised outlier\ndetection algorithms: One-Class SVM (OCSVM), Local Outlier Factor (LOF), and\nIsolation Forest (iForest). Across four rigorously designed test sets,\nincluding combinations of multiple CERT dataset releases, our UBS-Transformer\npipeline consistently achieves state-of-the-art performance - notably 96.61%\naccuracy, 99.43% recall, 96.38% F1-score, 95.00% AUROC, and exceptionally low\nfalse negative (0.0057) and false positive (0.0571) rates. Comparative analyses\ndemonstrate that our approach substantially outperforms tabular and\nconventional autoencoder baselines, underscoring the efficacy of sequential\nuser modeling and advanced anomaly detection in the insider threat domain.", "categories": ["cs.LG"], "published": "2025-06-30T00:47:31+00:00", "updated": "2025-07-10T02:22:22+00:00", "url": "http://arxiv.org/pdf/2506.23446v2", "data_source_type": ["cybersecurity"], "data_source_name": ["CERT insider threat dataset"], "fraud_type": "insider threat detection", "technical_approach_category": ["transformer", "anomaly detection", "sequential modeling", "unsupervised learning"], "technical_approach_method": ["Transformer Encoder", "One-Class SVM (OCSVM)", "Local Outlier Factor (LOF)", "Isolation Forest (iForest)"], "technical_approach_description": "Proposes a User-Based Sequencing methodology to transform user activity data into temporal sequences, then uses a Transformer Encoder to model benign user activity and employs reconstruction errors as anomaly scores evaluated with unsupervised outlier detection algorithms.", "innovation_points": "User-Based Sequencing methodology for structured temporal sequences, Transformer Encoder architecture for modeling benign activity, and integration with unsupervised outlier detection algorithms that consistently achieves state-of-the-art performance across multiple test sets.", "github_repo": ""}
{"id": "2506.21382v1", "title": "Temporal-Aware Graph Attention Network for Cryptocurrency Transaction Fraud Detection", "authors": ["Zhi Zheng", "Bochuan Zhou", "Yuping Song"], "abstract": "Cryptocurrency transaction fraud detection faces the dual challenges of\nincreasingly complex transaction patterns and severe class imbalance.\nTraditional methods rely on manual feature engineering and struggle to capture\ntemporal and structural dependencies in transaction networks. This paper\nproposes an Augmented Temporal-aware Graph Attention Network (ATGAT) that\nenhances detection performance through three modules: (1) designing an advanced\ntemporal embedding module that fuses multi-scale time difference features with\nperiodic position encoding; (2) constructing a temporal-aware triple attention\nmechanism that jointly optimizes structural, temporal, and global context\nattention; (3) employing weighted BCE loss to address class imbalance.\nExperiments on the Elliptic++ cryptocurrency dataset demonstrate that ATGAT\nachieves an AUC of 0.9130, representing a 9.2% improvement over the best\ntraditional method XGBoost, 12.0% over GCN, and 10.0% over standard GAT. This\nmethod not only validates the enhancement effect of temporal awareness and\ntriple attention mechanisms on graph neural networks, but also provides\nfinancial institutions with more reliable fraud detection tools, with its\ndesign principles generalizable to other temporal graph anomaly detection\ntasks.", "categories": ["cs.LG", "cs.AI"], "published": "2025-06-26T15:34:06+00:00", "updated": "2025-06-26T15:34:06+00:00", "url": "http://arxiv.org/pdf/2506.21382v1", "data_source_type": ["cryptocurrency"], "data_source_name": ["Elliptic++"], "fraud_type": "cryptocurrency transaction fraud", "technical_approach_category": ["GNN", "temporal modeling", "attention mechanism", "anomaly detection", "class imbalance handling"], "technical_approach_method": ["Augmented Temporal-aware Graph Attention Network (ATGAT)", "temporal embedding module", "temporal-aware triple attention mechanism", "weighted BCE loss"], "technical_approach_description": "Proposes ATGAT with three modules: temporal embedding fusing multi-scale time difference features with periodic position encoding, temporal-aware triple attention mechanism for structural/temporal/global context, and weighted BCE loss for class imbalance.", "innovation_points": "Augmented Temporal-aware Graph Attention Network with advanced temporal embedding, temporal-aware triple attention mechanism, and weighted BCE loss to address complex transaction patterns and class imbalance.", "github_repo": ""}
{"id": "2508.09320v1", "title": "Exact Verification of Graph Neural Networks with Incremental Constraint Solving", "authors": ["Minghao Liu", "Chia-Hsuan Lu", "Marta Kwiatkowska"], "abstract": "Graph neural networks (GNNs) are increasingly employed in high-stakes\napplications, such as fraud detection or healthcare, but are susceptible to\nadversarial attacks. A number of techniques have been proposed to provide\nadversarial robustness guarantees, but support for commonly used aggregation\nfunctions in message-passing GNNs is still lacking. In this paper, we develop\nan exact (sound and complete) verification method for GNNs to compute\nguarantees against attribute and structural perturbations that involve edge\naddition or deletion, subject to budget constraints. Focusing on node\nclassification tasks, our method employs constraint solving with bound\ntightening, and iteratively solves a sequence of relaxed constraint\nsatisfaction problems while relying on incremental solving capabilities of\nsolvers to improve efficiency. We implement GNNev, a versatile solver for\nmessage-passing neural networks, which supports three aggregation functions,\nsum, max and mean, with the latter two considered here for the first time.\nExtensive experimental evaluation of GNNev on two standard benchmarks (Cora and\nCiteSeer) and two real-world fraud datasets (Amazon and Yelp) demonstrates its\nusability and effectiveness, as well as superior performance compared to\nexisting {exact verification} tools on sum-aggregated node classification\ntasks.", "categories": ["cs.LG", "cs.AI", "cs.CR"], "published": "2025-08-12T20:10:31+00:00", "updated": "2025-08-12T20:10:31+00:00", "url": "http://arxiv.org/pdf/2508.09320v1", "data_source_type": ["e-commerce", "review platform"], "data_source_name": ["Amazon", "Yelp"], "fraud_type": "node classification adversarial robustness", "technical_approach_category": ["constraint solving", "formal verification", "adversarial robustness", "graph neural networks"], "technical_approach_method": ["incremental constraint solving", "bound tightening", "constraint satisfaction problem solving"], "technical_approach_description": "Exact verification method for GNNs that computes guarantees against attribute and structural perturbations involving edge addition/deletion under budget constraints. Uses constraint solving with bound tightening and iteratively solves relaxed constraint satisfaction problems with incremental solving for efficiency.", "innovation_points": "First exact verification method supporting max and mean aggregation functions in message-passing GNNs, in addition to sum aggregation. Implements GNNev, a versatile solver that provides sound and complete verification for node classification tasks.", "github_repo": ""}
{"id": "2508.09237v1", "title": "Blockchain Network Analysis using Quantum Inspired Graph Neural Networks & Ensemble Models", "authors": ["Luigi D'Amico", "Daniel De Rosso", "Ninad Dixit", "Raul Salles de Padua", "Samuel Palmer", "Samuel Mugel", "Román Orús", "Holger Eble", "Ali Abedi"], "abstract": "In the rapidly evolving domain of financial technology, the detection of\nillicit transactions within blockchain networks remains a critical challenge,\nnecessitating robust and innovative solutions. This work proposes a novel\napproach by combining Quantum Inspired Graph Neural Networks (QI-GNN) with\nflexibility of choice of an Ensemble Model using QBoost or a classic model such\nas Random Forrest Classifier. This system is tailored specifically for\nblockchain network analysis in anti-money laundering (AML) efforts. Our\nmethodology to design this system incorporates a novel component, a Canonical\nPolyadic (CP) decomposition layer within the graph neural network framework,\nenhancing its capability to process and analyze complex data structures\nefficiently. Our technical approach has undergone rigorous evaluation against\nclassical machine learning implementations, achieving an F2 score of 74.8% in\ndetecting fraudulent transactions. These results highlight the potential of\nquantum-inspired techniques, supplemented by the structural advancements of the\nCP layer, to not only match but potentially exceed traditional methods in\ncomplex network analysis for financial security. The findings advocate for a\nbroader adoption and further exploration of quantum-inspired algorithms within\nthe financial sector to effectively combat fraud.", "categories": ["cs.LG", "quant-ph"], "published": "2025-08-12T12:11:43+00:00", "updated": "2025-08-12T12:11:43+00:00", "url": "http://arxiv.org/pdf/2508.09237v1", "data_source_type": ["blockchain"], "data_source_name": [], "fraud_type": "illicit transactions", "technical_approach_category": ["Graph Neural Networks", "quantum-inspired computing", "ensemble learning", "tensor decomposition"], "technical_approach_method": ["Quantum Inspired Graph Neural Networks (QI-GNN)", "QBoost", "Random Forest Classifier", "Canonical Polyadic (CP) decomposition"], "technical_approach_description": "Combines Quantum Inspired Graph Neural Networks with ensemble models (QBoost or Random Forest) for blockchain network analysis. Incorporates a Canonical Polyadic decomposition layer within the GNN framework to efficiently process complex data structures.", "innovation_points": "Novel approach combining QI-GNN with ensemble models, incorporating a CP decomposition layer within the GNN framework to enhance capability to process complex data structures efficiently.", "github_repo": ""}
{"id": "2508.05074v1", "title": "Align-for-Fusion: Harmonizing Triple Preferences via Dual-oriented Diffusion for Cross-domain Sequential Recommendation", "authors": ["Yongfu Zha", "Xinxin Dong", "Haokai Ma", "Yonghui Yang", "Xiaodong Wang"], "abstract": "Personalized sequential recommendation aims to predict appropriate items for\nusers based on their behavioral sequences. To alleviate data sparsity and\ninterest drift issues, conventional approaches typically incorporate auxiliary\nbehaviors from other domains via cross-domain transition. However, existing\ncross-domain sequential recommendation (CDSR) methods often follow an\nalign-then-fusion paradigm that performs representation-level alignment across\nmultiple domains and combines them mechanically for recommendation, overlooking\nthe fine-grained fusion of domain-specific preferences. Inspired by recent\nadvances in diffusion models (DMs) for distribution matching, we propose an\nalign-for-fusion framework for CDSR to harmonize triple preferences via\ndual-oriented DMs, termed HorizonRec. Specifically, we investigate the\nuncertainty injection of DMs and identify stochastic noise as a key source of\ninstability in existing DM-based recommenders. To address this, we introduce a\nmixed-conditioned distribution retrieval strategy that leverages distributions\nretrieved from users' authentic behavioral logic as semantic bridges across\ndomains, enabling consistent multi-domain preference modeling. Furthermore, we\npropose a dual-oriented preference diffusion method to suppress potential noise\nand emphasize target-relevant interests during multi-domain user representation\nfusion. Extensive experiments on four CDSR datasets from two distinct platforms\ndemonstrate the effectiveness and robustness of HorizonRec in fine-grained\ntriple-domain preference fusion.", "categories": ["cs.IR", "cs.AI"], "published": "2025-08-07T07:00:29+00:00", "updated": "2025-08-07T07:00:29+00:00", "url": "http://arxiv.org/pdf/2508.05074v1", "data_source_type": ["e-commerce", "online platform"], "data_source_name": [], "fraud_type": "cross-domain sequential recommendation", "technical_approach_category": ["diffusion models", "distribution matching", "multi-domain fusion", "representation learning", "preference modeling"], "technical_approach_method": ["dual-oriented diffusion", "mixed-conditioned distribution retrieval", "HorizonRec"], "technical_approach_description": "Proposes an align-for-fusion framework using dual-oriented diffusion models to harmonize triple preferences across domains for cross-domain sequential recommendation, addressing data sparsity and interest drift issues.", "innovation_points": "Introduces mixed-conditioned distribution retrieval strategy using authentic behavioral logic as semantic bridges across domains, and dual-oriented preference diffusion to suppress noise and emphasize target-relevant interests during multi-domain fusion.", "github_repo": ""}
{"id": "2508.05696v1", "title": "Log2Sig: Frequency-Aware Insider Threat Detection via Multivariate Behavioral Signal Decomposition", "authors": ["Kaichuan Kong", "Dongjie Liu", "Xiaobo Jin", "Zhiying Li", "Guanggang Geng"], "abstract": "Insider threat detection presents a significant challenge due to the\ndeceptive nature of malicious behaviors, which often resemble legitimate user\noperations. However, existing approaches typically model system logs as flat\nevent sequences, thereby failing to capture the inherent frequency dynamics and\nmultiscale disturbance patterns embedded in user behavior. To address these\nlimitations, we propose Log2Sig, a robust anomaly detection framework that\ntransforms user logs into multivariate behavioral frequency signals,\nintroducing a novel representation of user behavior. Log2Sig employs\nMultivariate Variational Mode Decomposition (MVMD) to extract Intrinsic Mode\nFunctions (IMFs), which reveal behavioral fluctuations across multiple temporal\nscales. Based on this, the model further performs joint modeling of behavioral\nsequences and frequency-decomposed signals: the daily behavior sequences are\nencoded using a Mamba-based temporal encoder to capture long-term dependencies,\nwhile the corresponding frequency components are linearly projected to match\nthe encoder's output dimension. These dual-view representations are then fused\nto construct a comprehensive user behavior profile, which is fed into a\nmultilayer perceptron for precise anomaly detection. Experimental results on\nthe CERT r4.2 and r5.2 datasets demonstrate that Log2Sig significantly\noutperforms state-of-the-art baselines in both accuracy and F1 score.", "categories": ["cs.CR", "cs.AI"], "published": "2025-08-06T18:47:26+00:00", "updated": "2025-08-06T18:47:26+00:00", "url": "http://arxiv.org/pdf/2508.05696v1", "data_source_type": ["system logs"], "data_source_name": ["CERT r4.2", "CERT r5.2"], "fraud_type": "insider threat", "technical_approach_category": ["anomaly detection", "signal processing", "temporal encoder", "multimodal fusion"], "technical_approach_method": ["Multivariate Variational Mode Decomposition (MVMD)", "Intrinsic Mode Functions (IMFs)", "Mamba-based temporal encoder", "multilayer perceptron"], "technical_approach_description": "Transforms user logs into multivariate behavioral frequency signals. Uses MVMD to extract IMFs revealing behavioral fluctuations across temporal scales. Jointly models behavioral sequences (with a Mamba encoder) and frequency-decomposed signals. Fuses these dual-view representations for anomaly detection.", "innovation_points": "Introduces a novel frequency-aware representation of user behavior. Proposes the Log2Sig framework that captures inherent frequency dynamics and multiscale disturbance patterns, overcoming limitations of modeling logs as flat event sequences.", "github_repo": ""}
{"id": "2508.05690v2", "title": "Leveraging large language models for SQL behavior-based database intrusion detection", "authors": ["Meital Shlezinger", "Shay Akirav", "Lei Zhou", "Liang Guo", "Avi Kessel", "Guoliang Li"], "abstract": "Database systems are extensively used to store critical data across various\ndomains. However, the frequency of abnormal database access behaviors, such as\ndatabase intrusion by internal and external attacks, continues to rise.\nInternal masqueraders often have greater organizational knowledge, making it\neasier to mimic employee behavior effectively. In contrast, external\nmasqueraders may behave differently due to their lack of familiarity with the\norganization. Current approaches lack the granularity needed to detect\nanomalies at the operational level, frequently misclassifying entire sequences\nof operations as anomalies, even though most operations are likely to represent\nnormal behavior. On the other hand, some anomalous behaviors often resemble\nnormal activities, making them difficult for existing detection methods to\nidentify. This paper introduces a two-tiered anomaly detection approach for\nStructured Query Language (SQL) using the Bidirectional Encoder Representations\nfrom Transformers (BERT) model, specifically DistilBERT, a more efficient,\npre-trained version. Our method combines both unsupervised and supervised\nmachine learning techniques to accurately identify anomalous activities while\nminimizing the need for data labeling. First, the unsupervised method uses\nensemble anomaly detectors that flag embedding vectors distant from learned\nnormal patterns of typical user behavior across the database (out-of-scope\nqueries). Second, the supervised method uses fine-tuned transformer-based\nmodels to detect internal attacks with high precision (in-scope queries), using\nrole-labeled classification, even on limited labeled SQL data. Our findings\nmake a significant contribution by providing an effective solution for\nsafeguarding critical database systems from sophisticated threats.", "categories": ["cs.CR", "cs.DB", "cs.LG"], "published": "2025-08-06T09:53:38+00:00", "updated": "2025-08-14T17:51:40+00:00", "url": "http://arxiv.org/pdf/2508.05690v2", "data_source_type": ["database"], "data_source_name": [], "fraud_type": "database intrusion", "technical_approach_category": ["anomaly detection", "unsupervised learning", "supervised learning", "transformer", "feature engineering"], "technical_approach_method": ["DistilBERT", "BERT", "ensemble anomaly detectors", "transformer-based models"], "technical_approach_description": "A two-tiered SQL anomaly detection approach using DistilBERT. Unsupervised ensemble detectors flag out-of-scope queries distant from normal user behavior patterns. Supervised fine-tuned transformer models detect internal attacks with high precision using role-labeled classification on limited labeled SQL data.", "innovation_points": "Combines unsupervised and supervised ML to accurately identify anomalous activities while minimizing data labeling needs. Provides granular detection at the operational level to distinguish between normal and anomalous SQL operations that resemble normal activities.", "github_repo": ""}
{"id": "2508.03484v1", "title": "Semantic-aware Graph-guided Behavior Sequences Generation with Large Language Models for Smart Homes", "authors": ["Zhiyao Xu", "Dan Zhao", "Qingsong Zou", "Qing Li", "Yong Jiang", "Yuhang Wang", "Jingyu Xiao"], "abstract": "As smart homes become increasingly prevalent, intelligent models are widely\nused for tasks such as anomaly detection and behavior prediction. These models\nare typically trained on static datasets, making them brittle to behavioral\ndrift caused by seasonal changes, lifestyle shifts, or evolving routines.\nHowever, collecting new behavior data for retraining is often impractical due\nto its slow pace, high cost, and privacy concerns. In this paper, we propose\nSmartGen, an LLM-based framework that synthesizes context-aware user behavior\ndata to support continual adaptation of downstream smart home models. SmartGen\nconsists of four key components. First, we design a Time and Semantic-aware\nSplit module to divide long behavior sequences into manageable, semantically\ncoherent subsequences under dual time-span constraints. Second, we propose\nSemantic-aware Sequence Compression to reduce input length while preserving\nrepresentative semantics by clustering behavior mapping in latent space. Third,\nwe introduce Graph-guided Sequence Synthesis, which constructs a behavior\nrelationship graph and encodes frequent transitions into prompts, guiding the\nLLM to generate data aligned with contextual changes while retaining core\nbehavior patterns. Finally, we design a Two-stage Outlier Filter to identify\nand remove implausible or semantically inconsistent outputs, aiming to improve\nthe factual coherence and behavioral validity of the generated sequences.\nExperiments on three real-world datasets demonstrate that SmartGen\nsignificantly enhances model performance on anomaly detection and behavior\nprediction tasks under behavioral drift, with anomaly detection improving by\n85.43% and behavior prediction by 70.51% on average. The code is available at\nhttps://github.com/horizonsinzqs/SmartGen.", "categories": ["cs.AI"], "published": "2025-08-05T14:16:10+00:00", "updated": "2025-08-05T14:16:10+00:00", "url": "http://arxiv.org/pdf/2508.03484v1", "data_source_type": ["smart home"], "data_source_name": [], "fraud_type": "anomaly detection in smart home behavior", "technical_approach_category": ["large language models", "sequence generation", "graph-based methods", "semantic analysis", "anomaly detection", "data synthesis"], "technical_approach_method": ["Time and Semantic-aware Split", "Semantic-aware Sequence Compression", "Graph-guided Sequence Synthesis", "Two-stage Outlier Filter"], "technical_approach_description": "LLM-based framework that synthesizes context-aware user behavior data to support continual adaptation of smart home models. It involves semantic-aware sequence splitting, compression, graph-guided synthesis with behavior relationship graphs, and outlier filtering to generate plausible behavior sequences.", "innovation_points": "Proposes SmartGen framework for generating synthetic smart home behavior data to address behavioral drift, using semantic-aware sequence processing and graph-guided LLM synthesis to maintain contextual alignment while preserving core behavior patterns.", "github_repo": "https://github.com/horizonsinzqs/SmartGen"}
{"id": "2508.03251v1", "title": "Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning", "authors": ["Osama Mohammed", "Jiaxin Pan", "Mojtaba Nayyeri", "Daniel Hernández", "Steffen Staab"], "abstract": "Modeling evolving interactions among entities is critical in many real-world\ntasks. For example, predicting driver maneuvers in traffic requires tracking\nhow neighboring vehicles accelerate, brake, and change lanes relative to one\nanother over consecutive frames. Likewise, detecting financial fraud hinges on\nfollowing the flow of funds through successive transactions as they propagate\nthrough the network. Unlike classic time-series forecasting, these settings\ndemand reasoning over who interacts with whom and when, calling for a\ntemporal-graph representation that makes both the relations and their evolution\nexplicit. Existing temporal-graph methods typically use snapshot graphs to\nencode temporal evolution. We introduce a full-history graph that instantiates\none node for every entity at every time step and separates two edge sets: (i)\nintra-time-step edges that capture relations within a single frame and (ii)\ninter-time-step edges that connect an entity to itself at consecutive steps. To\nlearn on this graph we design an Edge-Type Decoupled Network (ETDNet) with\nparallel modules: a graph-attention module aggregates information along\nintra-time-step edges, a multi-head temporal-attention module attends over an\nentity's inter-time-step history, and a fusion module combines the two messages\nafter every layer. Evaluated on driver-intention prediction (Waymo) and Bitcoin\nfraud detection (Elliptic++), ETDNet consistently surpasses strong baselines,\nlifting Waymo joint accuracy to 75.6\\% (vs. 74.1\\%) and raising Elliptic++\nillicit-class F1 to 88.1\\% (vs. 60.4\\%). These gains demonstrate the benefit of\nrepresenting structural and temporal relations as distinct edges in a single\ngraph.", "categories": ["cs.AI"], "published": "2025-08-05T09:29:07+00:00", "updated": "2025-08-05T09:29:07+00:00", "url": "http://arxiv.org/pdf/2508.03251v1", "data_source_type": ["autonomous driving", "cryptocurrency"], "data_source_name": ["Waymo", "Elliptic++"], "fraud_type": "Bitcoin fraud detection", "technical_approach_category": ["temporal graph networks", "graph attention", "temporal attention", "neural network architecture"], "technical_approach_method": ["Edge-Type Decoupled Network (ETDNet)", "graph-attention module", "multi-head temporal-attention module", "fusion module"], "technical_approach_description": "Introduces a full-history graph representation with separate intra-time-step and inter-time-step edge sets. ETDNet uses parallel modules: graph-attention for intra-time-step edges, temporal-attention for inter-time-step history, and a fusion module to combine messages after each layer.", "innovation_points": "A full-history graph that instantiates one node per entity per time step with two distinct edge sets. An Edge-Type Decoupled Network (ETDNet) with parallel modules to separately process structural and temporal relations as distinct edges in a single graph.", "github_repo": ""}
{"id": "2508.01422v1", "title": "AI-Driven Cybersecurity Threat Detection: Building Resilient Defense Systems Using Predictive Analytics", "authors": ["Biswajit Chandra Das", "M Saif Sartaz", "Syed Ali Reza", "Arat Hossain", "Md Nasiruddin", "Kanchon Kumar Bishnu", "Kazi Sharmin Sultana", "Sadia Sharmeen Shatyi", "MD Azam Khan", "Joynal Abed"], "abstract": "This study examines how Artificial Intelligence can aid in identifying and\nmitigating cyber threats in the U.S. across four key areas: intrusion\ndetection, malware classification, phishing detection, and insider threat\nanalysis. Each of these problems has its quirks, meaning there needs to be\ndifferent approaches to each, so we matched the models to the shape of the\nproblem. For intrusion detection, catching things like unauthorized access, we\ntested unsupervised anomaly detection methods. Isolation forests and deep\nautoencoders both gave us useful signals by picking up odd patterns in network\ntraffic. When it came to malware detection, we leaned on ensemble models like\nRandom Forest and XGBoost, trained on features pulled from files and traffic\nlogs. Phishing was more straightforward. We fed standard classifiers (logistic\nregression, Random Forest, XGBoost) a mix of email and web-based features.\nThese models handled the task surprisingly well. Phishing turned out to be the\neasiest problem to crack, at least with the data we had. There was a different\nstory. We utilized an LSTM autoencoder to identify behavioral anomalies in user\nactivity logs. It caught every suspicious behavior but flagged a lot of\nharmless ones too. That kind of model makes sense when the cost of missing a\nthreat is high and you are willing to sift through some noise. What we saw\nacross the board is that performance was not about stacking the most complex\nmodel. What mattered was how well the models structure matched the way the data\nbehaved. When signals were strong and obvious, simple models worked fine. But\nfor messier, more subtle threats, we needed something more adaptive, sequence\nmodels and anomaly detectors, though they brought their trade offs. The\ntakeaway here is clear in cybersecurity, context drives the solution.", "categories": ["cs.CR"], "published": "2025-08-02T16:03:35+00:00", "updated": "2025-08-02T16:03:35+00:00", "url": "http://arxiv.org/pdf/2508.01422v1", "data_source_type": ["network traffic", "file logs", "email", "web data", "user activity logs"], "data_source_name": [], "fraud_type": "cybersecurity threat detection", "technical_approach_category": ["anomaly detection", "ensemble learning", "deep learning", "sequence modeling", "predictive analytics"], "technical_approach_method": ["Isolation Forest", "Deep Autoencoder", "Random Forest", "XGBoost", "Logistic Regression", "LSTM Autoencoder"], "technical_approach_description": "The study employs different AI models tailored to specific cybersecurity problems: unsupervised anomaly detection for intrusion detection, ensemble models for malware classification, standard classifiers for phishing detection, and LSTM autoencoders for insider threat analysis based on behavioral anomalies.", "innovation_points": "The key innovation is demonstrating that cybersecurity solution performance depends on matching model structure to data behavior rather than using the most complex models, with context driving the appropriate technical approach for each threat type.", "github_repo": ""}
{"id": "2507.23267v1", "title": "Your Spending Needs Attention: Modeling Financial Habits with Transformers", "authors": ["D. T. Braithwaite", "Misael Cavalcanti", "R. Austin McEver", "Hiroto Udagawa", "Daniel Silva", "Rohan Ramanath", "Felipe Meneses", "Arissa Yoshida", "Evan Wingert", "Matheus Ramos", "Brian Zanfelice", "Aman Gupta"], "abstract": "Predictive models play a crucial role in the financial industry, enabling\nrisk prediction, fraud detection, and personalized recommendations, where\nslight changes in core model performance can result in billions of dollars in\nrevenue or losses. While financial institutions have access to enormous amounts\nof user data (e.g., bank transactions, in-app events, and customer support\nlogs), leveraging this data effectively remains challenging due to its\ncomplexity and scale. Thus, in many financial institutions, most production\nmodels follow traditional machine learning (ML) approaches by converting\nunstructured data into manually engineered tabular features. Conversely, other\ndomains (e.g., natural language processing) have effectively utilized\nself-supervised learning (SSL) to learn rich representations from raw data,\nremoving the need for manual feature extraction. In this paper, we investigate\nusing transformer-based representation learning models for transaction data,\nhypothesizing that these models, trained on massive data, can provide a novel\nand powerful approach to understanding customer behavior. We propose a new\nmethod enabling the use of SSL with transaction data by adapting\ntransformer-based models to handle both textual and structured attributes. Our\napproach, denoted nuFormer, includes an end-to-end fine-tuning method that\nintegrates user embeddings with existing tabular features. Our experiments\ndemonstrate improvements for large-scale recommendation problems at Nubank.\nNotably, these gains are achieved solely through enhanced representation\nlearning rather than incorporating new data sources.", "categories": ["cs.IR"], "published": "2025-07-31T05:56:21+00:00", "updated": "2025-07-31T05:56:21+00:00", "url": "http://arxiv.org/pdf/2507.23267v1", "data_source_type": ["banking", "financial services"], "data_source_name": ["Nubank"], "fraud_type": "risk prediction", "technical_approach_category": ["self-supervised learning", "transformer", "representation learning", "multimodal fusion"], "technical_approach_method": ["nuFormer", "transformer-based representation learning"], "technical_approach_description": "Proposes transformer-based models for financial transaction data that handle both textual and structured attributes using self-supervised learning, with an end-to-end fine-tuning method that integrates user embeddings with existing tabular features.", "innovation_points": "Novel approach enabling self-supervised learning with transaction data by adapting transformer-based models to handle both textual and structured attributes, providing enhanced representation learning without incorporating new data sources.", "github_repo": ""}
{"id": "2508.02702v1", "title": "Evaluating Transfer Learning Methods on Real-World Data Streams: A Case Study in Financial Fraud Detection", "authors": ["Ricardo Ribeiro Pereira", "Jacopo Bono", "Hugo Ferreira", "Pedro Ribeiro", "Carlos Soares", "Pedro Bizarro"], "abstract": "When the available data for a target domain is limited, transfer learning\n(TL) methods can be used to develop models on related data-rich domains, before\ndeploying them on the target domain. However, these TL methods are typically\ndesigned with specific, static assumptions on the amount of available labeled\nand unlabeled target data. This is in contrast with many real world\napplications, where the availability of data and corresponding labels varies\nover time. Since the evaluation of the TL methods is typically also performed\nunder the same static data availability assumptions, this would lead to\nunrealistic expectations concerning their performance in real world settings.\nTo support a more realistic evaluation and comparison of TL algorithms and\nmodels, we propose a data manipulation framework that (1) simulates varying\ndata availability scenarios over time, (2) creates multiple domains through\nresampling of a given dataset and (3) introduces inter-domain variability by\napplying realistic domain transformations, e.g., creating a variety of\npotentially time-dependent covariate and concept shifts. These capabilities\nenable simulation of a large number of realistic variants of the experiments,\nin turn providing more information about the potential behavior of algorithms\nwhen deployed in dynamic settings. We demonstrate the usefulness of the\nproposed framework by performing a case study on a proprietary real-world suite\nof card payment datasets. Given the confidential nature of the case study, we\nalso illustrate the use of the framework on the publicly available Bank Account\nFraud (BAF) dataset. By providing a methodology for evaluating TL methods over\ntime and in realistic data availability scenarios, our framework facilitates\nunderstanding of the behavior of models and algorithms. This leads to better\ndecision making when deploying models for new domains in real-world\nenvironments.", "categories": ["q-fin.ST", "cs.LG"], "published": "2025-07-29T14:12:21+00:00", "updated": "2025-07-29T14:12:21+00:00", "url": "http://arxiv.org/pdf/2508.02702v1", "data_source_type": ["payment", "banking"], "data_source_name": ["proprietary card payment datasets", "Bank Account Fraud (BAF)"], "fraud_type": "financial fraud detection", "technical_approach_category": ["transfer learning", "domain adaptation", "data simulation", "evaluation framework"], "technical_approach_method": ["transfer learning evaluation framework", "domain transformation methods"], "technical_approach_description": "Proposes a data manipulation framework that simulates varying data availability scenarios over time, creates multiple domains through resampling, and introduces inter-domain variability through realistic covariate and concept shifts for evaluating transfer learning methods.", "innovation_points": "A framework for realistic evaluation of transfer learning methods that simulates dynamic data availability scenarios over time and introduces realistic domain transformations, enabling better understanding of model behavior in real-world deployment environments.", "github_repo": ""}
{"id": "2507.19402v1", "title": "FD4QC: Application of Classical and Quantum-Hybrid Machine Learning for Financial Fraud Detection A Technical Report", "authors": ["Matteo Cardaioli", "Luca Marangoni", "Giada Martini", "Francesco Mazzolin", "Luca Pajola", "Andrea Ferretto Parodi", "Alessandra Saitta", "Maria Chiara Vernillo"], "abstract": "The increasing complexity and volume of financial transactions pose\nsignificant challenges to traditional fraud detection systems. This technical\nreport investigates and compares the efficacy of classical, quantum, and\nquantum-hybrid machine learning models for the binary classification of\nfraudulent financial activities.\n  As of our methodology, first, we develop a comprehensive behavioural feature\nengineering framework to transform raw transactional data into a rich,\ndescriptive feature set. Second, we implement and evaluate a range of models on\nthe IBM Anti-Money Laundering (AML) dataset. The classical baseline models\ninclude Logistic Regression, Decision Tree, Random Forest, and XGBoost. These\nare compared against three hybrid classic quantum algorithms architectures: a\nQuantum Support Vector Machine (QSVM), a Variational Quantum Classifier (VQC),\nand a Hybrid Quantum Neural Network (HQNN).\n  Furthermore, we propose Fraud Detection for Quantum Computing (FD4QC), a\npractical, API-driven system architecture designed for real-world deployment,\nfeaturing a classical-first, quantum-enhanced philosophy with robust fallback\nmechanisms.\n  Our results demonstrate that classical tree-based models, particularly\n\\textit{Random Forest}, significantly outperform the quantum counterparts in\nthe current setup, achieving high accuracy (\\(97.34\\%\\)) and F-measure\n(\\(86.95\\%\\)). Among the quantum models, \\textbf{QSVM} shows the most promise,\ndelivering high precision (\\(77.15\\%\\)) and a low false-positive rate\n(\\(1.36\\%\\)), albeit with lower recall and significant computational overhead.\n  This report provides a benchmark for a real-world financial application,\nhighlights the current limitations of quantum machine learning in this domain,\nand outlines promising directions for future research.", "categories": ["cs.LG", "cs.CE"], "published": "2025-07-25T16:08:22+00:00", "updated": "2025-07-25T16:08:22+00:00", "url": "http://arxiv.org/pdf/2507.19402v1", "data_source_type": ["banking", "financial services"], "data_source_name": ["IBM Anti-Money Laundering (AML)"], "fraud_type": "financial fraud detection", "technical_approach_category": ["feature engineering", "quantum machine learning", "hybrid classical-quantum systems", "binary classification"], "technical_approach_method": ["Logistic Regression", "Decision Tree", "Random Forest", "XGBoost", "Quantum Support Vector Machine (QSVM)", "Variational Quantum Classifier (VQC)", "Hybrid Quantum Neural Network (HQNN)"], "technical_approach_description": "Compares classical, quantum, and quantum-hybrid machine learning models for binary classification of fraudulent financial activities using behavioral feature engineering and evaluation on IBM AML dataset.", "innovation_points": "Proposes FD4QC, a practical API-driven system architecture with classical-first, quantum-enhanced philosophy and robust fallback mechanisms for real-world deployment.", "github_repo": ""}
{"id": "2507.11997v1", "title": "Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection", "authors": ["Tairan Huang", "Yili Wang"], "abstract": "Graph fraud detection has garnered significant attention as Graph Neural\nNetworks (GNNs) have proven effective in modeling complex relationships within\nmultimodal data. However, existing graph fraud detection methods typically use\npreprocessed node embeddings and predefined graph structures to reveal\nfraudsters, which ignore the rich semantic cues contained in raw textual\ninformation. Although Large Language Models (LLMs) exhibit powerful\ncapabilities in processing textual information, it remains a significant\nchallenge to perform multimodal fusion of processed textual embeddings with\ngraph structures. In this paper, we propose a \\textbf{M}ulti-level \\textbf{L}LM\n\\textbf{E}nhanced Graph Fraud \\textbf{D}etection framework called MLED. In\nMLED, we utilize LLMs to extract external knowledge from textual information to\nenhance graph fraud detection methods. To integrate LLMs with graph structure\ninformation and enhance the ability to distinguish fraudsters, we design a\nmulti-level LLM enhanced framework including type-level enhancer and\nrelation-level enhancer. One is to enhance the difference between the\nfraudsters and the benign entities, the other is to enhance the importance of\nthe fraudsters in different relations. The experiments on four real-world\ndatasets show that MLED achieves state-of-the-art performance in graph fraud\ndetection as a generalized framework that can be applied to existing methods.", "categories": ["cs.LG", "cs.AI"], "published": "2025-07-16T07:50:43+00:00", "updated": "2025-07-16T07:50:43+00:00", "url": "http://arxiv.org/pdf/2507.11997v1", "data_source_type": [], "data_source_name": [], "fraud_type": "graph fraud detection", "technical_approach_category": ["multimodal fusion", "GNN", "LLM", "knowledge extraction"], "technical_approach_method": ["Multi-level LLM Enhanced Graph Fraud Detection (MLED)", "type-level enhancer", "relation-level enhancer"], "technical_approach_description": "Proposes a multi-level LLM enhanced framework that extracts external knowledge from raw textual information using LLMs and integrates it with graph structure information through type-level and relation-level enhancers to improve fraudster detection in graph data.", "innovation_points": "Utilizes LLMs to extract semantic cues from raw textual information ignored by previous methods, designs a multi-level enhancement framework to integrate LLMs with graph structures, and demonstrates state-of-the-art performance as a generalized framework applicable to existing methods.", "github_repo": ""}
{"id": "2507.22908v1", "title": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection", "authors": ["Abhishek Sawaika", "Swetang Krishna", "Tushar Tomar", "Durga Pritam Suggisetti", "Aditi Lal", "Tanmaya Shrivastav", "Nouhaila Innan", "Muhammad Shafique"], "abstract": "Rapid growth of digital transactions has led to a surge in fraudulent\nactivities, challenging traditional detection methods in the financial sector.\nTo tackle this problem, we introduce a specialised federated learning framework\nthat uniquely combines a quantum-enhanced Long Short-Term Memory (LSTM) model\nwith advanced privacy preserving techniques. By integrating quantum layers into\nthe LSTM architecture, our approach adeptly captures complex\ncross-transactional patters, resulting in an approximate 5% performance\nimprovement across key evaluation metrics compared to conventional models.\nCentral to our framework is \"FedRansel\", a novel method designed to defend\nagainst poisoning and inference attacks, thereby reducing model degradation and\ninference accuracy by 4-8%, compared to standard differential privacy\nmechanisms. This pseudo-centralised setup with a Quantum LSTM model, enhances\nfraud detection accuracy and reinforces the security and confidentiality of\nsensitive financial data.", "categories": ["q-fin.CP", "cs.AI", "cs.LG", "I.2"], "published": "2025-07-15T17:29:12+00:00", "updated": "2025-07-15T17:29:12+00:00", "url": "http://arxiv.org/pdf/2507.22908v1", "data_source_type": ["financial"], "data_source_name": [], "fraud_type": "financial fraud", "technical_approach_category": ["federated learning", "quantum machine learning", "privacy preserving techniques", "LSTM", "anomaly detection"], "technical_approach_method": ["Quantum-enhanced Long Short-Term Memory (LSTM)", "FedRansel"], "technical_approach_description": "A federated learning framework that integrates quantum layers into an LSTM architecture to capture complex cross-transactional patterns for fraud detection, combined with privacy-preserving techniques to defend against attacks.", "innovation_points": "Unique combination of quantum-enhanced LSTM with privacy preserving techniques; FedRansel method defends against poisoning and inference attacks; achieves ~5% performance improvement and reduces model degradation/inference accuracy by 4-8% compared to standard differential privacy.", "github_repo": ""}
{"id": "2509.07392v1", "title": "Hybrid GCN-GRU Model for Anomaly Detection in Cryptocurrency Transactions", "authors": ["Gyuyeon Na", "Minjung Park", "Hyeonjeong Cha", "Soyoun Kim", "Sunyoung Moon", "Sua Lee", "Jaeyoung Choi", "Hyemin Lee", "Sangmi Chai"], "abstract": "Blockchain transaction networks are complex, with evolving temporal patterns\nand inter-node relationships. To detect illicit activities, we propose a hybrid\nGCN-GRU model that captures both structural and sequential features. Using real\nBitcoin transaction data (2020-2024), our model achieved 0.9470 Accuracy and\n0.9807 AUC-ROC, outperforming all baselines.", "categories": ["cs.LG", "cs.AI"], "published": "2025-09-09T05:14:26+00:00", "updated": "2025-09-09T05:14:26+00:00", "url": "http://arxiv.org/pdf/2509.07392v1", "data_source_type": ["cryptocurrency"], "data_source_name": ["Bitcoin"], "fraud_type": "illicit cryptocurrency transactions", "technical_approach_category": ["GNN", "RNN", "anomaly detection", "hybrid model"], "technical_approach_method": ["GCN", "GRU"], "technical_approach_description": "A hybrid GCN-GRU model that captures both structural relationships and sequential temporal patterns in blockchain transaction networks to detect illicit activities.", "innovation_points": "Proposes a hybrid model combining GCN and GRU to capture both structural and sequential features in cryptocurrency transaction networks for improved illicit activity detection.", "github_repo": ""}
{"id": "2509.03939v1", "title": "LMAE4Eth: Generalizable and Robust Ethereum Fraud Detection by Exploring Transaction Semantics and Masked Graph Embedding", "authors": ["Yifan Jia", "Yanbin Wang", "Jianguo Sun", "Ye Tian", "Peng Qian"], "abstract": "Current Ethereum fraud detection methods rely on context-independent,\nnumerical transaction sequences, failing to capture semantic of account\ntransactions. Furthermore, the pervasive homogeneity in Ethereum transaction\nrecords renders it challenging to learn discriminative account embeddings.\nMoreover, current self-supervised graph learning methods primarily learn node\nrepresentations through graph reconstruction, resulting in suboptimal\nperformance for node-level tasks like fraud account detection, while these\nmethods also encounter scalability challenges. To tackle these challenges, we\npropose LMAE4Eth, a multi-view learning framework that fuses transaction\nsemantics, masked graph embedding, and expert knowledge. We first propose a\ntransaction-token contrastive language model (TxCLM) that transforms\ncontext-independent numerical transaction records into logically cohesive\nlinguistic representations. To clearly characterize the semantic differences\nbetween accounts, we also use a token-aware contrastive learning pre-training\nobjective together with the masked transaction model pre-training objective,\nlearns high-expressive account representations. We then propose a masked\naccount graph autoencoder (MAGAE) using generative self-supervised learning,\nwhich achieves superior node-level account detection by focusing on\nreconstructing account node features. To enable MAGAE to scale for large-scale\ntraining, we propose to integrate layer-neighbor sampling into the graph, which\nreduces the number of sampled vertices by several times without compromising\ntraining quality. Finally, using a cross-attention fusion network, we unify the\nembeddings of TxCLM and MAGAE to leverage the benefits of both. We evaluate our\nmethod against 21 baseline approaches on three datasets. Experimental results\nshow that our method outperforms the best baseline by over 10% in F1-score on\ntwo of the datasets.", "categories": ["cs.CR", "cs.LG"], "published": "2025-09-04T06:56:32+00:00", "updated": "2025-09-04T06:56:32+00:00", "url": "http://arxiv.org/pdf/2509.03939v1", "data_source_type": ["blockchain"], "data_source_name": ["Ethereum"], "fraud_type": "Ethereum fraud account detection", "technical_approach_category": ["contrastive learning", "language model", "graph autoencoder", "self-supervised learning", "multi-view learning", "feature engineering"], "technical_approach_method": ["transaction-token contrastive language model (TxCLM)", "masked account graph autoencoder (MAGAE)", "layer-neighbor sampling", "cross-attention fusion network"], "technical_approach_description": "A multi-view learning framework that fuses transaction semantics and masked graph embedding. Uses TxCLM to transform numerical transaction records into linguistic representations and MAGAE for generative self-supervised learning to reconstruct account node features, unified via cross-attention fusion.", "innovation_points": "Captures transaction semantics through linguistic representations, uses token-aware contrastive learning with masked transaction modeling, proposes scalable masked graph autoencoder with layer-neighbor sampling, and integrates multi-view embeddings via cross-attention fusion.", "github_repo": ""}
{"id": "2509.03860v1", "title": "KGBERT4Eth: A Feature-Complete Transformer Powered by Knowledge Graph for Multi-Task Ethereum Fraud Detection", "authors": ["Yifan Jia", "Ye Tian", "Liguo Zhang", "Yanbin Wang", "Jianguo Sun", "Liangliang Song"], "abstract": "Ethereum's rapid ecosystem expansion and transaction anonymity have triggered\na surge in malicious activity. Detection mechanisms currently bifurcate into\nthree technical strands: expert-defined features, graph embeddings, and\nsequential transaction patterns, collectively spanning the complete feature\nsets of Ethereum's native data layer. Yet the absence of cross-paradigm\nintegration mechanisms forces practitioners to choose between sacrificing\nsequential context awareness, structured fund-flow patterns, or human-curated\nfeature insights in their solutions. To bridge this gap, we propose KGBERT4Eth,\na feature-complete pre-training encoder that synergistically combines two key\ncomponents: (1) a Transaction Semantic Extractor, where we train an enhanced\nTransaction Language Model (TLM) to learn contextual semantic representations\nfrom conceptualized transaction records, and (2) a Transaction Knowledge Graph\n(TKG) that incorporates expert-curated domain knowledge into graph node\nembeddings to capture fund flow patterns and human-curated feature insights. We\njointly optimize pre-training objectives for both components to fuse these\ncomplementary features, generating feature-complete embeddings. To emphasize\nrare anomalous transactions, we design a biased masking prediction task for TLM\nto focus on statistical outliers, while the Transaction TKG employs link\nprediction to learn latent transaction relationships and aggregate knowledge.\nFurthermore, we propose a mask-invariant attention coordination module to\nensure stable dynamic information exchange between TLM and TKG during\npre-training. KGBERT4Eth significantly outperforms state-of-the-art baselines\nin both phishing account detection and de-anonymization tasks, achieving\nabsolute F1-score improvements of 8-16% on three phishing detection benchmarks\nand 6-26% on four de-anonymization datasets.", "categories": ["cs.CR"], "published": "2025-09-04T03:38:11+00:00", "updated": "2025-09-04T03:38:11+00:00", "url": "http://arxiv.org/pdf/2509.03860v1", "data_source_type": ["cryptocurrency", "blockchain"], "data_source_name": ["Ethereum"], "fraud_type": "phishing account detection and de-anonymization", "technical_approach_category": ["Transformer", "knowledge graph", "pre-training", "multimodal fusion", "language model", "graph embeddings", "anomaly detection"], "technical_approach_method": ["KGBERT4Eth", "Transaction Language Model (TLM)", "Transaction Knowledge Graph (TKG)", "biased masking prediction", "link prediction", "mask-invariant attention coordination"], "technical_approach_description": "A feature-complete pre-training encoder that synergistically combines a Transaction Semantic Extractor (enhanced TLM for contextual semantic representations) and a Transaction Knowledge Graph (incorporating expert-curated domain knowledge) to fuse complementary features from sequential transaction patterns and structured fund-flow patterns.", "innovation_points": "Bridges the gap between three technical strands of Ethereum fraud detection by integrating sequential context awareness, structured fund-flow patterns, and human-curated feature insights through joint optimization of pre-training objectives and mask-invariant attention coordination module.", "github_repo": ""}
{"id": "2509.00931v2", "title": "Semi-Supervised Bayesian GANs with Log-Signatures for Uncertainty-Aware Credit Card Fraud Detection", "authors": ["David Hirnschall"], "abstract": "We present a novel deep generative semi-supervised framework for credit card\nfraud detection, formulated as time series classification task. As financial\ntransaction data streams grow in scale and complexity, traditional methods\noften require large labeled datasets, struggle with time series of irregular\nsampling frequencies and varying sequence lengths. To address these challenges,\nwe extend conditional Generative Adversarial Networks (GANs) for targeted data\naugmentation, integrate Bayesian inference to obtain predictive distributions\nand quantify uncertainty, and leverage log-signatures for robust feature\nencoding of transaction histories. We introduce a novel Wasserstein\ndistance-based loss to align generated and real unlabeled samples while\nsimultaneously maximizing classification accuracy on labeled data. Our approach\nis evaluated on the BankSim dataset, a widely used simulator for credit card\ntransaction data, under varying proportions of labeled samples, demonstrating\nconsistent improvements over benchmarks in both global statistical and\ndomain-specific metrics. These findings highlight the effectiveness of\nGAN-driven semi-supervised learning with log-signatures for irregularly sampled\ntime series and emphasize the importance of uncertainty-aware predictions.", "categories": ["stat.ML", "cs.LG"], "published": "2025-08-31T16:57:02+00:00", "updated": "2025-09-05T09:15:52+00:00", "url": "http://arxiv.org/pdf/2509.00931v2", "data_source_type": ["banking"], "data_source_name": ["BankSim"], "fraud_type": "credit card fraud", "technical_approach_category": ["GAN", "semi-supervised learning", "Bayesian inference", "time series analysis", "feature engineering", "uncertainty quantification"], "technical_approach_method": ["conditional Generative Adversarial Networks", "Bayesian GANs", "Wasserstein distance-based loss", "log-signatures"], "technical_approach_description": "A semi-supervised deep generative framework for credit card fraud detection using conditional GANs for targeted data augmentation, Bayesian inference for uncertainty quantification, and log-signatures for robust feature encoding of transaction histories with irregular sampling frequencies and varying sequence lengths.", "innovation_points": "Extends conditional GANs for targeted data augmentation, integrates Bayesian inference for predictive distributions and uncertainty quantification, leverages log-signatures for robust feature encoding, and introduces a novel Wasserstein distance-based loss to align generated and real unlabeled samples while maximizing classification accuracy.", "github_repo": ""}
{"id": "2508.20829v1", "title": "ATM-GAD: Adaptive Temporal Motif Graph Anomaly Detection for Financial Transaction Networks", "authors": ["Zeyue Zhang", "Lin Song", "Erkang Bao", "Xiaoling Lv", "Xinyue Wang"], "abstract": "Financial fraud detection is essential to safeguard billions of dollars, yet\nthe intertwined entities and fast-changing transaction behaviors in modern\nfinancial systems routinely defeat conventional machine learning models. Recent\ngraph-based detectors make headway by representing transactions as networks,\nbut they still overlook two fraud hallmarks rooted in time: (1) temporal\nmotifs--recurring, telltale subgraphs that reveal suspicious money flows as\nthey unfold--and (2) account-specific intervals of anomalous activity, when\nfraud surfaces only in short bursts unique to each entity. To exploit both\nsignals, we introduce ATM-GAD, an adaptive graph neural network that leverages\ntemporal motifs for financial anomaly detection. A Temporal Motif Extractor\ncondenses each account's transaction history into the most informative motifs,\npreserving both topology and temporal patterns. These motifs are then analyzed\nby dual-attention blocks: IntraA reasons over interactions within a single\nmotif, while InterA aggregates evidence across motifs to expose multi-step\nfraud schemes. In parallel, a differentiable Adaptive Time-Window Learner\ntailors the observation window for every node, allowing the model to focus\nprecisely on the most revealing time slices. Experiments on four real-world\ndatasets show that ATM-GAD consistently outperforms seven strong\nanomaly-detection baselines, uncovering fraud patterns missed by earlier\nmethods.", "categories": ["cs.LG"], "published": "2025-08-28T14:25:07+00:00", "updated": "2025-08-28T14:25:07+00:00", "url": "http://arxiv.org/pdf/2508.20829v1", "data_source_type": ["financial"], "data_source_name": [], "fraud_type": "financial fraud", "technical_approach_category": ["graph neural network", "anomaly detection", "temporal pattern analysis", "attention mechanism"], "technical_approach_method": ["Adaptive Temporal Motif Graph Anomaly Detection (ATM-GAD)", "Temporal Motif Extractor", "dual-attention blocks (IntraA, InterA)", "Adaptive Time-Window Learner"], "technical_approach_description": "A graph neural network that uses temporal motifs to detect financial anomalies. It extracts informative motifs from transaction histories, analyzes them with dual-attention blocks (intra-motif and inter-motif reasoning), and employs an adaptive time-window learner to tailor observation periods for each account.", "innovation_points": "Exploits two fraud hallmarks: temporal motifs (recurring suspicious subgraphs) and account-specific anomalous activity intervals. Introduces adaptive time-window learning to focus on the most revealing time slices for each entity.", "github_repo": ""}
{"id": "2508.11472v1", "title": "RMSL: Weakly-Supervised Insider Threat Detection with Robust Multi-sphere Learning", "authors": ["Yang Wang", "Yaxin Zhao", "Xinyu Jiao", "Sihan Xu", "Xiangrui Cai", "Ying Zhang", "Xiaojie Yuan"], "abstract": "Insider threat detection aims to identify malicious user behavior by\nanalyzing logs that record user interactions. Due to the lack of fine-grained\nbehavior-level annotations, detecting specific behavior-level anomalies within\nuser behavior sequences is challenging. Unsupervised methods face high false\npositive rates and miss rates due to the inherent ambiguity between normal and\nanomalous behaviors. In this work, we instead introduce weak labels of behavior\nsequences, which have lower annotation costs, i.e., the training labels\n(anomalous or normal) are at sequence-level instead of behavior-level, to\nenhance the detection capability for behavior-level anomalies by learning\ndiscriminative features. To achieve this, we propose a novel framework called\nRobust Multi-sphere Learning (RMSL). RMSL uses multiple hyper-spheres to\nrepresent the normal patterns of behaviors. Initially, a one-class classifier\nis constructed as a good anomaly-supervision-free starting point. Building on\nthis, using multiple instance learning and adaptive behavior-level\nself-training debiasing based on model prediction confidence, the framework\nfurther refines hyper-spheres and feature representations using weak\nsequence-level labels. This approach enhances the model's ability to\ndistinguish between normal and anomalous behaviors. Extensive experiments\ndemonstrate that RMSL significantly improves the performance of behavior-level\ninsider threat detection.", "categories": ["cs.CR", "cs.AI", "cs.LG"], "published": "2025-08-15T13:36:03+00:00", "updated": "2025-08-15T13:36:03+00:00", "url": "http://arxiv.org/pdf/2508.11472v1", "data_source_type": ["user behavior logs"], "data_source_name": [], "fraud_type": "insider threat detection", "technical_approach_category": ["weakly-supervised learning", "anomaly detection", "multiple instance learning", "self-training", "one-class classification"], "technical_approach_method": ["Robust Multi-sphere Learning (RMSL)", "multiple hyper-spheres representation", "adaptive behavior-level self-training debiasing"], "technical_approach_description": "Proposes RMSL framework that uses multiple hyper-spheres to represent normal behavior patterns. It starts with a one-class classifier, then refines hyper-spheres and feature representations using weak sequence-level labels through multiple instance learning and adaptive self-training debiasing based on prediction confidence.", "innovation_points": "Introduces weak sequence-level labels to enhance behavior-level anomaly detection, uses multiple hyper-spheres for normal pattern representation, and combines multiple instance learning with adaptive self-training debiasing to improve discrimination between normal and anomalous behaviors.", "github_repo": ""}
