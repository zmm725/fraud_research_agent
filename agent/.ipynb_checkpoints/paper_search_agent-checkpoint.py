# fraud_research_agent/agent/paper_search_agent.py

import itertools
from typing import List, Dict
from fraud_research_agent.agent.chain_builder import run_generate_queries_chain
from fraud_research_agent.tools.arxiv_tool import search_arxiv
from fraud_research_agent.utils.llm_utils import get_llm

def paper_search_agent(user_topic: str) -> List[Dict]:
    """
    é«˜å±‚å°è£…çš„è®ºæ–‡æœç´¢ Agentï¼š
    1. æ ¹æ®ç”¨æˆ·ä¸»é¢˜ç”Ÿæˆ query åˆ—è¡¨
    2. ç”¨ arxiv å·¥å…·é€ä¸ªæŠ“å–
    3. èšåˆç»“æœå¹¶å»é‡
    
    Args:
        user_topic (str): ç”¨æˆ·ç ”ç©¶ä¸»é¢˜ï¼Œæ¯”å¦‚ "fraud detection behavior sequence"
    
    Returns:
        List[Dict]: æŠ“å–åˆ°çš„è®ºæ–‡å…ƒæ•°æ®
    """
    # Step 1: ç”ŸæˆæŸ¥è¯¢åˆ—è¡¨
    llm = get_llm()
    queries = run_generate_queries_chain(user_topic, llm)
    print(f"ğŸ” ç”Ÿæˆ {len(queries)} ä¸ªæŸ¥è¯¢: {queries}")

    all_results = []

    # Step 2: é€ä¸ªæŸ¥è¯¢å¹¶æŠ“å–
    for i, q in enumerate(queries):
        print(f"\n=== æ‰§è¡Œæ£€ç´¢ query: {q} ===")
        file_name = "arxiv_results_%s.json".%str(i)
        results = search_arxiv(query=q, batch_size=50, file_name)
        all_results.extend(results)

    # Step 3: å»é‡ï¼ˆåŸºäºè®ºæ–‡ IDï¼‰
    seen = set()
    unique_results = []
    for paper in all_results:
        if paper["id"] not in seen:
            seen.add(paper["id"])
            unique_results.append(paper)

    print(f"\nğŸ“š æœ€ç»ˆè·å– {len(unique_results)} ç¯‡è®ºæ–‡ï¼ˆå»é‡åï¼‰")
    return unique_results


# ===========================
# ç¤ºä¾‹è°ƒç”¨
# ===========================

# if __name__ == "__main__":
#     papers = paper_search_agent("fraud detection behavior sequence")
#     print(f"\nç¤ºä¾‹è¾“å‡ºï¼š{papers[:2]}")  # æ‰“å°å‰ä¸¤ç¯‡çœ‹çœ‹
